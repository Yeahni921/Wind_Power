{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearnex import patch_sklearn, config_context\n",
    "patch_sklearn()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# custom functions\n",
    "import config\n",
    "from metric import NMAE\n",
    "from data_processor import WindTransformer, UVTransformer, FeatureTransformer\n",
    "\n",
    "# model import\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# logging\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    power = pd.read_parquet(config.input_path + \"dynamic_report_ewp02_2020_10min.parquet\").rename({'Date/Time': 'dt', 'WTG.Name': 'turbine_id'}, axis=1)\n",
    "    train_y = pd.read_parquet(config.input_path + \"train_y.parquet\").rename({'end_datetime': 'dt'}, axis=1)\n",
    "    ldaps = pd.read_parquet(config.input_path + \"train_ldaps_gyeongju.parquet\")\n",
    "\n",
    "    print(\"Power: \", power.shape)\n",
    "    print(\"train_y: \", train_y.shape)\n",
    "    print(\"LDAPS: \", ldaps.shape)\n",
    "\n",
    "    # data slicing\n",
    "    power = power[:-3]\n",
    "\n",
    "    datas = [power, train_y, ldaps]\n",
    "    #datas = [power, ldaps]\n",
    "    for d in datas:\n",
    "        try:\n",
    "            d['dt'] = (pd.to_datetime(d['dt'])\n",
    "                        .dt\n",
    "                        .tz_convert(\"Asia/Seoul\"))\n",
    "        except TypeError:\n",
    "            d['dt'] = (pd.to_datetime(d['dt'])\n",
    "                        .dt\n",
    "                        .tz_localize(\"Asia/Seoul\"))\n",
    "\n",
    "    train_y = (train_y.loc[(train_y['plant_name'] == \"경주풍력\")\n",
    "                          & (train_y['dt']).between('2020-01-01', '2022-01-01', inclusive='left')])\n",
    "\n",
    "    ldaps = ldaps.loc[ldaps['dt'].between('2020-01-01', '2022-01-01', inclusive='left')]\n",
    "\n",
    "    print(\"Power: \", power.shape, power['dt'].min(), power['dt'].max())\n",
    "    print(\"train_y: \", train_y.shape, train_y['dt'].min(), train_y['dt'].max())\n",
    "    print(\"LDAPS: \", ldaps.shape, ldaps['dt'].min(), ldaps['dt'].max())\n",
    "\n",
    "    return power, train_y, ldaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "0.2\n",
      "energy_kwh\n"
     ]
    }
   ],
   "source": [
    "print(config.mlflow)\n",
    "print(config.test_size)\n",
    "print(config.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power:  (52592, 29)\n",
      "train_y:  (52608, 4)\n",
      "LDAPS:  (235818, 15)\n",
      "Power:  (52589, 29) 2020-01-01 00:00:00+09:00 2020-12-31 23:50:00+09:00\n",
      "train_y:  (17543, 4) 2020-01-01 01:00:00+09:00 2021-12-31 23:00:00+09:00\n",
      "LDAPS:  (157671, 15) 2020-01-02 00:00:00+09:00 2021-12-31 23:00:00+09:00\n",
      "--------------------------------------------------\n",
      "Feature Engineering\n",
      "--------------------------------------------------\n",
      "Train Test Split\n",
      "(8760, 21) (8759, 21) (8760,) (8759,)\n",
      "--------------------------------------------------\n",
      "Train Model\n",
      "NMAE:  13.189758589095375\n"
     ]
    }
   ],
   "source": [
    "if config.mlflow:\n",
    "    # # create experiment\n",
    "    # exp = mlflow.set_experiment(\"windpower_experiment\")\n",
    "\n",
    "    # # start MLflow run\n",
    "    # with mlflow.start_run(experiment_id=exp.experiment_id):\n",
    "\n",
    "    #     # Train model\n",
    "    #     model = xgb.XGBRegressor()\n",
    "\n",
    "    #     # predict\n",
    "    #     y_pred = 0\n",
    "        \n",
    "    #     # Log model hyperparameters\n",
    "    #     mlflow.log_params(**config.xgb_params)\n",
    "\n",
    "    #     # Log performance metrics\n",
    "    #     mlflow.log_metrics({\n",
    "    #         \"R2 score\": r2_score(y_test, y_pred),\n",
    "    #         \"NMAE\": NMAE(y_test, y_pred)\n",
    "    #     })\n",
    "\n",
    "    #     # Log model\n",
    "    #     mlflow.sklearn.log_model(model, \"xgb\")\n",
    "    pass\n",
    "else:\n",
    "    # get data\n",
    "    scada, train_y, ldaps = get_data()\n",
    "\n",
    "    # build data pipeline\n",
    "    print('-' * 50)\n",
    "    print('Feature Engineering')\n",
    "    DataPipeline = Pipeline([\n",
    "        ('uv_transform', UVTransformer('wind_u_10m', 'wind_v_10m')),\n",
    "        ('wind_transform', WindTransformer('wind_speed', 10, 100, ldaps['surf_rough'].mean())),\n",
    "        ('feature engineering', FeatureTransformer())\n",
    "    ])\n",
    "\n",
    "    # data transform\n",
    "    ldaps = DataPipeline.fit_transform(ldaps)\n",
    "\n",
    "    # tmp = pd.merge(ldaps[ldaps['turbine_id'] == 'WTG01'], scada[['dt', 'EnergyProductionActiveEnergyProduction[KWh]']],\n",
    "    #            on = ['dt'])\n",
    "    # tmp.columns = tmp.columns.str.replace(\"[\", \"_\").str.replace(\"]\", \"\")\n",
    "\n",
    "    tmp = pd.merge(ldaps[ldaps['turbine_id'] == 'WTG01'], train_y[['dt', 'energy_kwh']])\n",
    "\n",
    "\n",
    "    # Split train valid\n",
    "    print('-' * 50)\n",
    "    print(\"Train Test Split\")\n",
    "    tmp = tmp.drop(['turbine_id'], axis=1)\n",
    "    # tmp = tmp.drop(['turbine_id', 'wind_speed'], axis=1)\n",
    "    target = config.target\n",
    "    x_train = tmp.loc[tmp['dt'].between('2020-01-01', '2021-01-01', inclusive='left')].drop(['dt', target], axis=1)\n",
    "    x_test = tmp.loc[tmp['dt'].between('2021-01-01', '2022-01-01', inclusive='left')].drop(['dt', target], axis=1)\n",
    "\n",
    "    y_train = tmp.loc[tmp['dt'].between('2020-01-01', '2021-01-01', inclusive='left'), target]# / 9\n",
    "    y_test = tmp.loc[tmp['dt'].between('2021-01-01', '2022-01-01', inclusive='left'), target]\n",
    "\n",
    "    print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "    # Train model\n",
    "    print('-' * 50)\n",
    "    print(\"Train Model\")\n",
    "    xgb = XGBRegressor(**config.xgb_params)\n",
    "    xgb.fit(x_train, y_train)\n",
    "\n",
    "    # predict\n",
    "    y_pred = xgb.predict(x_test)\n",
    "\n",
    "    # Scoring\n",
    "    print(\"NMAE: \", NMAE(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* dask transform -> 23.5s  \n",
    "* train_test split (각 1년씩)\n",
    "* 13.18975"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "windpower",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
