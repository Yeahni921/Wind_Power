{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearnex import patch_sklearn, config_context\n",
    "patch_sklearn()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# custom functions\n",
    "import config\n",
    "from utils import DataConnector\n",
    "from metric import NMAE\n",
    "from data_processor import WindTransformer, UVTransformer, FeatureTransformer\n",
    "\n",
    "# model import\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# logging\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_data():\n",
    "#     power = pd.read_parquet(config.input_path + \"dynamic_report_ewp02_2020_10min.parquet\").rename({'Date/Time': 'dt', 'WTG.Name': 'turbine_id'}, axis=1)\n",
    "#     train_y = pd.read_parquet(config.input_path + \"train_y.parquet\").rename({'end_datetime': 'dt'}, axis=1)\n",
    "#     ldaps = pd.read_parquet(config.input_path + \"train_ldaps_gyeongju.parquet\")\n",
    "\n",
    "#     # print(\"Power: \", power.shape)\n",
    "#     # print(\"train_y: \", train_y.shape)\n",
    "#     # print(\"LDAPS: \", ldaps.shape)\n",
    "\n",
    "#     # data slicing\n",
    "#     power = power[:-3]\n",
    "\n",
    "#     datas = [power, train_y, ldaps]\n",
    "#     #datas = [power, ldaps]\n",
    "#     for d in datas:\n",
    "#         try:\n",
    "#             d['dt'] = (pd.to_datetime(d['dt'])\n",
    "#                         .dt\n",
    "#                         .tz_convert(\"Asia/Seoul\"))\n",
    "#         except TypeError:\n",
    "#             d['dt'] = (pd.to_datetime(d['dt'])\n",
    "#                         .dt\n",
    "#                         .tz_localize(\"Asia/Seoul\"))\n",
    "\n",
    "#     train_y = (train_y.loc[(train_y['plant_name'] == \"경주풍력\")\n",
    "#                           & (train_y['dt']).between('2020-01-01', '2022-01-01', inclusive='left')])\n",
    "\n",
    "#     ldaps = ldaps.loc[ldaps['dt'].between('2020-01-01', '2022-01-01', inclusive='left')]\n",
    "\n",
    "#     print(\"Power: \", power.shape, power['dt'].min(), power['dt'].max())\n",
    "#     print(\"train_y: \", train_y.shape, train_y['dt'].min(), train_y['dt'].max())\n",
    "#     print(\"LDAPS: \", ldaps.shape, ldaps['dt'].min(), ldaps['dt'].max())\n",
    "\n",
    "#     return power, train_y, ldaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Simple Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.mlflow:\n",
    "    # # create experiment\n",
    "    # exp = mlflow.set_experiment(\"windpower_experiment\")\n",
    "\n",
    "    # # start MLflow run\n",
    "    # with mlflow.start_run(experiment_id=exp.experiment_id):\n",
    "\n",
    "    #     # Train model\n",
    "    #     model = xgb.XGBRegressor()\n",
    "\n",
    "    #     # predict\n",
    "    #     y_pred = 0\n",
    "        \n",
    "    #     # Log model hyperparameters\n",
    "    #     mlflow.log_params(**config.xgb_params)\n",
    "\n",
    "    #     # Log performance metrics\n",
    "    #     mlflow.log_metrics({\n",
    "    #         \"R2 score\": r2_score(y_test, y_pred),\n",
    "    #         \"NMAE\": NMAE(y_test, y_pred)\n",
    "    #     })\n",
    "\n",
    "    #     # Log model\n",
    "    #     mlflow.sklearn.log_model(model, \"xgb\")\n",
    "    pass\n",
    "else:\n",
    "    # get data\n",
    "    scada, train_y, ldaps = get_data()\n",
    "\n",
    "    # build data pipeline\n",
    "    print('-' * 50)\n",
    "    print('Feature Engineering')\n",
    "    DataPipeline = Pipeline([\n",
    "        ('uv_transform', UVTransformer('wind_u_10m', 'wind_v_10m')),\n",
    "        ('wind_transform', WindTransformer('wind_speed', 10, 100, ldaps['surf_rough'].mean())),\n",
    "        ('feature engineering', FeatureTransformer())\n",
    "    ])\n",
    "\n",
    "    # data transform\n",
    "    ldaps = DataPipeline.fit_transform(ldaps)\n",
    "\n",
    "    # tmp = pd.merge(ldaps[ldaps['turbine_id'] == 'WTG01'], scada[['dt', 'EnergyProductionActiveEnergyProduction[KWh]']],\n",
    "    #            on = ['dt'])\n",
    "    # tmp.columns = tmp.columns.str.replace(\"[\", \"_\").str.replace(\"]\", \"\")\n",
    "\n",
    "    tmp = pd.merge(ldaps[ldaps['turbine_id'] == 'WTG01'], train_y[['dt', 'energy_kwh']])\n",
    "\n",
    "\n",
    "    # Split train valid\n",
    "    print('-' * 50)\n",
    "    print(\"Train Test Split\")\n",
    "    tmp = tmp.drop(['turbine_id'], axis=1)\n",
    "    # tmp = tmp.drop(['turbine_id', 'wind_speed'], axis=1)\n",
    "    target = config.target\n",
    "    x_train = tmp.loc[tmp['dt'].between('2020-01-01', '2021-01-01', inclusive='left')].drop(['dt', target], axis=1)\n",
    "    x_test = tmp.loc[tmp['dt'].between('2021-01-01', '2022-01-01', inclusive='left')].drop(['dt', target], axis=1)\n",
    "\n",
    "    y_train = tmp.loc[tmp['dt'].between('2020-01-01', '2021-01-01', inclusive='left'), target]# / 9\n",
    "    y_test = tmp.loc[tmp['dt'].between('2021-01-01', '2022-01-01', inclusive='left'), target]\n",
    "\n",
    "    print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "    # Train model\n",
    "    print('-' * 50)\n",
    "    print(\"Train Model\")\n",
    "    xgb = XGBRegressor(**config.xgb_params)\n",
    "    xgb.fit(x_train, y_train)\n",
    "\n",
    "    # predict\n",
    "    y_pred = xgb.predict(x_test)\n",
    "\n",
    "    # Scoring\n",
    "    print(\"NMAE: \", NMAE(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* dask transform -> 23.5s  \n",
    "* train_test split (각 1년씩)\n",
    "* 13.18975"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Target 24h Shift + Simple Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET MLFLOW CONFIG\n",
    "target = config.target\n",
    "data_name = \"v1\" # data name\n",
    "artifact_path = 'baseline' # model name\n",
    "registered_model_name= 'tracking-test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Feature Engineering\n",
      "--------------------------------------------------\n",
      "Train Test Split\n",
      "(8760, 21) (8759, 21) (8760,) (8759,)\n",
      "--------------------------------------------------\n",
      "model runs & mlflow Logging...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/05 01:43:16 INFO mlflow.tracking.fluent: Experiment with name 'windpower_experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  22.45039329501389\n"
     ]
    }
   ],
   "source": [
    "if config.mlflow:\n",
    "    # get data\n",
    "    train_y, ldaps = DataConnector().get_data(start_date='2020-01-01',\n",
    "                                            end_date='2023-01-01',\n",
    "                                            plant_name='경주풍력')\n",
    "\n",
    "    # build data pipeline\n",
    "    print('-' * 50)\n",
    "    print('Feature Engineering')\n",
    "\n",
    "    DataPipeline = Pipeline([\n",
    "        ('uv_transform', UVTransformer('wind_u_10m', 'wind_v_10m')),\n",
    "        ('wind_transform', WindTransformer('wind_speed', 10, 100, ldaps['surf_rough'].mean())),\n",
    "        ('feature engineering', FeatureTransformer())\n",
    "    ])\n",
    "\n",
    "    # data transform\n",
    "    ldaps = DataPipeline.fit_transform(ldaps)\n",
    "\n",
    "    tmp = pd.merge(ldaps[ldaps['turbine_id'] == 'WTG01'], train_y[['dt', 'energy_kwh']])\n",
    "\n",
    "    # Split train valid\n",
    "    print('-' * 50)\n",
    "    print(\"Train Test Split\")\n",
    "    tmp = tmp.drop(['turbine_id'], axis=1)\n",
    "\n",
    "    # 24h shift\n",
    "    tmp['energy_kwh'] = tmp['energy_kwh'].shift(periods=-24)\n",
    "    tmp = tmp.dropna(axis=0)\n",
    "\n",
    "    target = config.target\n",
    "\n",
    "    train = tmp.loc[tmp['dt'].between('2020-01-01', '2021-01-01', inclusive='left')].drop(['dt'], axis=1)\n",
    "    test = tmp.loc[tmp['dt'].between('2021-01-01', '2022-01-01', inclusive='left')].drop(['dt'], axis=1)\n",
    "    \n",
    "    x_train, x_test = train.drop(target, axis=1), test.drop(target, axis=1)\n",
    "    y_train, y_test = train[target], test[target]\n",
    "\n",
    "    print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "    # MLFLOW\n",
    "    print('-' * 50)\n",
    "    print(\"model runs & mlflow Logging...\")\n",
    "\n",
    "    dataset = mlflow.data.from_pandas(\n",
    "        train, name=data_name, targets=config.target\n",
    "    )\n",
    "\n",
    "    signature = infer_signature(x_train, y_train)\n",
    "\n",
    "    # create experiment\n",
    "    exp = mlflow.set_experiment(\"windpower_experiment\")\n",
    "\n",
    "    # start MLflow run\n",
    "    with mlflow.start_run(experiment_id=exp.experiment_id):\n",
    "        # log input\n",
    "        mlflow.log_input(dataset, context=\"training\")\n",
    "\n",
    "        # Train model\n",
    "        model = xgb.XGBRegressor(random_state=1,\n",
    "                                 n_jobs=-1,\n",
    "                                 device='cuda',\n",
    "                                 objective='reg:absoluteerror',\n",
    "                                 eval_metric='mae',\n",
    "                                 **config.xgb_params)\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        # predict\n",
    "        y_pred = model.predict(x_test)\n",
    "        \n",
    "        # Log model hyperparameters\n",
    "        mlflow.log_params(config.xgb_params)\n",
    "\n",
    "        # Log performance metrics\n",
    "        mlflow.log_metrics({\n",
    "            \"eval_r2\": r2_score(y_test, y_pred),\n",
    "            \"eval_nmae\": NMAE(y_test, y_pred)\n",
    "        })\n",
    "\n",
    "        # Log model\n",
    "        mlflow.xgboost.log_model(artifact_path=artifact_path,\n",
    "                                 xgb_model=model,\n",
    "                                 signature=signature)\n",
    "        \n",
    "        \n",
    "        print(\"loss: \", NMAE(y_test, y_pred))\n",
    "\n",
    "else:\n",
    "    # get data\n",
    "    train_y, ldaps = DataConnector.get_data(start_date='2020-01-01',\n",
    "                                            end_date='2023-01-01',\n",
    "                                            plant_name='경주풍력')\n",
    "\n",
    "    # build data pipeline\n",
    "    print('-' * 50)\n",
    "    print('Feature Engineering')\n",
    "    DataPipeline = Pipeline([\n",
    "        ('uv_transform', UVTransformer('wind_u_10m', 'wind_v_10m')),\n",
    "        ('wind_transform', WindTransformer('wind_speed', 10, 100, ldaps['surf_rough'].mean())),\n",
    "        ('feature engineering', FeatureTransformer())\n",
    "    ])\n",
    "\n",
    "    # data transform\n",
    "    ldaps = DataPipeline.fit_transform(ldaps)\n",
    "\n",
    "    # tmp = pd.merge(ldaps[ldaps['turbine_id'] == 'WTG01'], scada[['dt', 'EnergyProductionActiveEnergyProduction[KWh]']],\n",
    "    #            on = ['dt'])\n",
    "    # tmp.columns = tmp.columns.str.replace(\"[\", \"_\").str.replace(\"]\", \"\")\n",
    "\n",
    "    tmp = pd.merge(ldaps[ldaps['turbine_id'] == 'WTG01'], train_y[['dt', 'energy_kwh']])\n",
    "\n",
    "\n",
    "    # Split train valid\n",
    "    print('-' * 50)\n",
    "    print(\"Train Test Split\")\n",
    "    tmp = tmp.drop(['turbine_id'], axis=1)\n",
    "\n",
    "    # 24h shift\n",
    "    tmp['energy_kwh'] = tmp['energy_kwh'].shift(periods=-24)\n",
    "    tmp = tmp.dropna(axis=0)\n",
    "\n",
    "    target = config.target\n",
    "    x_train = tmp.loc[tmp['dt'].between('2020-01-01', '2021-01-01', inclusive='left')].drop(['dt', target], axis=1)\n",
    "    x_test = tmp.loc[tmp['dt'].between('2021-01-01', '2022-01-01', inclusive='left')].drop(['dt', target], axis=1)\n",
    "\n",
    "    y_train = tmp.loc[tmp['dt'].between('2020-01-01', '2021-01-01', inclusive='left'), target]\n",
    "    y_test = tmp.loc[tmp['dt'].between('2021-01-01', '2022-01-01', inclusive='left'), target]\n",
    "\n",
    "    print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "    # Train model\n",
    "    print('-' * 50)\n",
    "    print(\"Train Model\")\n",
    "    xgb = XGBRegressor(config.xgb_params)\n",
    "    xgb.fit(x_train, y_train)\n",
    "\n",
    "    # predict\n",
    "    y_pred = xgb.predict(x_test)\n",
    "\n",
    "    # Scoring\n",
    "    print(\"NMAE: \", NMAE(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Time Series Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power:  (52592, 29)\n",
      "train_y:  (52608, 4)\n",
      "LDAPS:  (235818, 15)\n",
      "Power:  (52589, 29) 2020-01-01 00:00:00+09:00 2020-12-31 23:50:00+09:00\n",
      "train_y:  (17543, 4) 2020-01-01 01:00:00+09:00 2021-12-31 23:00:00+09:00\n",
      "LDAPS:  (157671, 15) 2020-01-02 00:00:00+09:00 2021-12-31 23:00:00+09:00\n",
      "--------------------------------------------------\n",
      "Feature Engineering\n",
      "--------------------------------------------------\n",
      "Train Test Split\n",
      "--------------------------------------------------\n",
      "Fold:  0\n",
      "(13199, 21) (720, 21) (13199,) (720,)\n",
      "--------------------------------------------------\n",
      "Train Model\n",
      "NMAE:  12.68159195131598\n",
      "--------------------------------------------------\n",
      "Fold:  1\n",
      "(13919, 21) (720, 21) (13919,) (720,)\n",
      "--------------------------------------------------\n",
      "Train Model\n",
      "NMAE:  13.22209786677866\n",
      "--------------------------------------------------\n",
      "Fold:  2\n",
      "(14639, 21) (720, 21) (14639,) (720,)\n",
      "--------------------------------------------------\n",
      "Train Model\n",
      "NMAE:  11.936203140497078\n",
      "--------------------------------------------------\n",
      "Fold:  3\n",
      "(15359, 21) (720, 21) (15359,) (720,)\n",
      "--------------------------------------------------\n",
      "Train Model\n",
      "NMAE:  14.030275296646616\n",
      "--------------------------------------------------\n",
      "Fold:  4\n",
      "(16079, 21) (720, 21) (16079,) (720,)\n",
      "--------------------------------------------------\n",
      "Train Model\n",
      "NMAE:  14.47133395659607\n",
      "Mean NMAE:  13.268300442366883\n"
     ]
    }
   ],
   "source": [
    "if config.mlflow:\n",
    "    # # create experiment\n",
    "    # exp = mlflow.set_experiment(\"windpower_experiment\")\n",
    "\n",
    "    # # start MLflow run\n",
    "    # with mlflow.start_run(experiment_id=exp.experiment_id):\n",
    "\n",
    "    #     # Train model\n",
    "    #     model = xgb.XGBRegressor()\n",
    "\n",
    "    #     # predict\n",
    "    #     y_pred = 0\n",
    "        \n",
    "    #     # Log model hyperparameters\n",
    "    #     mlflow.log_params(**config.xgb_params)\n",
    "\n",
    "    #     # Log performance metrics\n",
    "    #     mlflow.log_metrics({\n",
    "    #         \"R2 score\": r2_score(y_test, y_pred),\n",
    "    #         \"NMAE\": NMAE(y_test, y_pred)\n",
    "    #     })\n",
    "\n",
    "    #     # Log model\n",
    "    #     mlflow.sklearn.log_model(model, \"xgb\")\n",
    "    pass\n",
    "else:\n",
    "    # get data\n",
    "    scada, train_y, ldaps = get_data()\n",
    "\n",
    "    # build data pipeline\n",
    "    print('-' * 50)\n",
    "    print('Feature Engineering')\n",
    "    DataPipeline = Pipeline([\n",
    "        ('uv_transform', UVTransformer('wind_u_10m', 'wind_v_10m')),\n",
    "        ('wind_transform', WindTransformer('wind_speed', 10, 100, ldaps['surf_rough'].mean())),\n",
    "        ('feature engineering', FeatureTransformer())\n",
    "    ])\n",
    "\n",
    "    # data transform\n",
    "    ldaps = DataPipeline.fit_transform(ldaps)\n",
    "\n",
    "    # tmp = pd.merge(ldaps[ldaps['turbine_id'] == 'WTG01'], scada[['dt', 'EnergyProductionActiveEnergyProduction[KWh]']],\n",
    "    #            on = ['dt'])\n",
    "    # tmp.columns = tmp.columns.str.replace(\"[\", \"_\").str.replace(\"]\", \"\")\n",
    "\n",
    "    tmp = pd.merge(ldaps[ldaps['turbine_id'] == 'WTG01'], train_y[['dt', 'energy_kwh']])\n",
    "\n",
    "\n",
    "    # Split train valid\n",
    "    print('-' * 50)\n",
    "    print(\"Train Test Split\")\n",
    "    tmp = tmp.drop(['turbine_id', 'dt'], axis=1)\n",
    "\n",
    "    # # 24h shift\n",
    "    # tmp['energy_kwh'] = tmp['energy_kwh'].shift(periods=24)\n",
    "    # tmp = tmp.dropna(axis=0)\n",
    "\n",
    "    target = config.target\n",
    "    n_splits = 5\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits,  \n",
    "                           test_size=24*30, # test size는 하루? 아니면 그냥 길게?\n",
    "                           gap=24*30) # 한달의 gap\n",
    "\n",
    "\n",
    "    nmae_lists = []\n",
    "    idx = 0\n",
    "    for train_index, test_index in tscv.split(tmp):\n",
    "        train = tmp.iloc[train_index]\n",
    "        validate = tmp.iloc[test_index]\n",
    "\n",
    "        print('-' * 50)\n",
    "        print(\"Fold: \", idx)\n",
    "        x_train, y_train = train.drop(target, axis=1), train[target]\n",
    "        x_test, y_test = validate.drop(target, axis=1), validate[target]\n",
    "\n",
    "        print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "        # Train model\n",
    "        print('-' * 50)\n",
    "        print(\"Train Model\")\n",
    "        xgb = XGBRegressor(**config.xgb_params)\n",
    "        xgb.fit(x_train, y_train)\n",
    "\n",
    "        # predict\n",
    "        y_pred = xgb.predict(x_test)\n",
    "\n",
    "        # Scoring\n",
    "        print(\"NMAE: \", NMAE(y_test, y_pred))\n",
    "        nmae_lists.append(NMAE(y_test, y_pred))\n",
    "        idx += 1\n",
    "\n",
    "    print(\"Mean NMAE: \", np.mean(nmae_lists))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Target 24h Shift + Time Series Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power:  (52592, 29)\n",
      "train_y:  (52608, 4)\n",
      "LDAPS:  (235818, 15)\n",
      "Power:  (52589, 29) 2020-01-01 00:00:00+09:00 2020-12-31 23:50:00+09:00\n",
      "train_y:  (17543, 4) 2020-01-01 01:00:00+09:00 2021-12-31 23:00:00+09:00\n",
      "LDAPS:  (157671, 15) 2020-01-02 00:00:00+09:00 2021-12-31 23:00:00+09:00\n",
      "--------------------------------------------------\n",
      "Feature Engineering\n",
      "--------------------------------------------------\n",
      "Train Test Split\n",
      "--------------------------------------------------\n",
      "Fold:  0\n",
      "(13175, 21) (720, 21) (13175,) (720,)\n",
      "--------------------------------------------------\n",
      "Train Model\n",
      "NMAE:  18.619867066817456\n",
      "--------------------------------------------------\n",
      "Fold:  1\n",
      "(13895, 21) (720, 21) (13895,) (720,)\n",
      "--------------------------------------------------\n",
      "Train Model\n",
      "NMAE:  19.47732427927735\n",
      "--------------------------------------------------\n",
      "Fold:  2\n",
      "(14615, 21) (720, 21) (14615,) (720,)\n",
      "--------------------------------------------------\n",
      "Train Model\n",
      "NMAE:  21.969813565905863\n",
      "--------------------------------------------------\n",
      "Fold:  3\n",
      "(15335, 21) (720, 21) (15335,) (720,)\n",
      "--------------------------------------------------\n",
      "Train Model\n",
      "NMAE:  22.567667612156683\n",
      "--------------------------------------------------\n",
      "Fold:  4\n",
      "(16055, 21) (720, 21) (16055,) (720,)\n",
      "--------------------------------------------------\n",
      "Train Model\n",
      "NMAE:  23.411217049943208\n",
      "Mean NMAE:  21.20917791482011\n"
     ]
    }
   ],
   "source": [
    "if config.mlflow:\n",
    "    # # create experiment\n",
    "    # exp = mlflow.set_experiment(\"windpower_experiment\")\n",
    "\n",
    "    # # start MLflow run\n",
    "    # with mlflow.start_run(experiment_id=exp.experiment_id):\n",
    "\n",
    "    #     # Train model\n",
    "    #     model = xgb.XGBRegressor()\n",
    "\n",
    "    #     # predict\n",
    "    #     y_pred = 0\n",
    "        \n",
    "    #     # Log model hyperparameters\n",
    "    #     mlflow.log_params(**config.xgb_params)\n",
    "\n",
    "    #     # Log performance metrics\n",
    "    #     mlflow.log_metrics({\n",
    "    #         \"R2 score\": r2_score(y_test, y_pred),\n",
    "    #         \"NMAE\": NMAE(y_test, y_pred)\n",
    "    #     })\n",
    "\n",
    "    #     # Log model\n",
    "    #     mlflow.sklearn.log_model(model, \"xgb\")\n",
    "    pass\n",
    "else:\n",
    "    # get data\n",
    "    scada, train_y, ldaps = get_data()\n",
    "\n",
    "    # build data pipeline\n",
    "    print('-' * 50)\n",
    "    print('Feature Engineering')\n",
    "    DataPipeline = Pipeline([\n",
    "        ('uv_transform', UVTransformer('wind_u_10m', 'wind_v_10m')),\n",
    "        ('wind_transform', WindTransformer('wind_speed', 10, 100, ldaps['surf_rough'].mean())),\n",
    "        ('feature engineering', FeatureTransformer())\n",
    "    ])\n",
    "\n",
    "    # data transform\n",
    "    ldaps = DataPipeline.fit_transform(ldaps)\n",
    "\n",
    "    # tmp = pd.merge(ldaps[ldaps['turbine_id'] == 'WTG01'], scada[['dt', 'EnergyProductionActiveEnergyProduction[KWh]']],\n",
    "    #            on = ['dt'])\n",
    "    # tmp.columns = tmp.columns.str.replace(\"[\", \"_\").str.replace(\"]\", \"\")\n",
    "\n",
    "    tmp = pd.merge(ldaps[ldaps['turbine_id'] == 'WTG01'], train_y[['dt', 'energy_kwh']])\n",
    "\n",
    "\n",
    "    # Split train valid\n",
    "    print('-' * 50)\n",
    "    print(\"Train Test Split\")\n",
    "    tmp = tmp.drop(['turbine_id', 'dt'], axis=1)\n",
    "\n",
    "    # 24h shift\n",
    "    tmp['energy_kwh'] = tmp['energy_kwh'].shift(periods=-24)\n",
    "    tmp = tmp.dropna(axis=0)\n",
    "\n",
    "    target = config.target\n",
    "    n_splits = 5\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits,  \n",
    "                           test_size=24*30, # test size는 하루? 아니면 그냥 길게?\n",
    "                           gap=24*30) # 한달의 gap\n",
    "\n",
    "    nmae_lists = []\n",
    "    idx = 0\n",
    "    for train_index, test_index in tscv.split(tmp):\n",
    "        train = tmp.iloc[train_index]\n",
    "        validate = tmp.iloc[test_index]\n",
    "\n",
    "        print('-' * 50)\n",
    "        print(\"Fold: \", idx)\n",
    "        x_train, y_train = train.drop(target, axis=1), train[target]\n",
    "        x_test, y_test = validate.drop(target, axis=1), validate[target]\n",
    "\n",
    "        print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "        # Train model\n",
    "        print('-' * 50)\n",
    "        print(\"Train Model\")\n",
    "        xgb = XGBRegressor(**config.xgb_params)\n",
    "        xgb.fit(x_train, y_train)\n",
    "\n",
    "        # predict\n",
    "        y_pred = xgb.predict(x_test)\n",
    "\n",
    "        # Scoring\n",
    "        print(\"NMAE: \", NMAE(y_test, y_pred))\n",
    "        nmae_lists.append(NMAE(y_test, y_pred))\n",
    "        idx += 1\n",
    "\n",
    "    print(\"Mean NMAE: \", np.mean(nmae_lists))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정리\n",
    "(WTG01)\n",
    "* Simple Split: 13.189\n",
    "* Target 24h Shift + Simple Split: 21.711 \n",
    "* Time Series Split(5 Fold): 13.268 (average)\n",
    "* Target 24h Shift + Simple Split(5 Fold): 21.209 (average)\n",
    "\n",
    "(WTG02)  \n",
    "* Target 24h Shift + Simple Split: 21.5614\n",
    "\n",
    "([WTG01 + WTG02]/2)\n",
    "* Target 24h Shift + Simple Split: 21.2430"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "windpower",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
