{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearnex import patch_sklearn, config_context\n",
    "patch_sklearn()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "ipynb_path = os.getcwd()\n",
    "src_path = os.path.join(ipynb_path, 'src/')\n",
    "input_path = os.path.join(ipynb_path,\"input/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import scipy.stats as spst\n",
    "\n",
    "sys.path.append(src_path)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from windpowerlib.wind_speed import logarithmic_profile\n",
    "from src.utils import uv_to_wsd # 윈도우에서는 앞에 src를 뺄것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power:  (155528, 29)\n",
      "train_y:  (52608, 4)\n",
      "LDAPS:  (235818, 15)\n"
     ]
    }
   ],
   "source": [
    "power_2020 = pd.read_parquet(input_path + \"dynamic_report_ewp02_2020_10min.parquet\").rename({'Date/Time': 'dt', 'WTG.Name': 'turbine_id'}, axis=1)[:-3]\n",
    "power_2021 = pd.read_parquet(input_path + \"dynamic_report_ewp02_2021_10min.parquet\").rename({'Date/Time': 'dt', 'WTG.Name': 'turbine_id'}, axis=1)[:-3]\n",
    "power_2022 = pd.read_parquet(input_path + \"dynamic_report_ewp02_2022_10min.parquet\").rename({'Date/Time': 'dt', 'WTG.Name': 'turbine_id'}, axis=1)[:-3]\n",
    "power = pd.concat([power_2020, power_2021, power_2022], ignore_index=True)\n",
    "\n",
    "gj_y = pd.read_parquet(input_path + \"train_y.parquet\").rename({'end_datetime': 'dt'}, axis=1)\n",
    "ldaps = pd.read_parquet(input_path + \"train_ldaps_gyeongju.parquet\")\n",
    "\n",
    "print(\"Power: \", power.shape)\n",
    "print(\"train_y: \", gj_y.shape)\n",
    "print(\"LDAPS: \", ldaps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# yongmin's functions\n",
    "from src.utils import DataConnector\n",
    "from src.metric import NMAE\n",
    "from src.data_processor import *\n",
    "\n",
    "# model import\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(235818, 23)\n"
     ]
    }
   ],
   "source": [
    "# 파이프라인 구성 및 적용\n",
    "DataPipeline = Pipeline([\n",
    "    ('uv_transform', UVTransformer('wind_u_10m', 'wind_v_10m')),\n",
    "    ('wind_transform', WindTransformer('wind_speed', 10, 100, ldaps['surf_rough'].mean())),\n",
    "    ('feature_engineering', FeatureTransformer()),\n",
    "])\n",
    "\n",
    "# 파이프라인을 이용하여 ldaps 데이터 변환\n",
    "ldaps_transformed = DataPipeline.fit_transform(ldaps)\n",
    "\n",
    "print(ldaps_transformed.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_ldaps = ldaps_transformed.drop('turbine_id', axis=1).groupby('dt').mean()\n",
    "average_ldaps.columns = average_ldaps.columns.str.replace(r'[<>\\[\\]]', '_', regex=True)\n",
    "average_ldaps.columns = average_ldaps.columns.str.replace(r'[^\\w]', '_', regex=True)\n",
    "average_ldaps.columns = average_ldaps.columns.str.replace(r'__+', '_', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_ldaps.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_ldaps['dt'] = pd.to_datetime(average_ldaps['dt']).dt.tz_localize(None)\n",
    "gj_y['dt'] = pd.to_datetime(gj_y['dt']).dt.tz_localize(None)\n",
    "avg_data = pd.merge(average_ldaps, gj_y, on='dt', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_data_sorted = avg_data.sort_values(['dt', 'plant_name', 'energy_kwh'], ascending=[True, True, False])\n",
    "avg_data_cleaned = avg_data_sorted.drop_duplicates(subset=['dt', 'plant_name'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_data_cleaned = avg_data.drop_duplicates(subset=['dt'], keep='first')\n",
    "avg_data = avg_data_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "def get_trasforms_datas(merged_data, numeric_columns, target):\n",
    "    z_scaler = StandardScaler()\n",
    "    minmax_scaler = MinMaxScaler()\n",
    "    \n",
    "    x_train = merged_data.loc[merged_data['dt'].between('2020-01-01', '2020-12-31', inclusive='left'), numeric_columns]\n",
    "    x_test = merged_data.loc[merged_data['dt'].between('2021-01-01', '2022-12-31', inclusive='left'), numeric_columns]\n",
    "\n",
    "    y_train = merged_data.loc[merged_data['dt'].between('2020-01-01', '2020-12-31', inclusive='left'), target].shift(periods = -24)\n",
    "    y_test = merged_data.loc[merged_data['dt'].between('2021-01-01', '2022-12-31', inclusive='left'), target].shift(periods = -24)\n",
    "    #y_train = y_train.dropna()\n",
    "    #y_test = y_test.dropna()\n",
    "\n",
    "    x_train = x_train.iloc[:-24]\n",
    "    y_train = y_train.iloc[:-24]\n",
    "\n",
    "    x_test = x_test.iloc[:-24]\n",
    "    y_test = y_test.iloc[:-24]\n",
    "\n",
    "    # Min-Max Scaling\n",
    "    x_train_m = minmax_scaler.fit_transform(x_train)\n",
    "    x_train_m = pd.DataFrame(x_train_m, columns=x_train.columns)\n",
    "    x_test_m = minmax_scaler.transform(x_test)\n",
    "    x_test_m = pd.DataFrame(x_test_m, columns=x_train.columns)\n",
    "\n",
    "    # Standard Scaling\n",
    "    x_train_z = z_scaler.fit_transform(x_train)\n",
    "    x_train_z = pd.DataFrame(x_train_z, columns=x_train.columns)\n",
    "    x_test_z = z_scaler.transform(x_test)\n",
    "    x_test_z = pd.DataFrame(x_test_z, columns=x_train.columns)\n",
    "\n",
    "    return x_train, x_test, x_train_m, x_test_m, x_train_z, x_test_z, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# 이제 특징 생성에 클러스터링 결과는 보지 않을 예정.\n",
    "def addKmeansFeature(train_data, test_data):\n",
    "    pd.options.mode.chained_assignment = None\n",
    "\n",
    "    for n_clusters in range(2, 7):  # 2부터 6까지 클러스터 생성\n",
    "        kmeans = KMeans(n_clusters=n_clusters, n_init=10)\n",
    "\n",
    "        train_data[f'cluster_{n_clusters}'] = kmeans.fit_predict(train_data[['wind_speed', 'wind_direction']])\n",
    "        \n",
    "        test_data[f'cluster_{n_clusters}'] = kmeans.predict(test_data[['wind_speed', 'wind_direction']])\n",
    "\n",
    "    return train_data, test_data\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def addPCAFeature(train_data, test_data):\n",
    "    # PCA 적용할 특징 열 선택 (u, v 성분)\n",
    "    wind_features = ['storm_u_5m', 'storm_v_5m', 'wind_u_10m', 'wind_v_10m', \n",
    "                     'wind_speed', 'wind_direction']\n",
    "    \n",
    "    # 훈련 데이터에서 PCA 학습\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_train = pca.fit_transform(train_data[wind_features])\n",
    "    \n",
    "    # 훈련 데이터에 주성분 추가\n",
    "    train_data['PC1'] = pca_train[:, 0]\n",
    "    train_data['PC2'] = pca_train[:, 1]\n",
    "    \n",
    "    # 테스트 데이터에 PCA 적용\n",
    "    pca_test = pca.transform(test_data[wind_features])\n",
    "    test_data['PC1'] = pca_test[:, 0]\n",
    "    test_data['PC2'] = pca_test[:, 1]\n",
    "\n",
    "    # PCA 설명력 확인\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "    print(f\"PC1 설명력: {explained_variance[0]}\")\n",
    "    print(f\"PC2 설명력: {explained_variance[1]}\")\n",
    "\n",
    "    return train_data, test_data\n",
    "\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "\n",
    "def addKMedoidsFeature(train_data, test_data):\n",
    "    pd.options.mode.chained_assignment = None\n",
    "\n",
    "    for n_clusters in range(2, 7):  # 2부터 6까지 클러스터 생성\n",
    "        kmedoids = KMedoids(n_clusters=n_clusters, random_state=42)\n",
    "\n",
    "        # 훈련 데이터에 K-Medoids 클러스터링 적용\n",
    "        train_data[f'medoid_cluster_{n_clusters}'] = kmedoids.fit_predict(train_data[['wind_speed', 'wind_direction']])\n",
    "\n",
    "        # 테스트 데이터에 학습된 K-Medoids 모델 적용\n",
    "        test_data[f'medoid_cluster_{n_clusters}'] = kmedoids.predict(test_data[['wind_speed', 'wind_direction']])\n",
    "\n",
    "    return train_data, test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = avg_data.select_dtypes(include=['number']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, x_train_m, x_test_m, x_train_z, x_test_z, y_train, y_test = get_trasforms_datas(avg_data, numeric_columns, 'energy_kwh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmean 적용 완료\n",
      "PC1 설명력: 0.9982813596725464\n",
      "PC2 설명력: 0.0008244864293374121\n",
      "PC1 설명력: 0.7519216586247816\n",
      "PC2 설명력: 0.1166772803574429\n",
      "PC1 설명력: 0.3335494150013585\n",
      "PC2 설명력: 0.3287007000824763\n",
      "pca 적용 완료\n",
      "kmedoid 적용 완료\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test = addKmeansFeature(x_train, x_test)\n",
    "x_train_m, x_test_m = addKmeansFeature(x_train_m, x_test_m)\n",
    "x_train_z, x_test_z = addKmeansFeature(x_train_z, x_test_z)\n",
    "print('kmean 적용 완료')\n",
    "x_train, x_test = addPCAFeature(x_train, x_test)\n",
    "x_train_m, x_test_m = addPCAFeature(x_train_m, x_test_m)\n",
    "x_train_z, x_test_z = addPCAFeature(x_train_z, x_test_z)\n",
    "print('pca 적용 완료')\n",
    "\n",
    "x_train, x_test = addKMedoidsFeature(x_train, x_test)\n",
    "x_train_m, x_test_m = addKMedoidsFeature(x_train_m, x_test_m)\n",
    "x_train_z, x_test_z = addKMedoidsFeature(x_train_z, x_test_z)\n",
    "print('kmedoid 적용 완료')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dict = {\n",
    "    # 원본 데이터만 사용\n",
    "    'original': ['elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m', 'frictional_vmin_50m', \n",
    "                 'pressure', 'relative_humid', 'specific_humid', 'temp_air', 'storm_u_5m', 'storm_v_5m', \n",
    "                 'wind_u_10m', 'wind_v_10m', 'wind_speed', 'wind_direction', 'wind_speed_100m'],\n",
    "\n",
    "    # PCA 추가\n",
    "    'pca_only': ['elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m', 'frictional_vmin_50m', \n",
    "                 'pressure', 'relative_humid', 'specific_humid', 'temp_air', 'storm_u_5m', 'storm_v_5m', \n",
    "                 'wind_u_10m', 'wind_v_10m', 'wind_speed', 'wind_direction', 'wind_speed_100m', 'PC1', 'PC2'],\n",
    "\n",
    "    # 클러스터(2~6) 추가\n",
    "    'cluster_only': ['elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m', 'frictional_vmin_50m', \n",
    "                     'pressure', 'relative_humid', 'specific_humid', 'temp_air', 'storm_u_5m', 'storm_v_5m', \n",
    "                     'wind_u_10m', 'wind_v_10m', 'wind_speed', 'wind_direction', 'wind_speed_100m', \n",
    "                     'cluster_2', 'cluster_3', 'cluster_4', 'cluster_5', 'cluster_6'],\n",
    "\n",
    "    # PCA + 클러스터(2~6) 추가\n",
    "    'pca_and_cluster': ['elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m', 'frictional_vmin_50m', \n",
    "                        'pressure', 'relative_humid', 'specific_humid', 'temp_air', 'storm_u_5m', 'storm_v_5m', \n",
    "                        'wind_u_10m', 'wind_v_10m', 'wind_speed', 'wind_direction', 'wind_speed_100m', \n",
    "                        'PC1', 'PC2', 'cluster_2', 'cluster_3', 'cluster_4', 'cluster_5', 'cluster_6'],\n",
    "\n",
    "    # 클러스터 개수에 따른 경우\n",
    "    'cluster_2_only': ['elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m', 'frictional_vmin_50m', \n",
    "                       'pressure', 'relative_humid', 'specific_humid', 'temp_air', 'storm_u_5m', 'storm_v_5m', \n",
    "                       'wind_u_10m', 'wind_v_10m', 'wind_speed', 'wind_direction', 'wind_speed_100m', 'cluster_2'],\n",
    "    \n",
    "    'cluster_3_only': ['elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m', 'frictional_vmin_50m', \n",
    "                       'pressure', 'relative_humid', 'specific_humid', 'temp_air', 'storm_u_5m', 'storm_v_5m', \n",
    "                       'wind_u_10m', 'wind_v_10m', 'wind_speed', 'wind_direction', 'wind_speed_100m', 'cluster_3'],\n",
    "    \n",
    "    'cluster_4_only': ['elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m', 'frictional_vmin_50m', \n",
    "                       'pressure', 'relative_humid', 'specific_humid', 'temp_air', 'storm_u_5m', 'storm_v_5m', \n",
    "                       'wind_u_10m', 'wind_v_10m', 'wind_speed', 'wind_direction', 'wind_speed_100m', 'cluster_4'],\n",
    "    \n",
    "    'cluster_5_only': ['elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m', 'frictional_vmin_50m', \n",
    "                       'pressure', 'relative_humid', 'specific_humid', 'temp_air', 'storm_u_5m', 'storm_v_5m', \n",
    "                       'wind_u_10m', 'wind_v_10m', 'wind_speed', 'wind_direction', 'wind_speed_100m', 'cluster_5'],\n",
    "    \n",
    "    'cluster_6_only': ['elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m', 'frictional_vmin_50m', \n",
    "                       'pressure', 'relative_humid', 'specific_humid', 'temp_air', 'storm_u_5m', 'storm_v_5m', \n",
    "                       'wind_u_10m', 'wind_v_10m', 'wind_speed', 'wind_direction', 'wind_speed_100m', 'cluster_6'],\n",
    "\n",
    "    # KMedoids 추가\n",
    "    'kmedoids_only': ['elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m', 'frictional_vmin_50m', \n",
    "                      'pressure', 'relative_humid', 'specific_humid', 'temp_air', 'storm_u_5m', 'storm_v_5m', \n",
    "                      'wind_u_10m', 'wind_v_10m', 'wind_speed', 'wind_direction', 'wind_speed_100m', \n",
    "                      'medoid_cluster_2', 'medoid_cluster_3', 'medoid_cluster_4', 'medoid_cluster_5', 'medoid_cluster_6'],\n",
    "\n",
    "    # PCA + KMedoids 추가\n",
    "    'pca_and_kmedoids': ['elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m', 'frictional_vmin_50m', \n",
    "                         'pressure', 'relative_humid', 'specific_humid', 'temp_air', 'storm_u_5m', 'storm_v_5m', \n",
    "                         'wind_u_10m', 'wind_v_10m', 'wind_speed', 'wind_direction', 'wind_speed_100m', \n",
    "                         'PC1', 'PC2', 'medoid_cluster_2', 'medoid_cluster_3', 'medoid_cluster_4', 'medoid_cluster_5', 'medoid_cluster_6'],\n",
    "\n",
    "    # KMedoids 클러스터 개수에 따른 경우\n",
    "    'medoid_cluster_2_only': ['elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m', 'frictional_vmin_50m', \n",
    "                              'pressure', 'relative_humid', 'specific_humid', 'temp_air', 'storm_u_5m', 'storm_v_5m', \n",
    "                              'wind_u_10m', 'wind_v_10m', 'wind_speed', 'wind_direction', 'wind_speed_100m', 'medoid_cluster_2'],\n",
    "\n",
    "    'medoid_cluster_3_only': ['elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m', 'frictional_vmin_50m', \n",
    "                              'pressure', 'relative_humid', 'specific_humid', 'temp_air', 'storm_u_5m', 'storm_v_5m', \n",
    "                              'wind_u_10m', 'wind_v_10m', 'wind_speed', 'wind_direction', 'wind_speed_100m', 'medoid_cluster_3'],\n",
    "\n",
    "    'medoid_cluster_4_only': ['elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m', 'frictional_vmin_50m', \n",
    "                              'pressure', 'relative_humid', 'specific_humid', 'temp_air', 'storm_u_5m', 'storm_v_5m', \n",
    "                              'wind_u_10m', 'wind_v_10m', 'wind_speed', 'wind_direction', 'wind_speed_100m', 'medoid_cluster_4'],\n",
    "\n",
    "    'medoid_cluster_5_only': ['elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m', 'frictional_vmin_50m', \n",
    "                              'pressure', 'relative_humid', 'specific_humid', 'temp_air', 'storm_u_5m', 'storm_v_5m', \n",
    "                              'wind_u_10m', 'wind_v_10m', 'wind_speed', 'wind_direction', 'wind_speed_100m', 'medoid_cluster_5'],\n",
    "\n",
    "    'medoid_cluster_6_only': ['elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m', 'frictional_vmin_50m', \n",
    "                              'pressure', 'relative_humid', 'specific_humid', 'temp_air', 'storm_u_5m', 'storm_v_5m', \n",
    "                              'wind_u_10m', 'wind_v_10m', 'wind_speed', 'wind_direction', 'wind_speed_100m', 'medoid_cluster_6']\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.deepTrain_roughVer.Analysis_WindTurbine.Model.RNNs import RNN,LSTM,GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "def NMAE(y_true, y_pred):\n",
    "    \"\"\"NMAE 계산 함수.\"\"\"\n",
    "    return mean_absolute_error(y_true, y_pred) / (sum(abs(y_true)) / len(y_true)) * 100\n",
    "\n",
    "def train_model(save_dir, model, x_train, y_train, x_test, y_test, epochs=200, batch_size=30, lr=0.001):\n",
    "    if not torch.cuda.is_available():\n",
    "        raise RuntimeError(\"cuda is not available. Exiting...\")\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "\n",
    "    model = model.cuda()\n",
    "\n",
    "    x_train_tensor = torch.tensor(x_train.values, dtype=torch.float32).cuda()\n",
    "    y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1).cuda()\n",
    "    x_test_tensor = torch.tensor(x_test.values, dtype=torch.float32).cuda()\n",
    "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1).cuda()\n",
    "\n",
    "    train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "    test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_y_pred_list = []\n",
    "    best_y_true_list = []\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    csv_data = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        y_pred_list = []\n",
    "        y_true_list = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in test_loader:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "                outputs = model(inputs)\n",
    "                val_loss += criterion(outputs, targets).item()\n",
    "                y_pred_list.extend(outputs.cpu().numpy())\n",
    "                y_true_list.extend(targets.cpu().numpy())\n",
    "\n",
    "        y_pred_list = np.array(y_pred_list).flatten()\n",
    "        y_true_list = np.array(y_true_list).flatten()\n",
    "\n",
    "        mae = mean_absolute_error(y_true_list, y_pred_list)\n",
    "        nmae = NMAE(y_true_list, y_pred_list)\n",
    "        r2 = r2_score(y_true_list, y_pred_list)\n",
    "\n",
    "        train_losses.append(train_loss / len(train_loader))\n",
    "        val_losses.append(val_loss / len(test_loader))\n",
    "\n",
    "        csv_data.append([epoch + 1, train_loss / len(train_loader), val_loss / len(test_loader), mae, nmae, r2])\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_y_pred_list = y_pred_list\n",
    "            best_y_true_list = y_true_list\n",
    "            torch.save(model.state_dict(), os.path.join(save_dir, f\"{model.__class__.__name__}_best_model.pth\"))\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            torch.save(model.state_dict(), os.path.join(save_dir, f\"{model.__class__.__name__}_epoch_{epoch+1}.pth\"))\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "        print(f\"Train Loss: {train_loss/len(train_loader):.4f}\")\n",
    "        print(f\"Val Loss: {val_loss/len(test_loader):.4f}, MAE: {mae:.4f}, NMAE: {nmae:.4f}, R^2: {r2:.4f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), os.path.join(save_dir, f\"{model.__class__.__name__}_final_model.pth\"))\n",
    "\n",
    "    df = pd.DataFrame(csv_data, columns=[\"Epoch\", \"Train Loss\", \"Val Loss\", \"MAE\", \"NMAE\", \"R2\"])\n",
    "    df.to_csv(os.path.join(save_dir, \"training_log.csv\"), index=False)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(range(epochs), train_losses, label=\"Train Loss\")\n",
    "    plt.plot(range(epochs), val_losses, label=\"Val Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Loss plot\")\n",
    "    plt.savefig(os.path.join(save_dir, \"loss_plot.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(best_y_true_list, label=\"ground truth\")\n",
    "    plt.plot(best_y_pred_list, label=\"Pred\")\n",
    "    plt.xlabel(\"Samples\")\n",
    "    plt.ylabel(\"Values\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Pred and Truth Compare\")\n",
    "    plt.savefig(os.path.join(save_dir, \"best_pred_plot.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Log final performance\n",
    "    with open(os.path.join(save_dir, \"training_log.txt\"), \"w\") as f:\n",
    "        f.write(f\"Final Validation Loss: {best_val_loss:.4f}\\n\")\n",
    "        f.write(f\"MAE: {mae:.4f}, NMAE: {nmae:.4f}, R^2: {r2:.4f}\\n\")\n",
    "        f.write(f\"devide capacity => MAE/20700: {(mae/20700):.4f}, MAE/79600: {(mae/79600):.4f}\")\n",
    "\n",
    "    print(f\"Final Model saved with best validation loss: {best_val_loss:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}, NMAE: {nmae:.4f}, R^2: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2000]\n",
      "Train Loss: 85511134.2591\n",
      "Val Loss: 79098009.1164, MAE: 6528.5283, NMAE: 99.5328, R^2: -1.1638\n",
      "Epoch [2/2000]\n",
      "Train Loss: 85036494.5830\n",
      "Val Loss: 78673838.6599, MAE: 6502.4180, NMAE: 99.1347, R^2: -1.1522\n",
      "Epoch [3/2000]\n",
      "Train Loss: 84589209.4114\n",
      "Val Loss: 78261422.0663, MAE: 6477.5381, NMAE: 98.7554, R^2: -1.1410\n",
      "Epoch [4/2000]\n",
      "Train Loss: 84152791.2271\n",
      "Val Loss: 77856744.9660, MAE: 6453.5078, NMAE: 98.3890, R^2: -1.1299\n",
      "Epoch [5/2000]\n",
      "Train Loss: 83723354.5481\n",
      "Val Loss: 77457558.1315, MAE: 6430.1758, NMAE: 98.0333, R^2: -1.1190\n",
      "Epoch [6/2000]\n",
      "Train Loss: 83299070.7011\n",
      "Val Loss: 77062744.6563, MAE: 6407.4189, NMAE: 97.6864, R^2: -1.1082\n",
      "Epoch [7/2000]\n",
      "Train Loss: 82879007.2699\n",
      "Val Loss: 76671678.2096, MAE: 6385.0996, NMAE: 97.3461, R^2: -1.0975\n",
      "Epoch [8/2000]\n",
      "Train Loss: 82462623.8441\n",
      "Val Loss: 76283982.7792, MAE: 6363.2275, NMAE: 97.0126, R^2: -1.0869\n",
      "Epoch [9/2000]\n",
      "Train Loss: 82049578.7545\n",
      "Val Loss: 75899395.9374, MAE: 6341.7729, NMAE: 96.6855, R^2: -1.0763\n",
      "Epoch [10/2000]\n",
      "Train Loss: 81639637.1591\n",
      "Val Loss: 75517741.3961, MAE: 6320.6929, NMAE: 96.3641, R^2: -1.0659\n",
      "Epoch [11/2000]\n",
      "Train Loss: 81232636.6476\n",
      "Val Loss: 75138879.7298, MAE: 6299.9434, NMAE: 96.0478, R^2: -1.0555\n",
      "Epoch [12/2000]\n",
      "Train Loss: 80828454.6902\n",
      "Val Loss: 74762735.9492, MAE: 6279.5693, NMAE: 95.7372, R^2: -1.0452\n",
      "Epoch [13/2000]\n",
      "Train Loss: 80427000.8040\n",
      "Val Loss: 74389220.6210, MAE: 6259.5527, NMAE: 95.4320, R^2: -1.0350\n",
      "Epoch [14/2000]\n",
      "Train Loss: 80028205.0144\n",
      "Val Loss: 74018273.1124, MAE: 6239.8574, NMAE: 95.1317, R^2: -1.0249\n",
      "Epoch [15/2000]\n",
      "Train Loss: 79632013.1897\n",
      "Val Loss: 73649861.8476, MAE: 6220.4731, NMAE: 94.8362, R^2: -1.0148\n",
      "Epoch [16/2000]\n",
      "Train Loss: 79238382.2083\n",
      "Val Loss: 73283938.4171, MAE: 6201.3643, NMAE: 94.5449, R^2: -1.0048\n",
      "Epoch [17/2000]\n",
      "Train Loss: 78847280.4319\n",
      "Val Loss: 72920487.5473, MAE: 6182.5244, NMAE: 94.2577, R^2: -0.9948\n",
      "Epoch [18/2000]\n",
      "Train Loss: 78458676.2195\n",
      "Val Loss: 72559466.2443, MAE: 6163.9600, NMAE: 93.9746, R^2: -0.9850\n",
      "Epoch [19/2000]\n",
      "Train Loss: 78072546.9796\n",
      "Val Loss: 72200874.9827, MAE: 6145.6660, NMAE: 93.6957, R^2: -0.9752\n",
      "Epoch [20/2000]\n",
      "Train Loss: 77688885.7616\n",
      "Val Loss: 71844699.7027, MAE: 6127.6323, NMAE: 93.4208, R^2: -0.9654\n",
      "Epoch [21/2000]\n",
      "Train Loss: 77307670.9242\n",
      "Val Loss: 71490914.6019, MAE: 6109.8950, NMAE: 93.1504, R^2: -0.9557\n",
      "Epoch [22/2000]\n",
      "Train Loss: 76928892.3765\n",
      "Val Loss: 71139509.4485, MAE: 6092.4463, NMAE: 92.8843, R^2: -0.9461\n",
      "Epoch [23/2000]\n",
      "Train Loss: 76552537.9018\n",
      "Val Loss: 70790484.3064, MAE: 6075.2632, NMAE: 92.6224, R^2: -0.9366\n",
      "Epoch [24/2000]\n",
      "Train Loss: 76178597.0127\n",
      "Val Loss: 70443822.1428, MAE: 6058.3491, NMAE: 92.3645, R^2: -0.9271\n",
      "Epoch [25/2000]\n",
      "Train Loss: 75807062.4488\n",
      "Val Loss: 70099516.9321, MAE: 6041.6553, NMAE: 92.1100, R^2: -0.9177\n",
      "Epoch [26/2000]\n",
      "Train Loss: 75437921.6156\n",
      "Val Loss: 69757556.5356, MAE: 6025.1689, NMAE: 91.8586, R^2: -0.9083\n",
      "Epoch [27/2000]\n",
      "Train Loss: 75071174.5724\n",
      "Val Loss: 69417938.2458, MAE: 6008.9009, NMAE: 91.6106, R^2: -0.8990\n",
      "Epoch [28/2000]\n",
      "Train Loss: 74706807.4276\n",
      "Val Loss: 69080654.4409, MAE: 5992.8799, NMAE: 91.3664, R^2: -0.8898\n",
      "Epoch [29/2000]\n",
      "Train Loss: 74344820.8252\n",
      "Val Loss: 68745701.7023, MAE: 5977.0806, NMAE: 91.1255, R^2: -0.8806\n",
      "Epoch [30/2000]\n",
      "Train Loss: 73985208.7247\n",
      "Val Loss: 68413082.3905, MAE: 5961.4902, NMAE: 90.8878, R^2: -0.8715\n",
      "Epoch [31/2000]\n",
      "Train Loss: 73627970.7586\n",
      "Val Loss: 68082778.2639, MAE: 5946.1377, NMAE: 90.6537, R^2: -0.8625\n",
      "Epoch [32/2000]\n",
      "Train Loss: 73273088.5976\n",
      "Val Loss: 67754788.6550, MAE: 5931.0059, NMAE: 90.4231, R^2: -0.8535\n",
      "Epoch [33/2000]\n",
      "Train Loss: 72920570.5019\n",
      "Val Loss: 67429111.9287, MAE: 5916.0972, NMAE: 90.1958, R^2: -0.8446\n",
      "Epoch [34/2000]\n",
      "Train Loss: 72570410.4278\n",
      "Val Loss: 67105736.4732, MAE: 5901.4033, NMAE: 89.9717, R^2: -0.8358\n",
      "Epoch [35/2000]\n",
      "Train Loss: 72222589.1133\n",
      "Val Loss: 66784655.5743, MAE: 5886.9194, NMAE: 89.7509, R^2: -0.8270\n",
      "Epoch [36/2000]\n",
      "Train Loss: 71877118.1258\n",
      "Val Loss: 66465878.7151, MAE: 5872.6138, NMAE: 89.5328, R^2: -0.8183\n",
      "Epoch [37/2000]\n",
      "Train Loss: 71533978.3752\n",
      "Val Loss: 66149360.2801, MAE: 5858.5020, NMAE: 89.3177, R^2: -0.8096\n",
      "Epoch [38/2000]\n",
      "Train Loss: 71193158.2043\n",
      "Val Loss: 65835133.9333, MAE: 5844.5474, NMAE: 89.1049, R^2: -0.8010\n",
      "Epoch [39/2000]\n",
      "Train Loss: 70854673.3363\n",
      "Val Loss: 65523189.6601, MAE: 5830.7656, NMAE: 88.8948, R^2: -0.7925\n",
      "Epoch [40/2000]\n",
      "Train Loss: 70518507.9351\n",
      "Val Loss: 65213492.4853, MAE: 5817.2065, NMAE: 88.6881, R^2: -0.7840\n",
      "Epoch [41/2000]\n",
      "Train Loss: 70184660.5024\n",
      "Val Loss: 64906088.1740, MAE: 5803.8667, NMAE: 88.4847, R^2: -0.7756\n",
      "Epoch [42/2000]\n",
      "Train Loss: 69853128.7448\n",
      "Val Loss: 64600927.4545, MAE: 5790.7061, NMAE: 88.2841, R^2: -0.7673\n",
      "Epoch [43/2000]\n",
      "Train Loss: 69523901.4959\n",
      "Val Loss: 64298032.9544, MAE: 5777.7007, NMAE: 88.0858, R^2: -0.7590\n",
      "Epoch [44/2000]\n",
      "Train Loss: 69196976.3078\n",
      "Val Loss: 63997373.0247, MAE: 5764.8652, NMAE: 87.8901, R^2: -0.7507\n",
      "Epoch [45/2000]\n",
      "Train Loss: 68872350.1763\n",
      "Val Loss: 63698975.0315, MAE: 5752.2202, NMAE: 87.6973, R^2: -0.7426\n",
      "Epoch [46/2000]\n",
      "Train Loss: 68550020.5427\n",
      "Val Loss: 63402801.1614, MAE: 5739.7314, NMAE: 87.5069, R^2: -0.7345\n",
      "Epoch [47/2000]\n",
      "Train Loss: 68229966.4261\n",
      "Val Loss: 63108860.9642, MAE: 5727.4360, NMAE: 87.3195, R^2: -0.7264\n",
      "Epoch [48/2000]\n",
      "Train Loss: 67912190.1470\n",
      "Val Loss: 62817135.2812, MAE: 5715.3115, NMAE: 87.1346, R^2: -0.7185\n",
      "Epoch [49/2000]\n",
      "Train Loss: 67596686.9211\n",
      "Val Loss: 62527630.6319, MAE: 5703.3770, NMAE: 86.9527, R^2: -0.7105\n",
      "Epoch [50/2000]\n",
      "Train Loss: 67283447.8356\n",
      "Val Loss: 62240335.6176, MAE: 5691.6050, NMAE: 86.7732, R^2: -0.7027\n",
      "Epoch [51/2000]\n",
      "Train Loss: 66972464.2545\n",
      "Val Loss: 61955236.9491, MAE: 5679.9766, NMAE: 86.5959, R^2: -0.6949\n",
      "Epoch [52/2000]\n",
      "Train Loss: 66663743.8881\n",
      "Val Loss: 61672355.9106, MAE: 5668.5278, NMAE: 86.4214, R^2: -0.6871\n",
      "Epoch [53/2000]\n",
      "Train Loss: 66357278.4446\n",
      "Val Loss: 61391663.4773, MAE: 5657.2261, NMAE: 86.2491, R^2: -0.6795\n",
      "Epoch [54/2000]\n",
      "Train Loss: 66053058.6681\n",
      "Val Loss: 61113159.1145, MAE: 5646.0654, NMAE: 86.0789, R^2: -0.6718\n",
      "Epoch [55/2000]\n",
      "Train Loss: 65751076.5987\n",
      "Val Loss: 60836835.6192, MAE: 5635.0483, NMAE: 85.9109, R^2: -0.6643\n",
      "Epoch [56/2000]\n",
      "Train Loss: 65451320.9761\n",
      "Val Loss: 60562682.1503, MAE: 5624.1831, NMAE: 85.7453, R^2: -0.6568\n",
      "Epoch [57/2000]\n",
      "Train Loss: 65153794.5207\n",
      "Val Loss: 60290704.4320, MAE: 5613.4766, NMAE: 85.5821, R^2: -0.6493\n",
      "Epoch [58/2000]\n",
      "Train Loss: 64858491.5591\n",
      "Val Loss: 60020879.5470, MAE: 5602.9199, NMAE: 85.4211, R^2: -0.6420\n",
      "Epoch [59/2000]\n",
      "Train Loss: 64565392.1224\n",
      "Val Loss: 59753209.1988, MAE: 5592.5063, NMAE: 85.2623, R^2: -0.6346\n",
      "Epoch [60/2000]\n",
      "Train Loss: 64274501.3478\n",
      "Val Loss: 59487682.5483, MAE: 5582.2451, NMAE: 85.1059, R^2: -0.6274\n",
      "Epoch [61/2000]\n",
      "Train Loss: 63985813.7728\n",
      "Val Loss: 59224303.5806, MAE: 5572.1309, NMAE: 84.9517, R^2: -0.6202\n",
      "Epoch [62/2000]\n",
      "Train Loss: 63699320.8784\n",
      "Val Loss: 58963059.4987, MAE: 5562.1387, NMAE: 84.7994, R^2: -0.6130\n",
      "Epoch [63/2000]\n",
      "Train Loss: 63415012.1530\n",
      "Val Loss: 58703934.5639, MAE: 5552.2983, NMAE: 84.6493, R^2: -0.6059\n",
      "Epoch [64/2000]\n",
      "Train Loss: 63132887.1453\n",
      "Val Loss: 58446940.6448, MAE: 5542.5923, NMAE: 84.5014, R^2: -0.5989\n",
      "Epoch [65/2000]\n",
      "Train Loss: 62852942.8198\n",
      "Val Loss: 58192055.0053, MAE: 5532.9971, NMAE: 84.3551, R^2: -0.5919\n",
      "Epoch [66/2000]\n",
      "Train Loss: 62575173.2750\n",
      "Val Loss: 57939294.2943, MAE: 5523.5322, NMAE: 84.2108, R^2: -0.5850\n",
      "Epoch [67/2000]\n",
      "Train Loss: 62299561.3759\n",
      "Val Loss: 57688618.3943, MAE: 5514.1982, NMAE: 84.0685, R^2: -0.5782\n",
      "Epoch [68/2000]\n",
      "Train Loss: 62026103.8591\n",
      "Val Loss: 57440035.5782, MAE: 5505.0117, NMAE: 83.9284, R^2: -0.5714\n",
      "Epoch [69/2000]\n",
      "Train Loss: 61754797.7625\n",
      "Val Loss: 57193553.2212, MAE: 5495.9546, NMAE: 83.7903, R^2: -0.5646\n",
      "Epoch [70/2000]\n",
      "Train Loss: 61485637.3121\n",
      "Val Loss: 56949135.6756, MAE: 5487.0264, NMAE: 83.6542, R^2: -0.5579\n",
      "Epoch [71/2000]\n",
      "Train Loss: 61218608.2892\n",
      "Val Loss: 56706794.1022, MAE: 5478.2300, NMAE: 83.5201, R^2: -0.5513\n",
      "Epoch [72/2000]\n",
      "Train Loss: 60953713.0129\n",
      "Val Loss: 56466514.4250, MAE: 5469.5645, NMAE: 83.3880, R^2: -0.5447\n",
      "Epoch [73/2000]\n",
      "Train Loss: 60690937.7228\n",
      "Val Loss: 56228305.8397, MAE: 5461.0181, NMAE: 83.2577, R^2: -0.5382\n",
      "Epoch [74/2000]\n",
      "Train Loss: 60430290.8664\n",
      "Val Loss: 55992150.5499, MAE: 5452.5962, NMAE: 83.1293, R^2: -0.5317\n",
      "Epoch [75/2000]\n",
      "Train Loss: 60171732.3517\n",
      "Val Loss: 55758014.1504, MAE: 5444.2871, NMAE: 83.0026, R^2: -0.5253\n",
      "Epoch [76/2000]\n",
      "Train Loss: 59915277.0612\n",
      "Val Loss: 55525922.8079, MAE: 5436.0986, NMAE: 82.8778, R^2: -0.5190\n",
      "Epoch [77/2000]\n",
      "Train Loss: 59660906.4698\n",
      "Val Loss: 55295844.2012, MAE: 5428.0244, NMAE: 82.7547, R^2: -0.5127\n",
      "Epoch [78/2000]\n",
      "Train Loss: 59408620.4435\n",
      "Val Loss: 55067781.9307, MAE: 5420.0771, NMAE: 82.6335, R^2: -0.5065\n",
      "Epoch [79/2000]\n",
      "Train Loss: 59158403.2776\n",
      "Val Loss: 54841735.8586, MAE: 5412.2490, NMAE: 82.5142, R^2: -0.5003\n",
      "Epoch [80/2000]\n",
      "Train Loss: 58910266.5797\n",
      "Val Loss: 54617682.9804, MAE: 5404.5469, NMAE: 82.3968, R^2: -0.4941\n",
      "Epoch [81/2000]\n",
      "Train Loss: 58664177.8315\n",
      "Val Loss: 54395612.1051, MAE: 5396.9419, NMAE: 82.2808, R^2: -0.4881\n",
      "Epoch [82/2000]\n",
      "Train Loss: 58420138.9203\n",
      "Val Loss: 54175549.5494, MAE: 5389.4399, NMAE: 82.1664, R^2: -0.4821\n",
      "Epoch [83/2000]\n",
      "Train Loss: 58178174.4293\n",
      "Val Loss: 53957476.8396, MAE: 5382.0488, NMAE: 82.0537, R^2: -0.4761\n",
      "Epoch [84/2000]\n",
      "Train Loss: 57938257.6280\n",
      "Val Loss: 53741385.6634, MAE: 5374.7690, NMAE: 81.9428, R^2: -0.4702\n",
      "Epoch [85/2000]\n",
      "Train Loss: 57700370.5836\n",
      "Val Loss: 53527248.5736, MAE: 5367.5767, NMAE: 81.8331, R^2: -0.4643\n",
      "Epoch [86/2000]\n",
      "Train Loss: 57464498.9461\n",
      "Val Loss: 53315046.5235, MAE: 5360.4790, NMAE: 81.7249, R^2: -0.4585\n",
      "Epoch [87/2000]\n",
      "Train Loss: 57230625.5461\n",
      "Val Loss: 53104790.1131, MAE: 5353.4858, NMAE: 81.6183, R^2: -0.4528\n",
      "Epoch [88/2000]\n",
      "Train Loss: 56998759.9203\n",
      "Val Loss: 52896461.1105, MAE: 5346.6021, NMAE: 81.5133, R^2: -0.4471\n",
      "Epoch [89/2000]\n",
      "Train Loss: 56768885.7591\n",
      "Val Loss: 52690056.3456, MAE: 5339.8320, NMAE: 81.4101, R^2: -0.4414\n",
      "Epoch [90/2000]\n",
      "Train Loss: 56541004.6496\n",
      "Val Loss: 52485586.3310, MAE: 5333.1602, NMAE: 81.3084, R^2: -0.4358\n",
      "Epoch [91/2000]\n",
      "Train Loss: 56315125.8328\n",
      "Val Loss: 52283046.1477, MAE: 5326.6040, NMAE: 81.2084, R^2: -0.4303\n",
      "Epoch [92/2000]\n",
      "Train Loss: 56091226.0026\n",
      "Val Loss: 52082389.2599, MAE: 5320.1489, NMAE: 81.1100, R^2: -0.4248\n",
      "Epoch [93/2000]\n",
      "Train Loss: 55869288.1302\n",
      "Val Loss: 51883645.6869, MAE: 5313.8018, NMAE: 81.0133, R^2: -0.4194\n",
      "Epoch [94/2000]\n",
      "Train Loss: 55649303.6573\n",
      "Val Loss: 51686766.8490, MAE: 5307.5659, NMAE: 80.9182, R^2: -0.4140\n",
      "Epoch [95/2000]\n",
      "Train Loss: 55431281.1582\n",
      "Val Loss: 51491796.6133, MAE: 5301.4341, NMAE: 80.8247, R^2: -0.4086\n",
      "Epoch [96/2000]\n",
      "Train Loss: 55215194.4534\n",
      "Val Loss: 51298652.0833, MAE: 5295.4067, NMAE: 80.7328, R^2: -0.4034\n",
      "Epoch [97/2000]\n",
      "Train Loss: 55001026.2871\n",
      "Val Loss: 51107389.0481, MAE: 5289.4971, NMAE: 80.6427, R^2: -0.3981\n",
      "Epoch [98/2000]\n",
      "Train Loss: 54788797.9470\n",
      "Val Loss: 50917975.3459, MAE: 5283.6846, NMAE: 80.5541, R^2: -0.3929\n",
      "Epoch [99/2000]\n",
      "Train Loss: 54578476.5647\n",
      "Val Loss: 50730384.4216, MAE: 5277.9634, NMAE: 80.4669, R^2: -0.3878\n",
      "Epoch [100/2000]\n",
      "Train Loss: 54370060.3216\n",
      "Val Loss: 50544646.0636, MAE: 5272.3198, NMAE: 80.3808, R^2: -0.3827\n",
      "Epoch [101/2000]\n",
      "Train Loss: 54163535.9362\n",
      "Val Loss: 50360706.6851, MAE: 5266.7749, NMAE: 80.2963, R^2: -0.3777\n",
      "Epoch [102/2000]\n",
      "Train Loss: 53958904.8388\n",
      "Val Loss: 50178603.4041, MAE: 5261.3389, NMAE: 80.2134, R^2: -0.3727\n",
      "Epoch [103/2000]\n",
      "Train Loss: 53756149.3065\n",
      "Val Loss: 49998282.8041, MAE: 5256.0122, NMAE: 80.1322, R^2: -0.3678\n",
      "Epoch [104/2000]\n",
      "Train Loss: 53555277.9823\n",
      "Val Loss: 49819789.2799, MAE: 5250.7793, NMAE: 80.0524, R^2: -0.3629\n",
      "Epoch [105/2000]\n",
      "Train Loss: 53356281.6849\n",
      "Val Loss: 49643081.8006, MAE: 5245.6543, NMAE: 79.9743, R^2: -0.3581\n",
      "Epoch [106/2000]\n",
      "Train Loss: 53159126.5397\n",
      "Val Loss: 49468128.3496, MAE: 5240.6245, NMAE: 79.8976, R^2: -0.3533\n",
      "Epoch [107/2000]\n",
      "Train Loss: 52963819.4737\n",
      "Val Loss: 49294964.9144, MAE: 5235.6904, NMAE: 79.8224, R^2: -0.3485\n",
      "Epoch [108/2000]\n",
      "Train Loss: 52770356.3435\n",
      "Val Loss: 49123550.6169, MAE: 5230.8525, NMAE: 79.7486, R^2: -0.3438\n",
      "Epoch [109/2000]\n",
      "Train Loss: 52578701.9211\n",
      "Val Loss: 48953863.5173, MAE: 5226.1025, NMAE: 79.6762, R^2: -0.3392\n",
      "Epoch [110/2000]\n",
      "Train Loss: 52388866.8530\n",
      "Val Loss: 48785950.5653, MAE: 5221.4321, NMAE: 79.6050, R^2: -0.3346\n",
      "Epoch [111/2000]\n",
      "Train Loss: 52200850.3263\n",
      "Val Loss: 48619746.1038, MAE: 5216.8525, NMAE: 79.5352, R^2: -0.3301\n",
      "Epoch [112/2000]\n",
      "Train Loss: 52014641.7552\n",
      "Val Loss: 48455283.5777, MAE: 5212.3608, NMAE: 79.4667, R^2: -0.3256\n",
      "Epoch [113/2000]\n",
      "Train Loss: 51830213.1591\n",
      "Val Loss: 48292506.0259, MAE: 5207.9629, NMAE: 79.3997, R^2: -0.3211\n",
      "Epoch [114/2000]\n",
      "Train Loss: 51647546.1039\n",
      "Val Loss: 48131426.2358, MAE: 5203.6255, NMAE: 79.3335, R^2: -0.3167\n",
      "Epoch [115/2000]\n",
      "Train Loss: 51466660.1716\n",
      "Val Loss: 47972055.4698, MAE: 5199.3804, NMAE: 79.2688, R^2: -0.3123\n",
      "Epoch [116/2000]\n",
      "Train Loss: 51287551.8560\n",
      "Val Loss: 47814357.8964, MAE: 5195.2271, NMAE: 79.2055, R^2: -0.3080\n",
      "Epoch [117/2000]\n",
      "Train Loss: 51110178.2629\n",
      "Val Loss: 47658330.1019, MAE: 5191.1440, NMAE: 79.1432, R^2: -0.3038\n",
      "Epoch [118/2000]\n",
      "Train Loss: 50934545.2284\n",
      "Val Loss: 47503958.7483, MAE: 5187.1265, NMAE: 79.0820, R^2: -0.2995\n",
      "Epoch [119/2000]\n",
      "Train Loss: 50760643.4366\n",
      "Val Loss: 47351234.0991, MAE: 5183.1855, NMAE: 79.0219, R^2: -0.2954\n",
      "Epoch [120/2000]\n",
      "Train Loss: 50588459.9099\n",
      "Val Loss: 47200154.9272, MAE: 5179.3242, NMAE: 78.9630, R^2: -0.2912\n",
      "Epoch [121/2000]\n",
      "Train Loss: 50417991.3147\n",
      "Val Loss: 47050697.1244, MAE: 5175.5410, NMAE: 78.9054, R^2: -0.2871\n",
      "Epoch [122/2000]\n",
      "Train Loss: 50249217.1871\n",
      "Val Loss: 46902860.6203, MAE: 5171.8340, NMAE: 78.8489, R^2: -0.2831\n",
      "Epoch [123/2000]\n",
      "Train Loss: 50082132.3220\n",
      "Val Loss: 46756635.2537, MAE: 5168.1875, NMAE: 78.7933, R^2: -0.2791\n",
      "Epoch [124/2000]\n",
      "Train Loss: 49916734.1884\n",
      "Val Loss: 46612007.1315, MAE: 5164.6089, NMAE: 78.7387, R^2: -0.2751\n",
      "Epoch [125/2000]\n",
      "Train Loss: 49753013.2026\n",
      "Val Loss: 46468977.1960, MAE: 5161.1069, NMAE: 78.6853, R^2: -0.2712\n",
      "Epoch [126/2000]\n",
      "Train Loss: 49590956.4655\n",
      "Val Loss: 46327528.0060, MAE: 5157.6890, NMAE: 78.6332, R^2: -0.2674\n",
      "Epoch [127/2000]\n",
      "Train Loss: 49430541.4164\n",
      "Val Loss: 46187628.1978, MAE: 5154.3398, NMAE: 78.5821, R^2: -0.2635\n",
      "Epoch [128/2000]\n",
      "Train Loss: 49271774.2478\n",
      "Val Loss: 46049308.0427, MAE: 5151.0576, NMAE: 78.5321, R^2: -0.2597\n",
      "Epoch [129/2000]\n",
      "Train Loss: 49114646.6629\n",
      "Val Loss: 45912532.7191, MAE: 5147.8486, NMAE: 78.4832, R^2: -0.2560\n",
      "Epoch [130/2000]\n",
      "Train Loss: 48959130.5401\n",
      "Val Loss: 45777282.2444, MAE: 5144.7065, NMAE: 78.4353, R^2: -0.2523\n",
      "Epoch [131/2000]\n",
      "Train Loss: 48805228.2457\n",
      "Val Loss: 45643576.2714, MAE: 5141.6484, NMAE: 78.3886, R^2: -0.2486\n",
      "Epoch [132/2000]\n",
      "Train Loss: 48652930.8009\n",
      "Val Loss: 45511373.4432, MAE: 5138.6572, NMAE: 78.3430, R^2: -0.2450\n",
      "Epoch [133/2000]\n",
      "Train Loss: 48502217.1319\n",
      "Val Loss: 45380677.6850, MAE: 5135.7344, NMAE: 78.2985, R^2: -0.2415\n",
      "Epoch [134/2000]\n",
      "Train Loss: 48353080.8716\n",
      "Val Loss: 45251472.8867, MAE: 5132.8892, NMAE: 78.2551, R^2: -0.2379\n",
      "Epoch [135/2000]\n",
      "Train Loss: 48205519.8444\n",
      "Val Loss: 45123763.2601, MAE: 5130.1362, NMAE: 78.2131, R^2: -0.2344\n",
      "Epoch [136/2000]\n",
      "Train Loss: 48059526.0017\n",
      "Val Loss: 44997533.0216, MAE: 5127.4541, NMAE: 78.1722, R^2: -0.2310\n",
      "Epoch [137/2000]\n",
      "Train Loss: 47915082.5190\n",
      "Val Loss: 44872762.6541, MAE: 5124.8232, NMAE: 78.1321, R^2: -0.2276\n",
      "Epoch [138/2000]\n",
      "Train Loss: 47772179.6069\n",
      "Val Loss: 44749457.5058, MAE: 5122.2432, NMAE: 78.0928, R^2: -0.2242\n",
      "Epoch [139/2000]\n",
      "Train Loss: 47630805.7009\n",
      "Val Loss: 44627578.5818, MAE: 5119.7217, NMAE: 78.0544, R^2: -0.2209\n",
      "Epoch [140/2000]\n",
      "Train Loss: 47490947.5397\n",
      "Val Loss: 44507140.7597, MAE: 5117.2778, NMAE: 78.0171, R^2: -0.2176\n",
      "Epoch [141/2000]\n",
      "Train Loss: 47352593.6586\n",
      "Val Loss: 44388116.9037, MAE: 5114.8984, NMAE: 77.9808, R^2: -0.2143\n",
      "Epoch [142/2000]\n",
      "Train Loss: 47215728.6345\n",
      "Val Loss: 44270500.6386, MAE: 5112.5786, NMAE: 77.9455, R^2: -0.2111\n",
      "Epoch [143/2000]\n",
      "Train Loss: 47080365.6612\n",
      "Val Loss: 44154301.4860, MAE: 5110.3247, NMAE: 77.9111, R^2: -0.2079\n",
      "Epoch [144/2000]\n",
      "Train Loss: 46946477.7103\n",
      "Val Loss: 44039474.8022, MAE: 5108.1260, NMAE: 77.8776, R^2: -0.2048\n",
      "Epoch [145/2000]\n",
      "Train Loss: 46814052.3552\n",
      "Val Loss: 43926038.3355, MAE: 5105.9829, NMAE: 77.8449, R^2: -0.2017\n",
      "Epoch [146/2000]\n",
      "Train Loss: 46683082.1914\n",
      "Val Loss: 43813966.4644, MAE: 5103.8965, NMAE: 77.8131, R^2: -0.1986\n",
      "Epoch [147/2000]\n",
      "Train Loss: 46553559.6388\n",
      "Val Loss: 43703254.7893, MAE: 5101.8638, NMAE: 77.7821, R^2: -0.1956\n",
      "Epoch [148/2000]\n",
      "Train Loss: 46425474.1638\n",
      "Val Loss: 43593896.3441, MAE: 5099.8745, NMAE: 77.7518, R^2: -0.1926\n",
      "Epoch [149/2000]\n",
      "Train Loss: 46298816.3276\n",
      "Val Loss: 43485863.9467, MAE: 5097.9497, NMAE: 77.7224, R^2: -0.1896\n",
      "Epoch [150/2000]\n",
      "Train Loss: 46173563.9784\n",
      "Val Loss: 43379167.9182, MAE: 5096.0884, NMAE: 77.6940, R^2: -0.1867\n",
      "Epoch [151/2000]\n",
      "Train Loss: 46049714.7940\n",
      "Val Loss: 43273768.7867, MAE: 5094.2700, NMAE: 77.6663, R^2: -0.1838\n",
      "Epoch [152/2000]\n",
      "Train Loss: 45927261.7940\n",
      "Val Loss: 43169693.3782, MAE: 5092.4937, NMAE: 77.6392, R^2: -0.1810\n",
      "Epoch [153/2000]\n",
      "Train Loss: 45806195.9578\n",
      "Val Loss: 43066908.4046, MAE: 5090.7637, NMAE: 77.6129, R^2: -0.1782\n",
      "Epoch [154/2000]\n",
      "Train Loss: 45686502.9164\n",
      "Val Loss: 42965408.3174, MAE: 5089.0850, NMAE: 77.5873, R^2: -0.1754\n",
      "Epoch [155/2000]\n",
      "Train Loss: 45568163.7914\n",
      "Val Loss: 42865170.5067, MAE: 5087.4541, NMAE: 77.5624, R^2: -0.1726\n",
      "Epoch [156/2000]\n",
      "Train Loss: 45451173.6733\n",
      "Val Loss: 42766200.1725, MAE: 5085.8628, NMAE: 77.5382, R^2: -0.1699\n",
      "Epoch [157/2000]\n",
      "Train Loss: 45335513.0466\n",
      "Val Loss: 42668466.3564, MAE: 5084.3242, NMAE: 77.5147, R^2: -0.1673\n",
      "Epoch [158/2000]\n",
      "Train Loss: 45221184.4302\n",
      "Val Loss: 42571981.3597, MAE: 5082.8291, NMAE: 77.4919, R^2: -0.1646\n",
      "Epoch [159/2000]\n",
      "Train Loss: 45108166.7190\n",
      "Val Loss: 42476710.5427, MAE: 5081.3926, NMAE: 77.4700, R^2: -0.1620\n",
      "Epoch [160/2000]\n",
      "Train Loss: 44996462.1664\n",
      "Val Loss: 42382680.9475, MAE: 5080.0054, NMAE: 77.4488, R^2: -0.1594\n",
      "Epoch [161/2000]\n",
      "Train Loss: 44886056.9853\n",
      "Val Loss: 42289853.0231, MAE: 5078.6597, NMAE: 77.4283, R^2: -0.1569\n",
      "Epoch [162/2000]\n",
      "Train Loss: 44776946.3776\n",
      "Val Loss: 42198220.1319, MAE: 5077.3613, NMAE: 77.4085, R^2: -0.1544\n",
      "Epoch [163/2000]\n",
      "Train Loss: 44669103.5733\n",
      "Val Loss: 42107776.0907, MAE: 5076.1162, NMAE: 77.3896, R^2: -0.1519\n",
      "Epoch [164/2000]\n",
      "Train Loss: 44562513.7552\n",
      "Val Loss: 42018487.4335, MAE: 5074.9082, NMAE: 77.3711, R^2: -0.1495\n",
      "Epoch [165/2000]\n",
      "Train Loss: 44457176.2698\n",
      "Val Loss: 41930365.9221, MAE: 5073.7412, NMAE: 77.3533, R^2: -0.1471\n",
      "Epoch [166/2000]\n",
      "Train Loss: 44353084.0690\n",
      "Val Loss: 41843419.4011, MAE: 5072.6118, NMAE: 77.3361, R^2: -0.1447\n",
      "Epoch [167/2000]\n",
      "Train Loss: 44250225.7716\n",
      "Val Loss: 41757590.8549, MAE: 5071.5171, NMAE: 77.3194, R^2: -0.1423\n",
      "Epoch [168/2000]\n",
      "Train Loss: 44148596.5164\n",
      "Val Loss: 41672924.6816, MAE: 5070.4570, NMAE: 77.3033, R^2: -0.1400\n",
      "Epoch [169/2000]\n",
      "Train Loss: 44048176.3043\n",
      "Val Loss: 41589364.5399, MAE: 5069.4336, NMAE: 77.2877, R^2: -0.1377\n",
      "Epoch [170/2000]\n",
      "Train Loss: 43948952.1052\n",
      "Val Loss: 41506917.9868, MAE: 5068.4448, NMAE: 77.2726, R^2: -0.1355\n",
      "Epoch [171/2000]\n",
      "Train Loss: 43850931.1250\n",
      "Val Loss: 41425587.3551, MAE: 5067.4956, NMAE: 77.2581, R^2: -0.1333\n",
      "Epoch [172/2000]\n",
      "Train Loss: 43754096.8345\n",
      "Val Loss: 41345341.1576, MAE: 5066.5811, NMAE: 77.2442, R^2: -0.1311\n",
      "Epoch [173/2000]\n",
      "Train Loss: 43658414.2276\n",
      "Val Loss: 41266163.7865, MAE: 5065.6948, NMAE: 77.2307, R^2: -0.1289\n",
      "Epoch [174/2000]\n",
      "Train Loss: 43563900.6810\n",
      "Val Loss: 41188074.7632, MAE: 5064.8398, NMAE: 77.2176, R^2: -0.1268\n",
      "Epoch [175/2000]\n",
      "Train Loss: 43470541.8974\n",
      "Val Loss: 41111047.1779, MAE: 5064.0142, NMAE: 77.2051, R^2: -0.1247\n",
      "Epoch [176/2000]\n",
      "Train Loss: 43378319.0750\n",
      "Val Loss: 41035053.2800, MAE: 5063.2183, NMAE: 77.1929, R^2: -0.1226\n",
      "Epoch [177/2000]\n",
      "Train Loss: 43287210.6983\n",
      "Val Loss: 40960092.1982, MAE: 5062.4565, NMAE: 77.1813, R^2: -0.1205\n",
      "Epoch [178/2000]\n",
      "Train Loss: 43197211.8716\n",
      "Val Loss: 40886145.7876, MAE: 5061.7310, NMAE: 77.1702, R^2: -0.1185\n",
      "Epoch [179/2000]\n",
      "Train Loss: 43108311.3922\n",
      "Val Loss: 40813236.5142, MAE: 5061.0400, NMAE: 77.1597, R^2: -0.1165\n",
      "Epoch [180/2000]\n",
      "Train Loss: 43020509.1655\n",
      "Val Loss: 40741317.2358, MAE: 5060.3804, NMAE: 77.1497, R^2: -0.1145\n",
      "Epoch [181/2000]\n",
      "Train Loss: 42933798.8534\n",
      "Val Loss: 40670418.4780, MAE: 5059.7500, NMAE: 77.1400, R^2: -0.1126\n",
      "Epoch [182/2000]\n",
      "Train Loss: 42848188.4621\n",
      "Val Loss: 40600514.2155, MAE: 5059.1509, NMAE: 77.1309, R^2: -0.1107\n",
      "Epoch [183/2000]\n",
      "Train Loss: 42763638.1414\n",
      "Val Loss: 40531579.0669, MAE: 5058.5845, NMAE: 77.1223, R^2: -0.1088\n",
      "Epoch [184/2000]\n",
      "Train Loss: 42680137.4836\n",
      "Val Loss: 40463610.2582, MAE: 5058.0527, NMAE: 77.1142, R^2: -0.1069\n",
      "Epoch [185/2000]\n",
      "Train Loss: 42597684.9741\n",
      "Val Loss: 40396598.8303, MAE: 5057.5552, NMAE: 77.1066, R^2: -0.1051\n",
      "Epoch [186/2000]\n",
      "Train Loss: 42516268.3155\n",
      "Val Loss: 40330542.7185, MAE: 5057.0898, NMAE: 77.0995, R^2: -0.1033\n",
      "Epoch [187/2000]\n",
      "Train Loss: 42435875.6819\n",
      "Val Loss: 40265415.9309, MAE: 5056.6567, NMAE: 77.0929, R^2: -0.1015\n",
      "Epoch [188/2000]\n",
      "Train Loss: 42356498.1595\n",
      "Val Loss: 40201207.3661, MAE: 5056.2559, NMAE: 77.0868, R^2: -0.0998\n",
      "Epoch [189/2000]\n",
      "Train Loss: 42278112.4612\n",
      "Val Loss: 40137920.9136, MAE: 5055.8892, NMAE: 77.0812, R^2: -0.0980\n",
      "Epoch [190/2000]\n",
      "Train Loss: 42200735.6828\n",
      "Val Loss: 40075547.5959, MAE: 5055.5513, NMAE: 77.0760, R^2: -0.0963\n",
      "Epoch [191/2000]\n",
      "Train Loss: 42124337.5595\n",
      "Val Loss: 40014062.4603, MAE: 5055.2476, NMAE: 77.0714, R^2: -0.0946\n",
      "Epoch [192/2000]\n",
      "Train Loss: 42048920.1233\n",
      "Val Loss: 39953476.7042, MAE: 5054.9790, NMAE: 77.0673, R^2: -0.0930\n",
      "Epoch [193/2000]\n",
      "Train Loss: 41974460.6672\n",
      "Val Loss: 39893746.3903, MAE: 5054.7383, NMAE: 77.0636, R^2: -0.0914\n",
      "Epoch [194/2000]\n",
      "Train Loss: 41900952.8612\n",
      "Val Loss: 39834910.9292, MAE: 5054.5283, NMAE: 77.0604, R^2: -0.0897\n",
      "Epoch [195/2000]\n",
      "Train Loss: 41828395.9784\n",
      "Val Loss: 39776905.9430, MAE: 5054.3467, NMAE: 77.0577, R^2: -0.0882\n",
      "Epoch [196/2000]\n",
      "Train Loss: 41756765.8879\n",
      "Val Loss: 39719766.5622, MAE: 5054.1855, NMAE: 77.0552, R^2: -0.0866\n",
      "Epoch [197/2000]\n",
      "Train Loss: 41686077.8914\n",
      "Val Loss: 39663478.7453, MAE: 5054.0537, NMAE: 77.0532, R^2: -0.0851\n",
      "Epoch [198/2000]\n",
      "Train Loss: 41616320.0060\n",
      "Val Loss: 39608023.5289, MAE: 5053.9434, NMAE: 77.0515, R^2: -0.0835\n",
      "Epoch [199/2000]\n",
      "Train Loss: 41547449.6974\n",
      "Val Loss: 39553368.2487, MAE: 5053.8501, NMAE: 77.0501, R^2: -0.0820\n",
      "Epoch [200/2000]\n",
      "Train Loss: 41479474.7164\n",
      "Val Loss: 39499529.7129, MAE: 5053.7778, NMAE: 77.0490, R^2: -0.0806\n",
      "Epoch [201/2000]\n",
      "Train Loss: 41412384.2784\n",
      "Val Loss: 39446496.6287, MAE: 5053.7246, NMAE: 77.0482, R^2: -0.0791\n",
      "Epoch [202/2000]\n",
      "Train Loss: 41346189.9931\n",
      "Val Loss: 39394260.7686, MAE: 5053.6992, NMAE: 77.0478, R^2: -0.0777\n",
      "Epoch [203/2000]\n",
      "Train Loss: 41280854.9034\n",
      "Val Loss: 39342801.8208, MAE: 5053.6958, NMAE: 77.0477, R^2: -0.0763\n",
      "Epoch [204/2000]\n",
      "Train Loss: 41216395.0388\n",
      "Val Loss: 39292138.9136, MAE: 5053.7173, NMAE: 77.0481, R^2: -0.0749\n",
      "Epoch [205/2000]\n",
      "Train Loss: 41152777.6647\n",
      "Val Loss: 39242223.0799, MAE: 5053.7686, NMAE: 77.0488, R^2: -0.0735\n",
      "Epoch [206/2000]\n",
      "Train Loss: 41089995.4397\n",
      "Val Loss: 39193058.1028, MAE: 5053.8433, NMAE: 77.0500, R^2: -0.0722\n",
      "Epoch [207/2000]\n",
      "Train Loss: 41028034.8509\n",
      "Val Loss: 39144635.3459, MAE: 5053.9434, NMAE: 77.0515, R^2: -0.0709\n",
      "Epoch [208/2000]\n",
      "Train Loss: 40966905.3905\n",
      "Val Loss: 39096970.5371, MAE: 5054.0610, NMAE: 77.0533, R^2: -0.0696\n",
      "Epoch [209/2000]\n",
      "Train Loss: 40906602.5526\n",
      "Val Loss: 39050028.7241, MAE: 5054.1978, NMAE: 77.0554, R^2: -0.0683\n",
      "Epoch [210/2000]\n",
      "Train Loss: 40847092.4241\n",
      "Val Loss: 39003796.2936, MAE: 5054.3569, NMAE: 77.0578, R^2: -0.0670\n",
      "Epoch [211/2000]\n",
      "Train Loss: 40788367.4716\n",
      "Val Loss: 38958283.0086, MAE: 5054.5356, NMAE: 77.0605, R^2: -0.0658\n",
      "Epoch [212/2000]\n",
      "Train Loss: 40730440.2767\n",
      "Val Loss: 38913470.5168, MAE: 5054.7295, NMAE: 77.0635, R^2: -0.0645\n",
      "Epoch [213/2000]\n",
      "Train Loss: 40673292.0103\n",
      "Val Loss: 38869359.7483, MAE: 5054.9355, NMAE: 77.0666, R^2: -0.0633\n",
      "Epoch [214/2000]\n",
      "Train Loss: 40616911.0138\n",
      "Val Loss: 38825927.8610, MAE: 5055.1484, NMAE: 77.0699, R^2: -0.0621\n",
      "Epoch [215/2000]\n",
      "Train Loss: 40561294.8155\n",
      "Val Loss: 38783180.5263, MAE: 5055.3726, NMAE: 77.0733, R^2: -0.0610\n",
      "Epoch [216/2000]\n",
      "Train Loss: 40506429.9690\n",
      "Val Loss: 38741106.8981, MAE: 5055.6089, NMAE: 77.0769, R^2: -0.0598\n",
      "Epoch [217/2000]\n",
      "Train Loss: 40452309.3181\n",
      "Val Loss: 38699683.0263, MAE: 5055.8628, NMAE: 77.0808, R^2: -0.0587\n",
      "Epoch [218/2000]\n",
      "Train Loss: 40398909.1422\n",
      "Val Loss: 38658905.1019, MAE: 5056.1313, NMAE: 77.0849, R^2: -0.0576\n",
      "Epoch [219/2000]\n",
      "Train Loss: 40346237.6267\n",
      "Val Loss: 38618781.3247, MAE: 5056.4150, NMAE: 77.0892, R^2: -0.0565\n",
      "Epoch [220/2000]\n",
      "Train Loss: 40294293.2267\n",
      "Val Loss: 38579298.3800, MAE: 5056.7207, NMAE: 77.0939, R^2: -0.0554\n",
      "Epoch [221/2000]\n",
      "Train Loss: 40243059.4724\n",
      "Val Loss: 38540443.2470, MAE: 5057.0391, NMAE: 77.0987, R^2: -0.0543\n",
      "Epoch [222/2000]\n",
      "Train Loss: 40192519.3112\n",
      "Val Loss: 38502198.3472, MAE: 5057.3755, NMAE: 77.1038, R^2: -0.0533\n",
      "Epoch [223/2000]\n",
      "Train Loss: 40142680.6422\n",
      "Val Loss: 38464580.3497, MAE: 5057.7202, NMAE: 77.1091, R^2: -0.0523\n",
      "Epoch [224/2000]\n",
      "Train Loss: 40093513.5302\n",
      "Val Loss: 38427541.0756, MAE: 5058.0732, NMAE: 77.1145, R^2: -0.0512\n",
      "Epoch [225/2000]\n",
      "Train Loss: 40045025.7224\n",
      "Val Loss: 38391119.7016, MAE: 5058.4473, NMAE: 77.1202, R^2: -0.0502\n",
      "Epoch [226/2000]\n",
      "Train Loss: 39997212.7388\n",
      "Val Loss: 38355284.4374, MAE: 5058.8438, NMAE: 77.1262, R^2: -0.0493\n",
      "Epoch [227/2000]\n",
      "Train Loss: 39950061.2526\n",
      "Val Loss: 38320032.8476, MAE: 5059.2524, NMAE: 77.1325, R^2: -0.0483\n",
      "Epoch [228/2000]\n",
      "Train Loss: 39903558.0828\n",
      "Val Loss: 38285342.7150, MAE: 5059.6758, NMAE: 77.1389, R^2: -0.0474\n",
      "Epoch [229/2000]\n",
      "Train Loss: 39857704.5319\n",
      "Val Loss: 38251235.8057, MAE: 5060.1182, NMAE: 77.1457, R^2: -0.0464\n",
      "Epoch [230/2000]\n",
      "Train Loss: 39812487.6759\n",
      "Val Loss: 38217685.6645, MAE: 5060.5776, NMAE: 77.1527, R^2: -0.0455\n",
      "Epoch [231/2000]\n",
      "Train Loss: 39767906.7836\n",
      "Val Loss: 38184681.6351, MAE: 5061.0498, NMAE: 77.1599, R^2: -0.0446\n",
      "Epoch [232/2000]\n",
      "Train Loss: 39723936.0767\n",
      "Val Loss: 38152216.9974, MAE: 5061.5288, NMAE: 77.1672, R^2: -0.0437\n",
      "Epoch [233/2000]\n",
      "Train Loss: 39680578.4500\n",
      "Val Loss: 38120286.8074, MAE: 5062.0142, NMAE: 77.1746, R^2: -0.0428\n",
      "Epoch [234/2000]\n",
      "Train Loss: 39637826.5043\n",
      "Val Loss: 38088885.5406, MAE: 5062.5093, NMAE: 77.1821, R^2: -0.0420\n",
      "Epoch [235/2000]\n",
      "Train Loss: 39595673.1405\n",
      "Val Loss: 38058009.3359, MAE: 5063.0137, NMAE: 77.1898, R^2: -0.0411\n",
      "Epoch [236/2000]\n",
      "Train Loss: 39554098.2414\n",
      "Val Loss: 38027610.6425, MAE: 5063.5200, NMAE: 77.1975, R^2: -0.0403\n",
      "Epoch [237/2000]\n",
      "Train Loss: 39513077.1534\n",
      "Val Loss: 37997691.9253, MAE: 5064.0176, NMAE: 77.2051, R^2: -0.0395\n",
      "Epoch [238/2000]\n",
      "Train Loss: 39472571.7319\n",
      "Val Loss: 37968170.5225, MAE: 5064.5005, NMAE: 77.2125, R^2: -0.0387\n",
      "Epoch [239/2000]\n",
      "Train Loss: 39432521.3888\n",
      "Val Loss: 37939021.8394, MAE: 5064.9575, NMAE: 77.2194, R^2: -0.0379\n",
      "Epoch [240/2000]\n",
      "Train Loss: 39392885.2957\n",
      "Val Loss: 37910248.0773, MAE: 5065.3877, NMAE: 77.2260, R^2: -0.0371\n",
      "Epoch [241/2000]\n",
      "Train Loss: 39353697.2276\n",
      "Val Loss: 37881938.5112, MAE: 5065.8120, NMAE: 77.2325, R^2: -0.0363\n",
      "Epoch [242/2000]\n",
      "Train Loss: 39315026.0647\n",
      "Val Loss: 37854128.6913, MAE: 5066.2427, NMAE: 77.2390, R^2: -0.0356\n",
      "Epoch [243/2000]\n",
      "Train Loss: 39276911.6000\n",
      "Val Loss: 37826830.7241, MAE: 5066.6909, NMAE: 77.2459, R^2: -0.0348\n",
      "Epoch [244/2000]\n",
      "Train Loss: 39239349.2000\n",
      "Val Loss: 37800015.0803, MAE: 5067.1528, NMAE: 77.2529, R^2: -0.0341\n",
      "Epoch [245/2000]\n",
      "Train Loss: 39202294.2664\n",
      "Val Loss: 37773659.7448, MAE: 5067.6235, NMAE: 77.2601, R^2: -0.0334\n",
      "Epoch [246/2000]\n",
      "Train Loss: 39165723.0121\n",
      "Val Loss: 37747770.9253, MAE: 5068.1060, NMAE: 77.2674, R^2: -0.0326\n",
      "Epoch [247/2000]\n",
      "Train Loss: 39129627.1819\n",
      "Val Loss: 37722335.9888, MAE: 5068.5933, NMAE: 77.2749, R^2: -0.0320\n",
      "Epoch [248/2000]\n",
      "Train Loss: 39094029.9983\n",
      "Val Loss: 37697396.3627, MAE: 5069.0845, NMAE: 77.2824, R^2: -0.0313\n",
      "Epoch [249/2000]\n",
      "Train Loss: 39058843.3009\n",
      "Val Loss: 37672909.4257, MAE: 5069.5737, NMAE: 77.2898, R^2: -0.0306\n",
      "Epoch [250/2000]\n",
      "Train Loss: 39024131.9759\n",
      "Val Loss: 37648927.6908, MAE: 5070.0640, NMAE: 77.2973, R^2: -0.0299\n",
      "Epoch [251/2000]\n",
      "Train Loss: 38989884.2397\n",
      "Val Loss: 37625426.9318, MAE: 5070.5703, NMAE: 77.3050, R^2: -0.0293\n",
      "Epoch [252/2000]\n",
      "Train Loss: 38956096.7112\n",
      "Val Loss: 37602397.0147, MAE: 5071.0889, NMAE: 77.3129, R^2: -0.0287\n",
      "Epoch [253/2000]\n",
      "Train Loss: 38922757.3009\n",
      "Val Loss: 37579827.6136, MAE: 5071.6123, NMAE: 77.3209, R^2: -0.0281\n",
      "Epoch [254/2000]\n",
      "Train Loss: 38890398.3181\n",
      "Val Loss: 37557572.1256, MAE: 5072.1499, NMAE: 77.3291, R^2: -0.0274\n",
      "Epoch [255/2000]\n",
      "Train Loss: 38857518.7483\n",
      "Val Loss: 37535753.6727, MAE: 5072.6963, NMAE: 77.3374, R^2: -0.0268\n",
      "Epoch [256/2000]\n",
      "Train Loss: 38826430.2190\n",
      "Val Loss: 37514349.5320, MAE: 5073.2876, NMAE: 77.3464, R^2: -0.0263\n",
      "Epoch [257/2000]\n",
      "Train Loss: 38794541.1707\n",
      "Val Loss: 37493227.7750, MAE: 5073.8726, NMAE: 77.3553, R^2: -0.0257\n",
      "Epoch [258/2000]\n",
      "Train Loss: 38763487.6310\n",
      "Val Loss: 37472485.3195, MAE: 5074.4707, NMAE: 77.3645, R^2: -0.0251\n",
      "Epoch [259/2000]\n",
      "Train Loss: 38738419.3405\n",
      "Val Loss: 37451577.9629, MAE: 5075.0078, NMAE: 77.3727, R^2: -0.0245\n",
      "Epoch [260/2000]\n",
      "Train Loss: 38709095.9328\n",
      "Val Loss: 37431449.5937, MAE: 5075.6152, NMAE: 77.3819, R^2: -0.0240\n",
      "Epoch [261/2000]\n",
      "Train Loss: 38685112.1310\n",
      "Val Loss: 37411073.4719, MAE: 5076.1367, NMAE: 77.3899, R^2: -0.0234\n",
      "Epoch [262/2000]\n",
      "Train Loss: 38918283.9207\n",
      "Val Loss: 37532694.9322, MAE: 5070.5195, NMAE: 77.3042, R^2: -0.0268\n",
      "Epoch [263/2000]\n",
      "Train Loss: 38658094.1267\n",
      "Val Loss: 37367632.3126, MAE: 5076.7964, NMAE: 77.3999, R^2: -0.0222\n",
      "Epoch [264/2000]\n",
      "Train Loss: 38696235.5155\n",
      "Val Loss: 37345123.4840, MAE: 5077.0098, NMAE: 77.4032, R^2: -0.0216\n",
      "Epoch [265/2000]\n",
      "Train Loss: 38562822.4983\n",
      "Val Loss: 37320616.1671, MAE: 5076.5962, NMAE: 77.3969, R^2: -0.0210\n",
      "Epoch [266/2000]\n",
      "Train Loss: 38584108.9293\n",
      "Val Loss: 37292677.6092, MAE: 5075.8960, NMAE: 77.3862, R^2: -0.0202\n",
      "Epoch [267/2000]\n",
      "Train Loss: 38562716.6164\n",
      "Val Loss: 37268725.5462, MAE: 5075.7593, NMAE: 77.3841, R^2: -0.0195\n",
      "Epoch [268/2000]\n",
      "Train Loss: 38566599.5534\n",
      "Val Loss: 37245314.6878, MAE: 5075.7505, NMAE: 77.3840, R^2: -0.0189\n",
      "Epoch [269/2000]\n",
      "Train Loss: 38441020.3595\n",
      "Val Loss: 37210480.7949, MAE: 5073.5405, NMAE: 77.3503, R^2: -0.0179\n",
      "Epoch [270/2000]\n",
      "Train Loss: 38438103.2966\n",
      "Val Loss: 37181960.8886, MAE: 5072.1479, NMAE: 77.3291, R^2: -0.0172\n",
      "Epoch [271/2000]\n",
      "Train Loss: 38417972.9112\n",
      "Val Loss: 37221356.5505, MAE: 5078.2920, NMAE: 77.4227, R^2: -0.0182\n",
      "Epoch [272/2000]\n",
      "Train Loss: 38495575.1784\n",
      "Val Loss: 37296409.6183, MAE: 5067.5723, NMAE: 77.2593, R^2: -0.0203\n",
      "Epoch [273/2000]\n",
      "Train Loss: 38557155.1086\n",
      "Val Loss: 37260233.9430, MAE: 5064.8574, NMAE: 77.2179, R^2: -0.0193\n",
      "Epoch [274/2000]\n",
      "Train Loss: 38559491.3457\n",
      "Val Loss: 37233015.0924, MAE: 5063.8433, NMAE: 77.2024, R^2: -0.0186\n",
      "Epoch [275/2000]\n",
      "Train Loss: 38580566.7328\n",
      "Val Loss: 37199289.0186, MAE: 5047.6997, NMAE: 76.9563, R^2: -0.0176\n",
      "Epoch [276/2000]\n",
      "Train Loss: 38512953.1897\n",
      "Val Loss: 37213963.4266, MAE: 5069.2734, NMAE: 77.2852, R^2: -0.0180\n",
      "Epoch [277/2000]\n",
      "Train Loss: 38540013.6647\n",
      "Val Loss: 37175207.4560, MAE: 5065.7539, NMAE: 77.2316, R^2: -0.0170\n",
      "Epoch [278/2000]\n",
      "Train Loss: 38350460.5716\n",
      "Val Loss: 37133647.2142, MAE: 5049.3345, NMAE: 76.9812, R^2: -0.0158\n",
      "Epoch [279/2000]\n",
      "Train Loss: 40542429.4250\n",
      "Val Loss: 39612084.0352, MAE: 4961.3228, NMAE: 75.6394, R^2: -0.0836\n",
      "Epoch [280/2000]\n",
      "Train Loss: 39513344.9991\n",
      "Val Loss: 37092223.7543, MAE: 4994.9019, NMAE: 76.1514, R^2: -0.0147\n",
      "Epoch [281/2000]\n",
      "Train Loss: 38484463.0759\n",
      "Val Loss: 37016053.9680, MAE: 5048.5337, NMAE: 76.9690, R^2: -0.0126\n",
      "Epoch [282/2000]\n",
      "Train Loss: 38261576.5466\n",
      "Val Loss: 36888593.4573, MAE: 5029.5435, NMAE: 76.6795, R^2: -0.0091\n",
      "Epoch [283/2000]\n",
      "Train Loss: 38208171.3371\n",
      "Val Loss: 36758568.2332, MAE: 4999.3384, NMAE: 76.2190, R^2: -0.0056\n",
      "Epoch [284/2000]\n",
      "Train Loss: 38172059.5052\n",
      "Val Loss: 36751730.4940, MAE: 5010.8706, NMAE: 76.3948, R^2: -0.0054\n",
      "Epoch [285/2000]\n",
      "Train Loss: 38107417.9810\n",
      "Val Loss: 36536840.1032, MAE: 5013.9517, NMAE: 76.4418, R^2: 0.0005\n",
      "Epoch [286/2000]\n",
      "Train Loss: 37736124.1009\n",
      "Val Loss: 36577592.4771, MAE: 5030.2036, NMAE: 76.6896, R^2: -0.0006\n",
      "Epoch [287/2000]\n",
      "Train Loss: 37714325.7526\n",
      "Val Loss: 36594594.9590, MAE: 5038.6890, NMAE: 76.8189, R^2: -0.0011\n",
      "Epoch [288/2000]\n",
      "Train Loss: 37700072.8078\n",
      "Val Loss: 36608630.3713, MAE: 5045.8027, NMAE: 76.9274, R^2: -0.0015\n",
      "Epoch [289/2000]\n",
      "Train Loss: 37700546.1284\n",
      "Val Loss: 36575013.0039, MAE: 5043.4023, NMAE: 76.8908, R^2: -0.0006\n",
      "Epoch [290/2000]\n",
      "Train Loss: 37705283.2224\n",
      "Val Loss: 36637796.6956, MAE: 5059.1504, NMAE: 77.1309, R^2: -0.0023\n",
      "Epoch [291/2000]\n",
      "Train Loss: 37690990.4103\n",
      "Val Loss: 36582647.1762, MAE: 5052.6475, NMAE: 77.0318, R^2: -0.0008\n",
      "Epoch [292/2000]\n",
      "Train Loss: 37646014.2422\n",
      "Val Loss: 36576110.6589, MAE: 5054.7090, NMAE: 77.0632, R^2: -0.0006\n",
      "Epoch [293/2000]\n",
      "Train Loss: 37607314.7129\n",
      "Val Loss: 36567475.5108, MAE: 5056.5576, NMAE: 77.0914, R^2: -0.0004\n",
      "Epoch [294/2000]\n",
      "Train Loss: 37577641.0241\n",
      "Val Loss: 36561537.2405, MAE: 5058.6821, NMAE: 77.1238, R^2: -0.0002\n",
      "Epoch [295/2000]\n",
      "Train Loss: 37542897.0509\n",
      "Val Loss: 36551586.0548, MAE: 5060.2778, NMAE: 77.1481, R^2: 0.0001\n",
      "Epoch [296/2000]\n",
      "Train Loss: 37484875.9517\n",
      "Val Loss: 36552927.9184, MAE: 5063.7153, NMAE: 77.2005, R^2: 0.0000\n",
      "Epoch [297/2000]\n",
      "Train Loss: 37544916.4621\n",
      "Val Loss: 36558305.2474, MAE: 5067.7905, NMAE: 77.2626, R^2: -0.0001\n",
      "Epoch [298/2000]\n",
      "Train Loss: 37518495.1129\n",
      "Val Loss: 36536268.6494, MAE: 5066.1704, NMAE: 77.2379, R^2: 0.0005\n",
      "Epoch [299/2000]\n",
      "Train Loss: 37468693.6560\n",
      "Val Loss: 36525047.6477, MAE: 5066.5684, NMAE: 77.2440, R^2: 0.0008\n",
      "Epoch [300/2000]\n",
      "Train Loss: 37411048.9560\n",
      "Val Loss: 36541274.2690, MAE: 5071.5815, NMAE: 77.3204, R^2: 0.0004\n",
      "Epoch [301/2000]\n",
      "Train Loss: 37718530.2966\n",
      "Val Loss: 36227183.8355, MAE: 4961.9092, NMAE: 75.6484, R^2: 0.0090\n",
      "Epoch [302/2000]\n",
      "Train Loss: 38361538.5052\n",
      "Val Loss: 37666032.0155, MAE: 5045.7847, NMAE: 76.9271, R^2: -0.0304\n",
      "Epoch [303/2000]\n",
      "Train Loss: 38653131.7190\n",
      "Val Loss: 37135476.2457, MAE: 5056.6670, NMAE: 77.0930, R^2: -0.0159\n",
      "Epoch [304/2000]\n",
      "Train Loss: 38232624.0853\n",
      "Val Loss: 37104689.0553, MAE: 5052.9341, NMAE: 77.0361, R^2: -0.0151\n",
      "Epoch [305/2000]\n",
      "Train Loss: 38027593.3681\n",
      "Val Loss: 37113007.9391, MAE: 5058.8447, NMAE: 77.1262, R^2: -0.0153\n",
      "Epoch [306/2000]\n",
      "Train Loss: 38156099.2086\n",
      "Val Loss: 36915600.9819, MAE: 5061.2437, NMAE: 77.1628, R^2: -0.0099\n",
      "Epoch [307/2000]\n",
      "Train Loss: 38015708.3509\n",
      "Val Loss: 36871778.0833, MAE: 5059.1738, NMAE: 77.1313, R^2: -0.0087\n",
      "Epoch [308/2000]\n",
      "Train Loss: 37779740.2517\n",
      "Val Loss: 36805597.6831, MAE: 5084.2007, NMAE: 77.5128, R^2: -0.0069\n",
      "Epoch [309/2000]\n",
      "Train Loss: 38042106.8155\n",
      "Val Loss: 36895023.4391, MAE: 5073.4165, NMAE: 77.3484, R^2: -0.0093\n",
      "Epoch [310/2000]\n",
      "Train Loss: 37920483.3164\n",
      "Val Loss: 36849114.6887, MAE: 5068.3193, NMAE: 77.2707, R^2: -0.0081\n",
      "Epoch [311/2000]\n",
      "Train Loss: 38064318.4810\n",
      "Val Loss: 36857983.4128, MAE: 5073.2925, NMAE: 77.3465, R^2: -0.0083\n",
      "Epoch [312/2000]\n",
      "Train Loss: 37841938.2552\n",
      "Val Loss: 36682045.5047, MAE: 5076.1982, NMAE: 77.3908, R^2: -0.0035\n",
      "Epoch [313/2000]\n",
      "Train Loss: 37638945.6991\n",
      "Val Loss: 36643689.6533, MAE: 5072.3433, NMAE: 77.3320, R^2: -0.0024\n",
      "Epoch [314/2000]\n",
      "Train Loss: 37632490.4664\n",
      "Val Loss: 36618819.9076, MAE: 5071.7529, NMAE: 77.3230, R^2: -0.0018\n",
      "Epoch [315/2000]\n",
      "Train Loss: 37561462.3310\n",
      "Val Loss: 36598747.4279, MAE: 5070.9478, NMAE: 77.3108, R^2: -0.0012\n",
      "Epoch [316/2000]\n",
      "Train Loss: 37576786.7724\n",
      "Val Loss: 36577980.3212, MAE: 5069.9038, NMAE: 77.2948, R^2: -0.0006\n",
      "Epoch [317/2000]\n",
      "Train Loss: 37578966.3957\n",
      "Val Loss: 36435377.7189, MAE: 5075.9067, NMAE: 77.3864, R^2: 0.0033\n",
      "Epoch [318/2000]\n",
      "Train Loss: 37331271.3224\n",
      "Val Loss: 36586604.7496, MAE: 5063.3169, NMAE: 77.1944, R^2: -0.0009\n",
      "Epoch [319/2000]\n",
      "Train Loss: 37149839.1293\n",
      "Val Loss: 36659930.9270, MAE: 5067.8096, NMAE: 77.2629, R^2: -0.0029\n",
      "Epoch [320/2000]\n",
      "Train Loss: 37049547.4621\n",
      "Val Loss: 36564293.0138, MAE: 5082.6855, NMAE: 77.4897, R^2: -0.0003\n",
      "Epoch [321/2000]\n",
      "Train Loss: 37026877.2353\n",
      "Val Loss: 36509199.3839, MAE: 5071.6343, NMAE: 77.3212, R^2: 0.0012\n",
      "Epoch [322/2000]\n",
      "Train Loss: 37127643.2888\n",
      "Val Loss: 36480181.8182, MAE: 5027.4136, NMAE: 76.6470, R^2: 0.0020\n",
      "Epoch [323/2000]\n",
      "Train Loss: 37939987.2233\n",
      "Val Loss: 36646149.2828, MAE: 5075.8428, NMAE: 77.3854, R^2: -0.0025\n",
      "Epoch [324/2000]\n",
      "Train Loss: 37345686.0638\n",
      "Val Loss: 36583614.2979, MAE: 5114.8384, NMAE: 77.9799, R^2: -0.0008\n",
      "Epoch [325/2000]\n",
      "Train Loss: 37539586.9233\n",
      "Val Loss: 36697379.2858, MAE: 5086.9819, NMAE: 77.5552, R^2: -0.0039\n",
      "Epoch [326/2000]\n",
      "Train Loss: 37457201.3474\n",
      "Val Loss: 36541226.0449, MAE: 5090.9492, NMAE: 77.6157, R^2: 0.0004\n",
      "Epoch [327/2000]\n",
      "Train Loss: 37213495.4302\n",
      "Val Loss: 36368284.2457, MAE: 5090.5259, NMAE: 77.6092, R^2: 0.0051\n",
      "Epoch [328/2000]\n",
      "Train Loss: 37197186.1922\n",
      "Val Loss: 36424589.9059, MAE: 5077.1235, NMAE: 77.4049, R^2: 0.0036\n",
      "Epoch [329/2000]\n",
      "Train Loss: 37262947.9638\n",
      "Val Loss: 36386446.0056, MAE: 5073.7852, NMAE: 77.3540, R^2: 0.0046\n",
      "Epoch [330/2000]\n",
      "Train Loss: 37221377.6603\n",
      "Val Loss: 36345652.2232, MAE: 5070.0254, NMAE: 77.2967, R^2: 0.0057\n",
      "Epoch [331/2000]\n",
      "Train Loss: 37183519.1509\n",
      "Val Loss: 36314964.5790, MAE: 5067.8604, NMAE: 77.2637, R^2: 0.0065\n",
      "Epoch [332/2000]\n",
      "Train Loss: 37152868.2784\n",
      "Val Loss: 36293341.4352, MAE: 5067.1758, NMAE: 77.2533, R^2: 0.0071\n",
      "Epoch [333/2000]\n",
      "Train Loss: 37132803.0078\n",
      "Val Loss: 36274577.8709, MAE: 5066.9355, NMAE: 77.2496, R^2: 0.0077\n",
      "Epoch [334/2000]\n",
      "Train Loss: 37232287.4009\n",
      "Val Loss: 36397745.2431, MAE: 5062.4829, NMAE: 77.1817, R^2: 0.0043\n",
      "Epoch [335/2000]\n",
      "Train Loss: 37306223.3017\n",
      "Val Loss: 36384663.3126, MAE: 5063.5493, NMAE: 77.1980, R^2: 0.0046\n",
      "Epoch [336/2000]\n",
      "Train Loss: 37279397.5595\n",
      "Val Loss: 36343469.8696, MAE: 5063.3848, NMAE: 77.1955, R^2: 0.0058\n",
      "Epoch [337/2000]\n",
      "Train Loss: 37058760.3164\n",
      "Val Loss: 36231836.0635, MAE: 5070.7466, NMAE: 77.3077, R^2: 0.0088\n",
      "Epoch [338/2000]\n",
      "Train Loss: 37153359.8836\n",
      "Val Loss: 36236589.0997, MAE: 5063.2759, NMAE: 77.1938, R^2: 0.0087\n",
      "Epoch [339/2000]\n",
      "Train Loss: 37144671.4474\n",
      "Val Loss: 36338069.4275, MAE: 5066.6943, NMAE: 77.2459, R^2: 0.0059\n",
      "Epoch [340/2000]\n",
      "Train Loss: 37201591.1060\n",
      "Val Loss: 36328987.7168, MAE: 5067.9854, NMAE: 77.2656, R^2: 0.0062\n",
      "Epoch [341/2000]\n",
      "Train Loss: 37178485.5474\n",
      "Val Loss: 36320156.4003, MAE: 5069.2671, NMAE: 77.2851, R^2: 0.0064\n",
      "Epoch [342/2000]\n",
      "Train Loss: 37157944.5931\n",
      "Val Loss: 36310131.2820, MAE: 5070.2832, NMAE: 77.3006, R^2: 0.0067\n",
      "Epoch [343/2000]\n",
      "Train Loss: 37137327.6026\n",
      "Val Loss: 36300966.6796, MAE: 5071.3833, NMAE: 77.3174, R^2: 0.0069\n",
      "Epoch [344/2000]\n",
      "Train Loss: 37248994.0302\n",
      "Val Loss: 36445327.9547, MAE: 5066.3120, NMAE: 77.2401, R^2: 0.0030\n",
      "Epoch [345/2000]\n",
      "Train Loss: 37358203.8638\n",
      "Val Loss: 36429564.2077, MAE: 5066.5894, NMAE: 77.2443, R^2: 0.0034\n",
      "Epoch [346/2000]\n",
      "Train Loss: 37330577.4655\n",
      "Val Loss: 36418361.6347, MAE: 5067.6016, NMAE: 77.2597, R^2: 0.0037\n",
      "Epoch [347/2000]\n",
      "Train Loss: 37325299.7328\n",
      "Val Loss: 36414403.1498, MAE: 5069.7822, NMAE: 77.2930, R^2: 0.0038\n",
      "Epoch [348/2000]\n",
      "Train Loss: 37298065.2353\n",
      "Val Loss: 36393107.0397, MAE: 5068.9497, NMAE: 77.2803, R^2: 0.0044\n",
      "Epoch [349/2000]\n",
      "Train Loss: 37409852.7638\n",
      "Val Loss: 36527234.4719, MAE: 5064.8130, NMAE: 77.2172, R^2: 0.0007\n",
      "Epoch [350/2000]\n",
      "Train Loss: 37355332.4388\n",
      "Val Loss: 36369250.6528, MAE: 5070.2158, NMAE: 77.2996, R^2: 0.0051\n",
      "Epoch [351/2000]\n",
      "Train Loss: 37222849.1284\n",
      "Val Loss: 36352228.4249, MAE: 5070.0947, NMAE: 77.2978, R^2: 0.0055\n",
      "Epoch [352/2000]\n",
      "Train Loss: 37195177.9526\n",
      "Val Loss: 36335709.8528, MAE: 5070.0117, NMAE: 77.2965, R^2: 0.0060\n",
      "Epoch [353/2000]\n",
      "Train Loss: 37131596.8172\n",
      "Val Loss: 36192978.4331, MAE: 5075.2896, NMAE: 77.3770, R^2: 0.0099\n",
      "Epoch [354/2000]\n",
      "Train Loss: 36929818.9155\n",
      "Val Loss: 36191571.5639, MAE: 5077.3418, NMAE: 77.4082, R^2: 0.0099\n",
      "Epoch [355/2000]\n",
      "Train Loss: 36904355.1595\n",
      "Val Loss: 36175495.7694, MAE: 5077.1162, NMAE: 77.4048, R^2: 0.0104\n",
      "Epoch [356/2000]\n",
      "Train Loss: 36737155.1164\n",
      "Val Loss: 36062359.4041, MAE: 5083.9277, NMAE: 77.5086, R^2: 0.0135\n",
      "Epoch [357/2000]\n",
      "Train Loss: 36653833.9612\n",
      "Val Loss: 36047462.8506, MAE: 5083.5972, NMAE: 77.5036, R^2: 0.0139\n",
      "Epoch [358/2000]\n",
      "Train Loss: 36633045.7233\n",
      "Val Loss: 36057671.2103, MAE: 5085.5137, NMAE: 77.5328, R^2: 0.0136\n",
      "Epoch [359/2000]\n",
      "Train Loss: 36614627.4483\n",
      "Val Loss: 36039793.8968, MAE: 5084.6460, NMAE: 77.5196, R^2: 0.0141\n",
      "Epoch [360/2000]\n",
      "Train Loss: 36718819.5776\n",
      "Val Loss: 36109432.3869, MAE: 5074.1577, NMAE: 77.3597, R^2: 0.0122\n",
      "Epoch [361/2000]\n",
      "Train Loss: 36792880.3957\n",
      "Val Loss: 36126574.6136, MAE: 5076.0669, NMAE: 77.3888, R^2: 0.0117\n",
      "Epoch [362/2000]\n",
      "Train Loss: 36879944.5707\n",
      "Val Loss: 36063891.7578, MAE: 5056.0195, NMAE: 77.0832, R^2: 0.0134\n",
      "Epoch [363/2000]\n",
      "Train Loss: 36591744.8009\n",
      "Val Loss: 36063535.4193, MAE: 5054.9233, NMAE: 77.0665, R^2: 0.0134\n",
      "Epoch [364/2000]\n",
      "Train Loss: 37177267.3147\n",
      "Val Loss: 36468646.3649, MAE: 5113.4429, NMAE: 77.9586, R^2: 0.0023\n",
      "Epoch [365/2000]\n",
      "Train Loss: 36905503.5784\n",
      "Val Loss: 36270515.3890, MAE: 5109.0249, NMAE: 77.8913, R^2: 0.0078\n",
      "Epoch [366/2000]\n",
      "Train Loss: 36450577.6509\n",
      "Val Loss: 35992080.5367, MAE: 5110.6289, NMAE: 77.9157, R^2: 0.0154\n",
      "Epoch [367/2000]\n",
      "Train Loss: 36321279.4966\n",
      "Val Loss: 35927076.8895, MAE: 5101.6636, NMAE: 77.7790, R^2: 0.0172\n",
      "Epoch [368/2000]\n",
      "Train Loss: 36238450.4664\n",
      "Val Loss: 36048123.7737, MAE: 5104.9819, NMAE: 77.8296, R^2: 0.0138\n",
      "Epoch [369/2000]\n",
      "Train Loss: 36820285.3922\n",
      "Val Loss: 35819147.5415, MAE: 5070.3730, NMAE: 77.3020, R^2: 0.0201\n",
      "Epoch [370/2000]\n",
      "Train Loss: 36499852.8069\n",
      "Val Loss: 35941334.1187, MAE: 5068.4736, NMAE: 77.2730, R^2: 0.0168\n",
      "Epoch [371/2000]\n",
      "Train Loss: 36443138.9103\n",
      "Val Loss: 35815046.9728, MAE: 5071.9941, NMAE: 77.3267, R^2: 0.0202\n",
      "Epoch [372/2000]\n",
      "Train Loss: 36086829.6897\n",
      "Val Loss: 35755004.5440, MAE: 5085.3560, NMAE: 77.5304, R^2: 0.0219\n",
      "Epoch [373/2000]\n",
      "Train Loss: 36233714.9621\n",
      "Val Loss: 35709082.6701, MAE: 5080.4556, NMAE: 77.4557, R^2: 0.0231\n",
      "Epoch [374/2000]\n",
      "Train Loss: 36473551.8560\n",
      "Val Loss: 35659851.5972, MAE: 5044.9321, NMAE: 76.9141, R^2: 0.0245\n",
      "Epoch [375/2000]\n",
      "Train Loss: 36300368.1793\n",
      "Val Loss: 35578492.3342, MAE: 5063.3853, NMAE: 77.1955, R^2: 0.0267\n",
      "Epoch [376/2000]\n",
      "Train Loss: 36094387.0552\n",
      "Val Loss: 35422751.7032, MAE: 4936.4761, NMAE: 75.2606, R^2: 0.0310\n",
      "Epoch [377/2000]\n",
      "Train Loss: 36653609.4112\n",
      "Val Loss: 35370236.7543, MAE: 5007.9448, NMAE: 76.3502, R^2: 0.0324\n",
      "Epoch [378/2000]\n",
      "Train Loss: 36869335.8328\n",
      "Val Loss: 35461226.2668, MAE: 4969.8608, NMAE: 75.7696, R^2: 0.0299\n",
      "Epoch [379/2000]\n",
      "Train Loss: 36315582.4888\n",
      "Val Loss: 35420667.6446, MAE: 4996.1631, NMAE: 76.1706, R^2: 0.0310\n",
      "Epoch [380/2000]\n",
      "Train Loss: 36430279.3302\n",
      "Val Loss: 35381806.4512, MAE: 4993.5698, NMAE: 76.1311, R^2: 0.0321\n",
      "Epoch [381/2000]\n",
      "Train Loss: 36323989.8362\n",
      "Val Loss: 35482992.1494, MAE: 5053.4565, NMAE: 77.0441, R^2: 0.0293\n",
      "Epoch [382/2000]\n",
      "Train Loss: 35966008.9121\n",
      "Val Loss: 35441502.4633, MAE: 5057.6094, NMAE: 77.1074, R^2: 0.0304\n",
      "Epoch [383/2000]\n",
      "Train Loss: 35843607.6457\n",
      "Val Loss: 35320932.3795, MAE: 5037.9272, NMAE: 76.8073, R^2: 0.0337\n",
      "Epoch [384/2000]\n",
      "Train Loss: 35817303.4474\n",
      "Val Loss: 35313707.4396, MAE: 5035.7510, NMAE: 76.7742, R^2: 0.0339\n",
      "Epoch [385/2000]\n",
      "Train Loss: 35887863.6690\n",
      "Val Loss: 35293800.9188, MAE: 5001.0942, NMAE: 76.2458, R^2: 0.0345\n",
      "Epoch [386/2000]\n",
      "Train Loss: 35813925.7681\n",
      "Val Loss: 35326005.4538, MAE: 5041.8721, NMAE: 76.8675, R^2: 0.0336\n",
      "Epoch [387/2000]\n",
      "Train Loss: 35723677.2474\n",
      "Val Loss: 35298214.4810, MAE: 5040.1099, NMAE: 76.8406, R^2: 0.0344\n",
      "Epoch [388/2000]\n",
      "Train Loss: 35695968.4526\n",
      "Val Loss: 35283360.8813, MAE: 5037.5366, NMAE: 76.8014, R^2: 0.0348\n",
      "Epoch [389/2000]\n",
      "Train Loss: 35693621.1233\n",
      "Val Loss: 35278318.3165, MAE: 5042.2983, NMAE: 76.8740, R^2: 0.0349\n",
      "Epoch [390/2000]\n",
      "Train Loss: 35661090.9466\n",
      "Val Loss: 35265637.5216, MAE: 5038.5884, NMAE: 76.8174, R^2: 0.0353\n",
      "Epoch [391/2000]\n",
      "Train Loss: 35632977.9603\n",
      "Val Loss: 35264730.8692, MAE: 5040.7998, NMAE: 76.8511, R^2: 0.0353\n",
      "Epoch [392/2000]\n",
      "Train Loss: 35655773.8509\n",
      "Val Loss: 35260646.1792, MAE: 5047.3335, NMAE: 76.9507, R^2: 0.0354\n",
      "Epoch [393/2000]\n",
      "Train Loss: 35643910.4086\n",
      "Val Loss: 35247170.4996, MAE: 5044.0747, NMAE: 76.9011, R^2: 0.0358\n",
      "Epoch [394/2000]\n",
      "Train Loss: 35642627.2612\n",
      "Val Loss: 35277544.9875, MAE: 5039.1538, NMAE: 76.8260, R^2: 0.0349\n",
      "Epoch [395/2000]\n",
      "Train Loss: 35850675.7784\n",
      "Val Loss: 35247984.1680, MAE: 5048.5908, NMAE: 76.9699, R^2: 0.0357\n",
      "Epoch [396/2000]\n",
      "Train Loss: 35623191.8474\n",
      "Val Loss: 35303960.9344, MAE: 5059.7798, NMAE: 77.1405, R^2: 0.0342\n",
      "Epoch [397/2000]\n",
      "Train Loss: 35593466.5043\n",
      "Val Loss: 35263430.4961, MAE: 5054.7295, NMAE: 77.0635, R^2: 0.0353\n",
      "Epoch [398/2000]\n",
      "Train Loss: 35542516.4052\n",
      "Val Loss: 35236435.6226, MAE: 5050.4214, NMAE: 76.9978, R^2: 0.0361\n",
      "Epoch [399/2000]\n",
      "Train Loss: 35622279.1362\n",
      "Val Loss: 35312773.8307, MAE: 5051.6318, NMAE: 77.0163, R^2: 0.0340\n",
      "Epoch [400/2000]\n",
      "Train Loss: 35564531.8491\n",
      "Val Loss: 35291757.8057, MAE: 5052.1069, NMAE: 77.0235, R^2: 0.0345\n",
      "Epoch [401/2000]\n",
      "Train Loss: 35528565.9922\n",
      "Val Loss: 35241936.8992, MAE: 5042.9648, NMAE: 76.8841, R^2: 0.0359\n",
      "Epoch [402/2000]\n",
      "Train Loss: 35468288.7026\n",
      "Val Loss: 35236078.2379, MAE: 5041.7090, NMAE: 76.8650, R^2: 0.0361\n",
      "Epoch [403/2000]\n",
      "Train Loss: 35515711.1216\n",
      "Val Loss: 35275644.8055, MAE: 5054.1299, NMAE: 77.0544, R^2: 0.0350\n",
      "Epoch [404/2000]\n",
      "Train Loss: 35449324.5845\n",
      "Val Loss: 35209575.6434, MAE: 5042.3638, NMAE: 76.8750, R^2: 0.0368\n",
      "Epoch [405/2000]\n",
      "Train Loss: 35412975.0345\n",
      "Val Loss: 35270305.8767, MAE: 5046.6606, NMAE: 76.9405, R^2: 0.0351\n",
      "Epoch [406/2000]\n",
      "Train Loss: 35453835.0293\n",
      "Val Loss: 35177597.2826, MAE: 5049.3770, NMAE: 76.9819, R^2: 0.0377\n",
      "Epoch [407/2000]\n",
      "Train Loss: 35426588.6336\n",
      "Val Loss: 35078239.3359, MAE: 5046.4136, NMAE: 76.9367, R^2: 0.0404\n",
      "Epoch [408/2000]\n",
      "Train Loss: 35408391.2379\n",
      "Val Loss: 35036615.3640, MAE: 5040.4663, NMAE: 76.8460, R^2: 0.0415\n",
      "Epoch [409/2000]\n",
      "Train Loss: 35394827.3569\n",
      "Val Loss: 35023131.1416, MAE: 5039.2671, NMAE: 76.8278, R^2: 0.0419\n",
      "Epoch [410/2000]\n",
      "Train Loss: 35346873.7069\n",
      "Val Loss: 35017770.2522, MAE: 5039.6387, NMAE: 76.8334, R^2: 0.0420\n",
      "Epoch [411/2000]\n",
      "Train Loss: 35320577.9888\n",
      "Val Loss: 35011052.3618, MAE: 5040.0874, NMAE: 76.8403, R^2: 0.0422\n",
      "Epoch [412/2000]\n",
      "Train Loss: 35290108.0853\n",
      "Val Loss: 35007442.6567, MAE: 5041.5581, NMAE: 76.8627, R^2: 0.0423\n",
      "Epoch [413/2000]\n",
      "Train Loss: 35271745.3603\n",
      "Val Loss: 35002387.8782, MAE: 5041.9746, NMAE: 76.8690, R^2: 0.0425\n",
      "Epoch [414/2000]\n",
      "Train Loss: 35251702.8414\n",
      "Val Loss: 34992834.0004, MAE: 5042.4873, NMAE: 76.8769, R^2: 0.0427\n",
      "Epoch [415/2000]\n",
      "Train Loss: 35225382.6466\n",
      "Val Loss: 34981956.0479, MAE: 5040.7905, NMAE: 76.8510, R^2: 0.0430\n",
      "Epoch [416/2000]\n",
      "Train Loss: 35204499.5931\n",
      "Val Loss: 34982981.8411, MAE: 5043.7852, NMAE: 76.8966, R^2: 0.0430\n",
      "Epoch [417/2000]\n",
      "Train Loss: 35199654.6526\n",
      "Val Loss: 34964858.7845, MAE: 5040.1802, NMAE: 76.8417, R^2: 0.0435\n",
      "Epoch [418/2000]\n",
      "Train Loss: 35185282.8957\n",
      "Val Loss: 35041206.8182, MAE: 5046.1416, NMAE: 76.9326, R^2: 0.0414\n",
      "Epoch [419/2000]\n",
      "Train Loss: 35165747.0259\n",
      "Val Loss: 34940863.4706, MAE: 5041.0947, NMAE: 76.8556, R^2: 0.0441\n",
      "Epoch [420/2000]\n",
      "Train Loss: 35130920.2586\n",
      "Val Loss: 35003460.6848, MAE: 5044.8110, NMAE: 76.9123, R^2: 0.0424\n",
      "Epoch [421/2000]\n",
      "Train Loss: 35182842.4612\n",
      "Val Loss: 34894938.5885, MAE: 5035.8784, NMAE: 76.7761, R^2: 0.0454\n",
      "Epoch [422/2000]\n",
      "Train Loss: 34992871.8095\n",
      "Val Loss: 34864150.7530, MAE: 5028.5312, NMAE: 76.6641, R^2: 0.0462\n",
      "Epoch [423/2000]\n",
      "Train Loss: 34982932.4198\n",
      "Val Loss: 34883161.9465, MAE: 5032.1646, NMAE: 76.7195, R^2: 0.0457\n",
      "Epoch [424/2000]\n",
      "Train Loss: 35029690.0707\n",
      "Val Loss: 34857116.4685, MAE: 5028.6899, NMAE: 76.6665, R^2: 0.0464\n",
      "Epoch [425/2000]\n",
      "Train Loss: 34934492.5957\n",
      "Val Loss: 34910643.3493, MAE: 5039.1167, NMAE: 76.8255, R^2: 0.0450\n",
      "Epoch [426/2000]\n",
      "Train Loss: 35009036.4431\n",
      "Val Loss: 34914094.3476, MAE: 5038.0527, NMAE: 76.8092, R^2: 0.0449\n",
      "Epoch [427/2000]\n",
      "Train Loss: 34972692.1017\n",
      "Val Loss: 34915616.2627, MAE: 5038.2046, NMAE: 76.8116, R^2: 0.0448\n",
      "Epoch [428/2000]\n",
      "Train Loss: 35163088.5328\n",
      "Val Loss: 34921790.5298, MAE: 5031.2988, NMAE: 76.7063, R^2: 0.0447\n",
      "Epoch [429/2000]\n",
      "Train Loss: 35078049.4034\n",
      "Val Loss: 34811150.9581, MAE: 5033.8223, NMAE: 76.7448, R^2: 0.0477\n",
      "Epoch [430/2000]\n",
      "Train Loss: 35019109.2302\n",
      "Val Loss: 34860374.8463, MAE: 5042.9297, NMAE: 76.8836, R^2: 0.0463\n",
      "Epoch [431/2000]\n",
      "Train Loss: 35013465.9914\n",
      "Val Loss: 34770416.4227, MAE: 5032.3076, NMAE: 76.7217, R^2: 0.0488\n",
      "Epoch [432/2000]\n",
      "Train Loss: 34956322.0491\n",
      "Val Loss: 34742277.4927, MAE: 5027.4360, NMAE: 76.6474, R^2: 0.0496\n",
      "Epoch [433/2000]\n",
      "Train Loss: 34881274.2414\n",
      "Val Loss: 34745132.7392, MAE: 5028.1816, NMAE: 76.6588, R^2: 0.0495\n",
      "Epoch [434/2000]\n",
      "Train Loss: 34845447.2905\n",
      "Val Loss: 34735711.2556, MAE: 5032.2866, NMAE: 76.7213, R^2: 0.0498\n",
      "Epoch [435/2000]\n",
      "Train Loss: 34965163.8336\n",
      "Val Loss: 34657311.5976, MAE: 5019.2583, NMAE: 76.5227, R^2: 0.0519\n",
      "Epoch [436/2000]\n",
      "Train Loss: 34885778.6172\n",
      "Val Loss: 34740261.3256, MAE: 5032.5361, NMAE: 76.7251, R^2: 0.0496\n",
      "Epoch [437/2000]\n",
      "Train Loss: 34830363.5431\n",
      "Val Loss: 34742120.6736, MAE: 5035.5181, NMAE: 76.7706, R^2: 0.0496\n",
      "Epoch [438/2000]\n",
      "Train Loss: 34842089.0733\n",
      "Val Loss: 34788942.6028, MAE: 5017.5796, NMAE: 76.4971, R^2: 0.0483\n",
      "Epoch [439/2000]\n",
      "Train Loss: 34914596.3996\n",
      "Val Loss: 34725940.5933, MAE: 5022.9556, NMAE: 76.5791, R^2: 0.0500\n",
      "Epoch [440/2000]\n",
      "Train Loss: 35237977.7664\n",
      "Val Loss: 34738277.3631, MAE: 5028.4438, NMAE: 76.6628, R^2: 0.0497\n",
      "Epoch [441/2000]\n",
      "Train Loss: 35119674.7612\n",
      "Val Loss: 34629861.6822, MAE: 5004.2070, NMAE: 76.2932, R^2: 0.0526\n",
      "Epoch [442/2000]\n",
      "Train Loss: 35108036.1422\n",
      "Val Loss: 34570287.0177, MAE: 4995.6636, NMAE: 76.1630, R^2: 0.0543\n",
      "Epoch [443/2000]\n",
      "Train Loss: 35063271.6802\n",
      "Val Loss: 34570851.3597, MAE: 4998.8809, NMAE: 76.2120, R^2: 0.0543\n",
      "Epoch [444/2000]\n",
      "Train Loss: 34997050.3621\n",
      "Val Loss: 34578365.7686, MAE: 5002.2959, NMAE: 76.2641, R^2: 0.0541\n",
      "Epoch [445/2000]\n",
      "Train Loss: 34942074.9129\n",
      "Val Loss: 34603618.0665, MAE: 5008.6128, NMAE: 76.3604, R^2: 0.0534\n",
      "Epoch [446/2000]\n",
      "Train Loss: 34954334.4948\n",
      "Val Loss: 34560315.1239, MAE: 5003.2441, NMAE: 76.2786, R^2: 0.0546\n",
      "Epoch [447/2000]\n",
      "Train Loss: 34926551.3517\n",
      "Val Loss: 34538236.8761, MAE: 5000.9541, NMAE: 76.2436, R^2: 0.0552\n",
      "Epoch [448/2000]\n",
      "Train Loss: 34878421.1190\n",
      "Val Loss: 34591150.6606, MAE: 5012.5513, NMAE: 76.4205, R^2: 0.0537\n",
      "Epoch [449/2000]\n",
      "Train Loss: 34837111.4716\n",
      "Val Loss: 34576860.9780, MAE: 5010.4951, NMAE: 76.3891, R^2: 0.0541\n",
      "Epoch [450/2000]\n",
      "Train Loss: 34848293.0086\n",
      "Val Loss: 34644817.5514, MAE: 5022.7373, NMAE: 76.5758, R^2: 0.0522\n",
      "Epoch [451/2000]\n",
      "Train Loss: 34774602.2647\n",
      "Val Loss: 34636070.8510, MAE: 5023.0625, NMAE: 76.5807, R^2: 0.0525\n",
      "Epoch [452/2000]\n",
      "Train Loss: 34906168.7655\n",
      "Val Loss: 34615495.1408, MAE: 5019.1577, NMAE: 76.5212, R^2: 0.0530\n",
      "Epoch [453/2000]\n",
      "Train Loss: 34888377.8509\n",
      "Val Loss: 34546478.8739, MAE: 5010.9648, NMAE: 76.3963, R^2: 0.0549\n",
      "Epoch [454/2000]\n",
      "Train Loss: 34800764.3371\n",
      "Val Loss: 34611143.5449, MAE: 5022.5679, NMAE: 76.5732, R^2: 0.0532\n",
      "Epoch [455/2000]\n",
      "Train Loss: 34669756.2190\n",
      "Val Loss: 34680561.3364, MAE: 5033.0215, NMAE: 76.7325, R^2: 0.0513\n",
      "Epoch [456/2000]\n",
      "Train Loss: 34738336.7690\n",
      "Val Loss: 34637924.6356, MAE: 5029.3066, NMAE: 76.6759, R^2: 0.0524\n",
      "Epoch [457/2000]\n",
      "Train Loss: 34625437.4224\n",
      "Val Loss: 34800092.6222, MAE: 5056.0586, NMAE: 77.0838, R^2: 0.0480\n",
      "Epoch [458/2000]\n",
      "Train Loss: 34788041.7198\n",
      "Val Loss: 34568878.7146, MAE: 5023.0093, NMAE: 76.5799, R^2: 0.0543\n",
      "Epoch [459/2000]\n",
      "Train Loss: 34675288.6034\n",
      "Val Loss: 34521022.4037, MAE: 5016.2485, NMAE: 76.4768, R^2: 0.0556\n",
      "Epoch [460/2000]\n",
      "Train Loss: 34581467.0345\n",
      "Val Loss: 34528211.1718, MAE: 5019.2456, NMAE: 76.5225, R^2: 0.0554\n",
      "Epoch [461/2000]\n",
      "Train Loss: 34615743.5664\n",
      "Val Loss: 34569012.3459, MAE: 5025.6978, NMAE: 76.6209, R^2: 0.0543\n",
      "Epoch [462/2000]\n",
      "Train Loss: 34693840.9543\n",
      "Val Loss: 34551173.4072, MAE: 5022.9385, NMAE: 76.5788, R^2: 0.0548\n",
      "Epoch [463/2000]\n",
      "Train Loss: 34566971.9578\n",
      "Val Loss: 34522733.2979, MAE: 5020.5723, NMAE: 76.5427, R^2: 0.0556\n",
      "Epoch [464/2000]\n",
      "Train Loss: 34775476.6543\n",
      "Val Loss: 34636383.2647, MAE: 5038.1216, NMAE: 76.8103, R^2: 0.0525\n",
      "Epoch [465/2000]\n",
      "Train Loss: 34660997.7983\n",
      "Val Loss: 34507442.3307, MAE: 5020.2783, NMAE: 76.5383, R^2: 0.0560\n",
      "Epoch [466/2000]\n",
      "Train Loss: 34506577.3517\n",
      "Val Loss: 34472215.7336, MAE: 5014.4805, NMAE: 76.4499, R^2: 0.0570\n",
      "Epoch [467/2000]\n",
      "Train Loss: 34598271.6250\n",
      "Val Loss: 34482567.6351, MAE: 5019.7793, NMAE: 76.5307, R^2: 0.0567\n",
      "Epoch [468/2000]\n",
      "Train Loss: 34546034.5086\n",
      "Val Loss: 34499803.4439, MAE: 5021.3003, NMAE: 76.5538, R^2: 0.0562\n",
      "Epoch [469/2000]\n",
      "Train Loss: 34525581.4259\n",
      "Val Loss: 34583365.9775, MAE: 5023.1675, NMAE: 76.5823, R^2: 0.0539\n",
      "Epoch [470/2000]\n",
      "Train Loss: 34364455.1431\n",
      "Val Loss: 34502387.2111, MAE: 5014.1104, NMAE: 76.4442, R^2: 0.0561\n",
      "Epoch [471/2000]\n",
      "Train Loss: 34425726.4164\n",
      "Val Loss: 34411705.2565, MAE: 5007.6558, NMAE: 76.3458, R^2: 0.0586\n",
      "Epoch [472/2000]\n",
      "Train Loss: 34505904.9603\n",
      "Val Loss: 34569211.5756, MAE: 5018.6152, NMAE: 76.5129, R^2: 0.0543\n",
      "Epoch [473/2000]\n",
      "Train Loss: 34368818.8220\n",
      "Val Loss: 34593729.0479, MAE: 5016.5239, NMAE: 76.4810, R^2: 0.0536\n",
      "Epoch [474/2000]\n",
      "Train Loss: 34287298.8802\n",
      "Val Loss: 34544237.8569, MAE: 5007.1816, NMAE: 76.3386, R^2: 0.0550\n",
      "Epoch [475/2000]\n",
      "Train Loss: 34499363.6690\n",
      "Val Loss: 34581510.9357, MAE: 5042.0000, NMAE: 76.8694, R^2: 0.0540\n",
      "Epoch [476/2000]\n",
      "Train Loss: 34392468.9948\n",
      "Val Loss: 34400476.2880, MAE: 5017.7212, NMAE: 76.4993, R^2: 0.0589\n",
      "Epoch [477/2000]\n",
      "Train Loss: 35051227.7388\n",
      "Val Loss: 34986717.3299, MAE: 4984.8652, NMAE: 75.9984, R^2: 0.0429\n",
      "Epoch [478/2000]\n",
      "Train Loss: 35372331.3983\n",
      "Val Loss: 34895370.0367, MAE: 4998.6392, NMAE: 76.2084, R^2: 0.0454\n",
      "Epoch [479/2000]\n",
      "Train Loss: 35312269.4198\n",
      "Val Loss: 34779153.7245, MAE: 5002.9487, NMAE: 76.2741, R^2: 0.0486\n",
      "Epoch [480/2000]\n",
      "Train Loss: 35369370.7767\n",
      "Val Loss: 34757055.8994, MAE: 4991.0142, NMAE: 76.0921, R^2: 0.0492\n",
      "Epoch [481/2000]\n",
      "Train Loss: 34895414.0672\n",
      "Val Loss: 34709543.4706, MAE: 4993.8540, NMAE: 76.1354, R^2: 0.0505\n",
      "Epoch [482/2000]\n",
      "Train Loss: 34986198.3552\n",
      "Val Loss: 34680586.8700, MAE: 4992.7749, NMAE: 76.1189, R^2: 0.0513\n",
      "Epoch [483/2000]\n",
      "Train Loss: 34892507.7000\n",
      "Val Loss: 34624454.2750, MAE: 5007.9717, NMAE: 76.3506, R^2: 0.0528\n",
      "Epoch [484/2000]\n",
      "Train Loss: 34832005.0603\n",
      "Val Loss: 34571353.3005, MAE: 4995.8159, NMAE: 76.1653, R^2: 0.0542\n",
      "Epoch [485/2000]\n",
      "Train Loss: 35359866.5664\n",
      "Val Loss: 34452989.6649, MAE: 4946.6528, NMAE: 75.4158, R^2: 0.0575\n",
      "Epoch [486/2000]\n",
      "Train Loss: 34747692.8095\n",
      "Val Loss: 34634371.5820, MAE: 5011.3701, NMAE: 76.4024, R^2: 0.0525\n",
      "Epoch [487/2000]\n",
      "Train Loss: 34693319.1888\n",
      "Val Loss: 34597085.9883, MAE: 5002.5854, NMAE: 76.2685, R^2: 0.0535\n",
      "Epoch [488/2000]\n",
      "Train Loss: 34645004.7690\n",
      "Val Loss: 34516115.9400, MAE: 4986.4561, NMAE: 76.0226, R^2: 0.0558\n",
      "Epoch [489/2000]\n",
      "Train Loss: 35123268.2733\n",
      "Val Loss: 34589952.4266, MAE: 4951.1440, NMAE: 75.4843, R^2: 0.0537\n",
      "Epoch [490/2000]\n",
      "Train Loss: 35222959.7552\n",
      "Val Loss: 34766239.4374, MAE: 4998.6523, NMAE: 76.2086, R^2: 0.0489\n",
      "Epoch [491/2000]\n",
      "Train Loss: 34838003.9198\n",
      "Val Loss: 34689940.1852, MAE: 5018.7500, NMAE: 76.5150, R^2: 0.0510\n",
      "Epoch [492/2000]\n",
      "Train Loss: 34849275.3914\n",
      "Val Loss: 34536111.2824, MAE: 4990.3003, NMAE: 76.0812, R^2: 0.0552\n",
      "Epoch [493/2000]\n",
      "Train Loss: 34832663.7457\n",
      "Val Loss: 34608417.7202, MAE: 4997.6143, NMAE: 76.1927, R^2: 0.0532\n",
      "Epoch [494/2000]\n",
      "Train Loss: 34698635.6776\n",
      "Val Loss: 34599000.1390, MAE: 4995.1182, NMAE: 76.1547, R^2: 0.0535\n",
      "Epoch [495/2000]\n",
      "Train Loss: 34591886.4315\n",
      "Val Loss: 34767624.5160, MAE: 5023.4893, NMAE: 76.5872, R^2: 0.0489\n",
      "Epoch [496/2000]\n",
      "Train Loss: 34595236.5366\n",
      "Val Loss: 34701486.0514, MAE: 5007.7192, NMAE: 76.3468, R^2: 0.0507\n",
      "Epoch [497/2000]\n",
      "Train Loss: 35295064.7961\n",
      "Val Loss: 34684119.2152, MAE: 4981.5166, NMAE: 75.9473, R^2: 0.0512\n",
      "Epoch [498/2000]\n",
      "Train Loss: 35231429.4862\n",
      "Val Loss: 34553995.8247, MAE: 4945.2397, NMAE: 75.3942, R^2: 0.0547\n",
      "Epoch [499/2000]\n",
      "Train Loss: 36373011.5414\n",
      "Val Loss: 35788866.9185, MAE: 4981.1519, NMAE: 75.9417, R^2: 0.0209\n",
      "Epoch [500/2000]\n",
      "Train Loss: 36135421.7095\n",
      "Val Loss: 35617445.5786, MAE: 5003.6040, NMAE: 76.2840, R^2: 0.0256\n",
      "Epoch [501/2000]\n",
      "Train Loss: 35775620.7897\n",
      "Val Loss: 35544223.5231, MAE: 4999.4878, NMAE: 76.2213, R^2: 0.0276\n",
      "Epoch [502/2000]\n",
      "Train Loss: 36016115.9030\n",
      "Val Loss: 35308650.2526, MAE: 4996.5210, NMAE: 76.1761, R^2: 0.0341\n",
      "Epoch [503/2000]\n",
      "Train Loss: 35179046.4302\n",
      "Val Loss: 35370298.0186, MAE: 5026.2930, NMAE: 76.6300, R^2: 0.0324\n",
      "Epoch [504/2000]\n",
      "Train Loss: 35367641.4418\n",
      "Val Loss: 35276065.4553, MAE: 5017.4424, NMAE: 76.4950, R^2: 0.0350\n",
      "Epoch [505/2000]\n",
      "Train Loss: 35300920.6194\n",
      "Val Loss: 35037235.8877, MAE: 5004.8853, NMAE: 76.3036, R^2: 0.0415\n",
      "Epoch [506/2000]\n",
      "Train Loss: 34994133.8862\n",
      "Val Loss: 34641525.8882, MAE: 5030.8623, NMAE: 76.6996, R^2: 0.0523\n",
      "Epoch [507/2000]\n",
      "Train Loss: 34326375.5190\n",
      "Val Loss: 33967229.7664, MAE: 4951.5942, NMAE: 75.4911, R^2: 0.0708\n",
      "Epoch [508/2000]\n",
      "Train Loss: 34145686.8138\n",
      "Val Loss: 33952260.5617, MAE: 4950.9248, NMAE: 75.4809, R^2: 0.0712\n",
      "Epoch [509/2000]\n",
      "Train Loss: 34169237.8224\n",
      "Val Loss: 34179204.0557, MAE: 4994.1172, NMAE: 76.1394, R^2: 0.0650\n",
      "Epoch [510/2000]\n",
      "Train Loss: 34085486.3517\n",
      "Val Loss: 34141189.0354, MAE: 4988.9058, NMAE: 76.0600, R^2: 0.0660\n",
      "Epoch [511/2000]\n",
      "Train Loss: 33984818.4534\n",
      "Val Loss: 34181486.8407, MAE: 4980.2153, NMAE: 75.9275, R^2: 0.0649\n",
      "Epoch [512/2000]\n",
      "Train Loss: 34077058.0931\n",
      "Val Loss: 34348428.8765, MAE: 4996.5493, NMAE: 76.1765, R^2: 0.0603\n",
      "Epoch [513/2000]\n",
      "Train Loss: 34150960.1147\n",
      "Val Loss: 34198503.2966, MAE: 4992.1479, NMAE: 76.1094, R^2: 0.0644\n",
      "Epoch [514/2000]\n",
      "Train Loss: 33946119.4207\n",
      "Val Loss: 34300530.4005, MAE: 4996.8091, NMAE: 76.1805, R^2: 0.0617\n",
      "Epoch [515/2000]\n",
      "Train Loss: 34779355.2190\n",
      "Val Loss: 34258431.5928, MAE: 4982.6406, NMAE: 75.9644, R^2: 0.0628\n",
      "Epoch [516/2000]\n",
      "Train Loss: 34080166.3552\n",
      "Val Loss: 34404587.5807, MAE: 5002.1074, NMAE: 76.2612, R^2: 0.0588\n",
      "Epoch [517/2000]\n",
      "Train Loss: 34030514.9000\n",
      "Val Loss: 34414796.3843, MAE: 5008.2363, NMAE: 76.3547, R^2: 0.0585\n",
      "Epoch [518/2000]\n",
      "Train Loss: 34897653.7517\n",
      "Val Loss: 34113858.3804, MAE: 4937.3965, NMAE: 75.2747, R^2: 0.0668\n",
      "Epoch [519/2000]\n",
      "Train Loss: 35115335.0336\n",
      "Val Loss: 35582673.0820, MAE: 5158.7051, NMAE: 78.6487, R^2: 0.0266\n",
      "Epoch [520/2000]\n",
      "Train Loss: 34898747.6457\n",
      "Val Loss: 35053875.7457, MAE: 5086.9883, NMAE: 77.5553, R^2: 0.0410\n",
      "Epoch [521/2000]\n",
      "Train Loss: 34865046.9879\n",
      "Val Loss: 34914145.7966, MAE: 5084.6626, NMAE: 77.5199, R^2: 0.0449\n",
      "Epoch [522/2000]\n",
      "Train Loss: 34290673.9784\n",
      "Val Loss: 34125645.7483, MAE: 5007.8096, NMAE: 76.3482, R^2: 0.0664\n",
      "Epoch [523/2000]\n",
      "Train Loss: 34082871.3302\n",
      "Val Loss: 33941356.6390, MAE: 4979.7446, NMAE: 75.9203, R^2: 0.0715\n",
      "Epoch [524/2000]\n",
      "Train Loss: 34167530.0431\n",
      "Val Loss: 33966808.5946, MAE: 4982.6035, NMAE: 75.9639, R^2: 0.0708\n",
      "Epoch [525/2000]\n",
      "Train Loss: 33773159.0448\n",
      "Val Loss: 34057666.9298, MAE: 4986.4702, NMAE: 76.0228, R^2: 0.0683\n",
      "Epoch [526/2000]\n",
      "Train Loss: 34100637.1164\n",
      "Val Loss: 34095893.0278, MAE: 4985.1470, NMAE: 76.0027, R^2: 0.0673\n",
      "Epoch [527/2000]\n",
      "Train Loss: 33959727.9720\n",
      "Val Loss: 34184617.7595, MAE: 4986.0620, NMAE: 76.0166, R^2: 0.0648\n",
      "Epoch [528/2000]\n",
      "Train Loss: 34047431.5073\n",
      "Val Loss: 34026933.9400, MAE: 5003.3398, NMAE: 76.2800, R^2: 0.0691\n",
      "Epoch [529/2000]\n",
      "Train Loss: 33895041.2241\n",
      "Val Loss: 34039826.7319, MAE: 5003.8696, NMAE: 76.2881, R^2: 0.0688\n",
      "Epoch [530/2000]\n",
      "Train Loss: 33814190.7655\n",
      "Val Loss: 34130745.9996, MAE: 5011.6309, NMAE: 76.4064, R^2: 0.0663\n",
      "Epoch [531/2000]\n",
      "Train Loss: 33782072.9698\n",
      "Val Loss: 34148061.0216, MAE: 5011.3281, NMAE: 76.4018, R^2: 0.0658\n",
      "Epoch [532/2000]\n",
      "Train Loss: 33763255.3414\n",
      "Val Loss: 34085189.6680, MAE: 5011.4448, NMAE: 76.4036, R^2: 0.0675\n",
      "Epoch [533/2000]\n",
      "Train Loss: 33779040.3267\n",
      "Val Loss: 34001781.3117, MAE: 5000.5869, NMAE: 76.2380, R^2: 0.0698\n",
      "Epoch [534/2000]\n",
      "Train Loss: 33897855.6517\n",
      "Val Loss: 34026333.0155, MAE: 4991.2993, NMAE: 76.0965, R^2: 0.0692\n",
      "Epoch [535/2000]\n",
      "Train Loss: 33782530.0448\n",
      "Val Loss: 34068294.3066, MAE: 4997.3911, NMAE: 76.1893, R^2: 0.0680\n",
      "Epoch [536/2000]\n",
      "Train Loss: 33788409.4690\n",
      "Val Loss: 34105026.9814, MAE: 5003.3457, NMAE: 76.2801, R^2: 0.0670\n",
      "Epoch [537/2000]\n",
      "Train Loss: 33725742.7405\n",
      "Val Loss: 34096391.7729, MAE: 5008.9531, NMAE: 76.3656, R^2: 0.0672\n",
      "Epoch [538/2000]\n",
      "Train Loss: 33756480.9155\n",
      "Val Loss: 34053028.4577, MAE: 4990.2207, NMAE: 76.0800, R^2: 0.0684\n",
      "Epoch [539/2000]\n",
      "Train Loss: 33969587.2914\n",
      "Val Loss: 33887950.6351, MAE: 4967.0659, NMAE: 75.7270, R^2: 0.0729\n",
      "Epoch [540/2000]\n",
      "Train Loss: 33747160.4405\n",
      "Val Loss: 33868798.1166, MAE: 4976.9004, NMAE: 75.8769, R^2: 0.0735\n",
      "Epoch [541/2000]\n",
      "Train Loss: 33545908.4207\n",
      "Val Loss: 34107611.9555, MAE: 5019.9512, NMAE: 76.5333, R^2: 0.0669\n",
      "Epoch [542/2000]\n",
      "Train Loss: 33502126.4569\n",
      "Val Loss: 34060191.4024, MAE: 5009.6470, NMAE: 76.3762, R^2: 0.0682\n",
      "Epoch [543/2000]\n",
      "Train Loss: 33609213.8948\n",
      "Val Loss: 34048845.2642, MAE: 5013.7080, NMAE: 76.4381, R^2: 0.0685\n",
      "Epoch [544/2000]\n",
      "Train Loss: 33424409.2750\n",
      "Val Loss: 34074205.7431, MAE: 5024.6562, NMAE: 76.6050, R^2: 0.0678\n",
      "Epoch [545/2000]\n",
      "Train Loss: 33531905.4112\n",
      "Val Loss: 34044824.5380, MAE: 5017.2466, NMAE: 76.4920, R^2: 0.0687\n",
      "Epoch [546/2000]\n",
      "Train Loss: 33469390.9453\n",
      "Val Loss: 34380906.4883, MAE: 4995.0630, NMAE: 76.1538, R^2: 0.0595\n",
      "Epoch [547/2000]\n",
      "Train Loss: 33492829.2897\n",
      "Val Loss: 34169061.0684, MAE: 5012.7788, NMAE: 76.4239, R^2: 0.0653\n",
      "Epoch [548/2000]\n",
      "Train Loss: 33342934.3974\n",
      "Val Loss: 34140855.0415, MAE: 5006.8735, NMAE: 76.3339, R^2: 0.0660\n",
      "Epoch [549/2000]\n",
      "Train Loss: 33963319.7405\n",
      "Val Loss: 34398023.0674, MAE: 5012.5962, NMAE: 76.4211, R^2: 0.0590\n",
      "Epoch [550/2000]\n",
      "Train Loss: 33493277.5879\n",
      "Val Loss: 34364732.7621, MAE: 5060.0742, NMAE: 77.1450, R^2: 0.0599\n",
      "Epoch [551/2000]\n",
      "Train Loss: 33833722.1603\n",
      "Val Loss: 33809006.9832, MAE: 4999.5342, NMAE: 76.2220, R^2: 0.0751\n",
      "Epoch [552/2000]\n",
      "Train Loss: 33485459.5569\n",
      "Val Loss: 34197103.5915, MAE: 5014.9819, NMAE: 76.4575, R^2: 0.0645\n",
      "Epoch [553/2000]\n",
      "Train Loss: 33549848.8121\n",
      "Val Loss: 34456210.3148, MAE: 4993.7808, NMAE: 76.1343, R^2: 0.0574\n",
      "Epoch [554/2000]\n",
      "Train Loss: 33752200.7466\n",
      "Val Loss: 34108150.9538, MAE: 4993.6411, NMAE: 76.1322, R^2: 0.0669\n",
      "Epoch [555/2000]\n",
      "Train Loss: 34016786.0871\n",
      "Val Loss: 33640996.4095, MAE: 4936.7773, NMAE: 75.2652, R^2: 0.0797\n",
      "Epoch [556/2000]\n",
      "Train Loss: 33862573.9448\n",
      "Val Loss: 33742981.7159, MAE: 4947.2827, NMAE: 75.4254, R^2: 0.0769\n",
      "Epoch [557/2000]\n",
      "Train Loss: 33874703.2431\n",
      "Val Loss: 33870449.7338, MAE: 4981.6689, NMAE: 75.9496, R^2: 0.0734\n",
      "Epoch [558/2000]\n",
      "Train Loss: 33859140.2250\n",
      "Val Loss: 33899141.6347, MAE: 4995.6514, NMAE: 76.1628, R^2: 0.0726\n",
      "Epoch [559/2000]\n",
      "Train Loss: 33601868.4086\n",
      "Val Loss: 33803981.9709, MAE: 4976.4087, NMAE: 75.8694, R^2: 0.0752\n",
      "Epoch [560/2000]\n",
      "Train Loss: 33378438.9638\n",
      "Val Loss: 33873607.8320, MAE: 4968.6050, NMAE: 75.7505, R^2: 0.0733\n",
      "Epoch [561/2000]\n",
      "Train Loss: 33540232.5233\n",
      "Val Loss: 33718563.0782, MAE: 4969.9932, NMAE: 75.7716, R^2: 0.0776\n",
      "Epoch [562/2000]\n",
      "Train Loss: 33487079.6052\n",
      "Val Loss: 33500062.0432, MAE: 4939.1636, NMAE: 75.3016, R^2: 0.0836\n",
      "Epoch [563/2000]\n",
      "Train Loss: 33221823.7802\n",
      "Val Loss: 33454932.9920, MAE: 4940.2202, NMAE: 75.3177, R^2: 0.0848\n",
      "Epoch [564/2000]\n",
      "Train Loss: 33263271.5552\n",
      "Val Loss: 33479726.2582, MAE: 4947.6025, NMAE: 75.4303, R^2: 0.0841\n",
      "Epoch [565/2000]\n",
      "Train Loss: 33182926.3440\n",
      "Val Loss: 33919328.6472, MAE: 4991.6758, NMAE: 76.1022, R^2: 0.0721\n",
      "Epoch [566/2000]\n",
      "Train Loss: 33844047.3319\n",
      "Val Loss: 33491716.2660, MAE: 4954.5366, NMAE: 75.5360, R^2: 0.0838\n",
      "Epoch [567/2000]\n",
      "Train Loss: 33701354.2224\n",
      "Val Loss: 33920754.5877, MAE: 5018.3687, NMAE: 76.5091, R^2: 0.0720\n",
      "Epoch [568/2000]\n",
      "Train Loss: 33750084.7983\n",
      "Val Loss: 33799843.0259, MAE: 5009.2490, NMAE: 76.3701, R^2: 0.0754\n",
      "Epoch [569/2000]\n",
      "Train Loss: 33688441.9371\n",
      "Val Loss: 33904119.7427, MAE: 5019.4897, NMAE: 76.5262, R^2: 0.0725\n",
      "Epoch [570/2000]\n",
      "Train Loss: 33543490.0328\n",
      "Val Loss: 33840511.2565, MAE: 5009.8237, NMAE: 76.3789, R^2: 0.0742\n",
      "Epoch [571/2000]\n",
      "Train Loss: 33709169.4853\n",
      "Val Loss: 34065230.1425, MAE: 5008.1597, NMAE: 76.3535, R^2: 0.0681\n",
      "Epoch [572/2000]\n",
      "Train Loss: 33639344.9302\n",
      "Val Loss: 33890551.9400, MAE: 4992.4917, NMAE: 76.1146, R^2: 0.0729\n",
      "Epoch [573/2000]\n",
      "Train Loss: 33657372.0716\n",
      "Val Loss: 34017684.9737, MAE: 5019.7314, NMAE: 76.5299, R^2: 0.0694\n",
      "Epoch [574/2000]\n",
      "Train Loss: 33543592.3638\n",
      "Val Loss: 33991129.5600, MAE: 5016.9424, NMAE: 76.4874, R^2: 0.0701\n",
      "Epoch [575/2000]\n",
      "Train Loss: 33466388.4164\n",
      "Val Loss: 34068642.1891, MAE: 5033.3862, NMAE: 76.7381, R^2: 0.0680\n",
      "Epoch [576/2000]\n",
      "Train Loss: 33526173.2698\n",
      "Val Loss: 33841520.9344, MAE: 5013.6455, NMAE: 76.4371, R^2: 0.0742\n",
      "Epoch [577/2000]\n",
      "Train Loss: 33475337.7000\n",
      "Val Loss: 33597317.1641, MAE: 4991.4868, NMAE: 76.0993, R^2: 0.0809\n",
      "Epoch [578/2000]\n",
      "Train Loss: 33295656.3207\n",
      "Val Loss: 33538918.2245, MAE: 4991.9331, NMAE: 76.1061, R^2: 0.0825\n",
      "Epoch [579/2000]\n",
      "Train Loss: 33390148.0491\n",
      "Val Loss: 33400652.0756, MAE: 4971.7637, NMAE: 75.7986, R^2: 0.0863\n",
      "Epoch [580/2000]\n",
      "Train Loss: 33203189.3233\n",
      "Val Loss: 33785690.2008, MAE: 5016.5195, NMAE: 76.4810, R^2: 0.0757\n",
      "Epoch [581/2000]\n",
      "Train Loss: 33173025.3345\n",
      "Val Loss: 33336894.1658, MAE: 4968.6235, NMAE: 75.7507, R^2: 0.0880\n",
      "Epoch [582/2000]\n",
      "Train Loss: 33181000.5897\n",
      "Val Loss: 33366404.1675, MAE: 4975.4150, NMAE: 75.8543, R^2: 0.0872\n",
      "Epoch [583/2000]\n",
      "Train Loss: 33211094.1853\n",
      "Val Loss: 33415214.3402, MAE: 4981.5933, NMAE: 75.9485, R^2: 0.0859\n",
      "Epoch [584/2000]\n",
      "Train Loss: 33157855.7603\n",
      "Val Loss: 33471601.4387, MAE: 4986.5996, NMAE: 76.0248, R^2: 0.0843\n",
      "Epoch [585/2000]\n",
      "Train Loss: 33058738.0595\n",
      "Val Loss: 33204330.0492, MAE: 4945.0107, NMAE: 75.3907, R^2: 0.0916\n",
      "Epoch [586/2000]\n",
      "Train Loss: 33190291.7793\n",
      "Val Loss: 33271493.4564, MAE: 4948.4365, NMAE: 75.4430, R^2: 0.0898\n",
      "Epoch [587/2000]\n",
      "Train Loss: 33313114.3655\n",
      "Val Loss: 33161346.7617, MAE: 4943.1660, NMAE: 75.3626, R^2: 0.0928\n",
      "Epoch [588/2000]\n",
      "Train Loss: 32936441.2164\n",
      "Val Loss: 33515213.4888, MAE: 4988.2148, NMAE: 76.0494, R^2: 0.0831\n",
      "Epoch [589/2000]\n",
      "Train Loss: 32876388.5336\n",
      "Val Loss: 33310045.7617, MAE: 4965.0015, NMAE: 75.6955, R^2: 0.0888\n",
      "Epoch [590/2000]\n",
      "Train Loss: 33048677.6638\n",
      "Val Loss: 33358531.3698, MAE: 4972.7080, NMAE: 75.8130, R^2: 0.0874\n",
      "Epoch [591/2000]\n",
      "Train Loss: 33660715.3810\n",
      "Val Loss: 33844845.0484, MAE: 5020.2881, NMAE: 76.5384, R^2: 0.0741\n",
      "Epoch [592/2000]\n",
      "Train Loss: 33010445.8569\n",
      "Val Loss: 33353112.4277, MAE: 4959.2344, NMAE: 75.6076, R^2: 0.0876\n",
      "Epoch [593/2000]\n",
      "Train Loss: 33080468.8534\n",
      "Val Loss: 33400388.8221, MAE: 4961.1758, NMAE: 75.6372, R^2: 0.0863\n",
      "Epoch [594/2000]\n",
      "Train Loss: 33388151.7491\n",
      "Val Loss: 33193297.1770, MAE: 4933.5454, NMAE: 75.2159, R^2: 0.0919\n",
      "Epoch [595/2000]\n",
      "Train Loss: 33453599.8500\n",
      "Val Loss: 33591121.7807, MAE: 4992.7256, NMAE: 76.1182, R^2: 0.0811\n",
      "Epoch [596/2000]\n",
      "Train Loss: 33136976.8241\n",
      "Val Loss: 33420582.0255, MAE: 4972.0869, NMAE: 75.8035, R^2: 0.0857\n",
      "Epoch [597/2000]\n",
      "Train Loss: 33158970.7922\n",
      "Val Loss: 33271316.7180, MAE: 4951.8188, NMAE: 75.4945, R^2: 0.0898\n",
      "Epoch [598/2000]\n",
      "Train Loss: 33004124.6853\n",
      "Val Loss: 33301566.5393, MAE: 4953.9907, NMAE: 75.5277, R^2: 0.0890\n",
      "Epoch [599/2000]\n",
      "Train Loss: 33180933.6810\n",
      "Val Loss: 33207224.8579, MAE: 4933.6309, NMAE: 75.2172, R^2: 0.0916\n",
      "Epoch [600/2000]\n",
      "Train Loss: 33003429.9776\n",
      "Val Loss: 33148388.5389, MAE: 4933.3804, NMAE: 75.2134, R^2: 0.0932\n",
      "Epoch [601/2000]\n",
      "Train Loss: 33009328.8328\n",
      "Val Loss: 33253706.2841, MAE: 4952.9087, NMAE: 75.5112, R^2: 0.0903\n",
      "Epoch [602/2000]\n",
      "Train Loss: 32987378.6931\n",
      "Val Loss: 33414926.1054, MAE: 4974.6572, NMAE: 75.8427, R^2: 0.0859\n",
      "Epoch [603/2000]\n",
      "Train Loss: 32917940.5802\n",
      "Val Loss: 33450599.1149, MAE: 4977.5850, NMAE: 75.8874, R^2: 0.0849\n",
      "Epoch [604/2000]\n",
      "Train Loss: 32860784.9000\n",
      "Val Loss: 33754848.4465, MAE: 5015.9790, NMAE: 76.4727, R^2: 0.0766\n",
      "Epoch [605/2000]\n",
      "Train Loss: 32886127.8966\n",
      "Val Loss: 33447588.0820, MAE: 4979.9771, NMAE: 75.9238, R^2: 0.0850\n",
      "Epoch [606/2000]\n",
      "Train Loss: 32665594.2431\n",
      "Val Loss: 33496738.0782, MAE: 4978.2554, NMAE: 75.8976, R^2: 0.0836\n",
      "Epoch [607/2000]\n",
      "Train Loss: 32978090.1914\n",
      "Val Loss: 33515427.7375, MAE: 4988.6152, NMAE: 76.0555, R^2: 0.0831\n",
      "Epoch [608/2000]\n",
      "Train Loss: 32874952.7448\n",
      "Val Loss: 33406333.3856, MAE: 4969.7310, NMAE: 75.7676, R^2: 0.0861\n",
      "Epoch [609/2000]\n",
      "Train Loss: 33148166.3543\n",
      "Val Loss: 33529271.6477, MAE: 4983.8701, NMAE: 75.9832, R^2: 0.0828\n",
      "Epoch [610/2000]\n",
      "Train Loss: 32719605.3552\n",
      "Val Loss: 33618692.3912, MAE: 4998.6680, NMAE: 76.2088, R^2: 0.0803\n",
      "Epoch [611/2000]\n",
      "Train Loss: 32895560.5414\n",
      "Val Loss: 33676711.1939, MAE: 5007.8120, NMAE: 76.3482, R^2: 0.0787\n",
      "Epoch [612/2000]\n",
      "Train Loss: 32869352.8353\n",
      "Val Loss: 33612207.3152, MAE: 4999.2046, NMAE: 76.2170, R^2: 0.0805\n",
      "Epoch [613/2000]\n",
      "Train Loss: 32879356.3655\n",
      "Val Loss: 33248575.9266, MAE: 4953.6094, NMAE: 75.5218, R^2: 0.0904\n",
      "Epoch [614/2000]\n",
      "Train Loss: 34091820.1836\n",
      "Val Loss: 33874437.1550, MAE: 4924.6924, NMAE: 75.0810, R^2: 0.0733\n",
      "Epoch [615/2000]\n",
      "Train Loss: 33258371.9784\n",
      "Val Loss: 33008549.8657, MAE: 4908.6758, NMAE: 74.8368, R^2: 0.0970\n",
      "Epoch [616/2000]\n",
      "Train Loss: 33055589.4155\n",
      "Val Loss: 33159553.3541, MAE: 4924.5557, NMAE: 75.0789, R^2: 0.0929\n",
      "Epoch [617/2000]\n",
      "Train Loss: 33109988.2009\n",
      "Val Loss: 33322016.6390, MAE: 4962.7051, NMAE: 75.6605, R^2: 0.0884\n",
      "Epoch [618/2000]\n",
      "Train Loss: 33274730.6155\n",
      "Val Loss: 33317090.5013, MAE: 4962.7080, NMAE: 75.6606, R^2: 0.0886\n",
      "Epoch [619/2000]\n",
      "Train Loss: 32943198.6276\n",
      "Val Loss: 33375732.7757, MAE: 4967.4116, NMAE: 75.7323, R^2: 0.0870\n",
      "Epoch [620/2000]\n",
      "Train Loss: 33054389.7198\n",
      "Val Loss: 33585156.6205, MAE: 4998.8032, NMAE: 76.2109, R^2: 0.0812\n",
      "Epoch [621/2000]\n",
      "Train Loss: 32970013.2069\n",
      "Val Loss: 33355967.7958, MAE: 4966.3291, NMAE: 75.7158, R^2: 0.0875\n",
      "Epoch [622/2000]\n",
      "Train Loss: 32865146.4129\n",
      "Val Loss: 33440812.1524, MAE: 4980.0425, NMAE: 75.9248, R^2: 0.0852\n",
      "Epoch [623/2000]\n",
      "Train Loss: 32923974.5836\n",
      "Val Loss: 33219263.8364, MAE: 4947.3232, NMAE: 75.4260, R^2: 0.0912\n",
      "Epoch [624/2000]\n",
      "Train Loss: 32757603.2974\n",
      "Val Loss: 33660097.4111, MAE: 4989.4697, NMAE: 76.0686, R^2: 0.0792\n",
      "Epoch [625/2000]\n",
      "Train Loss: 33064764.4586\n",
      "Val Loss: 33226801.0682, MAE: 4924.3589, NMAE: 75.0759, R^2: 0.0910\n",
      "Epoch [626/2000]\n",
      "Train Loss: 32913132.5560\n",
      "Val Loss: 33084856.5112, MAE: 4907.8682, NMAE: 74.8245, R^2: 0.0949\n",
      "Epoch [627/2000]\n",
      "Train Loss: 32761860.4716\n",
      "Val Loss: 32669749.8497, MAE: 4863.4844, NMAE: 74.1478, R^2: 0.1063\n",
      "Epoch [628/2000]\n",
      "Train Loss: 32901851.9922\n",
      "Val Loss: 32672178.2949, MAE: 4868.3911, NMAE: 74.2226, R^2: 0.1062\n",
      "Epoch [629/2000]\n",
      "Train Loss: 32741998.0422\n",
      "Val Loss: 32760507.2940, MAE: 4888.5005, NMAE: 74.5292, R^2: 0.1038\n",
      "Epoch [630/2000]\n",
      "Train Loss: 32798886.3845\n",
      "Val Loss: 32896443.5823, MAE: 4909.2227, NMAE: 74.8451, R^2: 0.1001\n",
      "Epoch [631/2000]\n",
      "Train Loss: 32922161.2147\n",
      "Val Loss: 32612998.6801, MAE: 4861.2534, NMAE: 74.1138, R^2: 0.1078\n",
      "Epoch [632/2000]\n",
      "Train Loss: 32763247.3845\n",
      "Val Loss: 32761723.7785, MAE: 4895.3081, NMAE: 74.6330, R^2: 0.1038\n",
      "Epoch [633/2000]\n",
      "Train Loss: 32721779.4560\n",
      "Val Loss: 32777632.5367, MAE: 4901.4971, NMAE: 74.7273, R^2: 0.1033\n",
      "Epoch [634/2000]\n",
      "Train Loss: 32867204.0172\n",
      "Val Loss: 32759289.3748, MAE: 4886.9365, NMAE: 74.5054, R^2: 0.1038\n",
      "Epoch [635/2000]\n",
      "Train Loss: 32623009.3828\n",
      "Val Loss: 32813417.1926, MAE: 4906.2310, NMAE: 74.7995, R^2: 0.1023\n",
      "Epoch [636/2000]\n",
      "Train Loss: 32611121.5578\n",
      "Val Loss: 32954302.6114, MAE: 4927.8237, NMAE: 75.1287, R^2: 0.0985\n",
      "Epoch [637/2000]\n",
      "Train Loss: 32620355.8707\n",
      "Val Loss: 33064679.5959, MAE: 4947.5581, NMAE: 75.4296, R^2: 0.0955\n",
      "Epoch [638/2000]\n",
      "Train Loss: 32668128.7569\n",
      "Val Loss: 33039202.3187, MAE: 4935.8086, NMAE: 75.2505, R^2: 0.0962\n",
      "Epoch [639/2000]\n",
      "Train Loss: 32483731.5526\n",
      "Val Loss: 33189204.9728, MAE: 4956.8350, NMAE: 75.5710, R^2: 0.0921\n",
      "Epoch [640/2000]\n",
      "Train Loss: 32569191.2362\n",
      "Val Loss: 33244061.5278, MAE: 4968.1133, NMAE: 75.7430, R^2: 0.0906\n",
      "Epoch [641/2000]\n",
      "Train Loss: 32960657.8534\n",
      "Val Loss: 32723201.3247, MAE: 4877.6411, NMAE: 74.3636, R^2: 0.1048\n",
      "Epoch [642/2000]\n",
      "Train Loss: 34817663.0371\n",
      "Val Loss: 33826047.0954, MAE: 4995.2002, NMAE: 76.1559, R^2: 0.0746\n",
      "Epoch [643/2000]\n",
      "Train Loss: 33908503.8940\n",
      "Val Loss: 34192107.7327, MAE: 5073.2495, NMAE: 77.3459, R^2: 0.0646\n",
      "Epoch [644/2000]\n",
      "Train Loss: 33556504.7940\n",
      "Val Loss: 33850720.9184, MAE: 5037.2534, NMAE: 76.7971, R^2: 0.0740\n",
      "Epoch [645/2000]\n",
      "Train Loss: 33248455.0086\n",
      "Val Loss: 33918412.5984, MAE: 5043.4517, NMAE: 76.8916, R^2: 0.0721\n",
      "Epoch [646/2000]\n",
      "Train Loss: 33360041.2233\n",
      "Val Loss: 33853902.2530, MAE: 5037.5894, NMAE: 76.8022, R^2: 0.0739\n",
      "Epoch [647/2000]\n",
      "Train Loss: 33157329.2224\n",
      "Val Loss: 33646010.8156, MAE: 5014.7026, NMAE: 76.4533, R^2: 0.0796\n",
      "Epoch [648/2000]\n",
      "Train Loss: 33105882.8319\n",
      "Val Loss: 33672250.1485, MAE: 5017.0723, NMAE: 76.4894, R^2: 0.0788\n",
      "Epoch [649/2000]\n",
      "Train Loss: 33065340.8638\n",
      "Val Loss: 33699585.9236, MAE: 5020.8467, NMAE: 76.5469, R^2: 0.0781\n",
      "Epoch [650/2000]\n",
      "Train Loss: 33052908.6397\n",
      "Val Loss: 33651474.1900, MAE: 5015.6538, NMAE: 76.4678, R^2: 0.0794\n",
      "Epoch [651/2000]\n",
      "Train Loss: 32915971.2517\n",
      "Val Loss: 33765990.2081, MAE: 5027.6772, NMAE: 76.6511, R^2: 0.0763\n",
      "Epoch [652/2000]\n",
      "Train Loss: 32902602.8250\n",
      "Val Loss: 33779138.7021, MAE: 5028.0283, NMAE: 76.6564, R^2: 0.0759\n",
      "Epoch [653/2000]\n",
      "Train Loss: 32967147.9164\n",
      "Val Loss: 33607037.1384, MAE: 4997.1182, NMAE: 76.1852, R^2: 0.0806\n",
      "Epoch [654/2000]\n",
      "Train Loss: 33389788.5397\n",
      "Val Loss: 34504856.7250, MAE: 5090.7871, NMAE: 77.6132, R^2: 0.0561\n",
      "Epoch [655/2000]\n",
      "Train Loss: 33339108.9741\n",
      "Val Loss: 34276831.7491, MAE: 5064.3418, NMAE: 77.2100, R^2: 0.0623\n",
      "Epoch [656/2000]\n",
      "Train Loss: 33356673.5733\n",
      "Val Loss: 34068970.4514, MAE: 5027.7778, NMAE: 76.6526, R^2: 0.0680\n",
      "Epoch [657/2000]\n",
      "Train Loss: 33210767.0474\n",
      "Val Loss: 34380429.7347, MAE: 5074.6738, NMAE: 77.3676, R^2: 0.0595\n",
      "Epoch [658/2000]\n",
      "Train Loss: 33065338.3440\n",
      "Val Loss: 34084623.9037, MAE: 5032.0498, NMAE: 76.7177, R^2: 0.0676\n",
      "Epoch [659/2000]\n",
      "Train Loss: 32972864.7190\n",
      "Val Loss: 34005874.4093, MAE: 5038.2891, NMAE: 76.8129, R^2: 0.0697\n",
      "Epoch [660/2000]\n",
      "Train Loss: 32976571.8276\n",
      "Val Loss: 34167189.3778, MAE: 5064.0088, NMAE: 77.2050, R^2: 0.0653\n",
      "Epoch [661/2000]\n",
      "Train Loss: 32911610.7336\n",
      "Val Loss: 34007102.8377, MAE: 5046.4946, NMAE: 76.9380, R^2: 0.0697\n",
      "Epoch [662/2000]\n",
      "Train Loss: 32929667.9405\n",
      "Val Loss: 34184194.1611, MAE: 5066.5581, NMAE: 77.2438, R^2: 0.0648\n",
      "Epoch [663/2000]\n",
      "Train Loss: 33071348.7017\n",
      "Val Loss: 34110969.3333, MAE: 5050.8223, NMAE: 77.0039, R^2: 0.0668\n",
      "Epoch [664/2000]\n",
      "Train Loss: 32948905.7276\n",
      "Val Loss: 33929150.6054, MAE: 5029.5078, NMAE: 76.6790, R^2: 0.0718\n",
      "Epoch [665/2000]\n",
      "Train Loss: 32830598.6112\n",
      "Val Loss: 34238176.5501, MAE: 5075.3794, NMAE: 77.3783, R^2: 0.0634\n",
      "Epoch [666/2000]\n",
      "Train Loss: 32631247.1552\n",
      "Val Loss: 34261149.6343, MAE: 5079.7500, NMAE: 77.4450, R^2: 0.0627\n",
      "Epoch [667/2000]\n",
      "Train Loss: 32710838.2629\n",
      "Val Loss: 33869978.0626, MAE: 5035.7534, NMAE: 76.7742, R^2: 0.0734\n",
      "Epoch [668/2000]\n",
      "Train Loss: 32635849.4284\n",
      "Val Loss: 33916854.2513, MAE: 5030.4600, NMAE: 76.6935, R^2: 0.0722\n",
      "Epoch [669/2000]\n",
      "Train Loss: 32557177.1853\n",
      "Val Loss: 34009382.0678, MAE: 5044.0029, NMAE: 76.9000, R^2: 0.0696\n",
      "Epoch [670/2000]\n",
      "Train Loss: 32765900.0853\n",
      "Val Loss: 34042731.1541, MAE: 5055.3184, NMAE: 77.0725, R^2: 0.0687\n",
      "Epoch [671/2000]\n",
      "Train Loss: 32625774.3853\n",
      "Val Loss: 33666493.7360, MAE: 5013.0425, NMAE: 76.4279, R^2: 0.0790\n",
      "Epoch [672/2000]\n",
      "Train Loss: 32592739.5250\n",
      "Val Loss: 33646395.5397, MAE: 5016.1240, NMAE: 76.4749, R^2: 0.0796\n",
      "Epoch [673/2000]\n",
      "Train Loss: 33582451.9190\n",
      "Val Loss: 35668575.2176, MAE: 5225.8848, NMAE: 79.6729, R^2: 0.0242\n",
      "Epoch [674/2000]\n",
      "Train Loss: 35043496.2009\n",
      "Val Loss: 33213879.3109, MAE: 4947.8823, NMAE: 75.4345, R^2: 0.0914\n",
      "Epoch [675/2000]\n",
      "Train Loss: 32950271.6621\n",
      "Val Loss: 32813903.9249, MAE: 4911.1768, NMAE: 74.8749, R^2: 0.1023\n",
      "Epoch [676/2000]\n",
      "Train Loss: 33585646.9500\n",
      "Val Loss: 32947863.4896, MAE: 4917.8037, NMAE: 74.9760, R^2: 0.0987\n",
      "Epoch [677/2000]\n",
      "Train Loss: 33617760.9871\n",
      "Val Loss: 32469085.5268, MAE: 4858.7451, NMAE: 74.0756, R^2: 0.1118\n",
      "Epoch [678/2000]\n",
      "Train Loss: 34223030.3009\n",
      "Val Loss: 33186866.5915, MAE: 4937.2573, NMAE: 75.2725, R^2: 0.0921\n",
      "Epoch [679/2000]\n",
      "Train Loss: 33779228.9888\n",
      "Val Loss: 33230314.7686, MAE: 4935.9287, NMAE: 75.2523, R^2: 0.0909\n",
      "Epoch [680/2000]\n",
      "Train Loss: 33180330.7017\n",
      "Val Loss: 33274683.6960, MAE: 4953.1323, NMAE: 75.5146, R^2: 0.0897\n",
      "Epoch [681/2000]\n",
      "Train Loss: 33013093.6750\n",
      "Val Loss: 33055539.6887, MAE: 4925.6890, NMAE: 75.0962, R^2: 0.0957\n",
      "Epoch [682/2000]\n",
      "Train Loss: 33424862.2147\n",
      "Val Loss: 32890511.3040, MAE: 4905.1401, NMAE: 74.7829, R^2: 0.1002\n",
      "Epoch [683/2000]\n",
      "Train Loss: 33274410.0009\n",
      "Val Loss: 33199915.7267, MAE: 4965.2617, NMAE: 75.6995, R^2: 0.0918\n",
      "Epoch [684/2000]\n",
      "Train Loss: 32919156.7991\n",
      "Val Loss: 32982130.7012, MAE: 4932.6230, NMAE: 75.2019, R^2: 0.0977\n",
      "Epoch [685/2000]\n",
      "Train Loss: 33375265.3853\n",
      "Val Loss: 33663139.5466, MAE: 5025.7710, NMAE: 76.6220, R^2: 0.0791\n",
      "Epoch [686/2000]\n",
      "Train Loss: 32543236.7750\n",
      "Val Loss: 32920593.4417, MAE: 4941.4395, NMAE: 75.3363, R^2: 0.0994\n",
      "Epoch [687/2000]\n",
      "Train Loss: 32635690.5233\n",
      "Val Loss: 32798296.7807, MAE: 4922.8589, NMAE: 75.0530, R^2: 0.1028\n",
      "Epoch [688/2000]\n",
      "Train Loss: 32772382.6914\n",
      "Val Loss: 32614977.2733, MAE: 4890.2109, NMAE: 74.5553, R^2: 0.1078\n",
      "Epoch [689/2000]\n",
      "Train Loss: 32548301.1655\n",
      "Val Loss: 32851706.8195, MAE: 4933.3022, NMAE: 75.2122, R^2: 0.1013\n",
      "Epoch [690/2000]\n",
      "Train Loss: 32576028.2276\n",
      "Val Loss: 34018669.9663, MAE: 5085.8599, NMAE: 77.5381, R^2: 0.0694\n",
      "Epoch [691/2000]\n",
      "Train Loss: 33286912.8052\n",
      "Val Loss: 33098191.3990, MAE: 4972.2676, NMAE: 75.8063, R^2: 0.0945\n",
      "Epoch [692/2000]\n",
      "Train Loss: 32487966.9353\n",
      "Val Loss: 33270836.8528, MAE: 4986.0083, NMAE: 76.0158, R^2: 0.0898\n",
      "Epoch [693/2000]\n",
      "Train Loss: 32386580.7776\n",
      "Val Loss: 33093894.8841, MAE: 4958.4512, NMAE: 75.5957, R^2: 0.0947\n",
      "Epoch [694/2000]\n",
      "Train Loss: 32381840.7578\n",
      "Val Loss: 33286834.2055, MAE: 4982.9585, NMAE: 75.9693, R^2: 0.0894\n",
      "Epoch [695/2000]\n",
      "Train Loss: 32264912.5586\n",
      "Val Loss: 33613233.5859, MAE: 5022.1514, NMAE: 76.5668, R^2: 0.0805\n",
      "Epoch [696/2000]\n",
      "Train Loss: 32602467.6328\n",
      "Val Loss: 32819028.6170, MAE: 4921.0068, NMAE: 75.0248, R^2: 0.1022\n",
      "Epoch [697/2000]\n",
      "Train Loss: 32484363.9388\n",
      "Val Loss: 33105558.4374, MAE: 4959.7861, NMAE: 75.6160, R^2: 0.0943\n",
      "Epoch [698/2000]\n",
      "Train Loss: 32435742.4233\n",
      "Val Loss: 32770087.3500, MAE: 4922.5464, NMAE: 75.0483, R^2: 0.1035\n",
      "Epoch [699/2000]\n",
      "Train Loss: 32296081.5267\n",
      "Val Loss: 33850741.7111, MAE: 5056.5342, NMAE: 77.0910, R^2: 0.0740\n",
      "Epoch [700/2000]\n",
      "Train Loss: 33345129.2095\n",
      "Val Loss: 33089783.6066, MAE: 4960.5674, NMAE: 75.6279, R^2: 0.0948\n",
      "Epoch [701/2000]\n",
      "Train Loss: 32841830.5371\n",
      "Val Loss: 32886447.6524, MAE: 4938.8354, NMAE: 75.2966, R^2: 0.1003\n",
      "Epoch [702/2000]\n",
      "Train Loss: 32414387.2802\n",
      "Val Loss: 33092741.0507, MAE: 4969.0103, NMAE: 75.7566, R^2: 0.0947\n",
      "Epoch [703/2000]\n",
      "Train Loss: 32648295.4733\n",
      "Val Loss: 32735628.8113, MAE: 4923.6079, NMAE: 75.0644, R^2: 0.1045\n",
      "Epoch [704/2000]\n",
      "Train Loss: 32504016.1586\n",
      "Val Loss: 32594311.4529, MAE: 4895.9639, NMAE: 74.6430, R^2: 0.1083\n",
      "Epoch [705/2000]\n",
      "Train Loss: 32447689.8078\n",
      "Val Loss: 33103216.7716, MAE: 4967.0854, NMAE: 75.7273, R^2: 0.0944\n",
      "Epoch [706/2000]\n",
      "Train Loss: 32584286.6974\n",
      "Val Loss: 32466372.2051, MAE: 4891.6411, NMAE: 74.5771, R^2: 0.1118\n",
      "Epoch [707/2000]\n",
      "Train Loss: 32796213.0595\n",
      "Val Loss: 33082799.3651, MAE: 4961.5503, NMAE: 75.6429, R^2: 0.0950\n",
      "Epoch [708/2000]\n",
      "Train Loss: 32559504.1647\n",
      "Val Loss: 33070172.8433, MAE: 4963.2290, NMAE: 75.6685, R^2: 0.0953\n",
      "Epoch [709/2000]\n",
      "Train Loss: 32476157.1034\n",
      "Val Loss: 33189807.3156, MAE: 4975.6948, NMAE: 75.8585, R^2: 0.0920\n",
      "Epoch [710/2000]\n",
      "Train Loss: 32591061.7509\n",
      "Val Loss: 32795668.0283, MAE: 4935.5547, NMAE: 75.2466, R^2: 0.1028\n",
      "Epoch [711/2000]\n",
      "Train Loss: 32644674.1052\n",
      "Val Loss: 32852546.5037, MAE: 4931.3350, NMAE: 75.1822, R^2: 0.1013\n",
      "Epoch [712/2000]\n",
      "Train Loss: 32249223.8310\n",
      "Val Loss: 33402309.8310, MAE: 5001.4927, NMAE: 76.2519, R^2: 0.0862\n",
      "Epoch [713/2000]\n",
      "Train Loss: 32230218.0164\n",
      "Val Loss: 32761035.3566, MAE: 4918.5205, NMAE: 74.9869, R^2: 0.1038\n",
      "Epoch [714/2000]\n",
      "Train Loss: 32346813.4000\n",
      "Val Loss: 32573948.6645, MAE: 4896.8843, NMAE: 74.6570, R^2: 0.1089\n",
      "Epoch [715/2000]\n",
      "Train Loss: 32568963.0922\n",
      "Val Loss: 32904611.5607, MAE: 4917.6274, NMAE: 74.9733, R^2: 0.0998\n",
      "Epoch [716/2000]\n",
      "Train Loss: 32367755.7362\n",
      "Val Loss: 32939891.6019, MAE: 4922.5596, NMAE: 75.0485, R^2: 0.0989\n",
      "Epoch [717/2000]\n",
      "Train Loss: 32213175.3077\n",
      "Val Loss: 32846437.3494, MAE: 4910.4717, NMAE: 74.8642, R^2: 0.1014\n",
      "Epoch [718/2000]\n",
      "Train Loss: 32215362.4457\n",
      "Val Loss: 32628895.4448, MAE: 4908.6089, NMAE: 74.8358, R^2: 0.1074\n",
      "Epoch [719/2000]\n",
      "Train Loss: 32762916.9886\n",
      "Val Loss: 33227740.0723, MAE: 4954.6904, NMAE: 75.5383, R^2: 0.0910\n",
      "Epoch [720/2000]\n",
      "Train Loss: 32263816.5440\n",
      "Val Loss: 32760685.3248, MAE: 4912.7832, NMAE: 74.8994, R^2: 0.1038\n",
      "Epoch [721/2000]\n",
      "Train Loss: 33040687.8558\n",
      "Val Loss: 32937792.7696, MAE: 4916.3188, NMAE: 74.9533, R^2: 0.0989\n",
      "Epoch [722/2000]\n",
      "Train Loss: 31986892.8810\n",
      "Val Loss: 32491283.5730, MAE: 4866.1855, NMAE: 74.1890, R^2: 0.1112\n",
      "Epoch [723/2000]\n",
      "Train Loss: 32120281.0580\n",
      "Val Loss: 32720723.1103, MAE: 4895.1846, NMAE: 74.6311, R^2: 0.1049\n",
      "Epoch [724/2000]\n",
      "Train Loss: 32218578.8599\n",
      "Val Loss: 32932101.7063, MAE: 4919.1606, NMAE: 74.9966, R^2: 0.0991\n",
      "Epoch [725/2000]\n",
      "Train Loss: 32206739.8073\n",
      "Val Loss: 33710487.2336, MAE: 5036.2598, NMAE: 76.7819, R^2: 0.0778\n",
      "Epoch [726/2000]\n",
      "Train Loss: 33203401.9647\n",
      "Val Loss: 33910444.6455, MAE: 5063.7393, NMAE: 77.2009, R^2: 0.0723\n",
      "Epoch [727/2000]\n",
      "Train Loss: 33039232.5931\n",
      "Val Loss: 33400745.4845, MAE: 5005.5015, NMAE: 76.3130, R^2: 0.0863\n",
      "Epoch [728/2000]\n",
      "Train Loss: 32952856.0336\n",
      "Val Loss: 33031820.6343, MAE: 4965.1465, NMAE: 75.6977, R^2: 0.0964\n",
      "Epoch [729/2000]\n",
      "Train Loss: 32579737.2741\n",
      "Val Loss: 32744639.9819, MAE: 4906.2607, NMAE: 74.8000, R^2: 0.1042\n",
      "Epoch [730/2000]\n",
      "Train Loss: 32646134.1569\n",
      "Val Loss: 32838912.8389, MAE: 4881.1885, NMAE: 74.4177, R^2: 0.1016\n",
      "Epoch [731/2000]\n",
      "Train Loss: 32766974.7612\n",
      "Val Loss: 32142956.4970, MAE: 4805.3130, NMAE: 73.2609, R^2: 0.1207\n",
      "Epoch [732/2000]\n",
      "Train Loss: 32986874.3819\n",
      "Val Loss: 32769518.0039, MAE: 4892.7632, NMAE: 74.5942, R^2: 0.1035\n",
      "Epoch [733/2000]\n",
      "Train Loss: 32727572.0379\n",
      "Val Loss: 32793835.9072, MAE: 4941.4624, NMAE: 75.3366, R^2: 0.1029\n",
      "Epoch [734/2000]\n",
      "Train Loss: 32774454.5810\n",
      "Val Loss: 32831630.1731, MAE: 4935.0312, NMAE: 75.2386, R^2: 0.1018\n",
      "Epoch [735/2000]\n",
      "Train Loss: 32828973.4871\n",
      "Val Loss: 32618677.6006, MAE: 4910.9526, NMAE: 74.8715, R^2: 0.1077\n",
      "Epoch [736/2000]\n",
      "Train Loss: 32653540.5724\n",
      "Val Loss: 32315506.9415, MAE: 4872.1455, NMAE: 74.2799, R^2: 0.1160\n",
      "Epoch [737/2000]\n",
      "Train Loss: 32751463.1267\n",
      "Val Loss: 32797243.0557, MAE: 4936.9053, NMAE: 75.2672, R^2: 0.1028\n",
      "Epoch [738/2000]\n",
      "Train Loss: 32328224.8190\n",
      "Val Loss: 32349505.7168, MAE: 4876.5264, NMAE: 74.3466, R^2: 0.1150\n",
      "Epoch [739/2000]\n",
      "Train Loss: 32354207.8181\n",
      "Val Loss: 32312443.4737, MAE: 4869.2856, NMAE: 74.2363, R^2: 0.1160\n",
      "Epoch [740/2000]\n",
      "Train Loss: 32549294.0457\n",
      "Val Loss: 32401700.3424, MAE: 4880.6172, NMAE: 74.4090, R^2: 0.1136\n",
      "Epoch [741/2000]\n",
      "Train Loss: 32057018.9578\n",
      "Val Loss: 32470255.1930, MAE: 4869.9219, NMAE: 74.2460, R^2: 0.1117\n",
      "Epoch [742/2000]\n",
      "Train Loss: 32133245.0043\n",
      "Val Loss: 32375933.7919, MAE: 4878.4771, NMAE: 74.3764, R^2: 0.1143\n",
      "Epoch [743/2000]\n",
      "Train Loss: 39640073.3330\n",
      "Val Loss: 37365287.6224, MAE: 4788.4048, NMAE: 73.0032, R^2: -0.0222\n",
      "Epoch [744/2000]\n",
      "Train Loss: 33912382.7466\n",
      "Val Loss: 32029365.0458, MAE: 4749.8159, NMAE: 72.4148, R^2: 0.1238\n",
      "Epoch [745/2000]\n",
      "Train Loss: 32851899.0681\n",
      "Val Loss: 31885586.7733, MAE: 4749.3462, NMAE: 72.4077, R^2: 0.1277\n",
      "Epoch [746/2000]\n",
      "Train Loss: 32601572.3474\n",
      "Val Loss: 31850992.6269, MAE: 4756.1567, NMAE: 72.5115, R^2: 0.1287\n",
      "Epoch [747/2000]\n",
      "Train Loss: 32447640.6690\n",
      "Val Loss: 31990042.9750, MAE: 4813.2402, NMAE: 73.3818, R^2: 0.1249\n",
      "Epoch [748/2000]\n",
      "Train Loss: 32328272.9181\n",
      "Val Loss: 31928763.1507, MAE: 4800.4551, NMAE: 73.1869, R^2: 0.1265\n",
      "Epoch [749/2000]\n",
      "Train Loss: 32256885.4810\n",
      "Val Loss: 32020276.5026, MAE: 4815.4448, NMAE: 73.4154, R^2: 0.1240\n",
      "Epoch [750/2000]\n",
      "Train Loss: 32401185.4129\n",
      "Val Loss: 32191892.4931, MAE: 4810.9761, NMAE: 73.3473, R^2: 0.1193\n",
      "Epoch [751/2000]\n",
      "Train Loss: 32768568.4147\n",
      "Val Loss: 32076109.0060, MAE: 4819.0615, NMAE: 73.4705, R^2: 0.1225\n",
      "Epoch [752/2000]\n",
      "Train Loss: 33479349.1353\n",
      "Val Loss: 32367718.6369, MAE: 4851.7793, NMAE: 73.9694, R^2: 0.1145\n",
      "Epoch [753/2000]\n",
      "Train Loss: 32705411.6733\n",
      "Val Loss: 32218030.3320, MAE: 4827.8325, NMAE: 73.6043, R^2: 0.1186\n",
      "Epoch [754/2000]\n",
      "Train Loss: 32625890.6103\n",
      "Val Loss: 32208433.2526, MAE: 4807.5952, NMAE: 73.2957, R^2: 0.1189\n",
      "Epoch [755/2000]\n",
      "Train Loss: 32433670.0974\n",
      "Val Loss: 32126204.4162, MAE: 4824.1030, NMAE: 73.5474, R^2: 0.1211\n",
      "Epoch [756/2000]\n",
      "Train Loss: 32716085.9612\n",
      "Val Loss: 31876439.8843, MAE: 4783.2090, NMAE: 72.9239, R^2: 0.1280\n",
      "Epoch [757/2000]\n",
      "Train Loss: 32942138.3483\n",
      "Val Loss: 31866338.3890, MAE: 4744.5713, NMAE: 72.3349, R^2: 0.1282\n",
      "Epoch [758/2000]\n",
      "Train Loss: 32543310.6190\n",
      "Val Loss: 31945829.9046, MAE: 4799.2554, NMAE: 73.1686, R^2: 0.1261\n",
      "Epoch [759/2000]\n",
      "Train Loss: 32396235.2259\n",
      "Val Loss: 31782725.9542, MAE: 4794.1934, NMAE: 73.0914, R^2: 0.1305\n",
      "Epoch [760/2000]\n",
      "Train Loss: 32644184.0836\n",
      "Val Loss: 31638265.5881, MAE: 4749.7690, NMAE: 72.4141, R^2: 0.1345\n",
      "Epoch [761/2000]\n",
      "Train Loss: 32513105.0836\n",
      "Val Loss: 31690425.6123, MAE: 4780.4946, NMAE: 72.8826, R^2: 0.1331\n",
      "Epoch [762/2000]\n",
      "Train Loss: 32536832.8509\n",
      "Val Loss: 31689192.2191, MAE: 4777.8188, NMAE: 72.8418, R^2: 0.1331\n",
      "Epoch [763/2000]\n",
      "Train Loss: 32277246.4914\n",
      "Val Loss: 31919119.3692, MAE: 4809.4995, NMAE: 73.3248, R^2: 0.1268\n",
      "Epoch [764/2000]\n",
      "Train Loss: 32543091.5629\n",
      "Val Loss: 31921159.9607, MAE: 4803.2847, NMAE: 73.2300, R^2: 0.1267\n",
      "Epoch [765/2000]\n",
      "Train Loss: 32644022.5629\n",
      "Val Loss: 31988295.5648, MAE: 4821.0195, NMAE: 73.5004, R^2: 0.1249\n",
      "Epoch [766/2000]\n",
      "Train Loss: 32972061.6422\n",
      "Val Loss: 32286694.5117, MAE: 4832.4663, NMAE: 73.6749, R^2: 0.1167\n",
      "Epoch [767/2000]\n",
      "Train Loss: 32481906.3897\n",
      "Val Loss: 34134777.1775, MAE: 5063.7754, NMAE: 77.2014, R^2: 0.0662\n",
      "Epoch [768/2000]\n",
      "Train Loss: 32607806.5595\n",
      "Val Loss: 32748365.0376, MAE: 4917.9146, NMAE: 74.9776, R^2: 0.1041\n",
      "Epoch [769/2000]\n",
      "Train Loss: 32235258.9836\n",
      "Val Loss: 32384776.7927, MAE: 4866.1895, NMAE: 74.1891, R^2: 0.1141\n",
      "Epoch [770/2000]\n",
      "Train Loss: 32030568.8431\n",
      "Val Loss: 32727071.0512, MAE: 4905.8237, NMAE: 74.7933, R^2: 0.1047\n",
      "Epoch [771/2000]\n",
      "Train Loss: 32651830.4698\n",
      "Val Loss: 34527759.3696, MAE: 5139.8589, NMAE: 78.3614, R^2: 0.0554\n",
      "Epoch [772/2000]\n",
      "Train Loss: 33104842.1836\n",
      "Val Loss: 32399634.2453, MAE: 4916.1523, NMAE: 74.9508, R^2: 0.1137\n",
      "Epoch [773/2000]\n",
      "Train Loss: 32406858.6922\n",
      "Val Loss: 31949371.2537, MAE: 4852.5991, NMAE: 73.9819, R^2: 0.1260\n",
      "Epoch [774/2000]\n",
      "Train Loss: 32201247.6103\n",
      "Val Loss: 31926531.9737, MAE: 4831.0986, NMAE: 73.6541, R^2: 0.1266\n",
      "Epoch [775/2000]\n",
      "Train Loss: 32126412.6664\n",
      "Val Loss: 32176477.0959, MAE: 4820.3691, NMAE: 73.4905, R^2: 0.1198\n",
      "Epoch [776/2000]\n",
      "Train Loss: 32368534.5172\n",
      "Val Loss: 32059437.4421, MAE: 4830.9653, NMAE: 73.6520, R^2: 0.1230\n",
      "Epoch [777/2000]\n",
      "Train Loss: 32347664.5500\n",
      "Val Loss: 32026111.7353, MAE: 4837.7446, NMAE: 73.7554, R^2: 0.1239\n",
      "Epoch [778/2000]\n",
      "Train Loss: 31994910.0379\n",
      "Val Loss: 32017864.7923, MAE: 4838.1221, NMAE: 73.7611, R^2: 0.1241\n",
      "Epoch [779/2000]\n",
      "Train Loss: 32062275.4216\n",
      "Val Loss: 32117426.9106, MAE: 4871.4766, NMAE: 74.2697, R^2: 0.1214\n",
      "Epoch [780/2000]\n",
      "Train Loss: 32119508.4336\n",
      "Val Loss: 32318200.0503, MAE: 4893.9609, NMAE: 74.6124, R^2: 0.1159\n",
      "Epoch [781/2000]\n",
      "Train Loss: 31896777.4690\n",
      "Val Loss: 32220678.5894, MAE: 4864.7900, NMAE: 74.1677, R^2: 0.1186\n",
      "Epoch [782/2000]\n",
      "Train Loss: 32080473.4871\n",
      "Val Loss: 32235262.4516, MAE: 4887.7368, NMAE: 74.5176, R^2: 0.1182\n",
      "Epoch [783/2000]\n",
      "Train Loss: 31935137.8905\n",
      "Val Loss: 32158370.6775, MAE: 4880.2993, NMAE: 74.4042, R^2: 0.1203\n",
      "Epoch [784/2000]\n",
      "Train Loss: 32198919.2802\n",
      "Val Loss: 32143512.7737, MAE: 4863.7642, NMAE: 74.1521, R^2: 0.1207\n",
      "Epoch [785/2000]\n",
      "Train Loss: 32183495.0698\n",
      "Val Loss: 32630398.1636, MAE: 4930.5840, NMAE: 75.1708, R^2: 0.1073\n",
      "Epoch [786/2000]\n",
      "Train Loss: 32321150.7621\n",
      "Val Loss: 32394895.2440, MAE: 4851.8564, NMAE: 73.9705, R^2: 0.1138\n",
      "Epoch [787/2000]\n",
      "Train Loss: 32052262.0336\n",
      "Val Loss: 32002947.1416, MAE: 4850.6450, NMAE: 73.9521, R^2: 0.1245\n",
      "Epoch [788/2000]\n",
      "Train Loss: 31983576.7931\n",
      "Val Loss: 32150809.6865, MAE: 4891.3789, NMAE: 74.5731, R^2: 0.1205\n",
      "Epoch [789/2000]\n",
      "Train Loss: 32609754.6250\n",
      "Val Loss: 32312806.3165, MAE: 4909.8926, NMAE: 74.8553, R^2: 0.1160\n",
      "Epoch [790/2000]\n",
      "Train Loss: 32079918.6043\n",
      "Val Loss: 32219413.7794, MAE: 4898.2705, NMAE: 74.6782, R^2: 0.1186\n",
      "Epoch [791/2000]\n",
      "Train Loss: 31918028.7716\n",
      "Val Loss: 32343000.1768, MAE: 4916.7983, NMAE: 74.9606, R^2: 0.1152\n",
      "Epoch [792/2000]\n",
      "Train Loss: 32034341.7698\n",
      "Val Loss: 32389121.7200, MAE: 4919.9014, NMAE: 75.0079, R^2: 0.1139\n",
      "Epoch [793/2000]\n",
      "Train Loss: 32070612.1043\n",
      "Val Loss: 32620241.4417, MAE: 4947.0020, NMAE: 75.4211, R^2: 0.1076\n",
      "Epoch [794/2000]\n",
      "Train Loss: 32002513.5543\n",
      "Val Loss: 32044851.7878, MAE: 4881.4185, NMAE: 74.4212, R^2: 0.1234\n",
      "Epoch [795/2000]\n",
      "Train Loss: 31890360.8647\n",
      "Val Loss: 32734541.7137, MAE: 4959.4097, NMAE: 75.6103, R^2: 0.1045\n",
      "Epoch [796/2000]\n",
      "Train Loss: 31840129.8250\n",
      "Val Loss: 32354333.3260, MAE: 4911.8247, NMAE: 74.8848, R^2: 0.1149\n",
      "Epoch [797/2000]\n",
      "Train Loss: 32318713.2828\n",
      "Val Loss: 32061520.1813, MAE: 4874.1299, NMAE: 74.3101, R^2: 0.1229\n",
      "Epoch [798/2000]\n",
      "Train Loss: 31980190.0560\n",
      "Val Loss: 32309390.1995, MAE: 4903.5718, NMAE: 74.7590, R^2: 0.1161\n",
      "Epoch [799/2000]\n",
      "Train Loss: 32091081.6095\n",
      "Val Loss: 32039501.0358, MAE: 4860.7529, NMAE: 74.1062, R^2: 0.1235\n",
      "Epoch [800/2000]\n",
      "Train Loss: 31713165.4776\n",
      "Val Loss: 32130310.7174, MAE: 4877.1802, NMAE: 74.3566, R^2: 0.1210\n",
      "Epoch [801/2000]\n",
      "Train Loss: 31805186.3129\n",
      "Val Loss: 32546240.0548, MAE: 4929.9453, NMAE: 75.1611, R^2: 0.1096\n",
      "Epoch [802/2000]\n",
      "Train Loss: 32057226.6853\n",
      "Val Loss: 32210270.8359, MAE: 4877.1270, NMAE: 74.3558, R^2: 0.1188\n",
      "Epoch [803/2000]\n",
      "Train Loss: 32053137.9121\n",
      "Val Loss: 33209144.1280, MAE: 4989.5483, NMAE: 76.0698, R^2: 0.0915\n",
      "Epoch [804/2000]\n",
      "Train Loss: 32033850.2836\n",
      "Val Loss: 32009220.6552, MAE: 4862.1768, NMAE: 74.1279, R^2: 0.1243\n",
      "Epoch [805/2000]\n",
      "Train Loss: 32147730.5853\n",
      "Val Loss: 32101191.0902, MAE: 4871.5718, NMAE: 74.2711, R^2: 0.1218\n",
      "Epoch [806/2000]\n",
      "Train Loss: 32034844.3069\n",
      "Val Loss: 31936108.7848, MAE: 4844.6743, NMAE: 73.8610, R^2: 0.1263\n",
      "Epoch [807/2000]\n",
      "Train Loss: 31837485.1198\n",
      "Val Loss: 32223566.6645, MAE: 4886.6602, NMAE: 74.5011, R^2: 0.1185\n",
      "Epoch [808/2000]\n",
      "Train Loss: 31800861.8845\n",
      "Val Loss: 32325924.8575, MAE: 4901.7495, NMAE: 74.7312, R^2: 0.1157\n",
      "Epoch [809/2000]\n",
      "Train Loss: 32012735.9612\n",
      "Val Loss: 31970159.6759, MAE: 4835.8286, NMAE: 73.7262, R^2: 0.1254\n",
      "Epoch [810/2000]\n",
      "Train Loss: 31871091.9155\n",
      "Val Loss: 32208000.7275, MAE: 4890.1953, NMAE: 74.5550, R^2: 0.1189\n",
      "Epoch [811/2000]\n",
      "Train Loss: 31890943.0034\n",
      "Val Loss: 32214915.1844, MAE: 4868.7764, NMAE: 74.2285, R^2: 0.1187\n",
      "Epoch [812/2000]\n",
      "Train Loss: 31753066.2862\n",
      "Val Loss: 31956630.8895, MAE: 4857.1631, NMAE: 74.0514, R^2: 0.1258\n",
      "Epoch [813/2000]\n",
      "Train Loss: 31683373.5491\n",
      "Val Loss: 32625385.6164, MAE: 4944.8828, NMAE: 75.3888, R^2: 0.1075\n",
      "Epoch [814/2000]\n",
      "Train Loss: 31824012.9388\n",
      "Val Loss: 32798931.1546, MAE: 4971.8164, NMAE: 75.7994, R^2: 0.1027\n",
      "Epoch [815/2000]\n",
      "Train Loss: 31991299.9681\n",
      "Val Loss: 32451108.2500, MAE: 4929.8545, NMAE: 75.1597, R^2: 0.1123\n",
      "Epoch [816/2000]\n",
      "Train Loss: 31882508.1224\n",
      "Val Loss: 32129865.8443, MAE: 4888.4155, NMAE: 74.5279, R^2: 0.1210\n",
      "Epoch [817/2000]\n",
      "Train Loss: 31779419.4267\n",
      "Val Loss: 32665515.9853, MAE: 4948.6382, NMAE: 75.4460, R^2: 0.1064\n",
      "Epoch [818/2000]\n",
      "Train Loss: 31722760.2905\n",
      "Val Loss: 32485648.5579, MAE: 4929.9678, NMAE: 75.1614, R^2: 0.1113\n",
      "Epoch [819/2000]\n",
      "Train Loss: 31713532.1966\n",
      "Val Loss: 32515750.1166, MAE: 4917.6675, NMAE: 74.9739, R^2: 0.1105\n",
      "Epoch [820/2000]\n",
      "Train Loss: 31644900.0983\n",
      "Val Loss: 32235900.7576, MAE: 4884.2373, NMAE: 74.4642, R^2: 0.1181\n",
      "Epoch [821/2000]\n",
      "Train Loss: 31661866.3888\n",
      "Val Loss: 32426615.8366, MAE: 4913.8506, NMAE: 74.9157, R^2: 0.1129\n",
      "Epoch [822/2000]\n",
      "Train Loss: 31451639.7517\n",
      "Val Loss: 32618208.8966, MAE: 4924.6665, NMAE: 75.0806, R^2: 0.1077\n",
      "Epoch [823/2000]\n",
      "Train Loss: 31666250.6944\n",
      "Val Loss: 32492955.3711, MAE: 4924.5879, NMAE: 75.0794, R^2: 0.1111\n",
      "Epoch [824/2000]\n",
      "Train Loss: 31854957.1905\n",
      "Val Loss: 32459201.9009, MAE: 4920.8408, NMAE: 75.0223, R^2: 0.1120\n",
      "Epoch [825/2000]\n",
      "Train Loss: 31747612.2578\n",
      "Val Loss: 32551232.8014, MAE: 4923.0293, NMAE: 75.0556, R^2: 0.1095\n",
      "Epoch [826/2000]\n",
      "Train Loss: 33229542.7145\n",
      "Val Loss: 32391383.3474, MAE: 4913.0132, NMAE: 74.9029, R^2: 0.1139\n",
      "Epoch [827/2000]\n",
      "Train Loss: 32217092.5259\n",
      "Val Loss: 31908402.9832, MAE: 4869.8574, NMAE: 74.2450, R^2: 0.1271\n",
      "Epoch [828/2000]\n",
      "Train Loss: 32056164.7655\n",
      "Val Loss: 31755422.9799, MAE: 4808.9839, NMAE: 73.3169, R^2: 0.1313\n",
      "Epoch [829/2000]\n",
      "Train Loss: 32165209.8698\n",
      "Val Loss: 31826812.4456, MAE: 4837.9019, NMAE: 73.7578, R^2: 0.1293\n",
      "Epoch [830/2000]\n",
      "Train Loss: 31819869.5948\n",
      "Val Loss: 32503049.0173, MAE: 4924.3203, NMAE: 75.0753, R^2: 0.1108\n",
      "Epoch [831/2000]\n",
      "Train Loss: 31684223.1060\n",
      "Val Loss: 32688749.4357, MAE: 4949.2578, NMAE: 75.4555, R^2: 0.1058\n",
      "Epoch [832/2000]\n",
      "Train Loss: 33033838.5155\n",
      "Val Loss: 32234484.1222, MAE: 4755.3394, NMAE: 72.4990, R^2: 0.1182\n",
      "Epoch [833/2000]\n",
      "Train Loss: 32111675.7017\n",
      "Val Loss: 33061819.1667, MAE: 4949.2344, NMAE: 75.4551, R^2: 0.0955\n",
      "Epoch [834/2000]\n",
      "Train Loss: 33318162.4129\n",
      "Val Loss: 31541016.2962, MAE: 4758.3623, NMAE: 72.5451, R^2: 0.1371\n",
      "Epoch [835/2000]\n",
      "Train Loss: 32061747.7560\n",
      "Val Loss: 31477808.3459, MAE: 4791.1880, NMAE: 73.0456, R^2: 0.1389\n",
      "Epoch [836/2000]\n",
      "Train Loss: 31978886.5164\n",
      "Val Loss: 31430771.9564, MAE: 4782.2764, NMAE: 72.9097, R^2: 0.1402\n",
      "Epoch [837/2000]\n",
      "Train Loss: 32344434.6784\n",
      "Val Loss: 31589710.6736, MAE: 4818.7246, NMAE: 73.4654, R^2: 0.1358\n",
      "Epoch [838/2000]\n",
      "Train Loss: 32539282.1103\n",
      "Val Loss: 31541273.5078, MAE: 4755.8643, NMAE: 72.5071, R^2: 0.1371\n",
      "Epoch [839/2000]\n",
      "Train Loss: 32105074.1517\n",
      "Val Loss: 31900713.5609, MAE: 4854.5361, NMAE: 74.0114, R^2: 0.1273\n",
      "Epoch [840/2000]\n",
      "Train Loss: 32022171.8836\n",
      "Val Loss: 32536106.0484, MAE: 4946.4546, NMAE: 75.4128, R^2: 0.1099\n",
      "Epoch [841/2000]\n",
      "Train Loss: 31987365.4957\n",
      "Val Loss: 32293523.4670, MAE: 4918.0044, NMAE: 74.9790, R^2: 0.1166\n",
      "Epoch [842/2000]\n",
      "Train Loss: 32582873.4621\n",
      "Val Loss: 32087142.6969, MAE: 4871.3218, NMAE: 74.2673, R^2: 0.1222\n",
      "Epoch [843/2000]\n",
      "Train Loss: 32081264.2871\n",
      "Val Loss: 31895243.5835, MAE: 4845.6099, NMAE: 73.8753, R^2: 0.1275\n",
      "Epoch [844/2000]\n",
      "Train Loss: 31729258.3957\n",
      "Val Loss: 32412888.9972, MAE: 4914.9141, NMAE: 74.9319, R^2: 0.1133\n",
      "Epoch [845/2000]\n",
      "Train Loss: 31875677.2078\n",
      "Val Loss: 32280815.4044, MAE: 4898.0244, NMAE: 74.6744, R^2: 0.1169\n",
      "Epoch [846/2000]\n",
      "Train Loss: 31808983.1241\n",
      "Val Loss: 32034738.1883, MAE: 4869.2925, NMAE: 74.2364, R^2: 0.1236\n",
      "Epoch [847/2000]\n",
      "Train Loss: 31742653.5086\n",
      "Val Loss: 32761018.6669, MAE: 4962.2168, NMAE: 75.6531, R^2: 0.1038\n",
      "Epoch [848/2000]\n",
      "Train Loss: 31909295.1267\n",
      "Val Loss: 31962410.7748, MAE: 4845.9053, NMAE: 73.8798, R^2: 0.1256\n",
      "Epoch [849/2000]\n",
      "Train Loss: 31820765.9931\n",
      "Val Loss: 32560572.2647, MAE: 4942.9287, NMAE: 75.3590, R^2: 0.1093\n",
      "Epoch [850/2000]\n",
      "Train Loss: 34184308.8931\n",
      "Val Loss: 34082116.5058, MAE: 4848.9927, NMAE: 73.9269, R^2: 0.0676\n",
      "Epoch [851/2000]\n",
      "Train Loss: 34311661.2422\n",
      "Val Loss: 32985084.1483, MAE: 4874.4546, NMAE: 74.3151, R^2: 0.0976\n",
      "Epoch [852/2000]\n",
      "Train Loss: 32192547.3991\n",
      "Val Loss: 31809687.3184, MAE: 4842.7402, NMAE: 73.8315, R^2: 0.1298\n",
      "Epoch [853/2000]\n",
      "Train Loss: 31610276.3767\n",
      "Val Loss: 31870786.0848, MAE: 4851.5669, NMAE: 73.9661, R^2: 0.1281\n",
      "Epoch [854/2000]\n",
      "Train Loss: 31550968.5457\n",
      "Val Loss: 32223158.5253, MAE: 4905.5986, NMAE: 74.7899, R^2: 0.1185\n",
      "Epoch [855/2000]\n",
      "Train Loss: 31695283.9862\n",
      "Val Loss: 31901245.1252, MAE: 4850.1880, NMAE: 73.9451, R^2: 0.1273\n",
      "Epoch [856/2000]\n",
      "Train Loss: 31565461.4733\n",
      "Val Loss: 32834963.6302, MAE: 4947.2925, NMAE: 75.4255, R^2: 0.1018\n",
      "Epoch [857/2000]\n",
      "Train Loss: 31686680.1698\n",
      "Val Loss: 31866793.8538, MAE: 4864.0532, NMAE: 74.1565, R^2: 0.1282\n",
      "Epoch [858/2000]\n",
      "Train Loss: 31938638.0224\n",
      "Val Loss: 31957003.1485, MAE: 4862.9263, NMAE: 74.1393, R^2: 0.1258\n",
      "Epoch [859/2000]\n",
      "Train Loss: 31856403.8466\n",
      "Val Loss: 33770208.7202, MAE: 5083.7539, NMAE: 77.5060, R^2: 0.0762\n",
      "Epoch [860/2000]\n",
      "Train Loss: 33823726.0784\n",
      "Val Loss: 32564053.2150, MAE: 4892.1118, NMAE: 74.5843, R^2: 0.1092\n",
      "Epoch [861/2000]\n",
      "Train Loss: 32533006.0345\n",
      "Val Loss: 32484511.2522, MAE: 4918.5146, NMAE: 74.9868, R^2: 0.1113\n",
      "Epoch [862/2000]\n",
      "Train Loss: 31961574.9336\n",
      "Val Loss: 32505817.5309, MAE: 4902.7178, NMAE: 74.7460, R^2: 0.1108\n",
      "Epoch [863/2000]\n",
      "Train Loss: 32166790.5940\n",
      "Val Loss: 32478069.5212, MAE: 4866.5083, NMAE: 74.1939, R^2: 0.1115\n",
      "Epoch [864/2000]\n",
      "Train Loss: 31991448.4681\n",
      "Val Loss: 32572592.0814, MAE: 4895.8154, NMAE: 74.6407, R^2: 0.1089\n",
      "Epoch [865/2000]\n",
      "Train Loss: 32488701.5513\n",
      "Val Loss: 32771828.8215, MAE: 4820.1016, NMAE: 73.4864, R^2: 0.1035\n",
      "Epoch [866/2000]\n",
      "Train Loss: 32317783.5690\n",
      "Val Loss: 31920530.5924, MAE: 4790.1426, NMAE: 73.0297, R^2: 0.1268\n",
      "Epoch [867/2000]\n",
      "Train Loss: 31967028.5483\n",
      "Val Loss: 31629423.4840, MAE: 4800.8643, NMAE: 73.1931, R^2: 0.1347\n",
      "Epoch [868/2000]\n",
      "Train Loss: 31692471.4095\n",
      "Val Loss: 31569678.8558, MAE: 4790.3384, NMAE: 73.0326, R^2: 0.1364\n",
      "Epoch [869/2000]\n",
      "Train Loss: 31458497.1026\n",
      "Val Loss: 31688333.2310, MAE: 4804.9927, NMAE: 73.2561, R^2: 0.1331\n",
      "Epoch [870/2000]\n",
      "Train Loss: 31574893.4569\n",
      "Val Loss: 32017876.0285, MAE: 4834.7349, NMAE: 73.7095, R^2: 0.1241\n",
      "Epoch [871/2000]\n",
      "Train Loss: 31748460.4276\n",
      "Val Loss: 31930146.7405, MAE: 4813.5137, NMAE: 73.3860, R^2: 0.1265\n",
      "Epoch [872/2000]\n",
      "Train Loss: 32287211.5123\n",
      "Val Loss: 32028786.7293, MAE: 4835.0605, NMAE: 73.7145, R^2: 0.1238\n",
      "Epoch [873/2000]\n",
      "Train Loss: 31633493.4647\n",
      "Val Loss: 31700579.9067, MAE: 4802.9829, NMAE: 73.2254, R^2: 0.1328\n",
      "Epoch [874/2000]\n",
      "Train Loss: 31469916.4198\n",
      "Val Loss: 31955865.6528, MAE: 4836.3140, NMAE: 73.7336, R^2: 0.1258\n",
      "Epoch [875/2000]\n",
      "Train Loss: 31434063.7345\n",
      "Val Loss: 31987694.7245, MAE: 4796.6006, NMAE: 73.1281, R^2: 0.1249\n",
      "Epoch [876/2000]\n",
      "Train Loss: 31676682.5517\n",
      "Val Loss: 31715335.2843, MAE: 4820.0566, NMAE: 73.4857, R^2: 0.1324\n",
      "Epoch [877/2000]\n",
      "Train Loss: 31647919.4276\n",
      "Val Loss: 32052469.4441, MAE: 4862.9722, NMAE: 74.1400, R^2: 0.1232\n",
      "Epoch [878/2000]\n",
      "Train Loss: 31465089.0397\n",
      "Val Loss: 31774146.1274, MAE: 4820.7559, NMAE: 73.4964, R^2: 0.1308\n",
      "Epoch [879/2000]\n",
      "Train Loss: 31287935.0474\n",
      "Val Loss: 32176774.2966, MAE: 4869.9248, NMAE: 74.2460, R^2: 0.1198\n",
      "Epoch [880/2000]\n",
      "Train Loss: 31287770.0802\n",
      "Val Loss: 32284616.0315, MAE: 4880.8486, NMAE: 74.4125, R^2: 0.1168\n",
      "Epoch [881/2000]\n",
      "Train Loss: 31378316.7888\n",
      "Val Loss: 31869363.6826, MAE: 4819.7905, NMAE: 73.4817, R^2: 0.1282\n",
      "Epoch [882/2000]\n",
      "Train Loss: 31694981.4026\n",
      "Val Loss: 31759100.7535, MAE: 4846.7954, NMAE: 73.8934, R^2: 0.1312\n",
      "Epoch [883/2000]\n",
      "Train Loss: 31922978.8069\n",
      "Val Loss: 31574454.8169, MAE: 4814.4194, NMAE: 73.3998, R^2: 0.1362\n",
      "Epoch [884/2000]\n",
      "Train Loss: 31490709.2733\n",
      "Val Loss: 32094980.8890, MAE: 4876.6753, NMAE: 74.3489, R^2: 0.1220\n",
      "Epoch [885/2000]\n",
      "Train Loss: 31639017.8862\n",
      "Val Loss: 31672612.3972, MAE: 4796.2686, NMAE: 73.1230, R^2: 0.1335\n",
      "Epoch [886/2000]\n",
      "Train Loss: 31644248.5526\n",
      "Val Loss: 31865667.0989, MAE: 4860.6401, NMAE: 74.1044, R^2: 0.1283\n",
      "Epoch [887/2000]\n",
      "Train Loss: 31627676.8138\n",
      "Val Loss: 32021282.9488, MAE: 4877.9771, NMAE: 74.3688, R^2: 0.1240\n",
      "Epoch [888/2000]\n",
      "Train Loss: 31620730.2853\n",
      "Val Loss: 32233001.8908, MAE: 4902.0957, NMAE: 74.7365, R^2: 0.1182\n",
      "Epoch [889/2000]\n",
      "Train Loss: 32339144.4578\n",
      "Val Loss: 31524449.8014, MAE: 4805.4487, NMAE: 73.2630, R^2: 0.1376\n",
      "Epoch [890/2000]\n",
      "Train Loss: 31802203.5276\n",
      "Val Loss: 31610237.2284, MAE: 4829.0806, NMAE: 73.6233, R^2: 0.1353\n",
      "Epoch [891/2000]\n",
      "Train Loss: 32213541.7336\n",
      "Val Loss: 31110426.8521, MAE: 4763.3687, NMAE: 72.6215, R^2: 0.1489\n",
      "Epoch [892/2000]\n",
      "Train Loss: 31744476.3647\n",
      "Val Loss: 31600131.1136, MAE: 4839.8774, NMAE: 73.7879, R^2: 0.1355\n",
      "Epoch [893/2000]\n",
      "Train Loss: 31879545.3957\n",
      "Val Loss: 31438807.7809, MAE: 4825.0049, NMAE: 73.5612, R^2: 0.1399\n",
      "Epoch [894/2000]\n",
      "Train Loss: 31790785.1017\n",
      "Val Loss: 31687765.4089, MAE: 4852.6367, NMAE: 73.9824, R^2: 0.1331\n",
      "Epoch [895/2000]\n",
      "Train Loss: 31656177.3172\n",
      "Val Loss: 31515560.2664, MAE: 4811.6479, NMAE: 73.3575, R^2: 0.1378\n",
      "Epoch [896/2000]\n",
      "Train Loss: 31594509.5500\n",
      "Val Loss: 31962738.3424, MAE: 4867.2368, NMAE: 74.2050, R^2: 0.1256\n",
      "Epoch [897/2000]\n",
      "Train Loss: 31535274.1164\n",
      "Val Loss: 32021179.7440, MAE: 4876.3545, NMAE: 74.3440, R^2: 0.1240\n",
      "Epoch [898/2000]\n",
      "Train Loss: 32036620.4328\n",
      "Val Loss: 32016441.4447, MAE: 4852.1870, NMAE: 73.9756, R^2: 0.1241\n",
      "Epoch [899/2000]\n",
      "Train Loss: 31851630.5931\n",
      "Val Loss: 31723220.3588, MAE: 4836.1582, NMAE: 73.7312, R^2: 0.1322\n",
      "Epoch [900/2000]\n",
      "Train Loss: 31432674.3690\n",
      "Val Loss: 32176661.4469, MAE: 4888.6587, NMAE: 74.5316, R^2: 0.1198\n",
      "Epoch [901/2000]\n",
      "Train Loss: 31672562.5741\n",
      "Val Loss: 32086507.3053, MAE: 4878.8452, NMAE: 74.3820, R^2: 0.1222\n",
      "Epoch [902/2000]\n",
      "Train Loss: 31719691.3931\n",
      "Val Loss: 31760389.9283, MAE: 4868.6411, NMAE: 74.2264, R^2: 0.1311\n",
      "Epoch [903/2000]\n",
      "Train Loss: 31722580.2595\n",
      "Val Loss: 31895593.8048, MAE: 4874.3433, NMAE: 74.3134, R^2: 0.1274\n",
      "Epoch [904/2000]\n",
      "Train Loss: 31679620.0638\n",
      "Val Loss: 31950308.0099, MAE: 4877.7090, NMAE: 74.3647, R^2: 0.1260\n",
      "Epoch [905/2000]\n",
      "Train Loss: 31658184.5810\n",
      "Val Loss: 31759533.5134, MAE: 4849.9141, NMAE: 73.9409, R^2: 0.1312\n",
      "Epoch [906/2000]\n",
      "Train Loss: 31518341.6198\n",
      "Val Loss: 31881213.0032, MAE: 4873.1099, NMAE: 74.2946, R^2: 0.1278\n",
      "Epoch [907/2000]\n",
      "Train Loss: 31702413.7241\n",
      "Val Loss: 31737344.5106, MAE: 4853.4961, NMAE: 73.9955, R^2: 0.1318\n",
      "Epoch [908/2000]\n",
      "Train Loss: 31455097.0190\n",
      "Val Loss: 31958239.6654, MAE: 4881.0791, NMAE: 74.4161, R^2: 0.1257\n",
      "Epoch [909/2000]\n",
      "Train Loss: 31720190.5129\n",
      "Val Loss: 31692525.3925, MAE: 4851.0859, NMAE: 73.9588, R^2: 0.1330\n",
      "Epoch [910/2000]\n",
      "Train Loss: 31583538.2345\n",
      "Val Loss: 32099508.8985, MAE: 4899.8564, NMAE: 74.7023, R^2: 0.1219\n",
      "Epoch [911/2000]\n",
      "Train Loss: 31667262.7009\n",
      "Val Loss: 32667942.6036, MAE: 4959.0776, NMAE: 75.6052, R^2: 0.1063\n",
      "Epoch [912/2000]\n",
      "Train Loss: 31565232.6043\n",
      "Val Loss: 31803911.1088, MAE: 4860.2944, NMAE: 74.0992, R^2: 0.1300\n",
      "Epoch [913/2000]\n",
      "Train Loss: 31726709.7491\n",
      "Val Loss: 31826994.1395, MAE: 4864.4209, NMAE: 74.1621, R^2: 0.1293\n",
      "Epoch [914/2000]\n",
      "Train Loss: 31989587.7095\n",
      "Val Loss: 31948355.3057, MAE: 4882.0083, NMAE: 74.4302, R^2: 0.1260\n",
      "Epoch [915/2000]\n",
      "Train Loss: 31814440.3638\n",
      "Val Loss: 32994950.1986, MAE: 4974.8770, NMAE: 75.8461, R^2: 0.0974\n",
      "Epoch [916/2000]\n",
      "Train Loss: 31742539.7828\n",
      "Val Loss: 31995979.8063, MAE: 4864.9355, NMAE: 74.1699, R^2: 0.1247\n",
      "Epoch [917/2000]\n",
      "Train Loss: 31586078.3681\n",
      "Val Loss: 31869591.4687, MAE: 4871.2036, NMAE: 74.2655, R^2: 0.1282\n",
      "Epoch [918/2000]\n",
      "Train Loss: 31752955.8638\n",
      "Val Loss: 31587156.6058, MAE: 4832.3154, NMAE: 73.6726, R^2: 0.1359\n",
      "Epoch [919/2000]\n",
      "Train Loss: 31793000.8621\n",
      "Val Loss: 31695374.4294, MAE: 4847.8208, NMAE: 73.9090, R^2: 0.1329\n",
      "Epoch [920/2000]\n",
      "Train Loss: 31569983.7112\n",
      "Val Loss: 32588442.5669, MAE: 4959.7520, NMAE: 75.6155, R^2: 0.1085\n",
      "Epoch [921/2000]\n",
      "Train Loss: 32006033.6664\n",
      "Val Loss: 32097040.6250, MAE: 4897.9751, NMAE: 74.6736, R^2: 0.1219\n",
      "Epoch [922/2000]\n",
      "Train Loss: 31533964.1578\n",
      "Val Loss: 33928063.5220, MAE: 5112.1089, NMAE: 77.9383, R^2: 0.0718\n",
      "Epoch [923/2000]\n",
      "Train Loss: 32782946.1845\n",
      "Val Loss: 31939742.9119, MAE: 4890.1152, NMAE: 74.5538, R^2: 0.1262\n",
      "Epoch [924/2000]\n",
      "Train Loss: 31524617.2216\n",
      "Val Loss: 32409214.2707, MAE: 4953.3506, NMAE: 75.5179, R^2: 0.1134\n",
      "Epoch [925/2000]\n",
      "Train Loss: 31795419.9448\n",
      "Val Loss: 31983318.1002, MAE: 4897.8193, NMAE: 74.6713, R^2: 0.1250\n",
      "Epoch [926/2000]\n",
      "Train Loss: 31495395.2517\n",
      "Val Loss: 32079130.5995, MAE: 4884.3945, NMAE: 74.4666, R^2: 0.1224\n",
      "Epoch [927/2000]\n",
      "Train Loss: 31132479.0776\n",
      "Val Loss: 32722468.0522, MAE: 4948.6216, NMAE: 75.4458, R^2: 0.1048\n",
      "Epoch [928/2000]\n",
      "Train Loss: 31271649.0026\n",
      "Val Loss: 32063783.8856, MAE: 4884.9297, NMAE: 74.4748, R^2: 0.1228\n",
      "Epoch [929/2000]\n",
      "Train Loss: 31399734.9121\n",
      "Val Loss: 32916354.9206, MAE: 4977.6182, NMAE: 75.8879, R^2: 0.0995\n",
      "Epoch [930/2000]\n",
      "Train Loss: 32369170.5733\n",
      "Val Loss: 31750376.3497, MAE: 4857.0864, NMAE: 74.0503, R^2: 0.1314\n",
      "Epoch [931/2000]\n",
      "Train Loss: 31874182.2802\n",
      "Val Loss: 32126597.9940, MAE: 4892.6514, NMAE: 74.5925, R^2: 0.1211\n",
      "Epoch [932/2000]\n",
      "Train Loss: 31627860.4379\n",
      "Val Loss: 31602578.4529, MAE: 4823.8252, NMAE: 73.5432, R^2: 0.1355\n",
      "Epoch [933/2000]\n",
      "Train Loss: 31418988.4121\n",
      "Val Loss: 31685034.4167, MAE: 4830.6484, NMAE: 73.6472, R^2: 0.1332\n",
      "Epoch [934/2000]\n",
      "Train Loss: 31200006.5612\n",
      "Val Loss: 31935232.7528, MAE: 4867.3135, NMAE: 74.2062, R^2: 0.1264\n",
      "Epoch [935/2000]\n",
      "Train Loss: 31423133.1552\n",
      "Val Loss: 32045402.1576, MAE: 4885.9414, NMAE: 74.4902, R^2: 0.1234\n",
      "Epoch [936/2000]\n",
      "Train Loss: 31353865.7302\n",
      "Val Loss: 31842750.8797, MAE: 4857.9253, NMAE: 74.0631, R^2: 0.1289\n",
      "Epoch [937/2000]\n",
      "Train Loss: 31254125.3250\n",
      "Val Loss: 32678876.2198, MAE: 4967.4814, NMAE: 75.7333, R^2: 0.1060\n",
      "Epoch [938/2000]\n",
      "Train Loss: 31381875.4190\n",
      "Val Loss: 32454624.8109, MAE: 4931.2251, NMAE: 75.1806, R^2: 0.1122\n",
      "Epoch [939/2000]\n",
      "Train Loss: 31179288.5922\n",
      "Val Loss: 32624084.3994, MAE: 4941.3257, NMAE: 75.3346, R^2: 0.1075\n",
      "Epoch [940/2000]\n",
      "Train Loss: 31714365.3138\n",
      "Val Loss: 31719431.3193, MAE: 4838.0928, NMAE: 73.7607, R^2: 0.1323\n",
      "Epoch [941/2000]\n",
      "Train Loss: 31510369.7672\n",
      "Val Loss: 32888760.0035, MAE: 4974.1704, NMAE: 75.8353, R^2: 0.1003\n",
      "Epoch [942/2000]\n",
      "Train Loss: 31083026.1138\n",
      "Val Loss: 32166181.6149, MAE: 4885.6421, NMAE: 74.4856, R^2: 0.1200\n",
      "Epoch [943/2000]\n",
      "Train Loss: 31410986.9302\n",
      "Val Loss: 32917330.1999, MAE: 4955.4585, NMAE: 75.5500, R^2: 0.0995\n",
      "Epoch [944/2000]\n",
      "Train Loss: 31284203.3595\n",
      "Val Loss: 31750378.9275, MAE: 4829.5127, NMAE: 73.6299, R^2: 0.1314\n",
      "Epoch [945/2000]\n",
      "Train Loss: 31326705.8888\n",
      "Val Loss: 32290776.3709, MAE: 4897.9888, NMAE: 74.6739, R^2: 0.1166\n",
      "Epoch [946/2000]\n",
      "Train Loss: 31885874.8336\n",
      "Val Loss: 31590071.8752, MAE: 4808.5352, NMAE: 73.3101, R^2: 0.1358\n",
      "Epoch [947/2000]\n",
      "Train Loss: 31589021.4345\n",
      "Val Loss: 38982506.5462, MAE: 5515.1050, NMAE: 84.0823, R^2: -0.0664\n",
      "Epoch [948/2000]\n",
      "Train Loss: 35491226.6431\n",
      "Val Loss: 33739273.4201, MAE: 5080.5288, NMAE: 77.4568, R^2: 0.0770\n",
      "Epoch [949/2000]\n",
      "Train Loss: 33307882.0164\n",
      "Val Loss: 33076421.4262, MAE: 5002.9233, NMAE: 76.2737, R^2: 0.0951\n",
      "Epoch [950/2000]\n",
      "Train Loss: 32998764.3397\n",
      "Val Loss: 32938329.3161, MAE: 4999.5190, NMAE: 76.2218, R^2: 0.0989\n",
      "Epoch [951/2000]\n",
      "Train Loss: 32736472.3379\n",
      "Val Loss: 32752887.2435, MAE: 4982.3247, NMAE: 75.9596, R^2: 0.1040\n",
      "Epoch [952/2000]\n",
      "Train Loss: 32820452.1422\n",
      "Val Loss: 32657156.1710, MAE: 4974.9487, NMAE: 75.8472, R^2: 0.1066\n",
      "Epoch [953/2000]\n",
      "Train Loss: 32608071.5000\n",
      "Val Loss: 31978517.2681, MAE: 4886.9893, NMAE: 74.5062, R^2: 0.1252\n",
      "Epoch [954/2000]\n",
      "Train Loss: 32238672.0664\n",
      "Val Loss: 32055668.9283, MAE: 4899.0845, NMAE: 74.6906, R^2: 0.1231\n",
      "Epoch [955/2000]\n",
      "Train Loss: 32919933.6448\n",
      "Val Loss: 31694535.9832, MAE: 4718.2656, NMAE: 71.9338, R^2: 0.1329\n",
      "Epoch [956/2000]\n",
      "Train Loss: 32332180.8586\n",
      "Val Loss: 31941848.1455, MAE: 4863.9751, NMAE: 74.1553, R^2: 0.1262\n",
      "Epoch [957/2000]\n",
      "Train Loss: 31823836.5474\n",
      "Val Loss: 31596438.6313, MAE: 4790.8613, NMAE: 73.0406, R^2: 0.1356\n",
      "Epoch [958/2000]\n",
      "Train Loss: 32247923.7690\n",
      "Val Loss: 31378789.1861, MAE: 4769.4902, NMAE: 72.7148, R^2: 0.1416\n",
      "Epoch [959/2000]\n",
      "Train Loss: 31714299.6853\n",
      "Val Loss: 31497632.1807, MAE: 4801.4160, NMAE: 73.2015, R^2: 0.1383\n",
      "Epoch [960/2000]\n",
      "Train Loss: 31747756.2267\n",
      "Val Loss: 31632537.8804, MAE: 4822.9331, NMAE: 73.5296, R^2: 0.1346\n",
      "Epoch [961/2000]\n",
      "Train Loss: 31844592.2129\n",
      "Val Loss: 31936167.7427, MAE: 4831.8809, NMAE: 73.6660, R^2: 0.1263\n",
      "Epoch [962/2000]\n",
      "Train Loss: 31615413.2319\n",
      "Val Loss: 31790281.4011, MAE: 4825.5376, NMAE: 73.5693, R^2: 0.1303\n",
      "Epoch [963/2000]\n",
      "Train Loss: 31765663.9862\n",
      "Val Loss: 31451679.9581, MAE: 4789.9980, NMAE: 73.0274, R^2: 0.1396\n",
      "Epoch [964/2000]\n",
      "Train Loss: 31451682.0793\n",
      "Val Loss: 31067640.0963, MAE: 4728.0366, NMAE: 72.0828, R^2: 0.1501\n",
      "Epoch [965/2000]\n",
      "Train Loss: 31272879.4655\n",
      "Val Loss: 32905082.5924, MAE: 4953.2192, NMAE: 75.5159, R^2: 0.0998\n",
      "Epoch [966/2000]\n",
      "Train Loss: 31263728.3750\n",
      "Val Loss: 31568224.5946, MAE: 4797.0107, NMAE: 73.1344, R^2: 0.1364\n",
      "Epoch [967/2000]\n",
      "Train Loss: 31163351.3448\n",
      "Val Loss: 32115839.3359, MAE: 4879.8931, NMAE: 74.3980, R^2: 0.1214\n",
      "Epoch [968/2000]\n",
      "Train Loss: 31245225.0603\n",
      "Val Loss: 31778204.4607, MAE: 4827.5820, NMAE: 73.6004, R^2: 0.1307\n",
      "Epoch [969/2000]\n",
      "Train Loss: 31487771.8129\n",
      "Val Loss: 31989727.1768, MAE: 4853.3745, NMAE: 73.9937, R^2: 0.1249\n",
      "Epoch [970/2000]\n",
      "Train Loss: 31479505.3121\n",
      "Val Loss: 31631269.5089, MAE: 4816.4038, NMAE: 73.4300, R^2: 0.1347\n",
      "Epoch [971/2000]\n",
      "Train Loss: 31301142.9026\n",
      "Val Loss: 33710948.1667, MAE: 5056.8755, NMAE: 77.0962, R^2: 0.0778\n",
      "Epoch [972/2000]\n",
      "Train Loss: 32719205.7397\n",
      "Val Loss: 31285937.5835, MAE: 4773.6597, NMAE: 72.7784, R^2: 0.1441\n",
      "Epoch [973/2000]\n",
      "Train Loss: 34080753.8526\n",
      "Val Loss: 33577543.9944, MAE: 5058.5342, NMAE: 77.1215, R^2: 0.0814\n",
      "Epoch [974/2000]\n",
      "Train Loss: 31949688.9060\n",
      "Val Loss: 32203011.8856, MAE: 4896.8940, NMAE: 74.6572, R^2: 0.1190\n",
      "Epoch [975/2000]\n",
      "Train Loss: 32679130.7112\n",
      "Val Loss: 31313891.7411, MAE: 4785.6792, NMAE: 72.9616, R^2: 0.1434\n",
      "Epoch [976/2000]\n",
      "Train Loss: 31769317.7491\n",
      "Val Loss: 31683321.8990, MAE: 4839.6562, NMAE: 73.7845, R^2: 0.1333\n",
      "Epoch [977/2000]\n",
      "Train Loss: 32089501.4905\n",
      "Val Loss: 31738067.2070, MAE: 4832.4692, NMAE: 73.6750, R^2: 0.1318\n",
      "Epoch [978/2000]\n",
      "Train Loss: 32074980.9681\n",
      "Val Loss: 31574217.5846, MAE: 4817.1172, NMAE: 73.4409, R^2: 0.1362\n",
      "Epoch [979/2000]\n",
      "Train Loss: 32013547.1362\n",
      "Val Loss: 31315831.4268, MAE: 4802.5435, NMAE: 73.2187, R^2: 0.1433\n",
      "Epoch [980/2000]\n",
      "Train Loss: 31755626.5586\n",
      "Val Loss: 31325506.2997, MAE: 4795.7173, NMAE: 73.1146, R^2: 0.1430\n",
      "Epoch [981/2000]\n",
      "Train Loss: 31725123.4310\n",
      "Val Loss: 31678495.6475, MAE: 4843.0708, NMAE: 73.8366, R^2: 0.1334\n",
      "Epoch [982/2000]\n",
      "Train Loss: 31531081.2440\n",
      "Val Loss: 32111162.0095, MAE: 4893.1348, NMAE: 74.5999, R^2: 0.1216\n",
      "Epoch [983/2000]\n",
      "Train Loss: 31503907.9983\n",
      "Val Loss: 32030173.0799, MAE: 4886.1318, NMAE: 74.4931, R^2: 0.1238\n",
      "Epoch [984/2000]\n",
      "Train Loss: 33089866.0595\n",
      "Val Loss: 31202505.6915, MAE: 4753.1782, NMAE: 72.4661, R^2: 0.1464\n",
      "Epoch [985/2000]\n",
      "Train Loss: 31853899.2681\n",
      "Val Loss: 31579069.8664, MAE: 4836.9199, NMAE: 73.7428, R^2: 0.1361\n",
      "Epoch [986/2000]\n",
      "Train Loss: 31534398.3190\n",
      "Val Loss: 31685431.6662, MAE: 4850.1333, NMAE: 73.9443, R^2: 0.1332\n",
      "Epoch [987/2000]\n",
      "Train Loss: 31847058.7845\n",
      "Val Loss: 32181952.8072, MAE: 4891.9995, NMAE: 74.5825, R^2: 0.1196\n",
      "Epoch [988/2000]\n",
      "Train Loss: 31660298.9129\n",
      "Val Loss: 31342675.6658, MAE: 4781.5015, NMAE: 72.8979, R^2: 0.1426\n",
      "Epoch [989/2000]\n",
      "Train Loss: 31585299.1198\n",
      "Val Loss: 31998268.2416, MAE: 4894.1880, NMAE: 74.6159, R^2: 0.1246\n",
      "Epoch [990/2000]\n",
      "Train Loss: 31644748.4284\n",
      "Val Loss: 31335873.8005, MAE: 4805.9790, NMAE: 73.2711, R^2: 0.1428\n",
      "Epoch [991/2000]\n",
      "Train Loss: 31394444.2043\n",
      "Val Loss: 32142109.2757, MAE: 4897.2314, NMAE: 74.6623, R^2: 0.1207\n",
      "Epoch [992/2000]\n",
      "Train Loss: 32103420.0845\n",
      "Val Loss: 32159373.1185, MAE: 4894.7812, NMAE: 74.6250, R^2: 0.1202\n",
      "Epoch [993/2000]\n",
      "Train Loss: 31837125.0914\n",
      "Val Loss: 32201486.7422, MAE: 4927.4775, NMAE: 75.1234, R^2: 0.1191\n",
      "Epoch [994/2000]\n",
      "Train Loss: 31666656.7871\n",
      "Val Loss: 32907641.8057, MAE: 4991.9521, NMAE: 76.1064, R^2: 0.0998\n",
      "Epoch [995/2000]\n",
      "Train Loss: 31517089.1784\n",
      "Val Loss: 31939329.0525, MAE: 4847.6387, NMAE: 73.9062, R^2: 0.1263\n",
      "Epoch [996/2000]\n",
      "Train Loss: 31440247.1069\n",
      "Val Loss: 33028943.4676, MAE: 4970.6099, NMAE: 75.7810, R^2: 0.0964\n",
      "Epoch [997/2000]\n",
      "Train Loss: 31880125.8828\n",
      "Val Loss: 32932055.4767, MAE: 4960.9746, NMAE: 75.6341, R^2: 0.0991\n",
      "Epoch [998/2000]\n",
      "Train Loss: 32297654.4078\n",
      "Val Loss: 31844335.5248, MAE: 4819.1211, NMAE: 73.4715, R^2: 0.1289\n",
      "Epoch [999/2000]\n",
      "Train Loss: 32941781.7759\n",
      "Val Loss: 32916810.8005, MAE: 4999.3247, NMAE: 76.2188, R^2: 0.0995\n",
      "Epoch [1000/2000]\n",
      "Train Loss: 33178760.4767\n",
      "Val Loss: 32086029.4931, MAE: 4881.8638, NMAE: 74.4280, R^2: 0.1222\n",
      "Epoch [1001/2000]\n",
      "Train Loss: 32287558.2690\n",
      "Val Loss: 32622594.0415, MAE: 4959.5117, NMAE: 75.6118, R^2: 0.1076\n",
      "Epoch [1002/2000]\n",
      "Train Loss: 32415892.7931\n",
      "Val Loss: 31713060.6434, MAE: 4855.4517, NMAE: 74.0253, R^2: 0.1324\n",
      "Epoch [1003/2000]\n",
      "Train Loss: 32526552.0638\n",
      "Val Loss: 31403306.9676, MAE: 4811.1494, NMAE: 73.3499, R^2: 0.1409\n",
      "Epoch [1004/2000]\n",
      "Train Loss: 32031044.8733\n",
      "Val Loss: 31806514.3748, MAE: 4872.8936, NMAE: 74.2913, R^2: 0.1299\n",
      "Epoch [1005/2000]\n",
      "Train Loss: 32434086.9759\n",
      "Val Loss: 31286546.9983, MAE: 4792.1040, NMAE: 73.0596, R^2: 0.1441\n",
      "Epoch [1006/2000]\n",
      "Train Loss: 31515137.7397\n",
      "Val Loss: 31347413.1548, MAE: 4807.6782, NMAE: 73.2970, R^2: 0.1424\n",
      "Epoch [1007/2000]\n",
      "Train Loss: 31625176.0836\n",
      "Val Loss: 31307120.7032, MAE: 4804.0723, NMAE: 73.2420, R^2: 0.1435\n",
      "Epoch [1008/2000]\n",
      "Train Loss: 31711465.8448\n",
      "Val Loss: 31356558.0969, MAE: 4800.4180, NMAE: 73.1863, R^2: 0.1422\n",
      "Epoch [1009/2000]\n",
      "Train Loss: 32453834.0017\n",
      "Val Loss: 31069524.0153, MAE: 4752.6328, NMAE: 72.4578, R^2: 0.1500\n",
      "Epoch [1010/2000]\n",
      "Train Loss: 32065198.1276\n",
      "Val Loss: 31244254.4747, MAE: 4776.1836, NMAE: 72.8168, R^2: 0.1453\n",
      "Epoch [1011/2000]\n",
      "Train Loss: 31703980.3190\n",
      "Val Loss: 31166380.5812, MAE: 4768.7993, NMAE: 72.7043, R^2: 0.1474\n",
      "Epoch [1012/2000]\n",
      "Train Loss: 31415437.3621\n",
      "Val Loss: 31532373.6256, MAE: 4820.6230, NMAE: 73.4944, R^2: 0.1374\n",
      "Epoch [1013/2000]\n",
      "Train Loss: 31992595.5560\n",
      "Val Loss: 31540014.7820, MAE: 4824.8818, NMAE: 73.5593, R^2: 0.1372\n",
      "Epoch [1014/2000]\n",
      "Train Loss: 31535075.6043\n",
      "Val Loss: 32048738.4521, MAE: 4889.2314, NMAE: 74.5403, R^2: 0.1233\n",
      "Epoch [1015/2000]\n",
      "Train Loss: 31660365.9267\n",
      "Val Loss: 32339514.8955, MAE: 4919.8140, NMAE: 75.0066, R^2: 0.1153\n",
      "Epoch [1016/2000]\n",
      "Train Loss: 31905429.5112\n",
      "Val Loss: 32301741.8761, MAE: 4920.0938, NMAE: 75.0109, R^2: 0.1163\n",
      "Epoch [1017/2000]\n",
      "Train Loss: 31488407.0586\n",
      "Val Loss: 32293936.9352, MAE: 4912.4668, NMAE: 74.8946, R^2: 0.1166\n",
      "Epoch [1018/2000]\n",
      "Train Loss: 31569709.2250\n",
      "Val Loss: 31870651.1900, MAE: 4873.2656, NMAE: 74.2969, R^2: 0.1281\n",
      "Epoch [1019/2000]\n",
      "Train Loss: 31833107.5276\n",
      "Val Loss: 32170428.2470, MAE: 4892.8037, NMAE: 74.5948, R^2: 0.1199\n",
      "Epoch [1020/2000]\n",
      "Train Loss: 31349916.4353\n",
      "Val Loss: 33014574.9525, MAE: 4997.5405, NMAE: 76.1916, R^2: 0.0968\n",
      "Epoch [1021/2000]\n",
      "Train Loss: 31361629.5733\n",
      "Val Loss: 33196537.9957, MAE: 4983.8169, NMAE: 75.9824, R^2: 0.0919\n",
      "Epoch [1022/2000]\n",
      "Train Loss: 31393895.1569\n",
      "Val Loss: 32773246.1585, MAE: 4944.3662, NMAE: 75.3809, R^2: 0.1034\n",
      "Epoch [1023/2000]\n",
      "Train Loss: 31800771.3198\n",
      "Val Loss: 32431383.8528, MAE: 4919.8218, NMAE: 75.0067, R^2: 0.1128\n",
      "Epoch [1024/2000]\n",
      "Train Loss: 31419537.4500\n",
      "Val Loss: 32534167.5052, MAE: 4939.2856, NMAE: 75.3035, R^2: 0.1100\n",
      "Epoch [1025/2000]\n",
      "Train Loss: 31321800.0681\n",
      "Val Loss: 32542016.8700, MAE: 4920.8730, NMAE: 75.0227, R^2: 0.1098\n",
      "Epoch [1026/2000]\n",
      "Train Loss: 31506605.4578\n",
      "Val Loss: 33190244.1399, MAE: 5015.9658, NMAE: 76.4725, R^2: 0.0920\n",
      "Epoch [1027/2000]\n",
      "Train Loss: 31623506.0905\n",
      "Val Loss: 32303531.4471, MAE: 4905.1875, NMAE: 74.7836, R^2: 0.1163\n",
      "Epoch [1028/2000]\n",
      "Train Loss: 31338158.5810\n",
      "Val Loss: 32085652.4635, MAE: 4876.1279, NMAE: 74.3406, R^2: 0.1222\n",
      "Epoch [1029/2000]\n",
      "Train Loss: 31733761.0612\n",
      "Val Loss: 32248893.5535, MAE: 4873.6108, NMAE: 74.3022, R^2: 0.1178\n",
      "Epoch [1030/2000]\n",
      "Train Loss: 31305597.4466\n",
      "Val Loss: 32483141.0134, MAE: 4917.8564, NMAE: 74.9768, R^2: 0.1114\n",
      "Epoch [1031/2000]\n",
      "Train Loss: 31480621.4345\n",
      "Val Loss: 32508601.5397, MAE: 4912.4111, NMAE: 74.8937, R^2: 0.1107\n",
      "Epoch [1032/2000]\n",
      "Train Loss: 31443001.1698\n",
      "Val Loss: 32387525.3627, MAE: 4914.3867, NMAE: 74.9239, R^2: 0.1140\n",
      "Epoch [1033/2000]\n",
      "Train Loss: 31678217.8060\n",
      "Val Loss: 32224094.0887, MAE: 4883.4336, NMAE: 74.4520, R^2: 0.1185\n",
      "Epoch [1034/2000]\n",
      "Train Loss: 31330635.9026\n",
      "Val Loss: 32443547.9186, MAE: 4918.7515, NMAE: 74.9904, R^2: 0.1125\n",
      "Epoch [1035/2000]\n",
      "Train Loss: 31316077.8319\n",
      "Val Loss: 32313869.0542, MAE: 4894.2441, NMAE: 74.6168, R^2: 0.1160\n",
      "Epoch [1036/2000]\n",
      "Train Loss: 31316901.0155\n",
      "Val Loss: 32429241.1721, MAE: 4919.1230, NMAE: 74.9961, R^2: 0.1128\n",
      "Epoch [1037/2000]\n",
      "Train Loss: 31367801.1776\n",
      "Val Loss: 33299710.9754, MAE: 4997.4297, NMAE: 76.1899, R^2: 0.0890\n",
      "Epoch [1038/2000]\n",
      "Train Loss: 31171476.2198\n",
      "Val Loss: 32680269.1028, MAE: 4935.6255, NMAE: 75.2477, R^2: 0.1060\n",
      "Epoch [1039/2000]\n",
      "Train Loss: 31136362.3948\n",
      "Val Loss: 33247709.1261, MAE: 5004.5571, NMAE: 76.2986, R^2: 0.0905\n",
      "Epoch [1040/2000]\n",
      "Train Loss: 31135454.2397\n",
      "Val Loss: 32584228.0717, MAE: 4938.8086, NMAE: 75.2962, R^2: 0.1086\n",
      "Epoch [1041/2000]\n",
      "Train Loss: 31264847.3517\n",
      "Val Loss: 31941376.8038, MAE: 4862.6978, NMAE: 74.1358, R^2: 0.1262\n",
      "Epoch [1042/2000]\n",
      "Train Loss: 31674421.3603\n",
      "Val Loss: 31792001.4773, MAE: 4834.3057, NMAE: 73.7030, R^2: 0.1303\n",
      "Epoch [1043/2000]\n",
      "Train Loss: 31382104.3819\n",
      "Val Loss: 32481822.4495, MAE: 4925.6069, NMAE: 75.0949, R^2: 0.1114\n",
      "Epoch [1044/2000]\n",
      "Train Loss: 31559872.4405\n",
      "Val Loss: 32830323.7535, MAE: 4970.5649, NMAE: 75.7803, R^2: 0.1019\n",
      "Epoch [1045/2000]\n",
      "Train Loss: 31671477.6845\n",
      "Val Loss: 31919539.1645, MAE: 4871.5771, NMAE: 74.2712, R^2: 0.1268\n",
      "Epoch [1046/2000]\n",
      "Train Loss: 31240473.7026\n",
      "Val Loss: 32355064.2532, MAE: 4894.8032, NMAE: 74.6253, R^2: 0.1149\n",
      "Epoch [1047/2000]\n",
      "Train Loss: 31222636.5457\n",
      "Val Loss: 31751242.9601, MAE: 4825.7925, NMAE: 73.5732, R^2: 0.1314\n",
      "Epoch [1048/2000]\n",
      "Train Loss: 31189014.7043\n",
      "Val Loss: 32195745.3491, MAE: 4861.6606, NMAE: 74.1200, R^2: 0.1192\n",
      "Epoch [1049/2000]\n",
      "Train Loss: 30965974.8534\n",
      "Val Loss: 32442551.5617, MAE: 4882.7969, NMAE: 74.4422, R^2: 0.1125\n",
      "Epoch [1050/2000]\n",
      "Train Loss: 31337762.7750\n",
      "Val Loss: 32156102.8007, MAE: 4862.6216, NMAE: 74.1347, R^2: 0.1203\n",
      "Epoch [1051/2000]\n",
      "Train Loss: 31282116.3552\n",
      "Val Loss: 31920930.3187, MAE: 4826.1460, NMAE: 73.5786, R^2: 0.1268\n",
      "Epoch [1052/2000]\n",
      "Train Loss: 31890356.7224\n",
      "Val Loss: 31601358.7953, MAE: 4804.6465, NMAE: 73.2508, R^2: 0.1355\n",
      "Epoch [1053/2000]\n",
      "Train Loss: 31435077.9241\n",
      "Val Loss: 31942684.4514, MAE: 4834.5850, NMAE: 73.7072, R^2: 0.1262\n",
      "Epoch [1054/2000]\n",
      "Train Loss: 31395580.4733\n",
      "Val Loss: 33154178.1861, MAE: 5002.5518, NMAE: 76.2680, R^2: 0.0930\n",
      "Epoch [1055/2000]\n",
      "Train Loss: 31323170.3784\n",
      "Val Loss: 31980509.3633, MAE: 4860.9453, NMAE: 74.1091, R^2: 0.1251\n",
      "Epoch [1056/2000]\n",
      "Train Loss: 32075974.1207\n",
      "Val Loss: 31731718.6058, MAE: 4829.6816, NMAE: 73.6325, R^2: 0.1319\n",
      "Epoch [1057/2000]\n",
      "Train Loss: 31188658.6052\n",
      "Val Loss: 31906404.5002, MAE: 4845.6152, NMAE: 73.8754, R^2: 0.1272\n",
      "Epoch [1058/2000]\n",
      "Train Loss: 31327652.0431\n",
      "Val Loss: 32408249.0825, MAE: 4893.9609, NMAE: 74.6124, R^2: 0.1134\n",
      "Epoch [1059/2000]\n",
      "Train Loss: 32601610.4500\n",
      "Val Loss: 31200726.7336, MAE: 4701.5762, NMAE: 71.6794, R^2: 0.1465\n",
      "Epoch [1060/2000]\n",
      "Train Loss: 33286025.5698\n",
      "Val Loss: 32717312.7366, MAE: 4848.3213, NMAE: 73.9166, R^2: 0.1050\n",
      "Epoch [1061/2000]\n",
      "Train Loss: 32943804.2819\n",
      "Val Loss: 32671071.6144, MAE: 4898.2119, NMAE: 74.6773, R^2: 0.1062\n",
      "Epoch [1062/2000]\n",
      "Train Loss: 32618339.5431\n",
      "Val Loss: 32375137.8834, MAE: 4884.8564, NMAE: 74.4736, R^2: 0.1143\n",
      "Epoch [1063/2000]\n",
      "Train Loss: 32403948.5741\n",
      "Val Loss: 33046754.1516, MAE: 4983.5112, NMAE: 75.9777, R^2: 0.0960\n",
      "Epoch [1064/2000]\n",
      "Train Loss: 32610030.0888\n",
      "Val Loss: 32106190.6563, MAE: 4885.7266, NMAE: 74.4869, R^2: 0.1217\n",
      "Epoch [1065/2000]\n",
      "Train Loss: 32040686.6198\n",
      "Val Loss: 32133948.2763, MAE: 4899.6187, NMAE: 74.6987, R^2: 0.1209\n",
      "Epoch [1066/2000]\n",
      "Train Loss: 32066978.6250\n",
      "Val Loss: 31741340.0794, MAE: 4857.2021, NMAE: 74.0520, R^2: 0.1317\n",
      "Epoch [1067/2000]\n",
      "Train Loss: 31816299.9655\n",
      "Val Loss: 31502316.4806, MAE: 4830.1846, NMAE: 73.6401, R^2: 0.1382\n",
      "Epoch [1068/2000]\n",
      "Train Loss: 31492030.7612\n",
      "Val Loss: 31760013.0807, MAE: 4864.3481, NMAE: 74.1610, R^2: 0.1312\n",
      "Epoch [1069/2000]\n",
      "Train Loss: 31664354.6698\n",
      "Val Loss: 31512727.7275, MAE: 4841.3145, NMAE: 73.8098, R^2: 0.1379\n",
      "Epoch [1070/2000]\n",
      "Train Loss: 31414109.1888\n",
      "Val Loss: 32151651.4344, MAE: 4907.1440, NMAE: 74.8134, R^2: 0.1204\n",
      "Epoch [1071/2000]\n",
      "Train Loss: 31609495.0457\n",
      "Val Loss: 31154113.9337, MAE: 4756.7109, NMAE: 72.5200, R^2: 0.1477\n",
      "Epoch [1072/2000]\n",
      "Train Loss: 32600458.4095\n",
      "Val Loss: 32506148.5177, MAE: 4873.6870, NMAE: 74.3034, R^2: 0.1107\n",
      "Epoch [1073/2000]\n",
      "Train Loss: 32396306.5698\n",
      "Val Loss: 32544682.9577, MAE: 4908.6431, NMAE: 74.8363, R^2: 0.1097\n",
      "Epoch [1074/2000]\n",
      "Train Loss: 32195448.4836\n",
      "Val Loss: 32612275.8888, MAE: 4926.6406, NMAE: 75.1107, R^2: 0.1078\n",
      "Epoch [1075/2000]\n",
      "Train Loss: 31866746.1647\n",
      "Val Loss: 32451338.1412, MAE: 4917.2266, NMAE: 74.9672, R^2: 0.1122\n",
      "Epoch [1076/2000]\n",
      "Train Loss: 31881759.6621\n",
      "Val Loss: 31922428.1926, MAE: 4857.6509, NMAE: 74.0589, R^2: 0.1267\n",
      "Epoch [1077/2000]\n",
      "Train Loss: 31369714.5216\n",
      "Val Loss: 33007528.7699, MAE: 4984.3525, NMAE: 75.9905, R^2: 0.0970\n",
      "Epoch [1078/2000]\n",
      "Train Loss: 31713499.0586\n",
      "Val Loss: 31753530.9547, MAE: 4843.2417, NMAE: 73.8392, R^2: 0.1313\n",
      "Epoch [1079/2000]\n",
      "Train Loss: 31212884.1345\n",
      "Val Loss: 31903664.6475, MAE: 4876.6230, NMAE: 74.3481, R^2: 0.1272\n",
      "Epoch [1080/2000]\n",
      "Train Loss: 31168911.2017\n",
      "Val Loss: 34638666.1105, MAE: 5142.5210, NMAE: 78.4020, R^2: 0.0524\n",
      "Epoch [1081/2000]\n",
      "Train Loss: 31667422.1267\n",
      "Val Loss: 31516829.4447, MAE: 4774.9980, NMAE: 72.7988, R^2: 0.1378\n",
      "Epoch [1082/2000]\n",
      "Train Loss: 31653062.0293\n",
      "Val Loss: 31323905.0551, MAE: 4756.5796, NMAE: 72.5180, R^2: 0.1431\n",
      "Epoch [1083/2000]\n",
      "Train Loss: 31118097.5009\n",
      "Val Loss: 31669416.2671, MAE: 4827.1353, NMAE: 73.5936, R^2: 0.1336\n",
      "Epoch [1084/2000]\n",
      "Train Loss: 31724010.6845\n",
      "Val Loss: 31937283.1988, MAE: 4855.8428, NMAE: 74.0313, R^2: 0.1263\n",
      "Epoch [1085/2000]\n",
      "Train Loss: 31187618.4509\n",
      "Val Loss: 32212479.4106, MAE: 4884.6348, NMAE: 74.4703, R^2: 0.1188\n",
      "Epoch [1086/2000]\n",
      "Train Loss: 32182641.1819\n",
      "Val Loss: 31277047.3452, MAE: 4774.3179, NMAE: 72.7884, R^2: 0.1444\n",
      "Epoch [1087/2000]\n",
      "Train Loss: 31717276.3138\n",
      "Val Loss: 31647045.6272, MAE: 4804.9624, NMAE: 73.2556, R^2: 0.1342\n",
      "Epoch [1088/2000]\n",
      "Train Loss: 31190473.2379\n",
      "Val Loss: 32071236.9920, MAE: 4874.1904, NMAE: 74.3110, R^2: 0.1226\n",
      "Epoch [1089/2000]\n",
      "Train Loss: 31432605.8328\n",
      "Val Loss: 31809208.6669, MAE: 4842.9419, NMAE: 73.8346, R^2: 0.1298\n",
      "Epoch [1090/2000]\n",
      "Train Loss: 31083956.3078\n",
      "Val Loss: 32754476.3735, MAE: 4945.5361, NMAE: 75.3988, R^2: 0.1040\n",
      "Epoch [1091/2000]\n",
      "Train Loss: 31313227.6241\n",
      "Val Loss: 31992027.6531, MAE: 4868.7480, NMAE: 74.2281, R^2: 0.1248\n",
      "Epoch [1092/2000]\n",
      "Train Loss: 31688872.9466\n",
      "Val Loss: 32212415.8368, MAE: 4879.0894, NMAE: 74.3857, R^2: 0.1188\n",
      "Epoch [1093/2000]\n",
      "Train Loss: 31474513.2974\n",
      "Val Loss: 32388578.1541, MAE: 4880.3438, NMAE: 74.4048, R^2: 0.1140\n",
      "Epoch [1094/2000]\n",
      "Train Loss: 31844923.1078\n",
      "Val Loss: 31482985.6887, MAE: 4797.8252, NMAE: 73.1468, R^2: 0.1387\n",
      "Epoch [1095/2000]\n",
      "Train Loss: 31718129.7483\n",
      "Val Loss: 31585497.3987, MAE: 4834.3857, NMAE: 73.7042, R^2: 0.1359\n",
      "Epoch [1096/2000]\n",
      "Train Loss: 34720000.8017\n",
      "Val Loss: 33539555.8130, MAE: 4859.8042, NMAE: 74.0917, R^2: 0.0825\n",
      "Epoch [1097/2000]\n",
      "Train Loss: 33496670.5569\n",
      "Val Loss: 31864972.0134, MAE: 4773.1270, NMAE: 72.7702, R^2: 0.1283\n",
      "Epoch [1098/2000]\n",
      "Train Loss: 32153976.3784\n",
      "Val Loss: 31873647.3718, MAE: 4810.3774, NMAE: 73.3382, R^2: 0.1280\n",
      "Epoch [1099/2000]\n",
      "Train Loss: 31767276.0284\n",
      "Val Loss: 31488692.7675, MAE: 4795.0522, NMAE: 73.1045, R^2: 0.1386\n",
      "Epoch [1100/2000]\n",
      "Train Loss: 31642283.4784\n",
      "Val Loss: 31547193.7345, MAE: 4822.4414, NMAE: 73.5221, R^2: 0.1370\n",
      "Epoch [1101/2000]\n",
      "Train Loss: 31502173.6250\n",
      "Val Loss: 31329699.6468, MAE: 4781.9233, NMAE: 72.9043, R^2: 0.1429\n",
      "Epoch [1102/2000]\n",
      "Train Loss: 31463671.4776\n",
      "Val Loss: 31930232.5762, MAE: 4858.1406, NMAE: 74.0663, R^2: 0.1265\n",
      "Epoch [1103/2000]\n",
      "Train Loss: 31326349.2345\n",
      "Val Loss: 31594736.3782, MAE: 4813.5571, NMAE: 73.3866, R^2: 0.1357\n",
      "Epoch [1104/2000]\n",
      "Train Loss: 31626159.2224\n",
      "Val Loss: 31129204.3681, MAE: 4763.7646, NMAE: 72.6275, R^2: 0.1484\n",
      "Epoch [1105/2000]\n",
      "Train Loss: 31126787.4129\n",
      "Val Loss: 31676496.4680, MAE: 4842.5815, NMAE: 73.8291, R^2: 0.1334\n",
      "Epoch [1106/2000]\n",
      "Train Loss: 31382542.6259\n",
      "Val Loss: 31585872.8608, MAE: 4832.5410, NMAE: 73.6761, R^2: 0.1359\n",
      "Epoch [1107/2000]\n",
      "Train Loss: 31333267.4784\n",
      "Val Loss: 31498025.0289, MAE: 4833.2817, NMAE: 73.6873, R^2: 0.1383\n",
      "Epoch [1108/2000]\n",
      "Train Loss: 31747891.1250\n",
      "Val Loss: 31626619.7353, MAE: 4856.9004, NMAE: 74.0474, R^2: 0.1348\n",
      "Epoch [1109/2000]\n",
      "Train Loss: 31531468.9560\n",
      "Val Loss: 31774801.1423, MAE: 4870.3081, NMAE: 74.2518, R^2: 0.1308\n",
      "Epoch [1110/2000]\n",
      "Train Loss: 31585275.4207\n",
      "Val Loss: 31829295.9313, MAE: 4875.2334, NMAE: 74.3269, R^2: 0.1293\n",
      "Epoch [1111/2000]\n",
      "Train Loss: 31721719.8457\n",
      "Val Loss: 31268166.3135, MAE: 4793.5337, NMAE: 73.0814, R^2: 0.1446\n",
      "Epoch [1112/2000]\n",
      "Train Loss: 31607266.3267\n",
      "Val Loss: 31954037.2342, MAE: 4844.7295, NMAE: 73.8619, R^2: 0.1258\n",
      "Epoch [1113/2000]\n",
      "Train Loss: 31564506.9552\n",
      "Val Loss: 31597873.4145, MAE: 4789.6133, NMAE: 73.0216, R^2: 0.1356\n",
      "Epoch [1114/2000]\n",
      "Train Loss: 32026612.1603\n",
      "Val Loss: 31983903.4380, MAE: 4841.7544, NMAE: 73.8165, R^2: 0.1250\n",
      "Epoch [1115/2000]\n",
      "Train Loss: 31526070.8776\n",
      "Val Loss: 32033188.3614, MAE: 4788.4160, NMAE: 73.0033, R^2: 0.1237\n",
      "Epoch [1116/2000]\n",
      "Train Loss: 31655804.3043\n",
      "Val Loss: 31635282.2660, MAE: 4767.0483, NMAE: 72.6776, R^2: 0.1346\n",
      "Epoch [1117/2000]\n",
      "Train Loss: 31386644.5517\n",
      "Val Loss: 31614865.7183, MAE: 4730.8755, NMAE: 72.1261, R^2: 0.1351\n",
      "Epoch [1118/2000]\n",
      "Train Loss: 32230777.5991\n",
      "Val Loss: 32870222.2902, MAE: 4983.2080, NMAE: 75.9731, R^2: 0.1008\n",
      "Epoch [1119/2000]\n",
      "Train Loss: 32181065.1578\n",
      "Val Loss: 32163965.5881, MAE: 4892.4678, NMAE: 74.5897, R^2: 0.1201\n",
      "Epoch [1120/2000]\n",
      "Train Loss: 31897938.0629\n",
      "Val Loss: 31691684.2593, MAE: 4838.4404, NMAE: 73.7660, R^2: 0.1330\n",
      "Epoch [1121/2000]\n",
      "Train Loss: 31469103.5009\n",
      "Val Loss: 31149503.7465, MAE: 4752.8169, NMAE: 72.4606, R^2: 0.1479\n",
      "Epoch [1122/2000]\n",
      "Train Loss: 31819216.6259\n",
      "Val Loss: 31193662.7200, MAE: 4736.7681, NMAE: 72.2159, R^2: 0.1467\n",
      "Epoch [1123/2000]\n",
      "Train Loss: 31731208.9991\n",
      "Val Loss: 32365503.6775, MAE: 4883.8872, NMAE: 74.4589, R^2: 0.1146\n",
      "Epoch [1124/2000]\n",
      "Train Loss: 31933650.4931\n",
      "Val Loss: 32381898.7340, MAE: 4950.8276, NMAE: 75.4794, R^2: 0.1141\n",
      "Epoch [1125/2000]\n",
      "Train Loss: 32139289.9698\n",
      "Val Loss: 32657219.6723, MAE: 4973.3145, NMAE: 75.8223, R^2: 0.1066\n",
      "Epoch [1126/2000]\n",
      "Train Loss: 32735826.0052\n",
      "Val Loss: 31577680.2923, MAE: 4819.9429, NMAE: 73.4840, R^2: 0.1361\n",
      "Epoch [1127/2000]\n",
      "Train Loss: 31749288.0353\n",
      "Val Loss: 31396734.1000, MAE: 4810.4502, NMAE: 73.3393, R^2: 0.1411\n",
      "Epoch [1128/2000]\n",
      "Train Loss: 31499486.7371\n",
      "Val Loss: 31529330.2781, MAE: 4824.0039, NMAE: 73.5459, R^2: 0.1375\n",
      "Epoch [1129/2000]\n",
      "Train Loss: 31542596.2405\n",
      "Val Loss: 31500107.0492, MAE: 4823.1587, NMAE: 73.5330, R^2: 0.1383\n",
      "Epoch [1130/2000]\n",
      "Train Loss: 32588440.4690\n",
      "Val Loss: 31896696.5242, MAE: 4660.0225, NMAE: 71.0459, R^2: 0.1274\n",
      "Epoch [1131/2000]\n",
      "Train Loss: 32342959.3991\n",
      "Val Loss: 31351257.7278, MAE: 4781.9502, NMAE: 72.9048, R^2: 0.1423\n",
      "Epoch [1132/2000]\n",
      "Train Loss: 32451773.9647\n",
      "Val Loss: 32067789.9279, MAE: 4829.8442, NMAE: 73.6349, R^2: 0.1227\n",
      "Epoch [1133/2000]\n",
      "Train Loss: 31975451.1612\n",
      "Val Loss: 32406337.5613, MAE: 4891.0933, NMAE: 74.5687, R^2: 0.1135\n",
      "Epoch [1134/2000]\n",
      "Train Loss: 32067152.8216\n",
      "Val Loss: 31780658.6809, MAE: 4784.7061, NMAE: 72.9468, R^2: 0.1306\n",
      "Epoch [1135/2000]\n",
      "Train Loss: 32085348.8129\n",
      "Val Loss: 31432143.3074, MAE: 4746.0054, NMAE: 72.3567, R^2: 0.1401\n",
      "Epoch [1136/2000]\n",
      "Train Loss: 31975005.2914\n",
      "Val Loss: 31122512.9702, MAE: 4701.0947, NMAE: 71.6720, R^2: 0.1486\n",
      "Epoch [1137/2000]\n",
      "Train Loss: 32754618.1276\n",
      "Val Loss: 32569378.6054, MAE: 4655.5146, NMAE: 70.9771, R^2: 0.1090\n",
      "Epoch [1138/2000]\n",
      "Train Loss: 31973635.0155\n",
      "Val Loss: 31135594.9080, MAE: 4733.5386, NMAE: 72.1667, R^2: 0.1482\n",
      "Epoch [1139/2000]\n",
      "Train Loss: 31625566.4302\n",
      "Val Loss: 31329427.5540, MAE: 4754.2119, NMAE: 72.4819, R^2: 0.1429\n",
      "Epoch [1140/2000]\n",
      "Train Loss: 31513843.9207\n",
      "Val Loss: 31351734.6028, MAE: 4765.3755, NMAE: 72.6521, R^2: 0.1423\n",
      "Epoch [1141/2000]\n",
      "Train Loss: 31758791.0509\n",
      "Val Loss: 31594605.2457, MAE: 4818.8618, NMAE: 73.4675, R^2: 0.1357\n",
      "Epoch [1142/2000]\n",
      "Train Loss: 31884381.6224\n",
      "Val Loss: 31111722.9165, MAE: 4731.7427, NMAE: 72.1393, R^2: 0.1489\n",
      "Epoch [1143/2000]\n",
      "Train Loss: 31449307.3147\n",
      "Val Loss: 31446786.7483, MAE: 4805.8047, NMAE: 73.2684, R^2: 0.1397\n",
      "Epoch [1144/2000]\n",
      "Train Loss: 31464475.8440\n",
      "Val Loss: 31537293.5371, MAE: 4804.6050, NMAE: 73.2501, R^2: 0.1373\n",
      "Epoch [1145/2000]\n",
      "Train Loss: 31427904.3302\n",
      "Val Loss: 31423268.8096, MAE: 4779.8506, NMAE: 72.8727, R^2: 0.1404\n",
      "Epoch [1146/2000]\n",
      "Train Loss: 31416364.4302\n",
      "Val Loss: 31683191.4875, MAE: 4817.3159, NMAE: 73.4439, R^2: 0.1333\n",
      "Epoch [1147/2000]\n",
      "Train Loss: 31457797.2940\n",
      "Val Loss: 31481631.8737, MAE: 4777.0312, NMAE: 72.8298, R^2: 0.1388\n",
      "Epoch [1148/2000]\n",
      "Train Loss: 31430930.1655\n",
      "Val Loss: 32350260.8672, MAE: 4898.5845, NMAE: 74.6829, R^2: 0.1150\n",
      "Epoch [1149/2000]\n",
      "Train Loss: 31511554.2750\n",
      "Val Loss: 31817696.9132, MAE: 4831.6030, NMAE: 73.6618, R^2: 0.1296\n",
      "Epoch [1150/2000]\n",
      "Train Loss: 31702534.8681\n",
      "Val Loss: 32291938.6775, MAE: 4913.8872, NMAE: 74.9162, R^2: 0.1166\n",
      "Epoch [1151/2000]\n",
      "Train Loss: 31649327.0362\n",
      "Val Loss: 31825782.2956, MAE: 4839.6470, NMAE: 73.7844, R^2: 0.1294\n",
      "Epoch [1152/2000]\n",
      "Train Loss: 31634385.2422\n",
      "Val Loss: 32226899.4745, MAE: 4853.7275, NMAE: 73.9991, R^2: 0.1184\n",
      "Epoch [1153/2000]\n",
      "Train Loss: 31922746.2129\n",
      "Val Loss: 31997948.7299, MAE: 4826.9209, NMAE: 73.5904, R^2: 0.1246\n",
      "Epoch [1154/2000]\n",
      "Train Loss: 31948061.1914\n",
      "Val Loss: 31867946.3076, MAE: 4822.3701, NMAE: 73.5210, R^2: 0.1282\n",
      "Epoch [1155/2000]\n",
      "Train Loss: 31374378.8784\n",
      "Val Loss: 31759424.2642, MAE: 4809.6191, NMAE: 73.3266, R^2: 0.1312\n",
      "Epoch [1156/2000]\n",
      "Train Loss: 31265804.7353\n",
      "Val Loss: 31872068.9257, MAE: 4822.1914, NMAE: 73.5183, R^2: 0.1281\n",
      "Epoch [1157/2000]\n",
      "Train Loss: 31590503.8241\n",
      "Val Loss: 32631690.7275, MAE: 4933.5288, NMAE: 75.2157, R^2: 0.1073\n",
      "Epoch [1158/2000]\n",
      "Train Loss: 32130006.6569\n",
      "Val Loss: 32468423.3353, MAE: 4884.6187, NMAE: 74.4700, R^2: 0.1118\n",
      "Epoch [1159/2000]\n",
      "Train Loss: 32020172.0060\n",
      "Val Loss: 33367028.1628, MAE: 4868.3145, NMAE: 74.2214, R^2: 0.0872\n",
      "Epoch [1160/2000]\n",
      "Train Loss: 31733494.3940\n",
      "Val Loss: 32648288.5831, MAE: 4893.4443, NMAE: 74.6046, R^2: 0.1069\n",
      "Epoch [1161/2000]\n",
      "Train Loss: 31508796.9603\n",
      "Val Loss: 32147245.1870, MAE: 4827.5659, NMAE: 73.6002, R^2: 0.1206\n",
      "Epoch [1162/2000]\n",
      "Train Loss: 32975310.8974\n",
      "Val Loss: 31842913.4231, MAE: 4806.3003, NMAE: 73.2760, R^2: 0.1289\n",
      "Epoch [1163/2000]\n",
      "Train Loss: 31576054.6000\n",
      "Val Loss: 31654731.7986, MAE: 4800.0015, NMAE: 73.1800, R^2: 0.1340\n",
      "Epoch [1164/2000]\n",
      "Train Loss: 31635268.4034\n",
      "Val Loss: 31843940.1416, MAE: 4830.7686, NMAE: 73.6490, R^2: 0.1289\n",
      "Epoch [1165/2000]\n",
      "Train Loss: 31628870.5655\n",
      "Val Loss: 31262397.9633, MAE: 4710.5850, NMAE: 71.8167, R^2: 0.1448\n",
      "Epoch [1166/2000]\n",
      "Train Loss: 31990144.8397\n",
      "Val Loss: 31823682.2681, MAE: 4810.4062, NMAE: 73.3386, R^2: 0.1294\n",
      "Epoch [1167/2000]\n",
      "Train Loss: 31799103.9845\n",
      "Val Loss: 32417646.0505, MAE: 4911.3599, NMAE: 74.8777, R^2: 0.1132\n",
      "Epoch [1168/2000]\n",
      "Train Loss: 31843653.3000\n",
      "Val Loss: 31995101.6585, MAE: 4826.1436, NMAE: 73.5785, R^2: 0.1247\n",
      "Epoch [1169/2000]\n",
      "Train Loss: 32064989.6138\n",
      "Val Loss: 31359113.8987, MAE: 4733.3931, NMAE: 72.1645, R^2: 0.1421\n",
      "Epoch [1170/2000]\n",
      "Train Loss: 31854681.9284\n",
      "Val Loss: 31972362.9460, MAE: 4847.6226, NMAE: 73.9060, R^2: 0.1253\n",
      "Epoch [1171/2000]\n",
      "Train Loss: 31618616.1940\n",
      "Val Loss: 32022947.2256, MAE: 4845.4912, NMAE: 73.8735, R^2: 0.1240\n",
      "Epoch [1172/2000]\n",
      "Train Loss: 32195212.8966\n",
      "Val Loss: 31712593.5544, MAE: 4811.6699, NMAE: 73.3579, R^2: 0.1325\n",
      "Epoch [1173/2000]\n",
      "Train Loss: 31719642.1784\n",
      "Val Loss: 31715166.9417, MAE: 4823.2139, NMAE: 73.5339, R^2: 0.1324\n",
      "Epoch [1174/2000]\n",
      "Train Loss: 31743954.7888\n",
      "Val Loss: 31312432.7746, MAE: 4756.7773, NMAE: 72.5210, R^2: 0.1434\n",
      "Epoch [1175/2000]\n",
      "Train Loss: 31574550.7009\n",
      "Val Loss: 31629096.0555, MAE: 4809.3228, NMAE: 73.3221, R^2: 0.1347\n",
      "Epoch [1176/2000]\n",
      "Train Loss: 31463414.8750\n",
      "Val Loss: 31695509.5520, MAE: 4823.0283, NMAE: 73.5310, R^2: 0.1329\n",
      "Epoch [1177/2000]\n",
      "Train Loss: 31914008.4672\n",
      "Val Loss: 31819356.2977, MAE: 4834.5786, NMAE: 73.7071, R^2: 0.1295\n",
      "Epoch [1178/2000]\n",
      "Train Loss: 31561855.6845\n",
      "Val Loss: 31625955.3258, MAE: 4797.5156, NMAE: 73.1421, R^2: 0.1348\n",
      "Epoch [1179/2000]\n",
      "Train Loss: 31810782.7026\n",
      "Val Loss: 31405538.0954, MAE: 4759.7354, NMAE: 72.5661, R^2: 0.1409\n",
      "Epoch [1180/2000]\n",
      "Train Loss: 31694006.2897\n",
      "Val Loss: 31287383.3256, MAE: 4747.0186, NMAE: 72.3722, R^2: 0.1441\n",
      "Epoch [1181/2000]\n",
      "Train Loss: 31492429.1060\n",
      "Val Loss: 31522225.5959, MAE: 4775.4990, NMAE: 72.8064, R^2: 0.1377\n",
      "Epoch [1182/2000]\n",
      "Train Loss: 31683332.8543\n",
      "Val Loss: 31377023.7254, MAE: 4761.4448, NMAE: 72.5921, R^2: 0.1416\n",
      "Epoch [1183/2000]\n",
      "Train Loss: 31488408.1767\n",
      "Val Loss: 31366034.4259, MAE: 4771.6992, NMAE: 72.7485, R^2: 0.1419\n",
      "Epoch [1184/2000]\n",
      "Train Loss: 31501775.0112\n",
      "Val Loss: 33214837.7491, MAE: 4959.8257, NMAE: 75.6166, R^2: 0.0914\n",
      "Epoch [1185/2000]\n",
      "Train Loss: 32170798.6526\n",
      "Val Loss: 31722721.7308, MAE: 4780.9849, NMAE: 72.8900, R^2: 0.1322\n",
      "Epoch [1186/2000]\n",
      "Train Loss: 31573237.0681\n",
      "Val Loss: 31431744.9437, MAE: 4774.8164, NMAE: 72.7960, R^2: 0.1401\n",
      "Epoch [1187/2000]\n",
      "Train Loss: 31354010.8767\n",
      "Val Loss: 31671659.6149, MAE: 4778.8354, NMAE: 72.8573, R^2: 0.1336\n",
      "Epoch [1188/2000]\n",
      "Train Loss: 31841057.2741\n",
      "Val Loss: 31430876.4719, MAE: 4733.8105, NMAE: 72.1708, R^2: 0.1402\n",
      "Epoch [1189/2000]\n",
      "Train Loss: 31857945.7767\n",
      "Val Loss: 31525700.0237, MAE: 4703.0337, NMAE: 71.7016, R^2: 0.1376\n",
      "Epoch [1190/2000]\n",
      "Train Loss: 31258009.5319\n",
      "Val Loss: 31625164.5151, MAE: 4770.7935, NMAE: 72.7347, R^2: 0.1348\n",
      "Epoch [1191/2000]\n",
      "Train Loss: 31004469.0172\n",
      "Val Loss: 31547640.1496, MAE: 4769.9746, NMAE: 72.7222, R^2: 0.1370\n",
      "Epoch [1192/2000]\n",
      "Train Loss: 31317613.5621\n",
      "Val Loss: 31509788.2314, MAE: 4750.3213, NMAE: 72.4225, R^2: 0.1380\n",
      "Epoch [1193/2000]\n",
      "Train Loss: 31070221.3259\n",
      "Val Loss: 31687618.5522, MAE: 4770.5137, NMAE: 72.7304, R^2: 0.1331\n",
      "Epoch [1194/2000]\n",
      "Train Loss: 32134560.2017\n",
      "Val Loss: 31348257.7586, MAE: 4742.6577, NMAE: 72.3057, R^2: 0.1424\n",
      "Epoch [1195/2000]\n",
      "Train Loss: 36038726.3750\n",
      "Val Loss: 38264485.1731, MAE: 4840.6270, NMAE: 73.7993, R^2: -0.0468\n",
      "Epoch [1196/2000]\n",
      "Train Loss: 35450094.0181\n",
      "Val Loss: 31576090.6727, MAE: 4679.2285, NMAE: 71.3387, R^2: 0.1362\n",
      "Epoch [1197/2000]\n",
      "Train Loss: 34270368.0983\n",
      "Val Loss: 33060402.6209, MAE: 4720.8052, NMAE: 71.9725, R^2: 0.0956\n",
      "Epoch [1198/2000]\n",
      "Train Loss: 32962070.2491\n",
      "Val Loss: 31211406.8808, MAE: 4722.6221, NMAE: 72.0002, R^2: 0.1462\n",
      "Epoch [1199/2000]\n",
      "Train Loss: 32028987.9534\n",
      "Val Loss: 31589945.2820, MAE: 4786.0742, NMAE: 72.9676, R^2: 0.1358\n",
      "Epoch [1200/2000]\n",
      "Train Loss: 32816228.8810\n",
      "Val Loss: 32657634.1382, MAE: 4968.3687, NMAE: 75.7469, R^2: 0.1066\n",
      "Epoch [1201/2000]\n",
      "Train Loss: 31687524.7595\n",
      "Val Loss: 32679586.9003, MAE: 4945.7793, NMAE: 75.4025, R^2: 0.1060\n",
      "Epoch [1202/2000]\n",
      "Train Loss: 31944205.8966\n",
      "Val Loss: 31277184.8402, MAE: 4764.5918, NMAE: 72.6401, R^2: 0.1444\n",
      "Epoch [1203/2000]\n",
      "Train Loss: 31147654.9991\n",
      "Val Loss: 31634477.4184, MAE: 4832.9121, NMAE: 73.6817, R^2: 0.1346\n",
      "Epoch [1204/2000]\n",
      "Train Loss: 31351936.4629\n",
      "Val Loss: 31271145.6982, MAE: 4771.4404, NMAE: 72.7445, R^2: 0.1445\n",
      "Epoch [1205/2000]\n",
      "Train Loss: 31169127.6397\n",
      "Val Loss: 31225647.1749, MAE: 4767.2480, NMAE: 72.6806, R^2: 0.1458\n",
      "Epoch [1206/2000]\n",
      "Train Loss: 30958432.8388\n",
      "Val Loss: 32019498.1131, MAE: 4861.9653, NMAE: 74.1247, R^2: 0.1241\n",
      "Epoch [1207/2000]\n",
      "Train Loss: 31229970.5845\n",
      "Val Loss: 31886520.8670, MAE: 4844.8423, NMAE: 73.8636, R^2: 0.1277\n",
      "Epoch [1208/2000]\n",
      "Train Loss: 31290956.9517\n",
      "Val Loss: 31310648.4894, MAE: 4789.0752, NMAE: 73.0134, R^2: 0.1435\n",
      "Epoch [1209/2000]\n",
      "Train Loss: 31160833.3638\n",
      "Val Loss: 31613642.8441, MAE: 4837.3096, NMAE: 73.7488, R^2: 0.1352\n",
      "Epoch [1210/2000]\n",
      "Train Loss: 31351282.3784\n",
      "Val Loss: 31453419.2539, MAE: 4826.4951, NMAE: 73.5839, R^2: 0.1395\n",
      "Epoch [1211/2000]\n",
      "Train Loss: 31149496.9422\n",
      "Val Loss: 31608522.5592, MAE: 4827.0547, NMAE: 73.5924, R^2: 0.1353\n",
      "Epoch [1212/2000]\n",
      "Train Loss: 31152146.2922\n",
      "Val Loss: 33068747.4344, MAE: 4971.8770, NMAE: 75.8003, R^2: 0.0954\n",
      "Epoch [1213/2000]\n",
      "Train Loss: 32901930.9164\n",
      "Val Loss: 31281537.7487, MAE: 4678.1045, NMAE: 71.3215, R^2: 0.1442\n",
      "Epoch [1214/2000]\n",
      "Train Loss: 31413282.3974\n",
      "Val Loss: 31097835.4305, MAE: 4721.6343, NMAE: 71.9852, R^2: 0.1493\n",
      "Epoch [1215/2000]\n",
      "Train Loss: 31632791.3224\n",
      "Val Loss: 30965902.2945, MAE: 4682.4009, NMAE: 71.3870, R^2: 0.1529\n",
      "Epoch [1216/2000]\n",
      "Train Loss: 31278732.8948\n",
      "Val Loss: 31931707.8968, MAE: 4815.2671, NMAE: 73.4127, R^2: 0.1265\n",
      "Epoch [1217/2000]\n",
      "Train Loss: 31172294.0974\n",
      "Val Loss: 31465545.2427, MAE: 4775.2646, NMAE: 72.8028, R^2: 0.1392\n",
      "Epoch [1218/2000]\n",
      "Train Loss: 31063150.5776\n",
      "Val Loss: 31316893.1015, MAE: 4765.4004, NMAE: 72.6524, R^2: 0.1433\n",
      "Epoch [1219/2000]\n",
      "Train Loss: 30805379.0103\n",
      "Val Loss: 32176703.6598, MAE: 4893.7075, NMAE: 74.6086, R^2: 0.1198\n",
      "Epoch [1220/2000]\n",
      "Train Loss: 30979454.1776\n",
      "Val Loss: 31366943.5911, MAE: 4814.9463, NMAE: 73.4078, R^2: 0.1419\n",
      "Epoch [1221/2000]\n",
      "Train Loss: 31805472.1362\n",
      "Val Loss: 31172504.1237, MAE: 4715.3311, NMAE: 71.8891, R^2: 0.1472\n",
      "Epoch [1222/2000]\n",
      "Train Loss: 31099326.4078\n",
      "Val Loss: 31410895.9171, MAE: 4812.9673, NMAE: 73.3776, R^2: 0.1407\n",
      "Epoch [1223/2000]\n",
      "Train Loss: 32088782.1716\n",
      "Val Loss: 30862543.0408, MAE: 4710.0420, NMAE: 71.8085, R^2: 0.1557\n",
      "Epoch [1224/2000]\n",
      "Train Loss: 31125794.2681\n",
      "Val Loss: 31128088.7560, MAE: 4758.7681, NMAE: 72.5513, R^2: 0.1484\n",
      "Epoch [1225/2000]\n",
      "Train Loss: 31293468.2224\n",
      "Val Loss: 30856865.0611, MAE: 4710.2915, NMAE: 71.8123, R^2: 0.1559\n",
      "Epoch [1226/2000]\n",
      "Train Loss: 31206926.7284\n",
      "Val Loss: 31614187.1328, MAE: 4834.9565, NMAE: 73.7129, R^2: 0.1351\n",
      "Epoch [1227/2000]\n",
      "Train Loss: 31021732.0284\n",
      "Val Loss: 32358488.4253, MAE: 4898.9668, NMAE: 74.6888, R^2: 0.1148\n",
      "Epoch [1228/2000]\n",
      "Train Loss: 31844446.9707\n",
      "Val Loss: 30887358.7904, MAE: 4718.7603, NMAE: 71.9414, R^2: 0.1550\n",
      "Epoch [1229/2000]\n",
      "Train Loss: 31028562.4078\n",
      "Val Loss: 31632165.6280, MAE: 4816.0054, NMAE: 73.4240, R^2: 0.1347\n",
      "Epoch [1230/2000]\n",
      "Train Loss: 32286232.0034\n",
      "Val Loss: 31750109.3135, MAE: 4724.3008, NMAE: 72.0258, R^2: 0.1314\n",
      "Epoch [1231/2000]\n",
      "Train Loss: 32735157.9879\n",
      "Val Loss: 31660179.8726, MAE: 4830.8950, NMAE: 73.6510, R^2: 0.1339\n",
      "Epoch [1232/2000]\n",
      "Train Loss: 31078782.3026\n",
      "Val Loss: 31360854.3670, MAE: 4800.5801, NMAE: 73.1888, R^2: 0.1421\n",
      "Epoch [1233/2000]\n",
      "Train Loss: 31542566.3931\n",
      "Val Loss: 30841476.8456, MAE: 4688.9814, NMAE: 71.4874, R^2: 0.1563\n",
      "Epoch [1234/2000]\n",
      "Train Loss: 31212255.7302\n",
      "Val Loss: 31407662.8925, MAE: 4803.1113, NMAE: 73.2274, R^2: 0.1408\n",
      "Epoch [1235/2000]\n",
      "Train Loss: 32168622.4078\n",
      "Val Loss: 30927238.6092, MAE: 4717.7158, NMAE: 71.9254, R^2: 0.1539\n",
      "Epoch [1236/2000]\n",
      "Train Loss: 32075929.3638\n",
      "Val Loss: 31471361.8161, MAE: 4824.6201, NMAE: 73.5553, R^2: 0.1391\n",
      "Epoch [1237/2000]\n",
      "Train Loss: 31464495.2431\n",
      "Val Loss: 31285957.8323, MAE: 4795.4248, NMAE: 73.1102, R^2: 0.1441\n",
      "Epoch [1238/2000]\n",
      "Train Loss: 31265419.8233\n",
      "Val Loss: 31069982.8372, MAE: 4747.0640, NMAE: 72.3729, R^2: 0.1500\n",
      "Epoch [1239/2000]\n",
      "Train Loss: 30847072.4371\n",
      "Val Loss: 32162566.6939, MAE: 4863.3501, NMAE: 74.1458, R^2: 0.1201\n",
      "Epoch [1240/2000]\n",
      "Train Loss: 31105661.5353\n",
      "Val Loss: 31239803.2811, MAE: 4753.5669, NMAE: 72.4720, R^2: 0.1454\n",
      "Epoch [1241/2000]\n",
      "Train Loss: 30973181.0216\n",
      "Val Loss: 31034216.4462, MAE: 4712.5581, NMAE: 71.8468, R^2: 0.1510\n",
      "Epoch [1242/2000]\n",
      "Train Loss: 31215353.9302\n",
      "Val Loss: 31210568.7135, MAE: 4718.5107, NMAE: 71.9376, R^2: 0.1462\n",
      "Epoch [1243/2000]\n",
      "Train Loss: 30853602.2302\n",
      "Val Loss: 31088679.6049, MAE: 4722.4272, NMAE: 71.9973, R^2: 0.1495\n",
      "Epoch [1244/2000]\n",
      "Train Loss: 30836013.5828\n",
      "Val Loss: 31035996.5091, MAE: 4744.1177, NMAE: 72.3280, R^2: 0.1510\n",
      "Epoch [1245/2000]\n",
      "Train Loss: 31341362.9716\n",
      "Val Loss: 30813888.4400, MAE: 4675.6812, NMAE: 71.2846, R^2: 0.1570\n",
      "Epoch [1246/2000]\n",
      "Train Loss: 30863877.6172\n",
      "Val Loss: 30884708.3061, MAE: 4725.5112, NMAE: 72.0443, R^2: 0.1551\n",
      "Epoch [1247/2000]\n",
      "Train Loss: 30528307.9931\n",
      "Val Loss: 30916738.7185, MAE: 4704.9092, NMAE: 71.7302, R^2: 0.1542\n",
      "Epoch [1248/2000]\n",
      "Train Loss: 31692184.5397\n",
      "Val Loss: 30826809.4607, MAE: 4695.7686, NMAE: 71.5908, R^2: 0.1567\n",
      "Epoch [1249/2000]\n",
      "Train Loss: 31073438.0259\n",
      "Val Loss: 31409391.0380, MAE: 4798.8843, NMAE: 73.1629, R^2: 0.1407\n",
      "Epoch [1250/2000]\n",
      "Train Loss: 31032338.8776\n",
      "Val Loss: 31386817.0460, MAE: 4791.4038, NMAE: 73.0489, R^2: 0.1414\n",
      "Epoch [1251/2000]\n",
      "Train Loss: 31010414.6267\n",
      "Val Loss: 31581979.9063, MAE: 4811.2007, NMAE: 73.3507, R^2: 0.1360\n",
      "Epoch [1252/2000]\n",
      "Train Loss: 31026497.1474\n",
      "Val Loss: 31302097.9726, MAE: 4726.1533, NMAE: 72.0541, R^2: 0.1437\n",
      "Epoch [1253/2000]\n",
      "Train Loss: 30886119.8207\n",
      "Val Loss: 31741311.6382, MAE: 4825.3296, NMAE: 73.5661, R^2: 0.1317\n",
      "Epoch [1254/2000]\n",
      "Train Loss: 31085902.7190\n",
      "Val Loss: 32201267.5112, MAE: 4877.8877, NMAE: 74.3674, R^2: 0.1191\n",
      "Epoch [1255/2000]\n",
      "Train Loss: 31175276.5267\n",
      "Val Loss: 31494891.9439, MAE: 4770.1953, NMAE: 72.7255, R^2: 0.1384\n",
      "Epoch [1256/2000]\n",
      "Train Loss: 31062745.4431\n",
      "Val Loss: 32144316.9652, MAE: 4824.9155, NMAE: 73.5598, R^2: 0.1206\n",
      "Epoch [1257/2000]\n",
      "Train Loss: 31685839.5612\n",
      "Val Loss: 35762360.1136, MAE: 5211.2100, NMAE: 79.4492, R^2: 0.0217\n",
      "Epoch [1258/2000]\n",
      "Train Loss: 34031379.1250\n",
      "Val Loss: 33982569.1507, MAE: 5047.7437, NMAE: 76.9570, R^2: 0.0704\n",
      "Epoch [1259/2000]\n",
      "Train Loss: 32584164.8397\n",
      "Val Loss: 33653125.0734, MAE: 5074.7974, NMAE: 77.3694, R^2: 0.0794\n",
      "Epoch [1260/2000]\n",
      "Train Loss: 34458074.6914\n",
      "Val Loss: 34117013.9853, MAE: 5005.2993, NMAE: 76.3099, R^2: 0.0667\n",
      "Epoch [1261/2000]\n",
      "Train Loss: 33315404.9224\n",
      "Val Loss: 32684470.9905, MAE: 4954.6797, NMAE: 75.5382, R^2: 0.1059\n",
      "Epoch [1262/2000]\n",
      "Train Loss: 32244667.3793\n",
      "Val Loss: 31854064.5984, MAE: 4781.2764, NMAE: 72.8945, R^2: 0.1286\n",
      "Epoch [1263/2000]\n",
      "Train Loss: 32059898.3388\n",
      "Val Loss: 31155667.2703, MAE: 4695.4795, NMAE: 71.5864, R^2: 0.1477\n",
      "Epoch [1264/2000]\n",
      "Train Loss: 32302329.3509\n",
      "Val Loss: 33352735.9970, MAE: 4920.4424, NMAE: 75.0162, R^2: 0.0876\n",
      "Epoch [1265/2000]\n",
      "Train Loss: 33159769.5164\n",
      "Val Loss: 30998756.3882, MAE: 4636.1670, NMAE: 70.6822, R^2: 0.1520\n",
      "Epoch [1266/2000]\n",
      "Train Loss: 32427443.0491\n",
      "Val Loss: 30938239.4870, MAE: 4640.3052, NMAE: 70.7453, R^2: 0.1536\n",
      "Epoch [1267/2000]\n",
      "Train Loss: 31475603.3233\n",
      "Val Loss: 30961465.8191, MAE: 4722.6436, NMAE: 72.0006, R^2: 0.1530\n",
      "Epoch [1268/2000]\n",
      "Train Loss: 30869504.6836\n",
      "Val Loss: 32537347.0674, MAE: 4922.7886, NMAE: 75.0520, R^2: 0.1099\n",
      "Epoch [1269/2000]\n",
      "Train Loss: 32130437.1241\n",
      "Val Loss: 30919999.2750, MAE: 4666.5581, NMAE: 71.1455, R^2: 0.1541\n",
      "Epoch [1270/2000]\n",
      "Train Loss: 34335551.8509\n",
      "Val Loss: 34023929.5086, MAE: 4803.5684, NMAE: 73.2343, R^2: 0.0692\n",
      "Epoch [1271/2000]\n",
      "Train Loss: 32103564.0388\n",
      "Val Loss: 31691761.7094, MAE: 4829.8628, NMAE: 73.6352, R^2: 0.1330\n",
      "Epoch [1272/2000]\n",
      "Train Loss: 31587692.9724\n",
      "Val Loss: 31615717.1578, MAE: 4832.4385, NMAE: 73.6745, R^2: 0.1351\n",
      "Epoch [1273/2000]\n",
      "Train Loss: 31225692.0250\n",
      "Val Loss: 31924133.0972, MAE: 4875.8472, NMAE: 74.3363, R^2: 0.1267\n",
      "Epoch [1274/2000]\n",
      "Train Loss: 32168135.8612\n",
      "Val Loss: 31181981.2241, MAE: 4679.8950, NMAE: 71.3488, R^2: 0.1470\n",
      "Epoch [1275/2000]\n",
      "Train Loss: 31314760.2629\n",
      "Val Loss: 31516485.7107, MAE: 4719.7998, NMAE: 71.9572, R^2: 0.1378\n",
      "Epoch [1276/2000]\n",
      "Train Loss: 31673078.5078\n",
      "Val Loss: 31222331.4402, MAE: 4705.1777, NMAE: 71.7343, R^2: 0.1459\n",
      "Epoch [1277/2000]\n",
      "Train Loss: 31341821.2034\n",
      "Val Loss: 31474771.6062, MAE: 4739.0312, NMAE: 72.2504, R^2: 0.1390\n",
      "Epoch [1278/2000]\n",
      "Train Loss: 31334896.1922\n",
      "Val Loss: 31385649.1831, MAE: 4777.3403, NMAE: 72.8345, R^2: 0.1414\n",
      "Epoch [1279/2000]\n",
      "Train Loss: 31252480.3810\n",
      "Val Loss: 31149870.6256, MAE: 4743.1240, NMAE: 72.3128, R^2: 0.1478\n",
      "Epoch [1280/2000]\n",
      "Train Loss: 31439457.4922\n",
      "Val Loss: 31670045.6213, MAE: 4810.6528, NMAE: 73.3423, R^2: 0.1336\n",
      "Epoch [1281/2000]\n",
      "Train Loss: 31709163.1672\n",
      "Val Loss: 31299163.2988, MAE: 4722.1479, NMAE: 71.9930, R^2: 0.1438\n",
      "Epoch [1282/2000]\n",
      "Train Loss: 32618587.4517\n",
      "Val Loss: 32209857.9542, MAE: 4892.5000, NMAE: 74.5902, R^2: 0.1189\n",
      "Epoch [1283/2000]\n",
      "Train Loss: 31766532.4595\n",
      "Val Loss: 31223563.6049, MAE: 4793.2920, NMAE: 73.0777, R^2: 0.1458\n",
      "Epoch [1284/2000]\n",
      "Train Loss: 31375759.1112\n",
      "Val Loss: 30939609.9003, MAE: 4723.2925, NMAE: 72.0105, R^2: 0.1536\n",
      "Epoch [1285/2000]\n",
      "Train Loss: 31069024.4672\n",
      "Val Loss: 31398173.8735, MAE: 4836.7666, NMAE: 73.7405, R^2: 0.1411\n",
      "Epoch [1286/2000]\n",
      "Train Loss: 31403991.2457\n",
      "Val Loss: 31141919.8953, MAE: 4794.0049, NMAE: 73.0885, R^2: 0.1481\n",
      "Epoch [1287/2000]\n",
      "Train Loss: 31307890.7233\n",
      "Val Loss: 30976042.5490, MAE: 4721.5190, NMAE: 71.9834, R^2: 0.1526\n",
      "Epoch [1288/2000]\n",
      "Train Loss: 32369085.1147\n",
      "Val Loss: 32386653.4629, MAE: 4891.0615, NMAE: 74.5682, R^2: 0.1140\n",
      "Epoch [1289/2000]\n",
      "Train Loss: 33352505.8009\n",
      "Val Loss: 32860267.0160, MAE: 4916.0908, NMAE: 74.9498, R^2: 0.1011\n",
      "Epoch [1290/2000]\n",
      "Train Loss: 32603380.5784\n",
      "Val Loss: 31774108.0557, MAE: 4793.3335, NMAE: 73.0783, R^2: 0.1308\n",
      "Epoch [1291/2000]\n",
      "Train Loss: 31870404.5612\n",
      "Val Loss: 31728019.0030, MAE: 4807.6245, NMAE: 73.2962, R^2: 0.1320\n",
      "Epoch [1292/2000]\n",
      "Train Loss: 31679826.2707\n",
      "Val Loss: 31529363.9089, MAE: 4747.8716, NMAE: 72.3852, R^2: 0.1375\n",
      "Epoch [1293/2000]\n",
      "Train Loss: 31532363.9888\n",
      "Val Loss: 31430486.9953, MAE: 4796.5796, NMAE: 73.1278, R^2: 0.1402\n",
      "Epoch [1294/2000]\n",
      "Train Loss: 31456594.3871\n",
      "Val Loss: 31560773.1660, MAE: 4784.0889, NMAE: 72.9374, R^2: 0.1366\n",
      "Epoch [1295/2000]\n",
      "Train Loss: 31248633.3302\n",
      "Val Loss: 31425035.8886, MAE: 4755.4102, NMAE: 72.5001, R^2: 0.1403\n",
      "Epoch [1296/2000]\n",
      "Train Loss: 31794714.6198\n",
      "Val Loss: 30742793.7750, MAE: 4675.3384, NMAE: 71.2794, R^2: 0.1590\n",
      "Epoch [1297/2000]\n",
      "Train Loss: 33417477.1862\n",
      "Val Loss: 31823874.7727, MAE: 4642.4077, NMAE: 70.7773, R^2: 0.1294\n",
      "Epoch [1298/2000]\n",
      "Train Loss: 32290073.3181\n",
      "Val Loss: 30852353.6442, MAE: 4631.7925, NMAE: 70.6155, R^2: 0.1560\n",
      "Epoch [1299/2000]\n",
      "Train Loss: 31628038.3888\n",
      "Val Loss: 30736887.1785, MAE: 4655.2432, NMAE: 70.9730, R^2: 0.1591\n",
      "Epoch [1300/2000]\n",
      "Train Loss: 31172249.2233\n",
      "Val Loss: 30575678.3448, MAE: 4701.6641, NMAE: 71.6807, R^2: 0.1636\n",
      "Epoch [1301/2000]\n",
      "Train Loss: 31190036.7233\n",
      "Val Loss: 30425176.4801, MAE: 4673.1548, NMAE: 71.2461, R^2: 0.1677\n",
      "Epoch [1302/2000]\n",
      "Train Loss: 31125319.6716\n",
      "Val Loss: 30339677.7556, MAE: 4671.0889, NMAE: 71.2146, R^2: 0.1700\n",
      "Epoch [1303/2000]\n",
      "Train Loss: 31578735.5336\n",
      "Val Loss: 30479508.3968, MAE: 4651.7358, NMAE: 70.9195, R^2: 0.1662\n",
      "Epoch [1304/2000]\n",
      "Train Loss: 31937659.8655\n",
      "Val Loss: 30844850.1047, MAE: 4713.7695, NMAE: 71.8653, R^2: 0.1562\n",
      "Epoch [1305/2000]\n",
      "Train Loss: 31676451.0362\n",
      "Val Loss: 30762358.1222, MAE: 4707.9746, NMAE: 71.7769, R^2: 0.1584\n",
      "Epoch [1306/2000]\n",
      "Train Loss: 31371389.2233\n",
      "Val Loss: 34439590.1913, MAE: 5129.5366, NMAE: 78.2040, R^2: 0.0579\n",
      "Epoch [1307/2000]\n",
      "Train Loss: 33107255.9302\n",
      "Val Loss: 32540306.6908, MAE: 4966.0664, NMAE: 75.7118, R^2: 0.1098\n",
      "Epoch [1308/2000]\n",
      "Train Loss: 31719803.4741\n",
      "Val Loss: 31002586.8817, MAE: 4770.5073, NMAE: 72.7303, R^2: 0.1519\n",
      "Epoch [1309/2000]\n",
      "Train Loss: 31715658.1000\n",
      "Val Loss: 30976172.6917, MAE: 4772.0801, NMAE: 72.7543, R^2: 0.1526\n",
      "Epoch [1310/2000]\n",
      "Train Loss: 31235326.0293\n",
      "Val Loss: 31120104.2638, MAE: 4800.8843, NMAE: 73.1934, R^2: 0.1487\n",
      "Epoch [1311/2000]\n",
      "Train Loss: 31447381.8543\n",
      "Val Loss: 30619885.4467, MAE: 4728.7412, NMAE: 72.0935, R^2: 0.1623\n",
      "Epoch [1312/2000]\n",
      "Train Loss: 31116090.4328\n",
      "Val Loss: 31100694.9208, MAE: 4798.5342, NMAE: 73.1576, R^2: 0.1492\n",
      "Epoch [1313/2000]\n",
      "Train Loss: 31258801.0026\n",
      "Val Loss: 31094455.8301, MAE: 4784.7095, NMAE: 72.9468, R^2: 0.1494\n",
      "Epoch [1314/2000]\n",
      "Train Loss: 31303248.1853\n",
      "Val Loss: 31230133.8638, MAE: 4789.8940, NMAE: 73.0259, R^2: 0.1457\n",
      "Epoch [1315/2000]\n",
      "Train Loss: 31495573.4853\n",
      "Val Loss: 31071752.9270, MAE: 4759.6802, NMAE: 72.5652, R^2: 0.1500\n",
      "Epoch [1316/2000]\n",
      "Train Loss: 30950803.1698\n",
      "Val Loss: 34449092.2180, MAE: 5165.1582, NMAE: 78.7471, R^2: 0.0576\n",
      "Epoch [1317/2000]\n",
      "Train Loss: 33745602.9216\n",
      "Val Loss: 33355199.5535, MAE: 5067.1069, NMAE: 77.2522, R^2: 0.0875\n",
      "Epoch [1318/2000]\n",
      "Train Loss: 33353062.4905\n",
      "Val Loss: 32218042.8260, MAE: 4944.6177, NMAE: 75.3848, R^2: 0.1186\n",
      "Epoch [1319/2000]\n",
      "Train Loss: 32020978.1043\n",
      "Val Loss: 31963203.0043, MAE: 4913.1377, NMAE: 74.9048, R^2: 0.1256\n",
      "Epoch [1320/2000]\n",
      "Train Loss: 31780542.0974\n",
      "Val Loss: 31384508.1811, MAE: 4825.6196, NMAE: 73.5705, R^2: 0.1414\n",
      "Epoch [1321/2000]\n",
      "Train Loss: 31953174.6629\n",
      "Val Loss: 30993239.3433, MAE: 4747.2671, NMAE: 72.3760, R^2: 0.1521\n",
      "Epoch [1322/2000]\n",
      "Train Loss: 32981094.4034\n",
      "Val Loss: 32263861.8476, MAE: 4832.4990, NMAE: 73.6754, R^2: 0.1174\n",
      "Epoch [1323/2000]\n",
      "Train Loss: 31965278.3698\n",
      "Val Loss: 31063555.6801, MAE: 4774.4868, NMAE: 72.7910, R^2: 0.1502\n",
      "Epoch [1324/2000]\n",
      "Train Loss: 31353913.2517\n",
      "Val Loss: 31071716.2003, MAE: 4758.7573, NMAE: 72.5512, R^2: 0.1500\n",
      "Epoch [1325/2000]\n",
      "Train Loss: 31414015.8017\n",
      "Val Loss: 31461746.8182, MAE: 4795.5425, NMAE: 73.1120, R^2: 0.1393\n",
      "Epoch [1326/2000]\n",
      "Train Loss: 31207172.0655\n",
      "Val Loss: 31372522.2977, MAE: 4748.7046, NMAE: 72.3979, R^2: 0.1418\n",
      "Epoch [1327/2000]\n",
      "Train Loss: 32108345.7724\n",
      "Val Loss: 31077112.2146, MAE: 4667.4585, NMAE: 71.1592, R^2: 0.1498\n",
      "Epoch [1328/2000]\n",
      "Train Loss: 31344582.5379\n",
      "Val Loss: 31333917.2893, MAE: 4759.0640, NMAE: 72.5558, R^2: 0.1428\n",
      "Epoch [1329/2000]\n",
      "Train Loss: 31220706.6483\n",
      "Val Loss: 31477685.2681, MAE: 4772.2729, NMAE: 72.7572, R^2: 0.1389\n",
      "Epoch [1330/2000]\n",
      "Train Loss: 31472713.5388\n",
      "Val Loss: 31468668.8228, MAE: 4769.4224, NMAE: 72.7138, R^2: 0.1391\n",
      "Epoch [1331/2000]\n",
      "Train Loss: 31243525.8586\n",
      "Val Loss: 31471652.4551, MAE: 4758.7563, NMAE: 72.5511, R^2: 0.1390\n",
      "Epoch [1332/2000]\n",
      "Train Loss: 31226286.6879\n",
      "Val Loss: 30986473.2025, MAE: 4706.0918, NMAE: 71.7482, R^2: 0.1523\n",
      "Epoch [1333/2000]\n",
      "Train Loss: 31198302.0250\n",
      "Val Loss: 31061230.1194, MAE: 4672.0850, NMAE: 71.2298, R^2: 0.1503\n",
      "Epoch [1334/2000]\n",
      "Train Loss: 30926016.4207\n",
      "Val Loss: 31077532.9482, MAE: 4669.7563, NMAE: 71.1943, R^2: 0.1498\n",
      "Epoch [1335/2000]\n",
      "Train Loss: 31596671.9496\n",
      "Val Loss: 30905168.6736, MAE: 4711.6240, NMAE: 71.8326, R^2: 0.1545\n",
      "Epoch [1336/2000]\n",
      "Train Loss: 31079256.9828\n",
      "Val Loss: 31727407.1494, MAE: 4854.5679, NMAE: 74.0119, R^2: 0.1320\n",
      "Epoch [1337/2000]\n",
      "Train Loss: 31561291.4543\n",
      "Val Loss: 31273303.4758, MAE: 4794.3354, NMAE: 73.0936, R^2: 0.1445\n",
      "Epoch [1338/2000]\n",
      "Train Loss: 31826660.2026\n",
      "Val Loss: 30451603.1218, MAE: 4636.0664, NMAE: 70.6806, R^2: 0.1670\n",
      "Epoch [1339/2000]\n",
      "Train Loss: 34672615.9375\n",
      "Val Loss: 34600721.8778, MAE: 4716.0210, NMAE: 71.8996, R^2: 0.0534\n",
      "Epoch [1340/2000]\n",
      "Train Loss: 35462681.3603\n",
      "Val Loss: 33598227.2388, MAE: 4723.3296, NMAE: 72.0110, R^2: 0.0809\n",
      "Epoch [1341/2000]\n",
      "Train Loss: 34226673.2000\n",
      "Val Loss: 32529108.7206, MAE: 4724.3447, NMAE: 72.0265, R^2: 0.1101\n",
      "Epoch [1342/2000]\n",
      "Train Loss: 33326663.6259\n",
      "Val Loss: 32016320.3243, MAE: 4746.3491, NMAE: 72.3620, R^2: 0.1241\n",
      "Epoch [1343/2000]\n",
      "Train Loss: 32819182.7793\n",
      "Val Loss: 31737969.2630, MAE: 4711.1431, NMAE: 71.8252, R^2: 0.1318\n",
      "Epoch [1344/2000]\n",
      "Train Loss: 32556042.7216\n",
      "Val Loss: 31678695.0086, MAE: 4727.4839, NMAE: 72.0744, R^2: 0.1334\n",
      "Epoch [1345/2000]\n",
      "Train Loss: 32589469.5164\n",
      "Val Loss: 31769734.5272, MAE: 4777.4570, NMAE: 72.8363, R^2: 0.1309\n",
      "Epoch [1346/2000]\n",
      "Train Loss: 32393050.4716\n",
      "Val Loss: 31519605.9102, MAE: 4744.8037, NMAE: 72.3384, R^2: 0.1377\n",
      "Epoch [1347/2000]\n",
      "Train Loss: 32368991.4940\n",
      "Val Loss: 31538265.1425, MAE: 4747.0767, NMAE: 72.3731, R^2: 0.1372\n",
      "Epoch [1348/2000]\n",
      "Train Loss: 32436778.2078\n",
      "Val Loss: 31377543.4227, MAE: 4744.8687, NMAE: 72.3394, R^2: 0.1416\n",
      "Epoch [1349/2000]\n",
      "Train Loss: 32177145.9112\n",
      "Val Loss: 31112011.5587, MAE: 4703.4712, NMAE: 71.7083, R^2: 0.1489\n",
      "Epoch [1350/2000]\n",
      "Train Loss: 31978615.9871\n",
      "Val Loss: 31621602.7582, MAE: 4812.6772, NMAE: 73.3732, R^2: 0.1349\n",
      "Epoch [1351/2000]\n",
      "Train Loss: 32047368.9733\n",
      "Val Loss: 31230249.3143, MAE: 4751.8984, NMAE: 72.4466, R^2: 0.1456\n",
      "Epoch [1352/2000]\n",
      "Train Loss: 32458825.6129\n",
      "Val Loss: 31146514.8657, MAE: 4731.6113, NMAE: 72.1373, R^2: 0.1479\n",
      "Epoch [1353/2000]\n",
      "Train Loss: 31877054.4534\n",
      "Val Loss: 31435750.8454, MAE: 4782.3916, NMAE: 72.9115, R^2: 0.1400\n",
      "Epoch [1354/2000]\n",
      "Train Loss: 31835680.9491\n",
      "Val Loss: 31016217.2081, MAE: 4735.2915, NMAE: 72.1934, R^2: 0.1515\n",
      "Epoch [1355/2000]\n",
      "Train Loss: 32074233.3052\n",
      "Val Loss: 32273774.6166, MAE: 4636.2520, NMAE: 70.6835, R^2: 0.1171\n",
      "Epoch [1356/2000]\n",
      "Train Loss: 35955033.3172\n",
      "Val Loss: 33902097.0861, MAE: 4675.7988, NMAE: 71.2864, R^2: 0.0726\n",
      "Epoch [1357/2000]\n",
      "Train Loss: 33428864.9948\n",
      "Val Loss: 32024326.5281, MAE: 4727.6050, NMAE: 72.0762, R^2: 0.1239\n",
      "Epoch [1358/2000]\n",
      "Train Loss: 32176743.9043\n",
      "Val Loss: 32255625.7975, MAE: 4896.9907, NMAE: 74.6586, R^2: 0.1176\n",
      "Epoch [1359/2000]\n",
      "Train Loss: 32243789.8276\n",
      "Val Loss: 31552475.7599, MAE: 4797.6470, NMAE: 73.1441, R^2: 0.1368\n",
      "Epoch [1360/2000]\n",
      "Train Loss: 31795902.8328\n",
      "Val Loss: 31406033.6054, MAE: 4761.8696, NMAE: 72.5986, R^2: 0.1408\n",
      "Epoch [1361/2000]\n",
      "Train Loss: 31739117.1216\n",
      "Val Loss: 31780235.1619, MAE: 4836.6631, NMAE: 73.7389, R^2: 0.1306\n",
      "Epoch [1362/2000]\n",
      "Train Loss: 31782566.9914\n",
      "Val Loss: 31173889.5069, MAE: 4757.9897, NMAE: 72.5395, R^2: 0.1472\n",
      "Epoch [1363/2000]\n",
      "Train Loss: 31601437.3293\n",
      "Val Loss: 30993754.3269, MAE: 4733.8896, NMAE: 72.1720, R^2: 0.1521\n",
      "Epoch [1364/2000]\n",
      "Train Loss: 31502867.1379\n",
      "Val Loss: 31276064.4827, MAE: 4786.7681, NMAE: 72.9782, R^2: 0.1444\n",
      "Epoch [1365/2000]\n",
      "Train Loss: 31242216.7914\n",
      "Val Loss: 31064567.2746, MAE: 4770.2261, NMAE: 72.7260, R^2: 0.1502\n",
      "Epoch [1366/2000]\n",
      "Train Loss: 31431839.6517\n",
      "Val Loss: 30814230.7932, MAE: 4730.6084, NMAE: 72.1220, R^2: 0.1570\n",
      "Epoch [1367/2000]\n",
      "Train Loss: 31429836.4466\n",
      "Val Loss: 30881084.2098, MAE: 4741.8989, NMAE: 72.2941, R^2: 0.1552\n",
      "Epoch [1368/2000]\n",
      "Train Loss: 30974528.2983\n",
      "Val Loss: 30948317.3307, MAE: 4753.7007, NMAE: 72.4741, R^2: 0.1534\n",
      "Epoch [1369/2000]\n",
      "Train Loss: 31003241.6060\n",
      "Val Loss: 31072845.5997, MAE: 4778.5850, NMAE: 72.8534, R^2: 0.1500\n",
      "Epoch [1370/2000]\n",
      "Train Loss: 31034936.9250\n",
      "Val Loss: 30884178.0056, MAE: 4775.4751, NMAE: 72.8060, R^2: 0.1551\n",
      "Epoch [1371/2000]\n",
      "Train Loss: 31360076.4940\n",
      "Val Loss: 31323825.1649, MAE: 4841.7949, NMAE: 73.8171, R^2: 0.1431\n",
      "Epoch [1372/2000]\n",
      "Train Loss: 31636479.3500\n",
      "Val Loss: 30969721.1064, MAE: 4792.7666, NMAE: 73.0697, R^2: 0.1528\n",
      "Epoch [1373/2000]\n",
      "Train Loss: 31261671.5784\n",
      "Val Loss: 31317031.4102, MAE: 4818.0483, NMAE: 73.4551, R^2: 0.1433\n",
      "Epoch [1374/2000]\n",
      "Train Loss: 32134273.7112\n",
      "Val Loss: 31523173.8895, MAE: 4738.5234, NMAE: 72.2427, R^2: 0.1376\n",
      "Epoch [1375/2000]\n",
      "Train Loss: 32272350.1759\n",
      "Val Loss: 31288750.1617, MAE: 4760.6177, NMAE: 72.5795, R^2: 0.1440\n",
      "Epoch [1376/2000]\n",
      "Train Loss: 31615270.7793\n",
      "Val Loss: 31300725.6986, MAE: 4803.7061, NMAE: 73.2364, R^2: 0.1437\n",
      "Epoch [1377/2000]\n",
      "Train Loss: 32042820.1388\n",
      "Val Loss: 30649514.2871, MAE: 4684.3057, NMAE: 71.4161, R^2: 0.1615\n",
      "Epoch [1378/2000]\n",
      "Train Loss: 30894878.9931\n",
      "Val Loss: 31145842.9339, MAE: 4779.2173, NMAE: 72.8631, R^2: 0.1480\n",
      "Epoch [1379/2000]\n",
      "Train Loss: 31965225.7129\n",
      "Val Loss: 36649737.5782, MAE: 5290.9346, NMAE: 80.6646, R^2: -0.0026\n",
      "Epoch [1380/2000]\n",
      "Train Loss: 33951261.2121\n",
      "Val Loss: 31071952.2038, MAE: 4701.0693, NMAE: 71.6717, R^2: 0.1500\n",
      "Epoch [1381/2000]\n",
      "Train Loss: 31420957.3940\n",
      "Val Loss: 31266055.5661, MAE: 4680.6450, NMAE: 71.3603, R^2: 0.1447\n",
      "Epoch [1382/2000]\n",
      "Train Loss: 31763440.3121\n",
      "Val Loss: 31375256.8374, MAE: 4697.6880, NMAE: 71.6201, R^2: 0.1417\n",
      "Epoch [1383/2000]\n",
      "Train Loss: 32891822.3966\n",
      "Val Loss: 30726557.8683, MAE: 4598.1025, NMAE: 70.1018, R^2: 0.1594\n",
      "Epoch [1384/2000]\n",
      "Train Loss: 30931263.8612\n",
      "Val Loss: 33913067.3316, MAE: 5089.0596, NMAE: 77.5869, R^2: 0.0723\n",
      "Epoch [1385/2000]\n",
      "Train Loss: 32709693.7457\n",
      "Val Loss: 31179356.6429, MAE: 4787.1011, NMAE: 72.9833, R^2: 0.1470\n",
      "Epoch [1386/2000]\n",
      "Train Loss: 31252177.6241\n",
      "Val Loss: 31124213.9601, MAE: 4773.8208, NMAE: 72.7808, R^2: 0.1486\n",
      "Epoch [1387/2000]\n",
      "Train Loss: 31584603.0172\n",
      "Val Loss: 30874551.5488, MAE: 4730.9214, NMAE: 72.1268, R^2: 0.1554\n",
      "Epoch [1388/2000]\n",
      "Train Loss: 30994301.6302\n",
      "Val Loss: 30535219.0443, MAE: 4698.5439, NMAE: 71.6332, R^2: 0.1647\n",
      "Epoch [1389/2000]\n",
      "Train Loss: 31522981.6716\n",
      "Val Loss: 31382350.0108, MAE: 4828.5991, NMAE: 73.6160, R^2: 0.1415\n",
      "Epoch [1390/2000]\n",
      "Train Loss: 32274916.9379\n",
      "Val Loss: 30638194.1136, MAE: 4597.3032, NMAE: 70.0897, R^2: 0.1618\n",
      "Epoch [1391/2000]\n",
      "Train Loss: 30816770.9517\n",
      "Val Loss: 30348279.3109, MAE: 4665.9429, NMAE: 71.1361, R^2: 0.1698\n",
      "Epoch [1392/2000]\n",
      "Train Loss: 30785880.4207\n",
      "Val Loss: 30426154.0119, MAE: 4661.1401, NMAE: 71.0629, R^2: 0.1676\n",
      "Epoch [1393/2000]\n",
      "Train Loss: 30482641.6888\n",
      "Val Loss: 31334623.7750, MAE: 4795.5239, NMAE: 73.1117, R^2: 0.1428\n",
      "Epoch [1394/2000]\n",
      "Train Loss: 31968844.8310\n",
      "Val Loss: 30885334.4663, MAE: 4647.0610, NMAE: 70.8483, R^2: 0.1551\n",
      "Epoch [1395/2000]\n",
      "Train Loss: 31182528.9276\n",
      "Val Loss: 30784854.8489, MAE: 4748.7275, NMAE: 72.3982, R^2: 0.1578\n",
      "Epoch [1396/2000]\n",
      "Train Loss: 31220710.9845\n",
      "Val Loss: 30920445.3752, MAE: 4683.4521, NMAE: 71.4031, R^2: 0.1541\n",
      "Epoch [1397/2000]\n",
      "Train Loss: 31651157.0638\n",
      "Val Loss: 30931160.5009, MAE: 4768.8887, NMAE: 72.7056, R^2: 0.1538\n",
      "Epoch [1398/2000]\n",
      "Train Loss: 31702223.4922\n",
      "Val Loss: 31124131.6870, MAE: 4643.8496, NMAE: 70.7993, R^2: 0.1486\n",
      "Epoch [1399/2000]\n",
      "Train Loss: 30932832.5250\n",
      "Val Loss: 30916078.3174, MAE: 4748.9263, NMAE: 72.4013, R^2: 0.1542\n",
      "Epoch [1400/2000]\n",
      "Train Loss: 31050734.6793\n",
      "Val Loss: 30632938.4540, MAE: 4698.1670, NMAE: 71.6274, R^2: 0.1620\n",
      "Epoch [1401/2000]\n",
      "Train Loss: 31248178.4121\n",
      "Val Loss: 30583046.2651, MAE: 4663.2178, NMAE: 71.0946, R^2: 0.1634\n",
      "Epoch [1402/2000]\n",
      "Train Loss: 30652106.9957\n",
      "Val Loss: 30873998.1058, MAE: 4743.0664, NMAE: 72.3119, R^2: 0.1554\n",
      "Epoch [1403/2000]\n",
      "Train Loss: 31038747.0198\n",
      "Val Loss: 34454207.0190, MAE: 5122.3853, NMAE: 78.0950, R^2: 0.0575\n",
      "Epoch [1404/2000]\n",
      "Train Loss: 32772586.3595\n",
      "Val Loss: 30578176.4326, MAE: 4658.6919, NMAE: 71.0256, R^2: 0.1635\n",
      "Epoch [1405/2000]\n",
      "Train Loss: 32576200.9621\n",
      "Val Loss: 31726763.3545, MAE: 4863.6011, NMAE: 74.1496, R^2: 0.1321\n",
      "Epoch [1406/2000]\n",
      "Train Loss: 31388311.4216\n",
      "Val Loss: 31112152.7718, MAE: 4788.7544, NMAE: 73.0085, R^2: 0.1489\n",
      "Epoch [1407/2000]\n",
      "Train Loss: 35508024.0991\n",
      "Val Loss: 38787918.7660, MAE: 5496.8994, NMAE: 83.8047, R^2: -0.0611\n",
      "Epoch [1408/2000]\n",
      "Train Loss: 35697796.0759\n",
      "Val Loss: 34233937.5699, MAE: 5130.9624, NMAE: 78.2257, R^2: 0.0635\n",
      "Epoch [1409/2000]\n",
      "Train Loss: 32824473.5612\n",
      "Val Loss: 31902530.0099, MAE: 4871.5649, NMAE: 74.2710, R^2: 0.1273\n",
      "Epoch [1410/2000]\n",
      "Train Loss: 31807848.1147\n",
      "Val Loss: 31326863.5548, MAE: 4809.4878, NMAE: 73.3246, R^2: 0.1430\n",
      "Epoch [1411/2000]\n",
      "Train Loss: 31560455.0810\n",
      "Val Loss: 31017328.6274, MAE: 4773.8965, NMAE: 72.7820, R^2: 0.1515\n",
      "Epoch [1412/2000]\n",
      "Train Loss: 31735525.6026\n",
      "Val Loss: 31434594.2474, MAE: 4827.8286, NMAE: 73.6042, R^2: 0.1401\n",
      "Epoch [1413/2000]\n",
      "Train Loss: 31866357.7009\n",
      "Val Loss: 30781941.1921, MAE: 4743.0737, NMAE: 72.3121, R^2: 0.1579\n",
      "Epoch [1414/2000]\n",
      "Train Loss: 32249584.0319\n",
      "Val Loss: 30563146.7427, MAE: 4674.1230, NMAE: 71.2608, R^2: 0.1639\n",
      "Epoch [1415/2000]\n",
      "Train Loss: 31620400.8371\n",
      "Val Loss: 30574844.7122, MAE: 4698.2188, NMAE: 71.6282, R^2: 0.1636\n",
      "Epoch [1416/2000]\n",
      "Train Loss: 34467026.6112\n",
      "Val Loss: 33413460.7953, MAE: 4725.2402, NMAE: 72.0402, R^2: 0.0859\n",
      "Epoch [1417/2000]\n",
      "Train Loss: 32588889.3397\n",
      "Val Loss: 30664176.7725, MAE: 4707.8428, NMAE: 71.7749, R^2: 0.1611\n",
      "Epoch [1418/2000]\n",
      "Train Loss: 31564653.3707\n",
      "Val Loss: 30661514.2159, MAE: 4704.5225, NMAE: 71.7243, R^2: 0.1612\n",
      "Epoch [1419/2000]\n",
      "Train Loss: 31733143.4716\n",
      "Val Loss: 30929641.7748, MAE: 4762.3081, NMAE: 72.6053, R^2: 0.1539\n",
      "Epoch [1420/2000]\n",
      "Train Loss: 31623354.9466\n",
      "Val Loss: 30571756.8122, MAE: 4709.6230, NMAE: 71.8021, R^2: 0.1637\n",
      "Epoch [1421/2000]\n",
      "Train Loss: 31704930.4552\n",
      "Val Loss: 30518704.0218, MAE: 4695.2388, NMAE: 71.5828, R^2: 0.1651\n",
      "Epoch [1422/2000]\n",
      "Train Loss: 32222541.6466\n",
      "Val Loss: 30899744.7660, MAE: 4672.1270, NMAE: 71.2304, R^2: 0.1547\n",
      "Epoch [1423/2000]\n",
      "Train Loss: 31430550.5310\n",
      "Val Loss: 30703029.8456, MAE: 4719.3135, NMAE: 71.9498, R^2: 0.1601\n",
      "Epoch [1424/2000]\n",
      "Train Loss: 31444429.7940\n",
      "Val Loss: 30804294.1036, MAE: 4679.5654, NMAE: 71.3438, R^2: 0.1573\n",
      "Epoch [1425/2000]\n",
      "Train Loss: 31246402.6560\n",
      "Val Loss: 30648668.6058, MAE: 4698.7930, NMAE: 71.6370, R^2: 0.1616\n",
      "Epoch [1426/2000]\n",
      "Train Loss: 31153365.9103\n",
      "Val Loss: 30375200.4521, MAE: 4661.6899, NMAE: 71.0713, R^2: 0.1690\n",
      "Epoch [1427/2000]\n",
      "Train Loss: 31091067.2491\n",
      "Val Loss: 30562145.6634, MAE: 4720.3413, NMAE: 71.9655, R^2: 0.1639\n",
      "Epoch [1428/2000]\n",
      "Train Loss: 31683199.6379\n",
      "Val Loss: 30881671.1818, MAE: 4683.5161, NMAE: 71.4040, R^2: 0.1552\n",
      "Epoch [1429/2000]\n",
      "Train Loss: 32035932.3293\n",
      "Val Loss: 30869541.3618, MAE: 4713.6416, NMAE: 71.8633, R^2: 0.1555\n",
      "Epoch [1430/2000]\n",
      "Train Loss: 31754862.3741\n",
      "Val Loss: 30904511.7988, MAE: 4716.3828, NMAE: 71.9051, R^2: 0.1546\n",
      "Epoch [1431/2000]\n",
      "Train Loss: 31390496.8578\n",
      "Val Loss: 31700507.3031, MAE: 4849.1548, NMAE: 73.9293, R^2: 0.1328\n",
      "Epoch [1432/2000]\n",
      "Train Loss: 31652237.1569\n",
      "Val Loss: 30818385.1913, MAE: 4754.7729, NMAE: 72.4904, R^2: 0.1569\n",
      "Epoch [1433/2000]\n",
      "Train Loss: 31427698.5112\n",
      "Val Loss: 32873282.0147, MAE: 4969.6206, NMAE: 75.7659, R^2: 0.1007\n",
      "Epoch [1434/2000]\n",
      "Train Loss: 31935774.1707\n",
      "Val Loss: 31054970.6988, MAE: 4680.2554, NMAE: 71.3543, R^2: 0.1504\n",
      "Epoch [1435/2000]\n",
      "Train Loss: 31749378.4250\n",
      "Val Loss: 30774299.4624, MAE: 4744.1064, NMAE: 72.3278, R^2: 0.1581\n",
      "Epoch [1436/2000]\n",
      "Train Loss: 31860116.6319\n",
      "Val Loss: 31704019.6477, MAE: 4632.6748, NMAE: 70.6289, R^2: 0.1327\n",
      "Epoch [1437/2000]\n",
      "Train Loss: 36880796.0362\n",
      "Val Loss: 33923627.8344, MAE: 4716.4946, NMAE: 71.9068, R^2: 0.0720\n",
      "Epoch [1438/2000]\n",
      "Train Loss: 34288296.0431\n",
      "Val Loss: 32042129.7794, MAE: 4693.3682, NMAE: 71.5542, R^2: 0.1234\n",
      "Epoch [1439/2000]\n",
      "Train Loss: 33529420.2957\n",
      "Val Loss: 31426149.4881, MAE: 4688.7207, NMAE: 71.4834, R^2: 0.1403\n",
      "Epoch [1440/2000]\n",
      "Train Loss: 32282780.1345\n",
      "Val Loss: 30767244.8029, MAE: 4658.7764, NMAE: 71.0269, R^2: 0.1583\n",
      "Epoch [1441/2000]\n",
      "Train Loss: 32036522.1802\n",
      "Val Loss: 31430560.7483, MAE: 4835.3550, NMAE: 73.7190, R^2: 0.1402\n",
      "Epoch [1442/2000]\n",
      "Train Loss: 32109861.4931\n",
      "Val Loss: 30856735.7405, MAE: 4744.3423, NMAE: 72.3314, R^2: 0.1559\n",
      "Epoch [1443/2000]\n",
      "Train Loss: 32200125.8164\n",
      "Val Loss: 30531394.0738, MAE: 4675.4028, NMAE: 71.2804, R^2: 0.1648\n",
      "Epoch [1444/2000]\n",
      "Train Loss: 31969279.8793\n",
      "Val Loss: 30553032.4611, MAE: 4728.0015, NMAE: 72.0823, R^2: 0.1642\n",
      "Epoch [1445/2000]\n",
      "Train Loss: 31500624.2922\n",
      "Val Loss: 32821698.6930, MAE: 5002.7188, NMAE: 76.2706, R^2: 0.1021\n",
      "Epoch [1446/2000]\n",
      "Train Loss: 32437507.8491\n",
      "Val Loss: 31816625.2586, MAE: 4867.8008, NMAE: 74.2136, R^2: 0.1296\n",
      "Epoch [1447/2000]\n",
      "Train Loss: 31810296.7207\n",
      "Val Loss: 32147914.1282, MAE: 4925.3062, NMAE: 75.0903, R^2: 0.1205\n",
      "Epoch [1448/2000]\n",
      "Train Loss: 32242613.6776\n",
      "Val Loss: 31358739.6386, MAE: 4832.0527, NMAE: 73.6686, R^2: 0.1421\n",
      "Epoch [1449/2000]\n",
      "Train Loss: 31887056.0603\n",
      "Val Loss: 30620343.4236, MAE: 4735.8755, NMAE: 72.2023, R^2: 0.1623\n",
      "Epoch [1450/2000]\n",
      "Train Loss: 31357727.9569\n",
      "Val Loss: 35925272.7029, MAE: 5273.1426, NMAE: 80.3934, R^2: 0.0172\n",
      "Epoch [1451/2000]\n",
      "Train Loss: 34585498.1741\n",
      "Val Loss: 33640033.6170, MAE: 5073.0547, NMAE: 77.3429, R^2: 0.0797\n",
      "Epoch [1452/2000]\n",
      "Train Loss: 33735179.7276\n",
      "Val Loss: 32087804.1870, MAE: 4888.2310, NMAE: 74.5251, R^2: 0.1222\n",
      "Epoch [1453/2000]\n",
      "Train Loss: 32554065.2526\n",
      "Val Loss: 32699111.6546, MAE: 4977.0996, NMAE: 75.8800, R^2: 0.1055\n",
      "Epoch [1454/2000]\n",
      "Train Loss: 32523488.1224\n",
      "Val Loss: 31020388.9206, MAE: 4744.0742, NMAE: 72.3273, R^2: 0.1514\n",
      "Epoch [1455/2000]\n",
      "Train Loss: 31523335.5534\n",
      "Val Loss: 31144556.3251, MAE: 4764.8887, NMAE: 72.6446, R^2: 0.1480\n",
      "Epoch [1456/2000]\n",
      "Train Loss: 31985919.5629\n",
      "Val Loss: 31280423.5535, MAE: 4767.8276, NMAE: 72.6894, R^2: 0.1443\n",
      "Epoch [1457/2000]\n",
      "Train Loss: 32311852.6672\n",
      "Val Loss: 31360904.0639, MAE: 4709.3604, NMAE: 71.7981, R^2: 0.1421\n",
      "Epoch [1458/2000]\n",
      "Train Loss: 31518689.5491\n",
      "Val Loss: 31433785.2349, MAE: 4719.0386, NMAE: 71.9456, R^2: 0.1401\n",
      "Epoch [1459/2000]\n",
      "Train Loss: 32076667.6422\n",
      "Val Loss: 31435020.6969, MAE: 4671.4316, NMAE: 71.2198, R^2: 0.1400\n",
      "Epoch [1460/2000]\n",
      "Train Loss: 31979843.5560\n",
      "Val Loss: 31621751.3135, MAE: 4738.3047, NMAE: 72.2393, R^2: 0.1349\n",
      "Epoch [1461/2000]\n",
      "Train Loss: 30876791.4466\n",
      "Val Loss: 31241930.8156, MAE: 4759.9795, NMAE: 72.5698, R^2: 0.1453\n",
      "Epoch [1462/2000]\n",
      "Train Loss: 31878188.7414\n",
      "Val Loss: 31212154.3381, MAE: 4744.4526, NMAE: 72.3331, R^2: 0.1461\n",
      "Epoch [1463/2000]\n",
      "Train Loss: 31876942.8802\n",
      "Val Loss: 30604863.3109, MAE: 4669.6895, NMAE: 71.1932, R^2: 0.1628\n",
      "Epoch [1464/2000]\n",
      "Train Loss: 31560878.5069\n",
      "Val Loss: 30645509.4562, MAE: 4667.5371, NMAE: 71.1604, R^2: 0.1616\n",
      "Epoch [1465/2000]\n",
      "Train Loss: 30935040.9483\n",
      "Val Loss: 31230712.4054, MAE: 4750.3936, NMAE: 72.4236, R^2: 0.1456\n",
      "Epoch [1466/2000]\n",
      "Train Loss: 31027141.9552\n",
      "Val Loss: 31076529.8169, MAE: 4712.4097, NMAE: 71.8446, R^2: 0.1499\n",
      "Epoch [1467/2000]\n",
      "Train Loss: 30805344.5931\n",
      "Val Loss: 31749367.5110, MAE: 4824.4414, NMAE: 73.5526, R^2: 0.1314\n",
      "Epoch [1468/2000]\n",
      "Train Loss: 30950579.4172\n",
      "Val Loss: 31351996.9119, MAE: 4722.4780, NMAE: 71.9981, R^2: 0.1423\n",
      "Epoch [1469/2000]\n",
      "Train Loss: 30690154.0897\n",
      "Val Loss: 31371479.9659, MAE: 4745.7812, NMAE: 72.3533, R^2: 0.1418\n",
      "Epoch [1470/2000]\n",
      "Train Loss: 31381850.3276\n",
      "Val Loss: 31689963.5790, MAE: 4775.7871, NMAE: 72.8108, R^2: 0.1331\n",
      "Epoch [1471/2000]\n",
      "Train Loss: 31964221.5931\n",
      "Val Loss: 31063733.2958, MAE: 4707.8096, NMAE: 71.7744, R^2: 0.1502\n",
      "Epoch [1472/2000]\n",
      "Train Loss: 31847205.7560\n",
      "Val Loss: 31752095.4156, MAE: 4825.2437, NMAE: 73.5648, R^2: 0.1314\n",
      "Epoch [1473/2000]\n",
      "Train Loss: 33825963.0578\n",
      "Val Loss: 32248497.5479, MAE: 4696.4858, NMAE: 71.6018, R^2: 0.1178\n",
      "Epoch [1474/2000]\n",
      "Train Loss: 31474393.6681\n",
      "Val Loss: 31001563.7714, MAE: 4731.5127, NMAE: 72.1358, R^2: 0.1519\n",
      "Epoch [1475/2000]\n",
      "Train Loss: 32288658.7483\n",
      "Val Loss: 32131489.0272, MAE: 4776.6382, NMAE: 72.8238, R^2: 0.1210\n",
      "Epoch [1476/2000]\n",
      "Train Loss: 32033062.5500\n",
      "Val Loss: 31739540.3066, MAE: 4791.7349, NMAE: 73.0539, R^2: 0.1317\n",
      "Epoch [1477/2000]\n",
      "Train Loss: 31498766.8733\n",
      "Val Loss: 31149450.7314, MAE: 4772.5933, NMAE: 72.7621, R^2: 0.1479\n",
      "Epoch [1478/2000]\n",
      "Train Loss: 31084788.2776\n",
      "Val Loss: 30901500.0866, MAE: 4728.9229, NMAE: 72.0963, R^2: 0.1546\n",
      "Epoch [1479/2000]\n",
      "Train Loss: 30927695.5034\n",
      "Val Loss: 31252687.2206, MAE: 4780.8506, NMAE: 72.8880, R^2: 0.1450\n",
      "Epoch [1480/2000]\n",
      "Train Loss: 30773155.1000\n",
      "Val Loss: 31644787.1108, MAE: 4823.3359, NMAE: 73.5357, R^2: 0.1343\n",
      "Epoch [1481/2000]\n",
      "Train Loss: 31048168.4569\n",
      "Val Loss: 30736247.5743, MAE: 4655.4204, NMAE: 70.9757, R^2: 0.1592\n",
      "Epoch [1482/2000]\n",
      "Train Loss: 30440609.4233\n",
      "Val Loss: 31648607.7794, MAE: 4815.5469, NMAE: 73.4170, R^2: 0.1342\n",
      "Epoch [1483/2000]\n",
      "Train Loss: 30732478.2819\n",
      "Val Loss: 31622099.5237, MAE: 4826.9346, NMAE: 73.5906, R^2: 0.1349\n",
      "Epoch [1484/2000]\n",
      "Train Loss: 30554050.7716\n",
      "Val Loss: 31612466.3778, MAE: 4817.5591, NMAE: 73.4476, R^2: 0.1352\n",
      "Epoch [1485/2000]\n",
      "Train Loss: 31388651.5828\n",
      "Val Loss: 31132423.2116, MAE: 4743.0869, NMAE: 72.3123, R^2: 0.1483\n",
      "Epoch [1486/2000]\n",
      "Train Loss: 31058901.6440\n",
      "Val Loss: 30813352.3769, MAE: 4728.3169, NMAE: 72.0871, R^2: 0.1571\n",
      "Epoch [1487/2000]\n",
      "Train Loss: 30790173.6250\n",
      "Val Loss: 31294241.4987, MAE: 4745.3813, NMAE: 72.3472, R^2: 0.1439\n",
      "Epoch [1488/2000]\n",
      "Train Loss: 30910332.7293\n",
      "Val Loss: 31197239.0915, MAE: 4699.3848, NMAE: 71.6460, R^2: 0.1466\n",
      "Epoch [1489/2000]\n",
      "Train Loss: 30173741.9431\n",
      "Val Loss: 31346673.8053, MAE: 4705.9292, NMAE: 71.7458, R^2: 0.1425\n",
      "Epoch [1490/2000]\n",
      "Train Loss: 30191001.1069\n",
      "Val Loss: 31583664.7459, MAE: 4765.2554, NMAE: 72.6502, R^2: 0.1360\n",
      "Epoch [1491/2000]\n",
      "Train Loss: 31612409.7586\n",
      "Val Loss: 31976079.2032, MAE: 4859.4365, NMAE: 74.0861, R^2: 0.1252\n",
      "Epoch [1492/2000]\n",
      "Train Loss: 31730857.4474\n",
      "Val Loss: 30925735.8385, MAE: 4701.9634, NMAE: 71.6853, R^2: 0.1540\n",
      "Epoch [1493/2000]\n",
      "Train Loss: 31227198.5129\n",
      "Val Loss: 31154554.5566, MAE: 4741.1460, NMAE: 72.2827, R^2: 0.1477\n",
      "Epoch [1494/2000]\n",
      "Train Loss: 30940362.1819\n",
      "Val Loss: 31007318.0656, MAE: 4735.5327, NMAE: 72.1971, R^2: 0.1517\n",
      "Epoch [1495/2000]\n",
      "Train Loss: 31369983.5233\n",
      "Val Loss: 30981981.5199, MAE: 4622.2842, NMAE: 70.4705, R^2: 0.1524\n",
      "Epoch [1496/2000]\n",
      "Train Loss: 32429414.0724\n",
      "Val Loss: 31561622.0846, MAE: 4700.1743, NMAE: 71.6580, R^2: 0.1366\n",
      "Epoch [1497/2000]\n",
      "Train Loss: 33850261.3190\n",
      "Val Loss: 32595141.1343, MAE: 4760.1226, NMAE: 72.5720, R^2: 0.1083\n",
      "Epoch [1498/2000]\n",
      "Train Loss: 32177454.9190\n",
      "Val Loss: 30834767.4443, MAE: 4734.3794, NMAE: 72.1795, R^2: 0.1565\n",
      "Epoch [1499/2000]\n",
      "Train Loss: 31107043.8302\n",
      "Val Loss: 30433399.2077, MAE: 4702.8491, NMAE: 71.6988, R^2: 0.1674\n",
      "Epoch [1500/2000]\n",
      "Train Loss: 30819933.2517\n",
      "Val Loss: 30447833.2791, MAE: 4702.7017, NMAE: 71.6965, R^2: 0.1671\n",
      "Epoch [1501/2000]\n",
      "Train Loss: 31088402.6483\n",
      "Val Loss: 30216892.9784, MAE: 4654.5552, NMAE: 70.9625, R^2: 0.1734\n",
      "Epoch [1502/2000]\n",
      "Train Loss: 30742998.4353\n",
      "Val Loss: 30353300.2103, MAE: 4676.2568, NMAE: 71.2934, R^2: 0.1696\n",
      "Epoch [1503/2000]\n",
      "Train Loss: 32394238.5310\n",
      "Val Loss: 31188247.9361, MAE: 4616.4731, NMAE: 70.3819, R^2: 0.1468\n",
      "Epoch [1504/2000]\n",
      "Train Loss: 31042053.8543\n",
      "Val Loss: 30825893.8614, MAE: 4759.6846, NMAE: 72.5653, R^2: 0.1567\n",
      "Epoch [1505/2000]\n",
      "Train Loss: 31368517.2190\n",
      "Val Loss: 30374575.5130, MAE: 4680.9785, NMAE: 71.3654, R^2: 0.1691\n",
      "Epoch [1506/2000]\n",
      "Train Loss: 30993551.5690\n",
      "Val Loss: 30685717.3109, MAE: 4744.2510, NMAE: 72.3300, R^2: 0.1605\n",
      "Epoch [1507/2000]\n",
      "Train Loss: 31091954.4198\n",
      "Val Loss: 30453202.4775, MAE: 4686.4463, NMAE: 71.4487, R^2: 0.1669\n",
      "Epoch [1508/2000]\n",
      "Train Loss: 30911822.5741\n",
      "Val Loss: 31105060.7919, MAE: 4772.8560, NMAE: 72.7661, R^2: 0.1491\n",
      "Epoch [1509/2000]\n",
      "Train Loss: 30873015.3181\n",
      "Val Loss: 31580199.8407, MAE: 4842.7002, NMAE: 73.8309, R^2: 0.1361\n",
      "Epoch [1510/2000]\n",
      "Train Loss: 31074770.0095\n",
      "Val Loss: 34362791.5026, MAE: 5073.4824, NMAE: 77.3494, R^2: 0.0600\n",
      "Epoch [1511/2000]\n",
      "Train Loss: 33284212.6526\n",
      "Val Loss: 31175956.6537, MAE: 4608.6392, NMAE: 70.2625, R^2: 0.1471\n",
      "Epoch [1512/2000]\n",
      "Train Loss: 31821410.4776\n",
      "Val Loss: 30709761.9275, MAE: 4658.2871, NMAE: 71.0194, R^2: 0.1599\n",
      "Epoch [1513/2000]\n",
      "Train Loss: 31277682.0552\n",
      "Val Loss: 30873778.8329, MAE: 4729.4819, NMAE: 72.1048, R^2: 0.1554\n",
      "Epoch [1514/2000]\n",
      "Train Loss: 31681081.4103\n",
      "Val Loss: 31273185.7155, MAE: 4761.7637, NMAE: 72.5970, R^2: 0.1445\n",
      "Epoch [1515/2000]\n",
      "Train Loss: 31775992.4250\n",
      "Val Loss: 31184081.4845, MAE: 4764.9619, NMAE: 72.6458, R^2: 0.1469\n",
      "Epoch [1516/2000]\n",
      "Train Loss: 31450403.0733\n",
      "Val Loss: 31070181.4028, MAE: 4736.0713, NMAE: 72.2053, R^2: 0.1500\n",
      "Epoch [1517/2000]\n",
      "Train Loss: 31378019.8741\n",
      "Val Loss: 31034300.7608, MAE: 4759.8271, NMAE: 72.5675, R^2: 0.1510\n",
      "Epoch [1518/2000]\n",
      "Train Loss: 31184740.4802\n",
      "Val Loss: 30993207.2949, MAE: 4760.3271, NMAE: 72.5751, R^2: 0.1521\n",
      "Epoch [1519/2000]\n",
      "Train Loss: 31484349.4095\n",
      "Val Loss: 31055141.4188, MAE: 4721.8257, NMAE: 71.9881, R^2: 0.1504\n",
      "Epoch [1520/2000]\n",
      "Train Loss: 33115322.5448\n",
      "Val Loss: 33701310.1455, MAE: 4701.9663, NMAE: 71.6853, R^2: 0.0781\n",
      "Epoch [1521/2000]\n",
      "Train Loss: 34303644.7379\n",
      "Val Loss: 33660668.2932, MAE: 4711.2285, NMAE: 71.8265, R^2: 0.0792\n",
      "Epoch [1522/2000]\n",
      "Train Loss: 34049135.2379\n",
      "Val Loss: 33352141.2517, MAE: 4708.7964, NMAE: 71.7895, R^2: 0.0876\n",
      "Epoch [1523/2000]\n",
      "Train Loss: 33798179.9828\n",
      "Val Loss: 33189958.7906, MAE: 4714.5312, NMAE: 71.8769, R^2: 0.0920\n",
      "Epoch [1524/2000]\n",
      "Train Loss: 33586792.3767\n",
      "Val Loss: 32986991.4935, MAE: 4705.6152, NMAE: 71.7410, R^2: 0.0976\n",
      "Epoch [1525/2000]\n",
      "Train Loss: 33561282.2362\n",
      "Val Loss: 32877851.0069, MAE: 4701.4155, NMAE: 71.6769, R^2: 0.1006\n",
      "Epoch [1526/2000]\n",
      "Train Loss: 33322056.4172\n",
      "Val Loss: 32698914.0043, MAE: 4694.6631, NMAE: 71.5740, R^2: 0.1055\n",
      "Epoch [1527/2000]\n",
      "Train Loss: 33327843.4233\n",
      "Val Loss: 32508571.4093, MAE: 4685.6445, NMAE: 71.4365, R^2: 0.1107\n",
      "Epoch [1528/2000]\n",
      "Train Loss: 32303732.4560\n",
      "Val Loss: 31316679.3282, MAE: 4665.0576, NMAE: 71.1226, R^2: 0.1433\n",
      "Epoch [1529/2000]\n",
      "Train Loss: 32274488.0267\n",
      "Val Loss: 31574698.3325, MAE: 4636.6733, NMAE: 70.6899, R^2: 0.1362\n",
      "Epoch [1530/2000]\n",
      "Train Loss: 32085395.4690\n",
      "Val Loss: 31266841.1274, MAE: 4685.4888, NMAE: 71.4341, R^2: 0.1446\n",
      "Epoch [1531/2000]\n",
      "Train Loss: 31713935.1733\n",
      "Val Loss: 31205083.2353, MAE: 4691.8193, NMAE: 71.5306, R^2: 0.1463\n",
      "Epoch [1532/2000]\n",
      "Train Loss: 31903425.1974\n",
      "Val Loss: 31404494.4491, MAE: 4697.7749, NMAE: 71.6214, R^2: 0.1409\n",
      "Epoch [1533/2000]\n",
      "Train Loss: 31455503.9379\n",
      "Val Loss: 31191095.0583, MAE: 4678.5879, NMAE: 71.3289, R^2: 0.1467\n",
      "Epoch [1534/2000]\n",
      "Train Loss: 31493349.4164\n",
      "Val Loss: 31044742.5009, MAE: 4692.7773, NMAE: 71.5452, R^2: 0.1507\n",
      "Epoch [1535/2000]\n",
      "Train Loss: 31231982.0172\n",
      "Val Loss: 30981382.4186, MAE: 4705.3936, NMAE: 71.7376, R^2: 0.1525\n",
      "Epoch [1536/2000]\n",
      "Train Loss: 31190574.7328\n",
      "Val Loss: 31015051.9560, MAE: 4680.7778, NMAE: 71.3623, R^2: 0.1515\n",
      "Epoch [1537/2000]\n",
      "Train Loss: 31218414.8647\n",
      "Val Loss: 30817283.6598, MAE: 4626.7808, NMAE: 70.5391, R^2: 0.1569\n",
      "Epoch [1538/2000]\n",
      "Train Loss: 30749283.1690\n",
      "Val Loss: 30930804.4393, MAE: 4753.1401, NMAE: 72.4655, R^2: 0.1538\n",
      "Epoch [1539/2000]\n",
      "Train Loss: 30908299.9603\n",
      "Val Loss: 30623905.7036, MAE: 4689.7378, NMAE: 71.4989, R^2: 0.1622\n",
      "Epoch [1540/2000]\n",
      "Train Loss: 31304531.6862\n",
      "Val Loss: 30830446.2230, MAE: 4653.8931, NMAE: 70.9524, R^2: 0.1566\n",
      "Epoch [1541/2000]\n",
      "Train Loss: 31038382.5888\n",
      "Val Loss: 30650865.3614, MAE: 4697.0020, NMAE: 71.6096, R^2: 0.1615\n",
      "Epoch [1542/2000]\n",
      "Train Loss: 30802368.6345\n",
      "Val Loss: 30707621.6401, MAE: 4705.3418, NMAE: 71.7368, R^2: 0.1599\n",
      "Epoch [1543/2000]\n",
      "Train Loss: 31340268.0681\n",
      "Val Loss: 30684607.0762, MAE: 4727.0806, NMAE: 72.0682, R^2: 0.1606\n",
      "Epoch [1544/2000]\n",
      "Train Loss: 31229324.0724\n",
      "Val Loss: 30616892.3387, MAE: 4661.7773, NMAE: 71.0726, R^2: 0.1624\n",
      "Epoch [1545/2000]\n",
      "Train Loss: 30493843.9328\n",
      "Val Loss: 31061682.8256, MAE: 4748.9019, NMAE: 72.4009, R^2: 0.1503\n",
      "Epoch [1546/2000]\n",
      "Train Loss: 32168860.2655\n",
      "Val Loss: 31966515.6500, MAE: 4863.5659, NMAE: 74.1491, R^2: 0.1255\n",
      "Epoch [1547/2000]\n",
      "Train Loss: 32152376.4940\n",
      "Val Loss: 31177523.8109, MAE: 4778.4985, NMAE: 72.8521, R^2: 0.1471\n",
      "Epoch [1548/2000]\n",
      "Train Loss: 31380753.1948\n",
      "Val Loss: 31566881.6334, MAE: 4800.9663, NMAE: 73.1947, R^2: 0.1364\n",
      "Epoch [1549/2000]\n",
      "Train Loss: 31075603.6871\n",
      "Val Loss: 30874883.3944, MAE: 4734.9233, NMAE: 72.1878, R^2: 0.1554\n",
      "Epoch [1550/2000]\n",
      "Train Loss: 35147863.7664\n",
      "Val Loss: 34641148.4059, MAE: 4704.5356, NMAE: 71.7245, R^2: 0.0523\n",
      "Epoch [1551/2000]\n",
      "Train Loss: 33987919.8526\n",
      "Val Loss: 31793427.8191, MAE: 4683.3784, NMAE: 71.4019, R^2: 0.1302\n",
      "Epoch [1552/2000]\n",
      "Train Loss: 32106014.8440\n",
      "Val Loss: 30986183.2332, MAE: 4699.1963, NMAE: 71.6431, R^2: 0.1523\n",
      "Epoch [1553/2000]\n",
      "Train Loss: 31726188.9198\n",
      "Val Loss: 31108571.4352, MAE: 4728.0977, NMAE: 72.0837, R^2: 0.1490\n",
      "Epoch [1554/2000]\n",
      "Train Loss: 31878076.6216\n",
      "Val Loss: 31052290.4870, MAE: 4708.1167, NMAE: 71.7791, R^2: 0.1505\n",
      "Epoch [1555/2000]\n",
      "Train Loss: 31783161.1043\n",
      "Val Loss: 31512290.1957, MAE: 4738.2812, NMAE: 72.2390, R^2: 0.1379\n",
      "Epoch [1556/2000]\n",
      "Train Loss: 31358537.2392\n",
      "Val Loss: 31259077.6974, MAE: 4699.4868, NMAE: 71.6475, R^2: 0.1449\n",
      "Epoch [1557/2000]\n",
      "Train Loss: 31010559.5203\n",
      "Val Loss: 31172029.4769, MAE: 4726.9570, NMAE: 72.0663, R^2: 0.1472\n",
      "Epoch [1558/2000]\n",
      "Train Loss: 31122351.2638\n",
      "Val Loss: 31440263.3750, MAE: 4747.4756, NMAE: 72.3792, R^2: 0.1399\n",
      "Epoch [1559/2000]\n",
      "Train Loss: 33091749.0405\n",
      "Val Loss: 32020966.8305, MAE: 4832.2124, NMAE: 73.6710, R^2: 0.1240\n",
      "Epoch [1560/2000]\n",
      "Train Loss: 31893010.5901\n",
      "Val Loss: 31314923.0484, MAE: 4752.6279, NMAE: 72.4577, R^2: 0.1433\n",
      "Epoch [1561/2000]\n",
      "Train Loss: 31378543.4047\n",
      "Val Loss: 31452057.1159, MAE: 4734.7217, NMAE: 72.1847, R^2: 0.1396\n",
      "Epoch [1562/2000]\n",
      "Train Loss: 31360181.3233\n",
      "Val Loss: 31249768.2047, MAE: 4656.3301, NMAE: 70.9896, R^2: 0.1451\n",
      "Epoch [1563/2000]\n",
      "Train Loss: 31264246.8828\n",
      "Val Loss: 31306721.4503, MAE: 4772.3228, NMAE: 72.7580, R^2: 0.1436\n",
      "Epoch [1564/2000]\n",
      "Train Loss: 31601435.7060\n",
      "Val Loss: 31267089.4741, MAE: 4725.4321, NMAE: 72.0431, R^2: 0.1446\n",
      "Epoch [1565/2000]\n",
      "Train Loss: 31540237.1802\n",
      "Val Loss: 31428090.9380, MAE: 4772.9609, NMAE: 72.7677, R^2: 0.1402\n",
      "Epoch [1566/2000]\n",
      "Train Loss: 31964564.3793\n",
      "Val Loss: 31498484.4080, MAE: 4696.7939, NMAE: 71.6065, R^2: 0.1383\n",
      "Epoch [1567/2000]\n",
      "Train Loss: 32707559.7086\n",
      "Val Loss: 31240078.0035, MAE: 4684.1431, NMAE: 71.4136, R^2: 0.1454\n",
      "Epoch [1568/2000]\n",
      "Train Loss: 32511638.6534\n",
      "Val Loss: 31163310.6084, MAE: 4659.7510, NMAE: 71.0417, R^2: 0.1475\n",
      "Epoch [1569/2000]\n",
      "Train Loss: 32137758.1560\n",
      "Val Loss: 30861259.6399, MAE: 4667.3325, NMAE: 71.1573, R^2: 0.1557\n",
      "Epoch [1570/2000]\n",
      "Train Loss: 32139590.5647\n",
      "Val Loss: 30968278.7366, MAE: 4676.8755, NMAE: 71.3028, R^2: 0.1528\n",
      "Epoch [1571/2000]\n",
      "Train Loss: 31608378.7957\n",
      "Val Loss: 30879600.9624, MAE: 4644.7515, NMAE: 70.8130, R^2: 0.1552\n",
      "Epoch [1572/2000]\n",
      "Train Loss: 31337262.7638\n",
      "Val Loss: 30800150.1421, MAE: 4710.0176, NMAE: 71.8081, R^2: 0.1574\n",
      "Epoch [1573/2000]\n",
      "Train Loss: 31607282.8974\n",
      "Val Loss: 31810790.8959, MAE: 4854.2876, NMAE: 74.0076, R^2: 0.1298\n",
      "Epoch [1574/2000]\n",
      "Train Loss: 31487732.5302\n",
      "Val Loss: 30922305.3715, MAE: 4752.4771, NMAE: 72.4554, R^2: 0.1541\n",
      "Epoch [1575/2000]\n",
      "Train Loss: 31546415.3491\n",
      "Val Loss: 31482638.8342, MAE: 4636.0205, NMAE: 70.6799, R^2: 0.1387\n",
      "Epoch [1576/2000]\n",
      "Train Loss: 31940189.1276\n",
      "Val Loss: 31000906.0406, MAE: 4641.9683, NMAE: 70.7706, R^2: 0.1519\n",
      "Epoch [1577/2000]\n",
      "Train Loss: 31275127.4147\n",
      "Val Loss: 30983037.0384, MAE: 4652.1743, NMAE: 70.9262, R^2: 0.1524\n",
      "Epoch [1578/2000]\n",
      "Train Loss: 30726669.9802\n",
      "Val Loss: 34024411.8005, MAE: 5065.3188, NMAE: 77.2249, R^2: 0.0692\n",
      "Epoch [1579/2000]\n",
      "Train Loss: 32898755.5802\n",
      "Val Loss: 33684310.1472, MAE: 5025.3467, NMAE: 76.6155, R^2: 0.0785\n",
      "Epoch [1580/2000]\n",
      "Train Loss: 32242100.9155\n",
      "Val Loss: 30926102.1347, MAE: 4714.5806, NMAE: 71.8776, R^2: 0.1540\n",
      "Epoch [1581/2000]\n",
      "Train Loss: 31602683.3767\n",
      "Val Loss: 31355544.5073, MAE: 4759.4688, NMAE: 72.5620, R^2: 0.1422\n",
      "Epoch [1582/2000]\n",
      "Train Loss: 31892532.6414\n",
      "Val Loss: 31584035.3187, MAE: 4671.5181, NMAE: 71.2211, R^2: 0.1360\n",
      "Epoch [1583/2000]\n",
      "Train Loss: 31720349.5534\n",
      "Val Loss: 31723117.2332, MAE: 4739.6528, NMAE: 72.2599, R^2: 0.1322\n",
      "Epoch [1584/2000]\n",
      "Train Loss: 31693158.9716\n",
      "Val Loss: 32539412.4577, MAE: 4906.9590, NMAE: 74.8106, R^2: 0.1098\n",
      "Epoch [1585/2000]\n",
      "Train Loss: 31820179.6328\n",
      "Val Loss: 31348295.9940, MAE: 4765.5742, NMAE: 72.6551, R^2: 0.1424\n",
      "Epoch [1586/2000]\n",
      "Train Loss: 31530702.3672\n",
      "Val Loss: 31106314.5976, MAE: 4738.4727, NMAE: 72.2419, R^2: 0.1490\n",
      "Epoch [1587/2000]\n",
      "Train Loss: 32626266.3586\n",
      "Val Loss: 31461921.6965, MAE: 4693.9287, NMAE: 71.5628, R^2: 0.1393\n",
      "Epoch [1588/2000]\n",
      "Train Loss: 31955193.8526\n",
      "Val Loss: 31126310.5954, MAE: 4688.4106, NMAE: 71.4787, R^2: 0.1485\n",
      "Epoch [1589/2000]\n",
      "Train Loss: 31527632.2017\n",
      "Val Loss: 30745748.1511, MAE: 4691.3062, NMAE: 71.5228, R^2: 0.1589\n",
      "Epoch [1590/2000]\n",
      "Train Loss: 31201324.6397\n",
      "Val Loss: 30857705.6891, MAE: 4744.6030, NMAE: 72.3354, R^2: 0.1558\n",
      "Epoch [1591/2000]\n",
      "Train Loss: 30648658.6017\n",
      "Val Loss: 31811317.0643, MAE: 4869.9121, NMAE: 74.2458, R^2: 0.1298\n",
      "Epoch [1592/2000]\n",
      "Train Loss: 32518818.7345\n",
      "Val Loss: 31666555.8195, MAE: 4593.5278, NMAE: 70.0321, R^2: 0.1337\n",
      "Epoch [1593/2000]\n",
      "Train Loss: 31941314.4828\n",
      "Val Loss: 30271216.3759, MAE: 4626.9854, NMAE: 70.5422, R^2: 0.1719\n",
      "Epoch [1594/2000]\n",
      "Train Loss: 31787981.6022\n",
      "Val Loss: 31053533.4370, MAE: 4646.7202, NMAE: 70.8431, R^2: 0.1505\n",
      "Epoch [1595/2000]\n",
      "Train Loss: 32990714.2793\n",
      "Val Loss: 32179203.6347, MAE: 4623.8276, NMAE: 70.4940, R^2: 0.1197\n",
      "Epoch [1596/2000]\n",
      "Train Loss: 31644897.8091\n",
      "Val Loss: 30415929.5268, MAE: 4649.7358, NMAE: 70.8890, R^2: 0.1679\n",
      "Epoch [1597/2000]\n",
      "Train Loss: 31352507.3871\n",
      "Val Loss: 30615664.3804, MAE: 4633.4736, NMAE: 70.6411, R^2: 0.1625\n",
      "Epoch [1598/2000]\n",
      "Train Loss: 31860450.2009\n",
      "Val Loss: 31073424.4007, MAE: 4711.1060, NMAE: 71.8247, R^2: 0.1499\n",
      "Epoch [1599/2000]\n",
      "Train Loss: 31595111.8233\n",
      "Val Loss: 30858777.1144, MAE: 4716.8770, NMAE: 71.9127, R^2: 0.1558\n",
      "Epoch [1600/2000]\n",
      "Train Loss: 31187112.2621\n",
      "Val Loss: 30600910.6183, MAE: 4717.6377, NMAE: 71.9243, R^2: 0.1629\n",
      "Epoch [1601/2000]\n",
      "Train Loss: 31213944.2793\n",
      "Val Loss: 31181893.7746, MAE: 4739.2676, NMAE: 72.2540, R^2: 0.1470\n",
      "Epoch [1602/2000]\n",
      "Train Loss: 31762663.9698\n",
      "Val Loss: 31191793.3856, MAE: 4696.7974, NMAE: 71.6065, R^2: 0.1467\n",
      "Epoch [1603/2000]\n",
      "Train Loss: 31660378.6767\n",
      "Val Loss: 30607202.9491, MAE: 4662.4600, NMAE: 71.0830, R^2: 0.1627\n",
      "Epoch [1604/2000]\n",
      "Train Loss: 31449332.0629\n",
      "Val Loss: 30841456.2496, MAE: 4720.6470, NMAE: 71.9701, R^2: 0.1563\n",
      "Epoch [1605/2000]\n",
      "Train Loss: 31225525.5293\n",
      "Val Loss: 30831008.0626, MAE: 4734.9268, NMAE: 72.1878, R^2: 0.1566\n",
      "Epoch [1606/2000]\n",
      "Train Loss: 30963678.0595\n",
      "Val Loss: 31188686.1231, MAE: 4794.5864, NMAE: 73.0974, R^2: 0.1468\n",
      "Epoch [1607/2000]\n",
      "Train Loss: 31406917.3388\n",
      "Val Loss: 30625522.0678, MAE: 4686.7417, NMAE: 71.4532, R^2: 0.1622\n",
      "Epoch [1608/2000]\n",
      "Train Loss: 31235072.5017\n",
      "Val Loss: 30324659.7753, MAE: 4652.1045, NMAE: 70.9251, R^2: 0.1704\n",
      "Epoch [1609/2000]\n",
      "Train Loss: 32561035.3233\n",
      "Val Loss: 33317130.5030, MAE: 4650.8730, NMAE: 70.9064, R^2: 0.0886\n",
      "Epoch [1610/2000]\n",
      "Train Loss: 34173385.6716\n",
      "Val Loss: 31638426.6777, MAE: 4625.0596, NMAE: 70.5128, R^2: 0.1345\n",
      "Epoch [1611/2000]\n",
      "Train Loss: 32443047.1629\n",
      "Val Loss: 32110886.9003, MAE: 4777.9971, NMAE: 72.8445, R^2: 0.1216\n",
      "Epoch [1612/2000]\n",
      "Train Loss: 33318684.1534\n",
      "Val Loss: 31737629.8450, MAE: 4752.4102, NMAE: 72.4544, R^2: 0.1318\n",
      "Epoch [1613/2000]\n",
      "Train Loss: 32936431.6353\n",
      "Val Loss: 32002436.8778, MAE: 4663.0190, NMAE: 71.0916, R^2: 0.1245\n",
      "Epoch [1614/2000]\n",
      "Train Loss: 37589475.3155\n",
      "Val Loss: 36802735.5773, MAE: 4804.8130, NMAE: 73.2533, R^2: -0.0068\n",
      "Epoch [1615/2000]\n",
      "Train Loss: 37685549.9897\n",
      "Val Loss: 35804967.4732, MAE: 4779.4824, NMAE: 72.8671, R^2: 0.0205\n",
      "Epoch [1616/2000]\n",
      "Train Loss: 36368841.2810\n",
      "Val Loss: 34680195.3083, MAE: 4744.6377, NMAE: 72.3359, R^2: 0.0513\n",
      "Epoch [1617/2000]\n",
      "Train Loss: 37563395.6595\n",
      "Val Loss: 35628611.6736, MAE: 4785.7607, NMAE: 72.9628, R^2: 0.0253\n",
      "Epoch [1618/2000]\n",
      "Train Loss: 36819349.9259\n",
      "Val Loss: 35702984.4437, MAE: 4794.3335, NMAE: 73.0935, R^2: 0.0233\n",
      "Epoch [1619/2000]\n",
      "Train Loss: 36278839.4345\n",
      "Val Loss: 35733990.7219, MAE: 4797.1455, NMAE: 73.1364, R^2: 0.0224\n",
      "Epoch [1620/2000]\n",
      "Train Loss: 36663556.4733\n",
      "Val Loss: 34889350.8787, MAE: 4769.7886, NMAE: 72.7193, R^2: 0.0455\n",
      "Epoch [1621/2000]\n",
      "Train Loss: 35577186.2966\n",
      "Val Loss: 33512335.8886, MAE: 4721.3042, NMAE: 71.9802, R^2: 0.0832\n",
      "Epoch [1622/2000]\n",
      "Train Loss: 33073840.8293\n",
      "Val Loss: 31752174.8765, MAE: 4688.4033, NMAE: 71.4786, R^2: 0.1314\n",
      "Epoch [1623/2000]\n",
      "Train Loss: 32152478.8517\n",
      "Val Loss: 31220197.4914, MAE: 4670.2700, NMAE: 71.2021, R^2: 0.1459\n",
      "Epoch [1624/2000]\n",
      "Train Loss: 31852782.7095\n",
      "Val Loss: 30791676.5555, MAE: 4677.4683, NMAE: 71.3118, R^2: 0.1576\n",
      "Epoch [1625/2000]\n",
      "Train Loss: 31375570.2009\n",
      "Val Loss: 30676032.3627, MAE: 4697.0059, NMAE: 71.6097, R^2: 0.1608\n",
      "Epoch [1626/2000]\n",
      "Train Loss: 31163851.7552\n",
      "Val Loss: 30580198.4581, MAE: 4673.2383, NMAE: 71.2474, R^2: 0.1634\n",
      "Epoch [1627/2000]\n",
      "Train Loss: 31153921.7103\n",
      "Val Loss: 30708692.6354, MAE: 4710.9175, NMAE: 71.8218, R^2: 0.1599\n",
      "Epoch [1628/2000]\n",
      "Train Loss: 31023386.6509\n",
      "Val Loss: 31054889.4620, MAE: 4748.0825, NMAE: 72.3884, R^2: 0.1504\n",
      "Epoch [1629/2000]\n",
      "Train Loss: 31147502.5845\n",
      "Val Loss: 30765150.4076, MAE: 4693.4634, NMAE: 71.5557, R^2: 0.1584\n",
      "Epoch [1630/2000]\n",
      "Train Loss: 31248213.5328\n",
      "Val Loss: 31141401.2700, MAE: 4630.2944, NMAE: 70.5926, R^2: 0.1481\n",
      "Epoch [1631/2000]\n",
      "Train Loss: 30946171.5457\n",
      "Val Loss: 31490114.3586, MAE: 4698.8267, NMAE: 71.6375, R^2: 0.1385\n",
      "Epoch [1632/2000]\n",
      "Train Loss: 30859785.5224\n",
      "Val Loss: 31367551.5773, MAE: 4727.9912, NMAE: 72.0821, R^2: 0.1419\n",
      "Epoch [1633/2000]\n",
      "Train Loss: 30937555.6681\n",
      "Val Loss: 31077693.8979, MAE: 4722.1851, NMAE: 71.9936, R^2: 0.1498\n",
      "Epoch [1634/2000]\n",
      "Train Loss: 30832758.7845\n",
      "Val Loss: 31263838.7168, MAE: 4692.3872, NMAE: 71.5393, R^2: 0.1447\n",
      "Epoch [1635/2000]\n",
      "Train Loss: 31953214.4500\n",
      "Val Loss: 31630325.8428, MAE: 4650.1011, NMAE: 70.8946, R^2: 0.1347\n",
      "Epoch [1636/2000]\n",
      "Train Loss: 31216319.3733\n",
      "Val Loss: 30948293.6250, MAE: 4696.0254, NMAE: 71.5948, R^2: 0.1534\n",
      "Epoch [1637/2000]\n",
      "Train Loss: 31964294.7198\n",
      "Val Loss: 30960825.9434, MAE: 4655.3203, NMAE: 70.9742, R^2: 0.1530\n",
      "Epoch [1638/2000]\n",
      "Train Loss: 31589289.5224\n",
      "Val Loss: 30821808.7440, MAE: 4697.5122, NMAE: 71.6174, R^2: 0.1568\n",
      "Epoch [1639/2000]\n",
      "Train Loss: 31623147.9586\n",
      "Val Loss: 30926274.6656, MAE: 4668.6362, NMAE: 71.1772, R^2: 0.1540\n",
      "Epoch [1640/2000]\n",
      "Train Loss: 32434604.5879\n",
      "Val Loss: 32299132.0492, MAE: 4818.0015, NMAE: 73.4544, R^2: 0.1164\n",
      "Epoch [1641/2000]\n",
      "Train Loss: 32518080.9009\n",
      "Val Loss: 32447189.6142, MAE: 4844.8813, NMAE: 73.8642, R^2: 0.1124\n",
      "Epoch [1642/2000]\n",
      "Train Loss: 32267739.9267\n",
      "Val Loss: 32220365.1781, MAE: 4813.0137, NMAE: 73.3783, R^2: 0.1186\n",
      "Epoch [1643/2000]\n",
      "Train Loss: 32003898.2517\n",
      "Val Loss: 32170287.9242, MAE: 4860.5015, NMAE: 74.1023, R^2: 0.1199\n",
      "Epoch [1644/2000]\n",
      "Train Loss: 31643076.4793\n",
      "Val Loss: 31395322.7057, MAE: 4799.7217, NMAE: 73.1757, R^2: 0.1411\n",
      "Epoch [1645/2000]\n",
      "Train Loss: 30652940.3448\n",
      "Val Loss: 31849720.0302, MAE: 4863.4600, NMAE: 74.1474, R^2: 0.1287\n",
      "Epoch [1646/2000]\n",
      "Train Loss: 32835001.6181\n",
      "Val Loss: 32086119.6619, MAE: 4669.5552, NMAE: 71.1912, R^2: 0.1222\n",
      "Epoch [1647/2000]\n",
      "Train Loss: 31395584.6578\n",
      "Val Loss: 31912511.7707, MAE: 4669.4331, NMAE: 71.1893, R^2: 0.1270\n",
      "Epoch [1648/2000]\n",
      "Train Loss: 31712096.6767\n",
      "Val Loss: 32074328.1572, MAE: 4847.4150, NMAE: 73.9028, R^2: 0.1226\n",
      "Epoch [1649/2000]\n",
      "Train Loss: 31692494.5164\n",
      "Val Loss: 31704254.2863, MAE: 4814.2456, NMAE: 73.3971, R^2: 0.1327\n",
      "Epoch [1650/2000]\n",
      "Train Loss: 31531191.9828\n",
      "Val Loss: 31350491.0434, MAE: 4766.1875, NMAE: 72.6644, R^2: 0.1424\n",
      "Epoch [1651/2000]\n",
      "Train Loss: 31075350.0578\n",
      "Val Loss: 31468599.4577, MAE: 4772.6133, NMAE: 72.7624, R^2: 0.1391\n",
      "Epoch [1652/2000]\n",
      "Train Loss: 31730426.5069\n",
      "Val Loss: 31543271.8767, MAE: 4718.7622, NMAE: 71.9414, R^2: 0.1371\n",
      "Epoch [1653/2000]\n",
      "Train Loss: 31415652.8310\n",
      "Val Loss: 31473606.6973, MAE: 4724.5410, NMAE: 72.0295, R^2: 0.1390\n",
      "Epoch [1654/2000]\n",
      "Train Loss: 31920212.1103\n",
      "Val Loss: 31799526.0706, MAE: 4651.9014, NMAE: 70.9221, R^2: 0.1301\n",
      "Epoch [1655/2000]\n",
      "Train Loss: 31508804.1948\n",
      "Val Loss: 31486099.2219, MAE: 4713.2842, NMAE: 71.8579, R^2: 0.1387\n",
      "Epoch [1656/2000]\n",
      "Train Loss: 31356876.8517\n",
      "Val Loss: 31568451.6997, MAE: 4763.7852, NMAE: 72.6278, R^2: 0.1364\n",
      "Epoch [1657/2000]\n",
      "Train Loss: 31995172.7267\n",
      "Val Loss: 31951672.7148, MAE: 4763.9443, NMAE: 72.6302, R^2: 0.1259\n",
      "Epoch [1658/2000]\n",
      "Train Loss: 31517758.8621\n",
      "Val Loss: 32165096.1170, MAE: 4771.9297, NMAE: 72.7520, R^2: 0.1201\n",
      "Epoch [1659/2000]\n",
      "Train Loss: 31942976.3767\n",
      "Val Loss: 32127182.4398, MAE: 4785.1406, NMAE: 72.9534, R^2: 0.1211\n",
      "Epoch [1660/2000]\n",
      "Train Loss: 31519271.0724\n",
      "Val Loss: 32618087.2936, MAE: 4906.9038, NMAE: 74.8098, R^2: 0.1077\n",
      "Epoch [1661/2000]\n",
      "Train Loss: 31950040.6009\n",
      "Val Loss: 31885743.4268, MAE: 4809.9932, NMAE: 73.3323, R^2: 0.1277\n",
      "Epoch [1662/2000]\n",
      "Train Loss: 30802018.4603\n",
      "Val Loss: 31609894.6831, MAE: 4728.8804, NMAE: 72.0957, R^2: 0.1353\n",
      "Epoch [1663/2000]\n",
      "Train Loss: 30718344.0767\n",
      "Val Loss: 31832396.4560, MAE: 4750.2725, NMAE: 72.4218, R^2: 0.1292\n",
      "Epoch [1664/2000]\n",
      "Train Loss: 30631103.7914\n",
      "Val Loss: 31415587.9745, MAE: 4757.3687, NMAE: 72.5300, R^2: 0.1406\n",
      "Epoch [1665/2000]\n",
      "Train Loss: 30681753.1905\n",
      "Val Loss: 31537615.1321, MAE: 4731.5918, NMAE: 72.1370, R^2: 0.1372\n",
      "Epoch [1666/2000]\n",
      "Train Loss: 30696722.2759\n",
      "Val Loss: 31222620.6380, MAE: 4723.3750, NMAE: 72.0117, R^2: 0.1459\n",
      "Epoch [1667/2000]\n",
      "Train Loss: 30886625.9819\n",
      "Val Loss: 31296949.0905, MAE: 4730.1255, NMAE: 72.1146, R^2: 0.1438\n",
      "Epoch [1668/2000]\n",
      "Train Loss: 31234591.4172\n",
      "Val Loss: 30997037.7027, MAE: 4705.3301, NMAE: 71.7366, R^2: 0.1520\n",
      "Epoch [1669/2000]\n",
      "Train Loss: 31004683.4940\n",
      "Val Loss: 30991897.2288, MAE: 4723.7485, NMAE: 72.0174, R^2: 0.1522\n",
      "Epoch [1670/2000]\n",
      "Train Loss: 30991375.2116\n",
      "Val Loss: 31118216.5082, MAE: 4783.6943, NMAE: 72.9313, R^2: 0.1487\n",
      "Epoch [1671/2000]\n",
      "Train Loss: 31212507.0164\n",
      "Val Loss: 31181169.0380, MAE: 4802.1162, NMAE: 73.2122, R^2: 0.1470\n",
      "Epoch [1672/2000]\n",
      "Train Loss: 31249827.1440\n",
      "Val Loss: 31286389.3808, MAE: 4807.5361, NMAE: 73.2948, R^2: 0.1441\n",
      "Epoch [1673/2000]\n",
      "Train Loss: 30694142.3224\n",
      "Val Loss: 31013723.9823, MAE: 4765.5073, NMAE: 72.6541, R^2: 0.1516\n",
      "Epoch [1674/2000]\n",
      "Train Loss: 30699167.0422\n",
      "Val Loss: 30720722.7927, MAE: 4705.5967, NMAE: 71.7407, R^2: 0.1596\n",
      "Epoch [1675/2000]\n",
      "Train Loss: 32196987.2172\n",
      "Val Loss: 31649885.3040, MAE: 4729.3882, NMAE: 72.1034, R^2: 0.1342\n",
      "Epoch [1676/2000]\n",
      "Train Loss: 31604492.0707\n",
      "Val Loss: 31466994.3009, MAE: 4744.0322, NMAE: 72.3267, R^2: 0.1392\n",
      "Epoch [1677/2000]\n",
      "Train Loss: 31211974.8138\n",
      "Val Loss: 31364577.6908, MAE: 4748.6919, NMAE: 72.3977, R^2: 0.1420\n",
      "Epoch [1678/2000]\n",
      "Train Loss: 31011023.5940\n",
      "Val Loss: 31256618.4784, MAE: 4691.3188, NMAE: 71.5230, R^2: 0.1449\n",
      "Epoch [1679/2000]\n",
      "Train Loss: 30714787.8060\n",
      "Val Loss: 31115200.0803, MAE: 4712.6147, NMAE: 71.8477, R^2: 0.1488\n",
      "Epoch [1680/2000]\n",
      "Train Loss: 30538135.6060\n",
      "Val Loss: 31233415.4689, MAE: 4740.2695, NMAE: 72.2693, R^2: 0.1456\n",
      "Epoch [1681/2000]\n",
      "Train Loss: 30673989.7888\n",
      "Val Loss: 31285790.5864, MAE: 4707.4521, NMAE: 71.7690, R^2: 0.1441\n",
      "Epoch [1682/2000]\n",
      "Train Loss: 30576212.0379\n",
      "Val Loss: 31593221.9538, MAE: 4737.1558, NMAE: 72.2218, R^2: 0.1357\n",
      "Epoch [1683/2000]\n",
      "Train Loss: 30478979.7241\n",
      "Val Loss: 31541835.7422, MAE: 4743.4038, NMAE: 72.3171, R^2: 0.1371\n",
      "Epoch [1684/2000]\n",
      "Train Loss: 30419525.1862\n",
      "Val Loss: 31547148.2297, MAE: 4785.8379, NMAE: 72.9640, R^2: 0.1370\n",
      "Epoch [1685/2000]\n",
      "Train Loss: 30273638.6569\n",
      "Val Loss: 31262831.5145, MAE: 4762.3901, NMAE: 72.6065, R^2: 0.1448\n",
      "Epoch [1686/2000]\n",
      "Train Loss: 30625010.9991\n",
      "Val Loss: 32820769.0514, MAE: 4944.3965, NMAE: 75.3814, R^2: 0.1021\n",
      "Epoch [1687/2000]\n",
      "Train Loss: 31254303.9052\n",
      "Val Loss: 32650508.3761, MAE: 4911.6006, NMAE: 74.8814, R^2: 0.1068\n",
      "Epoch [1688/2000]\n",
      "Train Loss: 30820362.6474\n",
      "Val Loss: 32142787.3053, MAE: 4869.2363, NMAE: 74.2355, R^2: 0.1207\n",
      "Epoch [1689/2000]\n",
      "Train Loss: 30688346.1052\n",
      "Val Loss: 31887626.6753, MAE: 4843.7646, NMAE: 73.8472, R^2: 0.1277\n",
      "Epoch [1690/2000]\n",
      "Train Loss: 30766565.5414\n",
      "Val Loss: 31720933.6598, MAE: 4833.6724, NMAE: 73.6933, R^2: 0.1322\n",
      "Epoch [1691/2000]\n",
      "Train Loss: 30640584.8129\n",
      "Val Loss: 32054090.7396, MAE: 4781.0352, NMAE: 72.8908, R^2: 0.1231\n",
      "Epoch [1692/2000]\n",
      "Train Loss: 31181495.2319\n",
      "Val Loss: 32524117.6183, MAE: 4731.0591, NMAE: 72.1289, R^2: 0.1103\n",
      "Epoch [1693/2000]\n",
      "Train Loss: 31325553.0927\n",
      "Val Loss: 31432395.4072, MAE: 4696.2593, NMAE: 71.5983, R^2: 0.1401\n",
      "Epoch [1694/2000]\n",
      "Train Loss: 30971113.2560\n",
      "Val Loss: 31384897.0997, MAE: 4739.9736, NMAE: 72.2648, R^2: 0.1414\n",
      "Epoch [1695/2000]\n",
      "Train Loss: 31062093.2534\n",
      "Val Loss: 31226870.4378, MAE: 4725.9780, NMAE: 72.0514, R^2: 0.1457\n",
      "Epoch [1696/2000]\n",
      "Train Loss: 31411513.6276\n",
      "Val Loss: 31673980.8519, MAE: 4687.6309, NMAE: 71.4668, R^2: 0.1335\n",
      "Epoch [1697/2000]\n",
      "Train Loss: 31478693.0121\n",
      "Val Loss: 31949642.9439, MAE: 4723.5869, NMAE: 72.0150, R^2: 0.1260\n",
      "Epoch [1698/2000]\n",
      "Train Loss: 31044288.2828\n",
      "Val Loss: 31250997.8161, MAE: 4674.7134, NMAE: 71.2698, R^2: 0.1451\n",
      "Epoch [1699/2000]\n",
      "Train Loss: 30687755.3815\n",
      "Val Loss: 30734061.8562, MAE: 4655.7910, NMAE: 70.9814, R^2: 0.1592\n",
      "Epoch [1700/2000]\n",
      "Train Loss: 30325845.2897\n",
      "Val Loss: 31233034.0302, MAE: 4785.6079, NMAE: 72.9605, R^2: 0.1456\n",
      "Epoch [1701/2000]\n",
      "Train Loss: 31104950.3155\n",
      "Val Loss: 31489926.6019, MAE: 4697.9014, NMAE: 71.6234, R^2: 0.1385\n",
      "Epoch [1702/2000]\n",
      "Train Loss: 33123043.0724\n",
      "Val Loss: 32346423.6904, MAE: 4627.4521, NMAE: 70.5493, R^2: 0.1151\n",
      "Epoch [1703/2000]\n",
      "Train Loss: 31990036.1060\n",
      "Val Loss: 31593350.4970, MAE: 4652.6792, NMAE: 70.9339, R^2: 0.1357\n",
      "Epoch [1704/2000]\n",
      "Train Loss: 31376239.6672\n",
      "Val Loss: 30803426.3325, MAE: 4661.1499, NMAE: 71.0631, R^2: 0.1573\n",
      "Epoch [1705/2000]\n",
      "Train Loss: 31045750.6698\n",
      "Val Loss: 30546052.7202, MAE: 4710.7466, NMAE: 71.8192, R^2: 0.1644\n",
      "Epoch [1706/2000]\n",
      "Train Loss: 31021644.5552\n",
      "Val Loss: 30634682.1239, MAE: 4732.2046, NMAE: 72.1463, R^2: 0.1619\n",
      "Epoch [1707/2000]\n",
      "Train Loss: 31323720.1086\n",
      "Val Loss: 30885492.4931, MAE: 4657.3394, NMAE: 71.0050, R^2: 0.1551\n",
      "Epoch [1708/2000]\n",
      "Train Loss: 31062751.8552\n",
      "Val Loss: 30208275.7297, MAE: 4606.9092, NMAE: 70.2361, R^2: 0.1736\n",
      "Epoch [1709/2000]\n",
      "Train Loss: 30978987.8112\n",
      "Val Loss: 30285877.5199, MAE: 4618.0923, NMAE: 70.4066, R^2: 0.1715\n",
      "Epoch [1710/2000]\n",
      "Train Loss: 30679100.6733\n",
      "Val Loss: 30318356.0600, MAE: 4662.0649, NMAE: 71.0770, R^2: 0.1706\n",
      "Epoch [1711/2000]\n",
      "Train Loss: 32332310.9017\n",
      "Val Loss: 32248391.9732, MAE: 4666.1582, NMAE: 71.1394, R^2: 0.1178\n",
      "Epoch [1712/2000]\n",
      "Train Loss: 32166022.2207\n",
      "Val Loss: 31783822.9832, MAE: 4702.2583, NMAE: 71.6898, R^2: 0.1305\n",
      "Epoch [1713/2000]\n",
      "Train Loss: 32012925.2207\n",
      "Val Loss: 31211487.3320, MAE: 4703.9517, NMAE: 71.7156, R^2: 0.1462\n",
      "Epoch [1714/2000]\n",
      "Train Loss: 31353595.0888\n",
      "Val Loss: 30948722.1660, MAE: 4712.5913, NMAE: 71.8473, R^2: 0.1534\n",
      "Epoch [1715/2000]\n",
      "Train Loss: 31368065.3603\n",
      "Val Loss: 31429061.3795, MAE: 4709.2461, NMAE: 71.7963, R^2: 0.1402\n",
      "Epoch [1716/2000]\n",
      "Train Loss: 31435284.7078\n",
      "Val Loss: 31126508.4983, MAE: 4697.4087, NMAE: 71.6158, R^2: 0.1485\n",
      "Epoch [1717/2000]\n",
      "Train Loss: 31102215.9060\n",
      "Val Loss: 30860066.7109, MAE: 4686.6538, NMAE: 71.4519, R^2: 0.1558\n",
      "Epoch [1718/2000]\n",
      "Train Loss: 30756865.0431\n",
      "Val Loss: 30889399.2753, MAE: 4705.0332, NMAE: 71.7321, R^2: 0.1550\n",
      "Epoch [1719/2000]\n",
      "Train Loss: 31325550.6405\n",
      "Val Loss: 30226055.4687, MAE: 4630.2847, NMAE: 70.5925, R^2: 0.1731\n",
      "Epoch [1720/2000]\n",
      "Train Loss: 31119122.6241\n",
      "Val Loss: 30833024.0820, MAE: 4654.7388, NMAE: 70.9653, R^2: 0.1565\n",
      "Epoch [1721/2000]\n",
      "Train Loss: 31900621.9500\n",
      "Val Loss: 31106354.5328, MAE: 4766.8828, NMAE: 72.6750, R^2: 0.1490\n",
      "Epoch [1722/2000]\n",
      "Train Loss: 31070503.4164\n",
      "Val Loss: 30559725.5466, MAE: 4668.0835, NMAE: 71.1688, R^2: 0.1640\n",
      "Epoch [1723/2000]\n",
      "Train Loss: 31603709.7845\n",
      "Val Loss: 31231206.7573, MAE: 4603.2090, NMAE: 70.1797, R^2: 0.1456\n",
      "Epoch [1724/2000]\n",
      "Train Loss: 32655327.9086\n",
      "Val Loss: 30937411.8931, MAE: 4692.2056, NMAE: 71.5365, R^2: 0.1537\n",
      "Epoch [1725/2000]\n",
      "Train Loss: 31505348.4371\n",
      "Val Loss: 33188297.6662, MAE: 4971.3521, NMAE: 75.7923, R^2: 0.0921\n",
      "Epoch [1726/2000]\n",
      "Train Loss: 33256536.0224\n",
      "Val Loss: 32160961.8966, MAE: 4571.9692, NMAE: 69.7034, R^2: 0.1202\n",
      "Epoch [1727/2000]\n",
      "Train Loss: 33192560.7914\n",
      "Val Loss: 31679586.5134, MAE: 4569.4058, NMAE: 69.6643, R^2: 0.1334\n",
      "Epoch [1728/2000]\n",
      "Train Loss: 33023666.8560\n",
      "Val Loss: 31651087.3472, MAE: 4569.7227, NMAE: 69.6692, R^2: 0.1341\n",
      "Epoch [1729/2000]\n",
      "Train Loss: 32795862.3966\n",
      "Val Loss: 31874729.7938, MAE: 4573.6689, NMAE: 69.7293, R^2: 0.1280\n",
      "Epoch [1730/2000]\n",
      "Train Loss: 32183357.1569\n",
      "Val Loss: 31026295.8029, MAE: 4601.1270, NMAE: 70.1480, R^2: 0.1512\n",
      "Epoch [1731/2000]\n",
      "Train Loss: 31215001.1603\n",
      "Val Loss: 30807219.1559, MAE: 4621.1875, NMAE: 70.4538, R^2: 0.1572\n",
      "Epoch [1732/2000]\n",
      "Train Loss: 30869611.3940\n",
      "Val Loss: 30785341.2016, MAE: 4645.8159, NMAE: 70.8293, R^2: 0.1578\n",
      "Epoch [1733/2000]\n",
      "Train Loss: 30943258.3241\n",
      "Val Loss: 31170949.1522, MAE: 4706.2148, NMAE: 71.7501, R^2: 0.1473\n",
      "Epoch [1734/2000]\n",
      "Train Loss: 30905627.7483\n",
      "Val Loss: 30973632.6328, MAE: 4677.7861, NMAE: 71.3167, R^2: 0.1527\n",
      "Epoch [1735/2000]\n",
      "Train Loss: 30893374.1733\n",
      "Val Loss: 31051624.2483, MAE: 4688.4072, NMAE: 71.4786, R^2: 0.1505\n",
      "Epoch [1736/2000]\n",
      "Train Loss: 30846236.9431\n",
      "Val Loss: 31063579.7129, MAE: 4724.0615, NMAE: 72.0222, R^2: 0.1502\n",
      "Epoch [1737/2000]\n",
      "Train Loss: 31170134.8379\n",
      "Val Loss: 31290174.4888, MAE: 4779.0176, NMAE: 72.8600, R^2: 0.1440\n",
      "Epoch [1738/2000]\n",
      "Train Loss: 31139185.3897\n",
      "Val Loss: 30996782.6164, MAE: 4733.9541, NMAE: 72.1730, R^2: 0.1520\n",
      "Epoch [1739/2000]\n",
      "Train Loss: 30891884.7250\n",
      "Val Loss: 31027558.5173, MAE: 4755.0591, NMAE: 72.4948, R^2: 0.1512\n",
      "Epoch [1740/2000]\n",
      "Train Loss: 31224025.2983\n",
      "Val Loss: 30666180.4616, MAE: 4641.6294, NMAE: 70.7654, R^2: 0.1611\n",
      "Epoch [1741/2000]\n",
      "Train Loss: 30713102.0103\n",
      "Val Loss: 30986368.8657, MAE: 4686.4194, NMAE: 71.4483, R^2: 0.1523\n",
      "Epoch [1742/2000]\n",
      "Train Loss: 30983451.1716\n",
      "Val Loss: 31284322.0691, MAE: 4759.4048, NMAE: 72.5610, R^2: 0.1442\n",
      "Epoch [1743/2000]\n",
      "Train Loss: 30835216.0552\n",
      "Val Loss: 30811600.2854, MAE: 4641.1250, NMAE: 70.7578, R^2: 0.1571\n",
      "Epoch [1744/2000]\n",
      "Train Loss: 34050360.5371\n",
      "Val Loss: 32155766.8009, MAE: 4638.3931, NMAE: 70.7161, R^2: 0.1203\n",
      "Epoch [1745/2000]\n",
      "Train Loss: 31892203.1362\n",
      "Val Loss: 31009642.7500, MAE: 4692.4395, NMAE: 71.5401, R^2: 0.1517\n",
      "Epoch [1746/2000]\n",
      "Train Loss: 31944019.6457\n",
      "Val Loss: 31207858.5760, MAE: 4683.1030, NMAE: 71.3977, R^2: 0.1463\n",
      "Epoch [1747/2000]\n",
      "Train Loss: 31239735.1319\n",
      "Val Loss: 30629499.9208, MAE: 4677.1069, NMAE: 71.3063, R^2: 0.1621\n",
      "Epoch [1748/2000]\n",
      "Train Loss: 30839188.2086\n",
      "Val Loss: 30795161.4853, MAE: 4715.4321, NMAE: 71.8906, R^2: 0.1576\n",
      "Epoch [1749/2000]\n",
      "Train Loss: 31011235.5009\n",
      "Val Loss: 30946831.2077, MAE: 4637.1899, NMAE: 70.6978, R^2: 0.1534\n",
      "Epoch [1750/2000]\n",
      "Train Loss: 30819305.7026\n",
      "Val Loss: 31224978.0330, MAE: 4787.9165, NMAE: 72.9957, R^2: 0.1458\n",
      "Epoch [1751/2000]\n",
      "Train Loss: 31252763.1103\n",
      "Val Loss: 30560632.4240, MAE: 4674.4341, NMAE: 71.2656, R^2: 0.1640\n",
      "Epoch [1752/2000]\n",
      "Train Loss: 30899694.8655\n",
      "Val Loss: 31155856.3612, MAE: 4783.5571, NMAE: 72.9293, R^2: 0.1477\n",
      "Epoch [1753/2000]\n",
      "Train Loss: 31569808.6603\n",
      "Val Loss: 30671968.8171, MAE: 4686.4229, NMAE: 71.4484, R^2: 0.1609\n",
      "Epoch [1754/2000]\n",
      "Train Loss: 31121807.8414\n",
      "Val Loss: 30808805.7837, MAE: 4662.1660, NMAE: 71.0785, R^2: 0.1572\n",
      "Epoch [1755/2000]\n",
      "Train Loss: 30982977.6845\n",
      "Val Loss: 30864181.9801, MAE: 4719.7378, NMAE: 71.9563, R^2: 0.1557\n",
      "Epoch [1756/2000]\n",
      "Train Loss: 30840906.3319\n",
      "Val Loss: 31463054.1759, MAE: 4799.4595, NMAE: 73.1717, R^2: 0.1393\n",
      "Epoch [1757/2000]\n",
      "Train Loss: 30881795.4397\n",
      "Val Loss: 33322032.5948, MAE: 4982.3677, NMAE: 75.9603, R^2: 0.0884\n",
      "Epoch [1758/2000]\n",
      "Train Loss: 32885318.9233\n",
      "Val Loss: 30954327.5255, MAE: 4618.0786, NMAE: 70.4064, R^2: 0.1532\n",
      "Epoch [1759/2000]\n",
      "Train Loss: 31145646.4198\n",
      "Val Loss: 31200918.4277, MAE: 4750.5283, NMAE: 72.4257, R^2: 0.1465\n",
      "Epoch [1760/2000]\n",
      "Train Loss: 31327492.5552\n",
      "Val Loss: 31448601.3238, MAE: 4704.9150, NMAE: 71.7303, R^2: 0.1397\n",
      "Epoch [1761/2000]\n",
      "Train Loss: 31777097.9103\n",
      "Val Loss: 31044067.1999, MAE: 4716.0444, NMAE: 71.9000, R^2: 0.1507\n",
      "Epoch [1762/2000]\n",
      "Train Loss: 31230706.8690\n",
      "Val Loss: 31087617.6362, MAE: 4695.3735, NMAE: 71.5848, R^2: 0.1496\n",
      "Epoch [1763/2000]\n",
      "Train Loss: 31587888.3466\n",
      "Val Loss: 30547261.6455, MAE: 4662.6665, NMAE: 71.0862, R^2: 0.1643\n",
      "Epoch [1764/2000]\n",
      "Train Loss: 31170761.4422\n",
      "Val Loss: 30508587.4298, MAE: 4676.0068, NMAE: 71.2896, R^2: 0.1654\n",
      "Epoch [1765/2000]\n",
      "Train Loss: 31089096.5267\n",
      "Val Loss: 32037042.2599, MAE: 4896.5518, NMAE: 74.6519, R^2: 0.1236\n",
      "Epoch [1766/2000]\n",
      "Train Loss: 32920308.9526\n",
      "Val Loss: 31702351.8890, MAE: 4728.7563, NMAE: 72.0938, R^2: 0.1327\n",
      "Epoch [1767/2000]\n",
      "Train Loss: 31241805.4586\n",
      "Val Loss: 31146631.6997, MAE: 4792.3896, NMAE: 73.0639, R^2: 0.1479\n",
      "Epoch [1768/2000]\n",
      "Train Loss: 32081578.5603\n",
      "Val Loss: 30960729.3245, MAE: 4765.4849, NMAE: 72.6537, R^2: 0.1530\n",
      "Epoch [1769/2000]\n",
      "Train Loss: 31630421.8284\n",
      "Val Loss: 30838109.7200, MAE: 4709.9946, NMAE: 71.8077, R^2: 0.1564\n",
      "Epoch [1770/2000]\n",
      "Train Loss: 31373496.0750\n",
      "Val Loss: 30634628.6492, MAE: 4720.6860, NMAE: 71.9707, R^2: 0.1619\n",
      "Epoch [1771/2000]\n",
      "Train Loss: 31367754.8474\n",
      "Val Loss: 31016913.7070, MAE: 4786.6240, NMAE: 72.9760, R^2: 0.1515\n",
      "Epoch [1772/2000]\n",
      "Train Loss: 32875935.3293\n",
      "Val Loss: 31118015.7742, MAE: 4775.6108, NMAE: 72.8081, R^2: 0.1487\n",
      "Epoch [1773/2000]\n",
      "Train Loss: 31477995.3647\n",
      "Val Loss: 30796537.7854, MAE: 4715.4048, NMAE: 71.8902, R^2: 0.1575\n",
      "Epoch [1774/2000]\n",
      "Train Loss: 30946230.6198\n",
      "Val Loss: 31472477.8009, MAE: 4838.1055, NMAE: 73.7609, R^2: 0.1390\n",
      "Epoch [1775/2000]\n",
      "Train Loss: 32624563.0310\n",
      "Val Loss: 31588160.7725, MAE: 4597.5596, NMAE: 70.0936, R^2: 0.1359\n",
      "Epoch [1776/2000]\n",
      "Train Loss: 31214576.5069\n",
      "Val Loss: 35506316.0354, MAE: 5187.2524, NMAE: 79.0839, R^2: 0.0287\n",
      "Epoch [1777/2000]\n",
      "Train Loss: 34857585.0784\n",
      "Val Loss: 32808673.7526, MAE: 4823.4766, NMAE: 73.5379, R^2: 0.1025\n",
      "Epoch [1778/2000]\n",
      "Train Loss: 32542503.5190\n",
      "Val Loss: 32789521.8165, MAE: 4833.5439, NMAE: 73.6913, R^2: 0.1030\n",
      "Epoch [1779/2000]\n",
      "Train Loss: 32770886.3828\n",
      "Val Loss: 33456220.1792, MAE: 4889.5161, NMAE: 74.5447, R^2: 0.0848\n",
      "Epoch [1780/2000]\n",
      "Train Loss: 33017405.2190\n",
      "Val Loss: 32810512.7725, MAE: 4813.1938, NMAE: 73.3811, R^2: 0.1024\n",
      "Epoch [1781/2000]\n",
      "Train Loss: 32204244.8776\n",
      "Val Loss: 31761910.0000, MAE: 4808.8057, NMAE: 73.3142, R^2: 0.1311\n",
      "Epoch [1782/2000]\n",
      "Train Loss: 31648435.1716\n",
      "Val Loss: 31018044.8221, MAE: 4748.2188, NMAE: 72.3905, R^2: 0.1515\n",
      "Epoch [1783/2000]\n",
      "Train Loss: 32084802.3259\n",
      "Val Loss: 31240220.6755, MAE: 4661.8921, NMAE: 71.0744, R^2: 0.1454\n",
      "Epoch [1784/2000]\n",
      "Train Loss: 31656654.1853\n",
      "Val Loss: 32986789.1015, MAE: 4948.9399, NMAE: 75.4506, R^2: 0.0976\n",
      "Epoch [1785/2000]\n",
      "Train Loss: 32397152.2526\n",
      "Val Loss: 34689584.9624, MAE: 5135.2656, NMAE: 78.2913, R^2: 0.0510\n",
      "Epoch [1786/2000]\n",
      "Train Loss: 33720579.1664\n",
      "Val Loss: 31013287.7679, MAE: 4742.2388, NMAE: 72.2993, R^2: 0.1516\n",
      "Epoch [1787/2000]\n",
      "Train Loss: 31460579.0078\n",
      "Val Loss: 30922234.0436, MAE: 4715.4829, NMAE: 71.8914, R^2: 0.1541\n",
      "Epoch [1788/2000]\n",
      "Train Loss: 31414405.5414\n",
      "Val Loss: 31079889.9486, MAE: 4759.6099, NMAE: 72.5642, R^2: 0.1498\n",
      "Epoch [1789/2000]\n",
      "Train Loss: 31570016.7716\n",
      "Val Loss: 30765981.6006, MAE: 4684.5962, NMAE: 71.4205, R^2: 0.1584\n",
      "Epoch [1790/2000]\n",
      "Train Loss: 31072036.7198\n",
      "Val Loss: 35567484.9417, MAE: 5237.4268, NMAE: 79.8489, R^2: 0.0270\n",
      "Epoch [1791/2000]\n",
      "Train Loss: 34985179.2810\n",
      "Val Loss: 34423597.0894, MAE: 5138.3066, NMAE: 78.3377, R^2: 0.0583\n",
      "Epoch [1792/2000]\n",
      "Train Loss: 33871774.2672\n",
      "Val Loss: 32414090.3208, MAE: 4935.0195, NMAE: 75.2384, R^2: 0.1133\n",
      "Epoch [1793/2000]\n",
      "Train Loss: 32327663.3595\n",
      "Val Loss: 31504015.4590, MAE: 4824.1899, NMAE: 73.5487, R^2: 0.1382\n",
      "Epoch [1794/2000]\n",
      "Train Loss: 31664908.7810\n",
      "Val Loss: 30710549.8335, MAE: 4697.1592, NMAE: 71.6120, R^2: 0.1599\n",
      "Epoch [1795/2000]\n",
      "Train Loss: 31653059.7586\n",
      "Val Loss: 30447744.5559, MAE: 4641.6040, NMAE: 70.7651, R^2: 0.1671\n",
      "Epoch [1796/2000]\n",
      "Train Loss: 31202761.9431\n",
      "Val Loss: 31128686.3014, MAE: 4769.6372, NMAE: 72.7170, R^2: 0.1484\n",
      "Epoch [1797/2000]\n",
      "Train Loss: 31775152.0552\n",
      "Val Loss: 31218561.0635, MAE: 4778.6890, NMAE: 72.8550, R^2: 0.1460\n",
      "Epoch [1798/2000]\n",
      "Train Loss: 31862419.9198\n",
      "Val Loss: 30583351.7675, MAE: 4658.8594, NMAE: 71.0281, R^2: 0.1633\n",
      "Epoch [1799/2000]\n",
      "Train Loss: 31128121.5043\n",
      "Val Loss: 30870754.9847, MAE: 4735.1138, NMAE: 72.1907, R^2: 0.1555\n",
      "Epoch [1800/2000]\n",
      "Train Loss: 32030084.8250\n",
      "Val Loss: 33613247.8178, MAE: 5030.7573, NMAE: 76.6980, R^2: 0.0805\n",
      "Epoch [1801/2000]\n",
      "Train Loss: 33566654.8431\n",
      "Val Loss: 32341064.6665, MAE: 4663.7397, NMAE: 71.1025, R^2: 0.1153\n",
      "Epoch [1802/2000]\n",
      "Train Loss: 32482361.7500\n",
      "Val Loss: 31542694.9827, MAE: 4701.0420, NMAE: 71.6712, R^2: 0.1371\n",
      "Epoch [1803/2000]\n",
      "Train Loss: 32137456.9586\n",
      "Val Loss: 31177224.0000, MAE: 4651.5024, NMAE: 70.9160, R^2: 0.1471\n",
      "Epoch [1804/2000]\n",
      "Train Loss: 31777038.9069\n",
      "Val Loss: 30778856.5799, MAE: 4671.2666, NMAE: 71.2173, R^2: 0.1580\n",
      "Epoch [1805/2000]\n",
      "Train Loss: 31406095.4448\n",
      "Val Loss: 32400681.3653, MAE: 4896.8735, NMAE: 74.6569, R^2: 0.1136\n",
      "Epoch [1806/2000]\n",
      "Train Loss: 32133947.8319\n",
      "Val Loss: 30616242.3705, MAE: 4652.7988, NMAE: 70.9357, R^2: 0.1624\n",
      "Epoch [1807/2000]\n",
      "Train Loss: 33677580.2241\n",
      "Val Loss: 32281030.7120, MAE: 4880.6978, NMAE: 74.4102, R^2: 0.1169\n",
      "Epoch [1808/2000]\n",
      "Train Loss: 33333673.3948\n",
      "Val Loss: 32323761.5881, MAE: 4911.1865, NMAE: 74.8751, R^2: 0.1157\n",
      "Epoch [1809/2000]\n",
      "Train Loss: 32581614.4362\n",
      "Val Loss: 31506163.4652, MAE: 4778.8765, NMAE: 72.8579, R^2: 0.1381\n",
      "Epoch [1810/2000]\n",
      "Train Loss: 31567448.4716\n",
      "Val Loss: 33106793.7021, MAE: 4968.0352, NMAE: 75.7418, R^2: 0.0943\n",
      "Epoch [1811/2000]\n",
      "Train Loss: 33612337.7681\n",
      "Val Loss: 31884187.0332, MAE: 4673.3643, NMAE: 71.2493, R^2: 0.1278\n",
      "Epoch [1812/2000]\n",
      "Train Loss: 32409504.6741\n",
      "Val Loss: 31026108.7034, MAE: 4690.7334, NMAE: 71.5141, R^2: 0.1512\n",
      "Epoch [1813/2000]\n",
      "Train Loss: 31324918.0034\n",
      "Val Loss: 30884372.6967, MAE: 4735.2295, NMAE: 72.1925, R^2: 0.1551\n",
      "Epoch [1814/2000]\n",
      "Train Loss: 31228809.4207\n",
      "Val Loss: 30982116.0518, MAE: 4759.6362, NMAE: 72.5646, R^2: 0.1524\n",
      "Epoch [1815/2000]\n",
      "Train Loss: 31444974.7991\n",
      "Val Loss: 30919353.3195, MAE: 4746.1128, NMAE: 72.3584, R^2: 0.1542\n",
      "Epoch [1816/2000]\n",
      "Train Loss: 33996938.2974\n",
      "Val Loss: 33147573.8687, MAE: 4710.2183, NMAE: 71.8111, R^2: 0.0932\n",
      "Epoch [1817/2000]\n",
      "Train Loss: 33624317.0836\n",
      "Val Loss: 31440109.4827, MAE: 4706.2085, NMAE: 71.7500, R^2: 0.1399\n",
      "Epoch [1818/2000]\n",
      "Train Loss: 31807848.2017\n",
      "Val Loss: 30783753.0039, MAE: 4730.2832, NMAE: 72.1170, R^2: 0.1579\n",
      "Epoch [1819/2000]\n",
      "Train Loss: 33425143.0940\n",
      "Val Loss: 32756600.5561, MAE: 4725.2803, NMAE: 72.0408, R^2: 0.1039\n",
      "Epoch [1820/2000]\n",
      "Train Loss: 32055026.3440\n",
      "Val Loss: 30906037.8057, MAE: 4784.6270, NMAE: 72.9456, R^2: 0.1545\n",
      "Epoch [1821/2000]\n",
      "Train Loss: 31260293.3655\n",
      "Val Loss: 30365665.0285, MAE: 4666.0781, NMAE: 71.1382, R^2: 0.1693\n",
      "Epoch [1822/2000]\n",
      "Train Loss: 32312101.2681\n",
      "Val Loss: 31127878.0466, MAE: 4621.4082, NMAE: 70.4572, R^2: 0.1485\n",
      "Epoch [1823/2000]\n",
      "Train Loss: 34262536.2603\n",
      "Val Loss: 34215079.5790, MAE: 4722.5483, NMAE: 71.9991, R^2: 0.0640\n",
      "Epoch [1824/2000]\n",
      "Train Loss: 34158948.4853\n",
      "Val Loss: 31422645.9633, MAE: 4660.0420, NMAE: 71.0462, R^2: 0.1404\n",
      "Epoch [1825/2000]\n",
      "Train Loss: 31883527.5302\n",
      "Val Loss: 30718453.4076, MAE: 4669.6226, NMAE: 71.1922, R^2: 0.1597\n",
      "Epoch [1826/2000]\n",
      "Train Loss: 31746593.7164\n",
      "Val Loss: 30640975.8744, MAE: 4668.3496, NMAE: 71.1728, R^2: 0.1618\n",
      "Epoch [1827/2000]\n",
      "Train Loss: 31369921.5431\n",
      "Val Loss: 30473601.8964, MAE: 4705.4863, NMAE: 71.7390, R^2: 0.1663\n",
      "Epoch [1828/2000]\n",
      "Train Loss: 31610380.4733\n",
      "Val Loss: 30472108.5184, MAE: 4666.6646, NMAE: 71.1471, R^2: 0.1664\n",
      "Epoch [1829/2000]\n",
      "Train Loss: 31193088.0017\n",
      "Val Loss: 30247313.8785, MAE: 4671.0469, NMAE: 71.2139, R^2: 0.1725\n",
      "Epoch [1830/2000]\n",
      "Train Loss: 31167379.5310\n",
      "Val Loss: 30233683.7433, MAE: 4653.9937, NMAE: 70.9540, R^2: 0.1729\n",
      "Epoch [1831/2000]\n",
      "Train Loss: 31480769.5388\n",
      "Val Loss: 30525997.3994, MAE: 4665.5293, NMAE: 71.1298, R^2: 0.1649\n",
      "Epoch [1832/2000]\n",
      "Train Loss: 31807361.6716\n",
      "Val Loss: 30321531.3245, MAE: 4675.9082, NMAE: 71.2881, R^2: 0.1705\n",
      "Epoch [1833/2000]\n",
      "Train Loss: 31730149.8474\n",
      "Val Loss: 31101353.2254, MAE: 4603.9424, NMAE: 70.1909, R^2: 0.1492\n",
      "Epoch [1834/2000]\n",
      "Train Loss: 31754285.2724\n",
      "Val Loss: 30250757.4674, MAE: 4613.9258, NMAE: 70.3431, R^2: 0.1724\n",
      "Epoch [1835/2000]\n",
      "Train Loss: 31648228.7233\n",
      "Val Loss: 30105412.3286, MAE: 4656.9531, NMAE: 70.9991, R^2: 0.1764\n",
      "Epoch [1836/2000]\n",
      "Train Loss: 30761818.2121\n",
      "Val Loss: 35204043.8204, MAE: 5165.9883, NMAE: 78.7597, R^2: 0.0369\n",
      "Epoch [1837/2000]\n",
      "Train Loss: 32975773.8526\n",
      "Val Loss: 31253316.3892, MAE: 4796.4756, NMAE: 73.1262, R^2: 0.1450\n",
      "Epoch [1838/2000]\n",
      "Train Loss: 32188193.3190\n",
      "Val Loss: 31167313.1667, MAE: 4784.0146, NMAE: 72.9362, R^2: 0.1474\n",
      "Epoch [1839/2000]\n",
      "Train Loss: 31815055.6802\n",
      "Val Loss: 30666924.9383, MAE: 4720.4292, NMAE: 71.9668, R^2: 0.1611\n",
      "Epoch [1840/2000]\n",
      "Train Loss: 31961232.7741\n",
      "Val Loss: 30561756.3344, MAE: 4710.9858, NMAE: 71.8228, R^2: 0.1639\n",
      "Epoch [1841/2000]\n",
      "Train Loss: 32392546.8983\n",
      "Val Loss: 30467485.1252, MAE: 4642.6060, NMAE: 70.7803, R^2: 0.1665\n",
      "Epoch [1842/2000]\n",
      "Train Loss: 31771105.6129\n",
      "Val Loss: 30487316.6464, MAE: 4702.6694, NMAE: 71.6961, R^2: 0.1660\n",
      "Epoch [1843/2000]\n",
      "Train Loss: 32547668.3336\n",
      "Val Loss: 31333511.7932, MAE: 4840.2095, NMAE: 73.7930, R^2: 0.1428\n",
      "Epoch [1844/2000]\n",
      "Train Loss: 32915028.3448\n",
      "Val Loss: 31239837.8707, MAE: 4704.0288, NMAE: 71.7168, R^2: 0.1454\n",
      "Epoch [1845/2000]\n",
      "Train Loss: 32678204.3845\n",
      "Val Loss: 32165604.8174, MAE: 4909.6841, NMAE: 74.8522, R^2: 0.1201\n",
      "Epoch [1846/2000]\n",
      "Train Loss: 32531174.5155\n",
      "Val Loss: 31962478.1110, MAE: 4892.3384, NMAE: 74.5877, R^2: 0.1256\n",
      "Epoch [1847/2000]\n",
      "Train Loss: 32433210.7284\n",
      "Val Loss: 31629637.2312, MAE: 4841.5537, NMAE: 73.8135, R^2: 0.1347\n",
      "Epoch [1848/2000]\n",
      "Train Loss: 32018775.7690\n",
      "Val Loss: 30775073.4821, MAE: 4727.9971, NMAE: 72.0822, R^2: 0.1581\n",
      "Epoch [1849/2000]\n",
      "Train Loss: 31611085.2043\n",
      "Val Loss: 30685042.7265, MAE: 4685.0977, NMAE: 71.4282, R^2: 0.1606\n",
      "Epoch [1850/2000]\n",
      "Train Loss: 31193599.8672\n",
      "Val Loss: 30663450.5859, MAE: 4721.7612, NMAE: 71.9871, R^2: 0.1612\n",
      "Epoch [1851/2000]\n",
      "Train Loss: 31148918.6612\n",
      "Val Loss: 30681074.8724, MAE: 4734.6328, NMAE: 72.1834, R^2: 0.1607\n",
      "Epoch [1852/2000]\n",
      "Train Loss: 31381048.3586\n",
      "Val Loss: 30936527.7200, MAE: 4761.0532, NMAE: 72.5862, R^2: 0.1537\n",
      "Epoch [1853/2000]\n",
      "Train Loss: 31324568.5802\n",
      "Val Loss: 30947192.6965, MAE: 4772.4224, NMAE: 72.7595, R^2: 0.1534\n",
      "Epoch [1854/2000]\n",
      "Train Loss: 31791641.9078\n",
      "Val Loss: 30725449.4838, MAE: 4729.9766, NMAE: 72.1124, R^2: 0.1595\n",
      "Epoch [1855/2000]\n",
      "Train Loss: 31902045.7336\n",
      "Val Loss: 30733082.8361, MAE: 4710.2402, NMAE: 71.8115, R^2: 0.1593\n",
      "Epoch [1856/2000]\n",
      "Train Loss: 32263406.0147\n",
      "Val Loss: 30721237.9322, MAE: 4724.7749, NMAE: 72.0331, R^2: 0.1596\n",
      "Epoch [1857/2000]\n",
      "Train Loss: 32257814.2000\n",
      "Val Loss: 31133836.6962, MAE: 4763.5303, NMAE: 72.6239, R^2: 0.1483\n",
      "Epoch [1858/2000]\n",
      "Train Loss: 32485177.7690\n",
      "Val Loss: 31182149.9981, MAE: 4715.3716, NMAE: 71.8897, R^2: 0.1470\n",
      "Epoch [1859/2000]\n",
      "Train Loss: 32489375.4103\n",
      "Val Loss: 30921824.0574, MAE: 4701.8511, NMAE: 71.6836, R^2: 0.1541\n",
      "Epoch [1860/2000]\n",
      "Train Loss: 32257303.7121\n",
      "Val Loss: 30883648.9549, MAE: 4695.3838, NMAE: 71.5850, R^2: 0.1551\n",
      "Epoch [1861/2000]\n",
      "Train Loss: 32565747.7095\n",
      "Val Loss: 30943796.3560, MAE: 4763.3799, NMAE: 72.6216, R^2: 0.1535\n",
      "Epoch [1862/2000]\n",
      "Train Loss: 31920416.0698\n",
      "Val Loss: 30909133.5019, MAE: 4725.8760, NMAE: 72.0499, R^2: 0.1544\n",
      "Epoch [1863/2000]\n",
      "Train Loss: 32023377.6991\n",
      "Val Loss: 31355280.8877, MAE: 4824.2690, NMAE: 73.5499, R^2: 0.1422\n",
      "Epoch [1864/2000]\n",
      "Train Loss: 31761265.1526\n",
      "Val Loss: 30903533.5930, MAE: 4786.3188, NMAE: 72.9714, R^2: 0.1546\n",
      "Epoch [1865/2000]\n",
      "Train Loss: 31718982.9353\n",
      "Val Loss: 31016475.2876, MAE: 4799.8433, NMAE: 73.1775, R^2: 0.1515\n",
      "Epoch [1866/2000]\n",
      "Train Loss: 31776896.8422\n",
      "Val Loss: 30626560.5995, MAE: 4699.5913, NMAE: 71.6491, R^2: 0.1622\n",
      "Epoch [1867/2000]\n",
      "Train Loss: 32750297.6543\n",
      "Val Loss: 31994923.2103, MAE: 4621.4595, NMAE: 70.4579, R^2: 0.1247\n",
      "Epoch [1868/2000]\n",
      "Train Loss: 31834367.4034\n",
      "Val Loss: 30650493.1915, MAE: 4670.1270, NMAE: 71.1999, R^2: 0.1615\n",
      "Epoch [1869/2000]\n",
      "Train Loss: 31538469.4310\n",
      "Val Loss: 30742314.5237, MAE: 4688.8750, NMAE: 71.4857, R^2: 0.1590\n",
      "Epoch [1870/2000]\n",
      "Train Loss: 31512679.7500\n",
      "Val Loss: 31028612.5369, MAE: 4720.0996, NMAE: 71.9618, R^2: 0.1512\n",
      "Epoch [1871/2000]\n",
      "Train Loss: 31716582.5241\n",
      "Val Loss: 30959057.8623, MAE: 4676.1880, NMAE: 71.2923, R^2: 0.1531\n",
      "Epoch [1872/2000]\n",
      "Train Loss: 31257103.6629\n",
      "Val Loss: 33190421.5462, MAE: 4959.7900, NMAE: 75.6161, R^2: 0.0920\n",
      "Epoch [1873/2000]\n",
      "Train Loss: 34304514.1397\n",
      "Val Loss: 32125381.8614, MAE: 4883.7930, NMAE: 74.4574, R^2: 0.1212\n",
      "Epoch [1874/2000]\n",
      "Train Loss: 31935985.4397\n",
      "Val Loss: 30974480.3877, MAE: 4737.9937, NMAE: 72.2346, R^2: 0.1526\n",
      "Epoch [1875/2000]\n",
      "Train Loss: 31791715.8543\n",
      "Val Loss: 31472972.4005, MAE: 4736.2031, NMAE: 72.2073, R^2: 0.1390\n",
      "Epoch [1876/2000]\n",
      "Train Loss: 32350654.5026\n",
      "Val Loss: 31338425.9275, MAE: 4682.3677, NMAE: 71.3865, R^2: 0.1427\n",
      "Epoch [1877/2000]\n",
      "Train Loss: 31951236.8578\n",
      "Val Loss: 33083048.7932, MAE: 5005.5098, NMAE: 76.3131, R^2: 0.0950\n",
      "Epoch [1878/2000]\n",
      "Train Loss: 33669288.5595\n",
      "Val Loss: 31402595.7228, MAE: 4680.4775, NMAE: 71.3577, R^2: 0.1409\n",
      "Epoch [1879/2000]\n",
      "Train Loss: 32020754.0724\n",
      "Val Loss: 31125356.7042, MAE: 4709.6816, NMAE: 71.8030, R^2: 0.1485\n",
      "Epoch [1880/2000]\n",
      "Train Loss: 32306061.9379\n",
      "Val Loss: 31811408.7517, MAE: 4822.4644, NMAE: 73.5224, R^2: 0.1298\n",
      "Epoch [1881/2000]\n",
      "Train Loss: 32687959.7302\n",
      "Val Loss: 31935498.1693, MAE: 4855.7617, NMAE: 74.0301, R^2: 0.1264\n",
      "Epoch [1882/2000]\n",
      "Train Loss: 32455989.7474\n",
      "Val Loss: 32183211.6010, MAE: 4892.0854, NMAE: 74.5839, R^2: 0.1196\n",
      "Epoch [1883/2000]\n",
      "Train Loss: 32198162.6621\n",
      "Val Loss: 32080192.9594, MAE: 4877.7217, NMAE: 74.3649, R^2: 0.1224\n",
      "Epoch [1884/2000]\n",
      "Train Loss: 32262013.4638\n",
      "Val Loss: 31665720.2431, MAE: 4848.1191, NMAE: 73.9136, R^2: 0.1337\n",
      "Epoch [1885/2000]\n",
      "Train Loss: 31309876.0905\n",
      "Val Loss: 31479101.1857, MAE: 4822.1670, NMAE: 73.5179, R^2: 0.1388\n",
      "Epoch [1886/2000]\n",
      "Train Loss: 31641225.5483\n",
      "Val Loss: 31063188.0501, MAE: 4789.6167, NMAE: 73.0216, R^2: 0.1502\n",
      "Epoch [1887/2000]\n",
      "Train Loss: 31209209.7371\n",
      "Val Loss: 30806269.6485, MAE: 4731.5415, NMAE: 72.1362, R^2: 0.1572\n",
      "Epoch [1888/2000]\n",
      "Train Loss: 31107385.6103\n",
      "Val Loss: 30940003.8860, MAE: 4736.7568, NMAE: 72.2157, R^2: 0.1536\n",
      "Epoch [1889/2000]\n",
      "Train Loss: 30958841.1560\n",
      "Val Loss: 30712981.7783, MAE: 4735.8730, NMAE: 72.2023, R^2: 0.1598\n",
      "Epoch [1890/2000]\n",
      "Train Loss: 31336041.7612\n",
      "Val Loss: 30458437.5341, MAE: 4668.9771, NMAE: 71.1824, R^2: 0.1668\n",
      "Epoch [1891/2000]\n",
      "Train Loss: 31768067.2862\n",
      "Val Loss: 31565420.4007, MAE: 4690.6597, NMAE: 71.5130, R^2: 0.1365\n",
      "Epoch [1892/2000]\n",
      "Train Loss: 32220213.6060\n",
      "Val Loss: 31351074.8130, MAE: 4682.7739, NMAE: 71.3927, R^2: 0.1423\n",
      "Epoch [1893/2000]\n",
      "Train Loss: 31805001.6845\n",
      "Val Loss: 30743728.9210, MAE: 4681.9858, NMAE: 71.3807, R^2: 0.1590\n",
      "Epoch [1894/2000]\n",
      "Train Loss: 31405418.2776\n",
      "Val Loss: 30845741.6021, MAE: 4671.4873, NMAE: 71.2207, R^2: 0.1562\n",
      "Epoch [1895/2000]\n",
      "Train Loss: 31349619.2138\n",
      "Val Loss: 30734306.5633, MAE: 4618.8521, NMAE: 70.4182, R^2: 0.1592\n",
      "Epoch [1896/2000]\n",
      "Train Loss: 31545424.7017\n",
      "Val Loss: 30905972.5263, MAE: 4691.6226, NMAE: 71.5276, R^2: 0.1545\n",
      "Epoch [1897/2000]\n",
      "Train Loss: 31435245.5629\n",
      "Val Loss: 30643804.2435, MAE: 4673.2178, NMAE: 71.2470, R^2: 0.1617\n",
      "Epoch [1898/2000]\n",
      "Train Loss: 31139810.8871\n",
      "Val Loss: 30538073.6015, MAE: 4689.9683, NMAE: 71.5024, R^2: 0.1646\n",
      "Epoch [1899/2000]\n",
      "Train Loss: 33623572.1586\n",
      "Val Loss: 35844012.1744, MAE: 5251.6436, NMAE: 80.0656, R^2: 0.0194\n",
      "Epoch [1900/2000]\n",
      "Train Loss: 33468345.5948\n",
      "Val Loss: 31872744.9296, MAE: 4887.7910, NMAE: 74.5184, R^2: 0.1281\n",
      "Epoch [1901/2000]\n",
      "Train Loss: 31862430.9957\n",
      "Val Loss: 31128934.8143, MAE: 4771.1196, NMAE: 72.7396, R^2: 0.1484\n",
      "Epoch [1902/2000]\n",
      "Train Loss: 31449990.1371\n",
      "Val Loss: 30981709.1731, MAE: 4761.4902, NMAE: 72.5928, R^2: 0.1524\n",
      "Epoch [1903/2000]\n",
      "Train Loss: 31205555.3224\n",
      "Val Loss: 30237623.0905, MAE: 4679.3013, NMAE: 71.3398, R^2: 0.1728\n",
      "Epoch [1904/2000]\n",
      "Train Loss: 31727826.7500\n",
      "Val Loss: 30948168.3117, MAE: 4618.7725, NMAE: 70.4170, R^2: 0.1534\n",
      "Epoch [1905/2000]\n",
      "Train Loss: 31915644.0655\n",
      "Val Loss: 30887407.3562, MAE: 4636.5708, NMAE: 70.6883, R^2: 0.1550\n",
      "Epoch [1906/2000]\n",
      "Train Loss: 31136128.6043\n",
      "Val Loss: 31008678.2019, MAE: 4723.7305, NMAE: 72.0171, R^2: 0.1517\n",
      "Epoch [1907/2000]\n",
      "Train Loss: 31254658.3164\n",
      "Val Loss: 30307216.7763, MAE: 4642.4668, NMAE: 70.7782, R^2: 0.1709\n",
      "Epoch [1908/2000]\n",
      "Train Loss: 31552684.1500\n",
      "Val Loss: 30647583.9234, MAE: 4683.7422, NMAE: 71.4075, R^2: 0.1616\n",
      "Epoch [1909/2000]\n",
      "Train Loss: 30718640.2216\n",
      "Val Loss: 30384180.8841, MAE: 4649.6216, NMAE: 70.8873, R^2: 0.1688\n",
      "Epoch [1910/2000]\n",
      "Train Loss: 32053872.4690\n",
      "Val Loss: 31015121.4845, MAE: 4803.0166, NMAE: 73.2259, R^2: 0.1515\n",
      "Epoch [1911/2000]\n",
      "Train Loss: 31213373.4371\n",
      "Val Loss: 30541159.1222, MAE: 4697.6733, NMAE: 71.6199, R^2: 0.1645\n",
      "Epoch [1912/2000]\n",
      "Train Loss: 31671055.1741\n",
      "Val Loss: 31428802.2418, MAE: 4610.8560, NMAE: 70.2963, R^2: 0.1402\n",
      "Epoch [1913/2000]\n",
      "Train Loss: 31751799.1293\n",
      "Val Loss: 30999598.0471, MAE: 4676.0742, NMAE: 71.2906, R^2: 0.1520\n",
      "Epoch [1914/2000]\n",
      "Train Loss: 31532370.0207\n",
      "Val Loss: 30903045.3122, MAE: 4690.7119, NMAE: 71.5138, R^2: 0.1546\n",
      "Epoch [1915/2000]\n",
      "Train Loss: 30808503.0138\n",
      "Val Loss: 30354958.6908, MAE: 4695.2549, NMAE: 71.5830, R^2: 0.1696\n",
      "Epoch [1916/2000]\n",
      "Train Loss: 31172174.4724\n",
      "Val Loss: 31293489.8273, MAE: 4777.2920, NMAE: 72.8337, R^2: 0.1439\n",
      "Epoch [1917/2000]\n",
      "Train Loss: 31845442.0793\n",
      "Val Loss: 31139642.2992, MAE: 4744.8979, NMAE: 72.3399, R^2: 0.1481\n",
      "Epoch [1918/2000]\n",
      "Train Loss: 31587239.0698\n",
      "Val Loss: 30553968.6969, MAE: 4671.3408, NMAE: 71.2184, R^2: 0.1642\n",
      "Epoch [1919/2000]\n",
      "Train Loss: 30954521.2103\n",
      "Val Loss: 30768803.0894, MAE: 4702.4907, NMAE: 71.6933, R^2: 0.1583\n",
      "Epoch [1920/2000]\n",
      "Train Loss: 31208152.4422\n",
      "Val Loss: 30739610.9732, MAE: 4712.7075, NMAE: 71.8491, R^2: 0.1591\n",
      "Epoch [1921/2000]\n",
      "Train Loss: 31121004.4319\n",
      "Val Loss: 30583508.1645, MAE: 4698.2866, NMAE: 71.6292, R^2: 0.1633\n",
      "Epoch [1922/2000]\n",
      "Train Loss: 31444427.7155\n",
      "Val Loss: 30926772.0587, MAE: 4720.3389, NMAE: 71.9654, R^2: 0.1540\n",
      "Epoch [1923/2000]\n",
      "Train Loss: 31484596.5569\n",
      "Val Loss: 30999488.8146, MAE: 4597.8213, NMAE: 70.0976, R^2: 0.1520\n",
      "Epoch [1924/2000]\n",
      "Train Loss: 31344142.6603\n",
      "Val Loss: 30557469.1367, MAE: 4655.4829, NMAE: 70.9767, R^2: 0.1641\n",
      "Epoch [1925/2000]\n",
      "Train Loss: 31496859.6922\n",
      "Val Loss: 30502500.4585, MAE: 4676.3486, NMAE: 71.2948, R^2: 0.1656\n",
      "Epoch [1926/2000]\n",
      "Train Loss: 31068751.0112\n",
      "Val Loss: 30596218.2722, MAE: 4685.6592, NMAE: 71.4367, R^2: 0.1630\n",
      "Epoch [1927/2000]\n",
      "Train Loss: 31448912.3690\n",
      "Val Loss: 31018211.9616, MAE: 4695.2729, NMAE: 71.5833, R^2: 0.1515\n",
      "Epoch [1928/2000]\n",
      "Train Loss: 31471943.0716\n",
      "Val Loss: 30663217.9024, MAE: 4712.3218, NMAE: 71.8432, R^2: 0.1612\n",
      "Epoch [1929/2000]\n",
      "Train Loss: 31214381.3431\n",
      "Val Loss: 30586861.4849, MAE: 4722.0415, NMAE: 71.9914, R^2: 0.1633\n",
      "Epoch [1930/2000]\n",
      "Train Loss: 30870685.1129\n",
      "Val Loss: 31309014.0820, MAE: 4808.0234, NMAE: 73.3023, R^2: 0.1435\n",
      "Epoch [1931/2000]\n",
      "Train Loss: 32618020.5991\n",
      "Val Loss: 31134390.4849, MAE: 4601.1636, NMAE: 70.1485, R^2: 0.1483\n",
      "Epoch [1932/2000]\n",
      "Train Loss: 31309660.8216\n",
      "Val Loss: 36752830.7306, MAE: 5332.8071, NMAE: 81.3030, R^2: -0.0054\n",
      "Epoch [1933/2000]\n",
      "Train Loss: 35137543.3155\n",
      "Val Loss: 32371781.1131, MAE: 4963.7378, NMAE: 75.6763, R^2: 0.1144\n",
      "Epoch [1934/2000]\n",
      "Train Loss: 32585853.0879\n",
      "Val Loss: 31162337.4836, MAE: 4782.0791, NMAE: 72.9067, R^2: 0.1475\n",
      "Epoch [1935/2000]\n",
      "Train Loss: 31606984.4362\n",
      "Val Loss: 30839307.2865, MAE: 4680.9941, NMAE: 71.3656, R^2: 0.1563\n",
      "Epoch [1936/2000]\n",
      "Train Loss: 31557176.3431\n",
      "Val Loss: 31052159.2038, MAE: 4632.9048, NMAE: 70.6324, R^2: 0.1505\n",
      "Epoch [1937/2000]\n",
      "Train Loss: 34326250.1741\n",
      "Val Loss: 32014098.2879, MAE: 4552.7803, NMAE: 69.4109, R^2: 0.1242\n",
      "Epoch [1938/2000]\n",
      "Train Loss: 32711306.7603\n",
      "Val Loss: 31298133.2843, MAE: 4549.3232, NMAE: 69.3582, R^2: 0.1438\n",
      "Epoch [1939/2000]\n",
      "Train Loss: 31795952.4750\n",
      "Val Loss: 30517802.2504, MAE: 4633.1177, NMAE: 70.6357, R^2: 0.1651\n",
      "Epoch [1940/2000]\n",
      "Train Loss: 31816728.2172\n",
      "Val Loss: 30489205.8830, MAE: 4553.6758, NMAE: 69.4245, R^2: 0.1659\n",
      "Epoch [1941/2000]\n",
      "Train Loss: 31845025.9793\n",
      "Val Loss: 30474125.8769, MAE: 4532.9824, NMAE: 69.1090, R^2: 0.1663\n",
      "Epoch [1942/2000]\n",
      "Train Loss: 31913218.5690\n",
      "Val Loss: 32148670.4907, MAE: 4686.1362, NMAE: 71.4440, R^2: 0.1205\n",
      "Epoch [1943/2000]\n",
      "Train Loss: 34009578.0584\n",
      "Val Loss: 34957063.4178, MAE: 4605.5308, NMAE: 70.2151, R^2: 0.0437\n",
      "Epoch [1944/2000]\n",
      "Train Loss: 34348197.1892\n",
      "Val Loss: 32800860.1282, MAE: 4546.2144, NMAE: 69.3108, R^2: 0.1027\n",
      "Epoch [1945/2000]\n",
      "Train Loss: 32156444.9147\n",
      "Val Loss: 30817514.9417, MAE: 4617.4541, NMAE: 70.3969, R^2: 0.1569\n",
      "Epoch [1946/2000]\n",
      "Train Loss: 32042875.1405\n",
      "Val Loss: 30698185.5071, MAE: 4566.2144, NMAE: 69.6157, R^2: 0.1602\n",
      "Epoch [1947/2000]\n",
      "Train Loss: 32054930.3336\n",
      "Val Loss: 31116333.8525, MAE: 4614.0103, NMAE: 70.3444, R^2: 0.1488\n",
      "Epoch [1948/2000]\n",
      "Train Loss: 32443369.2259\n",
      "Val Loss: 31264838.4128, MAE: 4524.7065, NMAE: 68.9829, R^2: 0.1447\n",
      "Epoch [1949/2000]\n",
      "Train Loss: 31829096.5216\n",
      "Val Loss: 30763619.6742, MAE: 4650.2192, NMAE: 70.8964, R^2: 0.1584\n",
      "Epoch [1950/2000]\n",
      "Train Loss: 31907019.4664\n",
      "Val Loss: 30679952.2837, MAE: 4563.8574, NMAE: 69.5798, R^2: 0.1607\n",
      "Epoch [1951/2000]\n",
      "Train Loss: 31539709.8095\n",
      "Val Loss: 31573490.4024, MAE: 4769.2686, NMAE: 72.7114, R^2: 0.1363\n",
      "Epoch [1952/2000]\n",
      "Train Loss: 32795338.9207\n",
      "Val Loss: 31046438.4491, MAE: 4701.2256, NMAE: 71.6740, R^2: 0.1507\n",
      "Epoch [1953/2000]\n",
      "Train Loss: 33560376.7431\n",
      "Val Loss: 32003417.9729, MAE: 4561.7505, NMAE: 69.5476, R^2: 0.1245\n",
      "Epoch [1954/2000]\n",
      "Train Loss: 34062320.6638\n",
      "Val Loss: 33255220.2130, MAE: 4583.0928, NMAE: 69.8730, R^2: 0.0903\n",
      "Epoch [1955/2000]\n",
      "Train Loss: 33524327.9017\n",
      "Val Loss: 31866878.4113, MAE: 4557.5630, NMAE: 69.4838, R^2: 0.1282\n",
      "Epoch [1956/2000]\n",
      "Train Loss: 33072499.5586\n",
      "Val Loss: 32498537.3454, MAE: 4770.4399, NMAE: 72.7293, R^2: 0.1110\n",
      "Epoch [1957/2000]\n",
      "Train Loss: 33171169.1306\n",
      "Val Loss: 33783566.6200, MAE: 4913.5347, NMAE: 74.9109, R^2: 0.0758\n",
      "Epoch [1958/2000]\n",
      "Train Loss: 33409118.3190\n",
      "Val Loss: 33127070.1446, MAE: 4878.9873, NMAE: 74.3842, R^2: 0.0938\n",
      "Epoch [1959/2000]\n",
      "Train Loss: 32542724.9534\n",
      "Val Loss: 31882581.8191, MAE: 4752.3633, NMAE: 72.4537, R^2: 0.1278\n",
      "Epoch [1960/2000]\n",
      "Train Loss: 32519698.0095\n",
      "Val Loss: 31262916.2142, MAE: 4548.2822, NMAE: 69.3423, R^2: 0.1448\n",
      "Epoch [1961/2000]\n",
      "Train Loss: 31922609.1491\n",
      "Val Loss: 31928641.8972, MAE: 4724.1104, NMAE: 72.0229, R^2: 0.1265\n",
      "Epoch [1962/2000]\n",
      "Train Loss: 33893929.0379\n",
      "Val Loss: 32840462.4598, MAE: 4824.7617, NMAE: 73.5575, R^2: 0.1016\n",
      "Epoch [1963/2000]\n",
      "Train Loss: 33579397.0345\n",
      "Val Loss: 32668719.9646, MAE: 4829.7510, NMAE: 73.6335, R^2: 0.1063\n",
      "Epoch [1964/2000]\n",
      "Train Loss: 33305073.0534\n",
      "Val Loss: 31956828.9870, MAE: 4749.9287, NMAE: 72.4166, R^2: 0.1258\n",
      "Epoch [1965/2000]\n",
      "Train Loss: 31994368.7060\n",
      "Val Loss: 31667068.1157, MAE: 4788.7622, NMAE: 73.0086, R^2: 0.1337\n",
      "Epoch [1966/2000]\n",
      "Train Loss: 31700296.1759\n",
      "Val Loss: 30866057.5747, MAE: 4670.9214, NMAE: 71.2120, R^2: 0.1556\n",
      "Epoch [1967/2000]\n",
      "Train Loss: 31126529.5216\n",
      "Val Loss: 31809865.4544, MAE: 4876.9443, NMAE: 74.3530, R^2: 0.1298\n",
      "Epoch [1968/2000]\n",
      "Train Loss: 31857062.1629\n",
      "Val Loss: 31121660.2655, MAE: 4757.9077, NMAE: 72.5382, R^2: 0.1486\n",
      "Epoch [1969/2000]\n",
      "Train Loss: 32568301.5517\n",
      "Val Loss: 32080072.2612, MAE: 4732.8516, NMAE: 72.1562, R^2: 0.1224\n",
      "Epoch [1970/2000]\n",
      "Train Loss: 32564614.6966\n",
      "Val Loss: 31964128.3150, MAE: 4787.2642, NMAE: 72.9858, R^2: 0.1256\n",
      "Epoch [1971/2000]\n",
      "Train Loss: 32179349.4052\n",
      "Val Loss: 31368222.0073, MAE: 4783.4810, NMAE: 72.9281, R^2: 0.1419\n",
      "Epoch [1972/2000]\n",
      "Train Loss: 31564069.5448\n",
      "Val Loss: 31215108.4469, MAE: 4773.6592, NMAE: 72.7784, R^2: 0.1461\n",
      "Epoch [1973/2000]\n",
      "Train Loss: 31508211.2129\n",
      "Val Loss: 31010975.7712, MAE: 4738.0732, NMAE: 72.2358, R^2: 0.1516\n",
      "Epoch [1974/2000]\n",
      "Train Loss: 31477999.4043\n",
      "Val Loss: 31239626.6218, MAE: 4793.2739, NMAE: 73.0774, R^2: 0.1454\n",
      "Epoch [1975/2000]\n",
      "Train Loss: 31638651.8784\n",
      "Val Loss: 31000046.8804, MAE: 4757.2192, NMAE: 72.5277, R^2: 0.1519\n",
      "Epoch [1976/2000]\n",
      "Train Loss: 31664597.0095\n",
      "Val Loss: 30668073.3718, MAE: 4687.3955, NMAE: 71.4632, R^2: 0.1610\n",
      "Epoch [1977/2000]\n",
      "Train Loss: 31781897.3078\n",
      "Val Loss: 30779251.7232, MAE: 4683.2622, NMAE: 71.4002, R^2: 0.1580\n",
      "Epoch [1978/2000]\n",
      "Train Loss: 31867421.8578\n",
      "Val Loss: 30716356.9596, MAE: 4703.3955, NMAE: 71.7071, R^2: 0.1597\n",
      "Epoch [1979/2000]\n",
      "Train Loss: 30961967.1328\n",
      "Val Loss: 31704345.6999, MAE: 4820.8359, NMAE: 73.4976, R^2: 0.1327\n",
      "Epoch [1980/2000]\n",
      "Train Loss: 33916664.5741\n",
      "Val Loss: 35214851.2414, MAE: 5188.1240, NMAE: 79.0972, R^2: 0.0366\n",
      "Epoch [1981/2000]\n",
      "Train Loss: 34245867.7707\n",
      "Val Loss: 33001811.7517, MAE: 4989.3286, NMAE: 76.0664, R^2: 0.0972\n",
      "Epoch [1982/2000]\n",
      "Train Loss: 33368221.8276\n",
      "Val Loss: 32293678.4270, MAE: 4912.9058, NMAE: 74.9013, R^2: 0.1166\n",
      "Epoch [1983/2000]\n",
      "Train Loss: 32446990.0578\n",
      "Val Loss: 32040715.1801, MAE: 4863.9531, NMAE: 74.1550, R^2: 0.1235\n",
      "Epoch [1984/2000]\n",
      "Train Loss: 32234244.4750\n",
      "Val Loss: 31862279.3946, MAE: 4839.0259, NMAE: 73.7749, R^2: 0.1284\n",
      "Epoch [1985/2000]\n",
      "Train Loss: 31953212.6767\n",
      "Val Loss: 31697461.8076, MAE: 4824.6182, NMAE: 73.5553, R^2: 0.1329\n",
      "Epoch [1986/2000]\n",
      "Train Loss: 31920516.1560\n",
      "Val Loss: 32015251.7642, MAE: 4872.6865, NMAE: 74.2881, R^2: 0.1242\n",
      "Epoch [1987/2000]\n",
      "Train Loss: 31931047.3147\n",
      "Val Loss: 31534270.2392, MAE: 4788.1787, NMAE: 72.9997, R^2: 0.1373\n",
      "Epoch [1988/2000]\n",
      "Train Loss: 31441993.1112\n",
      "Val Loss: 31655635.8346, MAE: 4818.4785, NMAE: 73.4617, R^2: 0.1340\n",
      "Epoch [1989/2000]\n",
      "Train Loss: 32145359.6069\n",
      "Val Loss: 31968065.0028, MAE: 4779.4517, NMAE: 72.8667, R^2: 0.1255\n",
      "Epoch [1990/2000]\n",
      "Train Loss: 31796664.8922\n",
      "Val Loss: 31862779.0488, MAE: 4787.4854, NMAE: 72.9891, R^2: 0.1283\n",
      "Epoch [1991/2000]\n",
      "Train Loss: 31681091.1431\n",
      "Val Loss: 31799037.5119, MAE: 4779.8745, NMAE: 72.8731, R^2: 0.1301\n",
      "Epoch [1992/2000]\n",
      "Train Loss: 31992339.3190\n",
      "Val Loss: 31672382.3411, MAE: 4755.0024, NMAE: 72.4939, R^2: 0.1336\n",
      "Epoch [1993/2000]\n",
      "Train Loss: 31744699.2172\n",
      "Val Loss: 31549148.8292, MAE: 4752.3423, NMAE: 72.4534, R^2: 0.1369\n",
      "Epoch [1994/2000]\n",
      "Train Loss: 31814851.8569\n",
      "Val Loss: 31568240.2377, MAE: 4755.5781, NMAE: 72.5027, R^2: 0.1364\n",
      "Epoch [1995/2000]\n",
      "Train Loss: 31839867.7060\n",
      "Val Loss: 31815584.7431, MAE: 4737.6860, NMAE: 72.2299, R^2: 0.1296\n",
      "Epoch [1996/2000]\n",
      "Train Loss: 31930012.1483\n",
      "Val Loss: 31757388.3551, MAE: 4748.2773, NMAE: 72.3914, R^2: 0.1312\n",
      "Epoch [1997/2000]\n",
      "Train Loss: 31915427.0138\n",
      "Val Loss: 32353552.3143, MAE: 4900.8682, NMAE: 74.7178, R^2: 0.1149\n",
      "Epoch [1998/2000]\n",
      "Train Loss: 31838610.1129\n",
      "Val Loss: 32142785.4072, MAE: 4867.5479, NMAE: 74.2098, R^2: 0.1207\n",
      "Epoch [1999/2000]\n",
      "Train Loss: 31809524.6879\n",
      "Val Loss: 31415819.1382, MAE: 4786.6128, NMAE: 72.9758, R^2: 0.1406\n",
      "Epoch [2000/2000]\n",
      "Train Loss: 31205558.3922\n",
      "Val Loss: 32656620.0225, MAE: 4917.0425, NMAE: 74.9643, R^2: 0.1066\n",
      "Final Model saved with best validation loss: 17431033738.2500\n",
      "MAE: 4917.0425, NMAE: 74.9643, R^2: 0.1066\n",
      "Epoch [1/2000]\n",
      "Train Loss: 85508301.3831\n",
      "Val Loss: 79079118.2598, MAE: 6527.3511, NMAE: 99.5148, R^2: -1.1633\n",
      "Epoch [2/2000]\n",
      "Train Loss: 85013112.4221\n",
      "Val Loss: 78650414.7530, MAE: 6500.9888, NMAE: 99.1129, R^2: -1.1516\n",
      "Epoch [3/2000]\n",
      "Train Loss: 84563155.9932\n",
      "Val Loss: 78236917.5858, MAE: 6476.0620, NMAE: 98.7329, R^2: -1.1403\n",
      "Epoch [4/2000]\n",
      "Train Loss: 84126452.4384\n",
      "Val Loss: 77832848.2998, MAE: 6452.0874, NMAE: 98.3674, R^2: -1.1292\n",
      "Epoch [5/2000]\n",
      "Train Loss: 83698224.4751\n",
      "Val Loss: 77435346.4539, MAE: 6428.8633, NMAE: 98.0133, R^2: -1.1184\n",
      "Epoch [6/2000]\n",
      "Train Loss: 83276052.4467\n",
      "Val Loss: 77042876.4372, MAE: 6406.2217, NMAE: 97.6681, R^2: -1.1076\n",
      "Epoch [7/2000]\n",
      "Train Loss: 82858649.1847\n",
      "Val Loss: 76654556.3651, MAE: 6384.0576, NMAE: 97.3302, R^2: -1.0970\n",
      "Epoch [8/2000]\n",
      "Train Loss: 82445274.7236\n",
      "Val Loss: 76269864.2973, MAE: 6362.3486, NMAE: 96.9992, R^2: -1.0865\n",
      "Epoch [9/2000]\n",
      "Train Loss: 82035461.1114\n",
      "Val Loss: 75888450.6421, MAE: 6341.0645, NMAE: 96.6747, R^2: -1.0760\n",
      "Epoch [10/2000]\n",
      "Train Loss: 81628899.2346\n",
      "Val Loss: 75510075.4013, MAE: 6320.1616, NMAE: 96.3560, R^2: -1.0657\n",
      "Epoch [11/2000]\n",
      "Train Loss: 81225369.5267\n",
      "Val Loss: 75134569.8691, MAE: 6299.6006, NMAE: 96.0426, R^2: -1.0554\n",
      "Epoch [12/2000]\n",
      "Train Loss: 80824715.7818\n",
      "Val Loss: 74761806.3144, MAE: 6279.4185, NMAE: 95.7349, R^2: -1.0452\n",
      "Epoch [13/2000]\n",
      "Train Loss: 80426820.4548\n",
      "Val Loss: 74391691.3184, MAE: 6259.5815, NMAE: 95.4325, R^2: -1.0351\n",
      "Epoch [14/2000]\n",
      "Train Loss: 80031595.2687\n",
      "Val Loss: 74024154.1440, MAE: 6240.0498, NMAE: 95.1347, R^2: -1.0250\n",
      "Epoch [15/2000]\n",
      "Train Loss: 79638974.1357\n",
      "Val Loss: 73659139.6612, MAE: 6220.8262, NMAE: 94.8416, R^2: -1.0151\n",
      "Epoch [16/2000]\n",
      "Train Loss: 79248903.1474\n",
      "Val Loss: 73296600.5775, MAE: 6201.8765, NMAE: 94.5527, R^2: -1.0051\n",
      "Epoch [17/2000]\n",
      "Train Loss: 78861340.0479\n",
      "Val Loss: 72936511.0131, MAE: 6183.1904, NMAE: 94.2678, R^2: -0.9953\n",
      "Epoch [18/2000]\n",
      "Train Loss: 78476252.2987\n",
      "Val Loss: 72578828.2939, MAE: 6164.7891, NMAE: 93.9873, R^2: -0.9855\n",
      "Epoch [19/2000]\n",
      "Train Loss: 78093616.9711\n",
      "Val Loss: 72223547.0732, MAE: 6146.6621, NMAE: 93.7109, R^2: -0.9758\n",
      "Epoch [20/2000]\n",
      "Train Loss: 77713415.0515\n",
      "Val Loss: 71870638.7372, MAE: 6128.7832, NMAE: 93.4383, R^2: -0.9661\n",
      "Epoch [21/2000]\n",
      "Train Loss: 77335625.1609\n",
      "Val Loss: 71520091.0438, MAE: 6111.2007, NMAE: 93.1703, R^2: -0.9565\n",
      "Epoch [22/2000]\n",
      "Train Loss: 76960232.4502\n",
      "Val Loss: 71171890.9846, MAE: 6093.8848, NMAE: 92.9063, R^2: -0.9470\n",
      "Epoch [23/2000]\n",
      "Train Loss: 76587231.1809\n",
      "Val Loss: 70826034.2942, MAE: 6076.8291, NMAE: 92.6462, R^2: -0.9376\n",
      "Epoch [24/2000]\n",
      "Train Loss: 76216602.4427\n",
      "Val Loss: 70482500.5199, MAE: 6060.0410, NMAE: 92.3903, R^2: -0.9282\n",
      "Epoch [25/2000]\n",
      "Train Loss: 75848347.6510\n",
      "Val Loss: 70141284.7345, MAE: 6043.4668, NMAE: 92.1376, R^2: -0.9188\n",
      "Epoch [26/2000]\n",
      "Train Loss: 75482445.5770\n",
      "Val Loss: 69802378.8511, MAE: 6027.1035, NMAE: 91.8881, R^2: -0.9095\n",
      "Epoch [27/2000]\n",
      "Train Loss: 75118899.9549\n",
      "Val Loss: 69465785.0162, MAE: 6010.9658, NMAE: 91.6421, R^2: -0.9003\n",
      "Epoch [28/2000]\n",
      "Train Loss: 74757702.1148\n",
      "Val Loss: 69131485.5746, MAE: 5995.0830, NMAE: 91.4000, R^2: -0.8912\n",
      "Epoch [29/2000]\n",
      "Train Loss: 74398843.5508\n",
      "Val Loss: 68799481.3823, MAE: 5979.4136, NMAE: 91.1611, R^2: -0.8821\n",
      "Epoch [30/2000]\n",
      "Train Loss: 74042320.9464\n",
      "Val Loss: 68469764.5251, MAE: 5963.9463, NMAE: 90.9253, R^2: -0.8731\n",
      "Epoch [31/2000]\n",
      "Train Loss: 73688134.9220\n",
      "Val Loss: 68142335.9331, MAE: 5948.7065, NMAE: 90.6929, R^2: -0.8641\n",
      "Epoch [32/2000]\n",
      "Train Loss: 73336272.7168\n",
      "Val Loss: 67817177.8460, MAE: 5933.6860, NMAE: 90.4639, R^2: -0.8552\n",
      "Epoch [33/2000]\n",
      "Train Loss: 72986728.0772\n",
      "Val Loss: 67494287.8443, MAE: 5918.8828, NMAE: 90.2382, R^2: -0.8464\n",
      "Epoch [34/2000]\n",
      "Train Loss: 72639495.3653\n",
      "Val Loss: 67173666.4002, MAE: 5904.2891, NMAE: 90.0157, R^2: -0.8376\n",
      "Epoch [35/2000]\n",
      "Train Loss: 72294568.0872\n",
      "Val Loss: 66855302.5359, MAE: 5889.8921, NMAE: 89.7962, R^2: -0.8289\n",
      "Epoch [36/2000]\n",
      "Train Loss: 71951946.9033\n",
      "Val Loss: 66539188.0741, MAE: 5875.6729, NMAE: 89.5795, R^2: -0.8203\n",
      "Epoch [37/2000]\n",
      "Train Loss: 71611623.4145\n",
      "Val Loss: 66225326.8194, MAE: 5861.6240, NMAE: 89.3653, R^2: -0.8117\n",
      "Epoch [38/2000]\n",
      "Train Loss: 71273594.6209\n",
      "Val Loss: 65913706.9601, MAE: 5847.7334, NMAE: 89.1535, R^2: -0.8032\n",
      "Epoch [39/2000]\n",
      "Train Loss: 70937863.1580\n",
      "Val Loss: 65604341.8357, MAE: 5834.0298, NMAE: 88.9446, R^2: -0.7947\n",
      "Epoch [40/2000]\n",
      "Train Loss: 70604418.6332\n",
      "Val Loss: 65297193.0855, MAE: 5820.5425, NMAE: 88.7389, R^2: -0.7863\n",
      "Epoch [41/2000]\n",
      "Train Loss: 70273239.9259\n",
      "Val Loss: 64992273.9642, MAE: 5807.2559, NMAE: 88.5364, R^2: -0.7780\n",
      "Epoch [42/2000]\n",
      "Train Loss: 69944335.4595\n",
      "Val Loss: 64689566.3841, MAE: 5794.1602, NMAE: 88.3367, R^2: -0.7697\n",
      "Epoch [43/2000]\n",
      "Train Loss: 69617691.4716\n",
      "Val Loss: 64389080.0765, MAE: 5781.2236, NMAE: 88.1395, R^2: -0.7615\n",
      "Epoch [44/2000]\n",
      "Train Loss: 69293321.3138\n",
      "Val Loss: 64090809.3513, MAE: 5768.4561, NMAE: 87.9448, R^2: -0.7533\n",
      "Epoch [45/2000]\n",
      "Train Loss: 68971206.4552\n",
      "Val Loss: 63794742.1430, MAE: 5755.8687, NMAE: 87.7529, R^2: -0.7452\n",
      "Epoch [46/2000]\n",
      "Train Loss: 68651345.6123\n",
      "Val Loss: 63500875.0978, MAE: 5743.4409, NMAE: 87.5635, R^2: -0.7372\n",
      "Epoch [47/2000]\n",
      "Train Loss: 68333735.9970\n",
      "Val Loss: 63209207.2463, MAE: 5731.2183, NMAE: 87.3771, R^2: -0.7292\n",
      "Epoch [48/2000]\n",
      "Train Loss: 68018367.3631\n",
      "Val Loss: 62919723.0011, MAE: 5719.1641, NMAE: 87.1933, R^2: -0.7213\n",
      "Epoch [49/2000]\n",
      "Train Loss: 67705233.7127\n",
      "Val Loss: 62632420.5111, MAE: 5707.3052, NMAE: 87.0125, R^2: -0.7134\n",
      "Epoch [50/2000]\n",
      "Train Loss: 67394328.2246\n",
      "Val Loss: 62347285.8524, MAE: 5695.5854, NMAE: 86.8339, R^2: -0.7056\n",
      "Epoch [51/2000]\n",
      "Train Loss: 67085643.2627\n",
      "Val Loss: 62064326.4196, MAE: 5684.0249, NMAE: 86.6576, R^2: -0.6979\n",
      "Epoch [52/2000]\n",
      "Train Loss: 66779188.0481\n",
      "Val Loss: 61783537.3494, MAE: 5672.6450, NMAE: 86.4841, R^2: -0.6902\n",
      "Epoch [53/2000]\n",
      "Train Loss: 66474944.3530\n",
      "Val Loss: 61504906.1521, MAE: 5661.4087, NMAE: 86.3128, R^2: -0.6826\n",
      "Epoch [54/2000]\n",
      "Train Loss: 66172906.1886\n",
      "Val Loss: 61228425.3068, MAE: 5650.3140, NMAE: 86.1437, R^2: -0.6750\n",
      "Epoch [55/2000]\n",
      "Train Loss: 65873070.8793\n",
      "Val Loss: 60954080.1424, MAE: 5639.3535, NMAE: 85.9766, R^2: -0.6675\n",
      "Epoch [56/2000]\n",
      "Train Loss: 65575430.0218\n",
      "Val Loss: 60681884.4525, MAE: 5628.5356, NMAE: 85.8116, R^2: -0.6600\n",
      "Epoch [57/2000]\n",
      "Train Loss: 65279980.7804\n",
      "Val Loss: 60411817.0625, MAE: 5617.8755, NMAE: 85.6491, R^2: -0.6527\n",
      "Epoch [58/2000]\n",
      "Train Loss: 64986719.1802\n",
      "Val Loss: 60143883.9415, MAE: 5607.3711, NMAE: 85.4890, R^2: -0.6453\n",
      "Epoch [59/2000]\n",
      "Train Loss: 64695636.7416\n",
      "Val Loss: 59878066.8126, MAE: 5597.0210, NMAE: 85.3312, R^2: -0.6381\n",
      "Epoch [60/2000]\n",
      "Train Loss: 64406724.0836\n",
      "Val Loss: 59614362.5544, MAE: 5586.8267, NMAE: 85.1758, R^2: -0.6308\n",
      "Epoch [61/2000]\n",
      "Train Loss: 64119974.6341\n",
      "Val Loss: 59352760.0699, MAE: 5576.7632, NMAE: 85.0223, R^2: -0.6237\n",
      "Epoch [62/2000]\n",
      "Train Loss: 63835383.1250\n",
      "Val Loss: 59093258.6657, MAE: 5566.8228, NMAE: 84.8708, R^2: -0.6166\n",
      "Epoch [63/2000]\n",
      "Train Loss: 63552950.6414\n",
      "Val Loss: 58835870.0394, MAE: 5557.0293, NMAE: 84.7215, R^2: -0.6095\n",
      "Epoch [64/2000]\n",
      "Train Loss: 63272673.6776\n",
      "Val Loss: 58580561.0268, MAE: 5547.3677, NMAE: 84.5742, R^2: -0.6026\n",
      "Epoch [65/2000]\n",
      "Train Loss: 62994535.5797\n",
      "Val Loss: 58327332.0101, MAE: 5537.8271, NMAE: 84.4287, R^2: -0.5956\n",
      "Epoch [66/2000]\n",
      "Train Loss: 62718526.1767\n",
      "Val Loss: 58076162.2800, MAE: 5528.4067, NMAE: 84.2851, R^2: -0.5888\n",
      "Epoch [67/2000]\n",
      "Train Loss: 62444636.7810\n",
      "Val Loss: 57827071.3310, MAE: 5519.1206, NMAE: 84.1435, R^2: -0.5819\n",
      "Epoch [68/2000]\n",
      "Train Loss: 62172883.4418\n",
      "Val Loss: 57580039.4812, MAE: 5509.9854, NMAE: 84.0042, R^2: -0.5752\n",
      "Epoch [69/2000]\n",
      "Train Loss: 61903242.8220\n",
      "Val Loss: 57335069.7637, MAE: 5500.9717, NMAE: 83.8668, R^2: -0.5685\n",
      "Epoch [70/2000]\n",
      "Train Loss: 61635717.8608\n",
      "Val Loss: 57092151.1064, MAE: 5492.0801, NMAE: 83.7313, R^2: -0.5618\n",
      "Epoch [71/2000]\n",
      "Train Loss: 61370292.5841\n",
      "Val Loss: 56851260.2807, MAE: 5483.3115, NMAE: 83.5976, R^2: -0.5553\n",
      "Epoch [72/2000]\n",
      "Train Loss: 61106956.8086\n",
      "Val Loss: 56612414.4536, MAE: 5474.6689, NMAE: 83.4658, R^2: -0.5487\n",
      "Epoch [73/2000]\n",
      "Train Loss: 60845718.6996\n",
      "Val Loss: 56375573.6641, MAE: 5466.1436, NMAE: 83.3358, R^2: -0.5422\n",
      "Epoch [74/2000]\n",
      "Train Loss: 60586563.0784\n",
      "Val Loss: 56140772.1619, MAE: 5457.7383, NMAE: 83.2077, R^2: -0.5358\n",
      "Epoch [75/2000]\n",
      "Train Loss: 60329479.9953\n",
      "Val Loss: 55907974.1744, MAE: 5449.4546, NMAE: 83.0814, R^2: -0.5294\n",
      "Epoch [76/2000]\n",
      "Train Loss: 60074459.4065\n",
      "Val Loss: 55677168.9662, MAE: 5441.2861, NMAE: 82.9569, R^2: -0.5231\n",
      "Epoch [77/2000]\n",
      "Train Loss: 59821486.4810\n",
      "Val Loss: 55448339.1702, MAE: 5433.2368, NMAE: 82.8342, R^2: -0.5169\n",
      "Epoch [78/2000]\n",
      "Train Loss: 59570557.4220\n",
      "Val Loss: 55221518.4238, MAE: 5425.3105, NMAE: 82.7133, R^2: -0.5107\n",
      "Epoch [79/2000]\n",
      "Train Loss: 59321695.0724\n",
      "Val Loss: 54996675.8706, MAE: 5417.4971, NMAE: 82.5942, R^2: -0.5045\n",
      "Epoch [80/2000]\n",
      "Train Loss: 59074864.8845\n",
      "Val Loss: 54773805.5039, MAE: 5409.8105, NMAE: 82.4770, R^2: -0.4984\n",
      "Epoch [81/2000]\n",
      "Train Loss: 58830075.0668\n",
      "Val Loss: 54552908.1852, MAE: 5402.2192, NMAE: 82.3613, R^2: -0.4924\n",
      "Epoch [82/2000]\n",
      "Train Loss: 58587310.1763\n",
      "Val Loss: 54333980.7027, MAE: 5394.7441, NMAE: 82.2473, R^2: -0.4864\n",
      "Epoch [83/2000]\n",
      "Train Loss: 58346567.5612\n",
      "Val Loss: 54116982.1017, MAE: 5387.3770, NMAE: 82.1350, R^2: -0.4805\n",
      "Epoch [84/2000]\n",
      "Train Loss: 58107822.6802\n",
      "Val Loss: 53901929.5395, MAE: 5380.1201, NMAE: 82.0243, R^2: -0.4746\n",
      "Epoch [85/2000]\n",
      "Train Loss: 57871087.2306\n",
      "Val Loss: 53688801.8877, MAE: 5372.9478, NMAE: 81.9150, R^2: -0.4687\n",
      "Epoch [86/2000]\n",
      "Train Loss: 57636326.8267\n",
      "Val Loss: 53477596.7714, MAE: 5365.8701, NMAE: 81.8071, R^2: -0.4630\n",
      "Epoch [87/2000]\n",
      "Train Loss: 57403551.6086\n",
      "Val Loss: 53268302.0846, MAE: 5358.8965, NMAE: 81.7008, R^2: -0.4572\n",
      "Epoch [88/2000]\n",
      "Train Loss: 57172748.5737\n",
      "Val Loss: 53060924.6103, MAE: 5352.0371, NMAE: 81.5962, R^2: -0.4516\n",
      "Epoch [89/2000]\n",
      "Train Loss: 56943927.4078\n",
      "Val Loss: 52855443.9534, MAE: 5345.2856, NMAE: 81.4933, R^2: -0.4459\n",
      "Epoch [90/2000]\n",
      "Train Loss: 56717056.1737\n",
      "Val Loss: 52651851.0792, MAE: 5338.6362, NMAE: 81.3919, R^2: -0.4404\n",
      "Epoch [91/2000]\n",
      "Train Loss: 56492146.9276\n",
      "Val Loss: 52450147.9119, MAE: 5332.0918, NMAE: 81.2921, R^2: -0.4349\n",
      "Epoch [92/2000]\n",
      "Train Loss: 56269200.2496\n",
      "Val Loss: 52250345.9301, MAE: 5325.6523, NMAE: 81.1939, R^2: -0.4294\n",
      "Epoch [93/2000]\n",
      "Train Loss: 56048198.1565\n",
      "Val Loss: 52052401.9454, MAE: 5319.3154, NMAE: 81.0973, R^2: -0.4240\n",
      "Epoch [94/2000]\n",
      "Train Loss: 55829112.8306\n",
      "Val Loss: 51856296.1414, MAE: 5313.0820, NMAE: 81.0023, R^2: -0.4186\n",
      "Epoch [95/2000]\n",
      "Train Loss: 55611935.0323\n",
      "Val Loss: 51662046.1803, MAE: 5306.9492, NMAE: 80.9088, R^2: -0.4133\n",
      "Epoch [96/2000]\n",
      "Train Loss: 55396684.7953\n",
      "Val Loss: 51469648.5829, MAE: 5300.9282, NMAE: 80.8170, R^2: -0.4080\n",
      "Epoch [97/2000]\n",
      "Train Loss: 55183343.6422\n",
      "Val Loss: 51279079.7191, MAE: 5295.0283, NMAE: 80.7271, R^2: -0.4028\n",
      "Epoch [98/2000]\n",
      "Train Loss: 54971888.0470\n",
      "Val Loss: 51090328.0946, MAE: 5289.2324, NMAE: 80.6387, R^2: -0.3977\n",
      "Epoch [99/2000]\n",
      "Train Loss: 54762329.2879\n",
      "Val Loss: 50903405.4279, MAE: 5283.5220, NMAE: 80.5516, R^2: -0.3925\n",
      "Epoch [100/2000]\n",
      "Train Loss: 54554660.3565\n",
      "Val Loss: 50718283.8354, MAE: 5277.8950, NMAE: 80.4658, R^2: -0.3875\n",
      "Epoch [101/2000]\n",
      "Train Loss: 54348843.5422\n",
      "Val Loss: 50534947.1468, MAE: 5272.3652, NMAE: 80.3815, R^2: -0.3825\n",
      "Epoch [102/2000]\n",
      "Train Loss: 54144886.2948\n",
      "Val Loss: 50353404.2886, MAE: 5266.9355, NMAE: 80.2988, R^2: -0.3775\n",
      "Epoch [103/2000]\n",
      "Train Loss: 53942785.6966\n",
      "Val Loss: 50173630.3815, MAE: 5261.6147, NMAE: 80.2176, R^2: -0.3726\n",
      "Epoch [104/2000]\n",
      "Train Loss: 53742530.6155\n",
      "Val Loss: 49995641.8489, MAE: 5256.3950, NMAE: 80.1381, R^2: -0.3677\n",
      "Epoch [105/2000]\n",
      "Train Loss: 53544124.1987\n",
      "Val Loss: 49819420.5329, MAE: 5251.2734, NMAE: 80.0600, R^2: -0.3629\n",
      "Epoch [106/2000]\n",
      "Train Loss: 53347551.0047\n",
      "Val Loss: 49644950.8968, MAE: 5246.2505, NMAE: 79.9834, R^2: -0.3581\n",
      "Epoch [107/2000]\n",
      "Train Loss: 53152786.6914\n",
      "Val Loss: 49472211.6388, MAE: 5241.3145, NMAE: 79.9081, R^2: -0.3534\n",
      "Epoch [108/2000]\n",
      "Train Loss: 52959840.0129\n",
      "Val Loss: 49301226.3400, MAE: 5236.4639, NMAE: 79.8342, R^2: -0.3487\n",
      "Epoch [109/2000]\n",
      "Train Loss: 52768688.0478\n",
      "Val Loss: 49131954.8769, MAE: 5231.6973, NMAE: 79.7615, R^2: -0.3441\n",
      "Epoch [110/2000]\n",
      "Train Loss: 52579332.8034\n",
      "Val Loss: 48964395.0905, MAE: 5227.0059, NMAE: 79.6900, R^2: -0.3395\n",
      "Epoch [111/2000]\n",
      "Train Loss: 52391762.1224\n",
      "Val Loss: 48798565.1682, MAE: 5222.4102, NMAE: 79.6199, R^2: -0.3350\n",
      "Epoch [112/2000]\n",
      "Train Loss: 52205976.7616\n",
      "Val Loss: 48634417.6902, MAE: 5217.9004, NMAE: 79.5512, R^2: -0.3305\n",
      "Epoch [113/2000]\n",
      "Train Loss: 52021947.9724\n",
      "Val Loss: 48471955.1611, MAE: 5213.4858, NMAE: 79.4839, R^2: -0.3260\n",
      "Epoch [114/2000]\n",
      "Train Loss: 51839659.7823\n",
      "Val Loss: 48311153.6369, MAE: 5209.1348, NMAE: 79.4175, R^2: -0.3216\n",
      "Epoch [115/2000]\n",
      "Train Loss: 51659125.7836\n",
      "Val Loss: 48152034.8905, MAE: 5204.8784, NMAE: 79.3526, R^2: -0.3173\n",
      "Epoch [116/2000]\n",
      "Train Loss: 51480340.7677\n",
      "Val Loss: 47994588.1367, MAE: 5200.7109, NMAE: 79.2891, R^2: -0.3130\n",
      "Epoch [117/2000]\n",
      "Train Loss: 51303282.5328\n",
      "Val Loss: 47838783.3873, MAE: 5196.6069, NMAE: 79.2265, R^2: -0.3087\n",
      "Epoch [118/2000]\n",
      "Train Loss: 51127939.1155\n",
      "Val Loss: 47684606.5320, MAE: 5192.5679, NMAE: 79.1650, R^2: -0.3045\n",
      "Epoch [119/2000]\n",
      "Train Loss: 50954298.8974\n",
      "Val Loss: 47532066.9165, MAE: 5188.6089, NMAE: 79.1046, R^2: -0.3003\n",
      "Epoch [120/2000]\n",
      "Train Loss: 50782367.3698\n",
      "Val Loss: 47381156.2321, MAE: 5184.7295, NMAE: 79.0455, R^2: -0.2962\n",
      "Epoch [121/2000]\n",
      "Train Loss: 50612130.3203\n",
      "Val Loss: 47231843.7776, MAE: 5180.9199, NMAE: 78.9874, R^2: -0.2921\n",
      "Epoch [122/2000]\n",
      "Train Loss: 50443562.3440\n",
      "Val Loss: 47084139.6088, MAE: 5177.1890, NMAE: 78.9305, R^2: -0.2881\n",
      "Epoch [123/2000]\n",
      "Train Loss: 50276673.9267\n",
      "Val Loss: 46938014.1481, MAE: 5173.5117, NMAE: 78.8744, R^2: -0.2841\n",
      "Epoch [124/2000]\n",
      "Train Loss: 50111439.5573\n",
      "Val Loss: 46793472.3273, MAE: 5169.9131, NMAE: 78.8196, R^2: -0.2801\n",
      "Epoch [125/2000]\n",
      "Train Loss: 49947852.5935\n",
      "Val Loss: 46650501.1548, MAE: 5166.3877, NMAE: 78.7658, R^2: -0.2762\n",
      "Epoch [126/2000]\n",
      "Train Loss: 49785911.9547\n",
      "Val Loss: 46509094.7688, MAE: 5162.9453, NMAE: 78.7133, R^2: -0.2723\n",
      "Epoch [127/2000]\n",
      "Train Loss: 49625617.1677\n",
      "Val Loss: 46369241.5283, MAE: 5159.5664, NMAE: 78.6618, R^2: -0.2685\n",
      "Epoch [128/2000]\n",
      "Train Loss: 49466927.4966\n",
      "Val Loss: 46230915.6235, MAE: 5156.2573, NMAE: 78.6114, R^2: -0.2647\n",
      "Epoch [129/2000]\n",
      "Train Loss: 49309844.1647\n",
      "Val Loss: 46094114.5693, MAE: 5153.0200, NMAE: 78.5620, R^2: -0.2610\n",
      "Epoch [130/2000]\n",
      "Train Loss: 49154368.9552\n",
      "Val Loss: 45958851.0639, MAE: 5149.8652, NMAE: 78.5139, R^2: -0.2573\n",
      "Epoch [131/2000]\n",
      "Train Loss: 49000493.8914\n",
      "Val Loss: 45825090.1764, MAE: 5146.7896, NMAE: 78.4670, R^2: -0.2536\n",
      "Epoch [132/2000]\n",
      "Train Loss: 48848205.1927\n",
      "Val Loss: 45692838.7060, MAE: 5143.7852, NMAE: 78.4212, R^2: -0.2500\n",
      "Epoch [133/2000]\n",
      "Train Loss: 48697485.7198\n",
      "Val Loss: 45562065.8605, MAE: 5140.8413, NMAE: 78.3763, R^2: -0.2464\n",
      "Epoch [134/2000]\n",
      "Train Loss: 48548323.0422\n",
      "Val Loss: 45432774.0076, MAE: 5137.9756, NMAE: 78.3327, R^2: -0.2429\n",
      "Epoch [135/2000]\n",
      "Train Loss: 48400720.5526\n",
      "Val Loss: 45304954.7446, MAE: 5135.1992, NMAE: 78.2903, R^2: -0.2394\n",
      "Epoch [136/2000]\n",
      "Train Loss: 48254659.2539\n",
      "Val Loss: 45178592.5820, MAE: 5132.4810, NMAE: 78.2489, R^2: -0.2359\n",
      "Epoch [137/2000]\n",
      "Train Loss: 48110130.8793\n",
      "Val Loss: 45053684.3517, MAE: 5129.8071, NMAE: 78.2081, R^2: -0.2325\n",
      "Epoch [138/2000]\n",
      "Train Loss: 47967131.6026\n",
      "Val Loss: 44930216.8253, MAE: 5127.1875, NMAE: 78.1682, R^2: -0.2291\n",
      "Epoch [139/2000]\n",
      "Train Loss: 47825644.0086\n",
      "Val Loss: 44808179.9400, MAE: 5124.6309, NMAE: 78.1292, R^2: -0.2258\n",
      "Epoch [140/2000]\n",
      "Train Loss: 47685658.8647\n",
      "Val Loss: 44687553.1358, MAE: 5122.1460, NMAE: 78.0913, R^2: -0.2225\n",
      "Epoch [141/2000]\n",
      "Train Loss: 47547159.4733\n",
      "Val Loss: 44568331.3150, MAE: 5119.7202, NMAE: 78.0543, R^2: -0.2192\n",
      "Epoch [142/2000]\n",
      "Train Loss: 47410135.0922\n",
      "Val Loss: 44450492.6671, MAE: 5117.3608, NMAE: 78.0184, R^2: -0.2160\n",
      "Epoch [143/2000]\n",
      "Train Loss: 47274574.1112\n",
      "Val Loss: 44334044.8053, MAE: 5115.0684, NMAE: 77.9834, R^2: -0.2128\n",
      "Epoch [144/2000]\n",
      "Train Loss: 47140486.4552\n",
      "Val Loss: 44218979.2329, MAE: 5112.8296, NMAE: 77.9493, R^2: -0.2097\n",
      "Epoch [145/2000]\n",
      "Train Loss: 47007852.5431\n",
      "Val Loss: 44105286.3389, MAE: 5110.6431, NMAE: 77.9159, R^2: -0.2066\n",
      "Epoch [146/2000]\n",
      "Train Loss: 46876662.4750\n",
      "Val Loss: 43992946.7509, MAE: 5108.5181, NMAE: 77.8835, R^2: -0.2035\n",
      "Epoch [147/2000]\n",
      "Train Loss: 46746908.5052\n",
      "Val Loss: 43881960.0091, MAE: 5106.4448, NMAE: 77.8519, R^2: -0.2005\n",
      "Epoch [148/2000]\n",
      "Train Loss: 46618576.7922\n",
      "Val Loss: 43772306.1164, MAE: 5104.4297, NMAE: 77.8212, R^2: -0.1975\n",
      "Epoch [149/2000]\n",
      "Train Loss: 46491650.2741\n",
      "Val Loss: 43663967.4588, MAE: 5102.4824, NMAE: 77.7915, R^2: -0.1945\n",
      "Epoch [150/2000]\n",
      "Train Loss: 46366121.2879\n",
      "Val Loss: 43556946.2884, MAE: 5100.5889, NMAE: 77.7627, R^2: -0.1916\n",
      "Epoch [151/2000]\n",
      "Train Loss: 46241978.2595\n",
      "Val Loss: 43451221.9279, MAE: 5098.7358, NMAE: 77.7344, R^2: -0.1887\n",
      "Epoch [152/2000]\n",
      "Train Loss: 46119219.6474\n",
      "Val Loss: 43346793.2247, MAE: 5096.9277, NMAE: 77.7068, R^2: -0.1858\n",
      "Epoch [153/2000]\n",
      "Train Loss: 45997828.2379\n",
      "Val Loss: 43243651.1792, MAE: 5095.1650, NMAE: 77.6800, R^2: -0.1830\n",
      "Epoch [154/2000]\n",
      "Train Loss: 45877791.6336\n",
      "Val Loss: 43141773.8603, MAE: 5093.4473, NMAE: 77.6538, R^2: -0.1802\n",
      "Epoch [155/2000]\n",
      "Train Loss: 45759107.3207\n",
      "Val Loss: 43041164.5533, MAE: 5091.7744, NMAE: 77.6283, R^2: -0.1775\n",
      "Epoch [156/2000]\n",
      "Train Loss: 45641764.1138\n",
      "Val Loss: 42941804.5563, MAE: 5090.1465, NMAE: 77.6035, R^2: -0.1747\n",
      "Epoch [157/2000]\n",
      "Train Loss: 45525741.0000\n",
      "Val Loss: 42843685.3892, MAE: 5088.5693, NMAE: 77.5794, R^2: -0.1721\n",
      "Epoch [158/2000]\n",
      "Train Loss: 45411032.8966\n",
      "Val Loss: 42746776.6779, MAE: 5087.0391, NMAE: 77.5561, R^2: -0.1694\n",
      "Epoch [159/2000]\n",
      "Train Loss: 45297628.1784\n",
      "Val Loss: 42651099.7690, MAE: 5085.5698, NMAE: 77.5337, R^2: -0.1668\n",
      "Epoch [160/2000]\n",
      "Train Loss: 45185513.7034\n",
      "Val Loss: 42556615.2323, MAE: 5084.1450, NMAE: 77.5120, R^2: -0.1642\n",
      "Epoch [161/2000]\n",
      "Train Loss: 45074699.8474\n",
      "Val Loss: 42463374.6962, MAE: 5082.7637, NMAE: 77.4909, R^2: -0.1616\n",
      "Epoch [162/2000]\n",
      "Train Loss: 44965167.8241\n",
      "Val Loss: 42371296.1952, MAE: 5081.4360, NMAE: 77.4707, R^2: -0.1591\n",
      "Epoch [163/2000]\n",
      "Train Loss: 44856910.7595\n",
      "Val Loss: 42280413.1403, MAE: 5080.1553, NMAE: 77.4511, R^2: -0.1566\n",
      "Epoch [164/2000]\n",
      "Train Loss: 44749897.1974\n",
      "Val Loss: 42190673.3946, MAE: 5078.9136, NMAE: 77.4322, R^2: -0.1542\n",
      "Epoch [165/2000]\n",
      "Train Loss: 44644120.9034\n",
      "Val Loss: 42102102.1740, MAE: 5077.7085, NMAE: 77.4138, R^2: -0.1518\n",
      "Epoch [166/2000]\n",
      "Train Loss: 44539571.8457\n",
      "Val Loss: 42014660.0138, MAE: 5076.5400, NMAE: 77.3960, R^2: -0.1494\n",
      "Epoch [167/2000]\n",
      "Train Loss: 44436243.6922\n",
      "Val Loss: 41928360.1947, MAE: 5075.4038, NMAE: 77.3787, R^2: -0.1470\n",
      "Epoch [168/2000]\n",
      "Train Loss: 44334153.9276\n",
      "Val Loss: 41843217.1457, MAE: 5074.3022, NMAE: 77.3619, R^2: -0.1447\n",
      "Epoch [169/2000]\n",
      "Train Loss: 44233259.6931\n",
      "Val Loss: 41759155.3763, MAE: 5073.2339, NMAE: 77.3456, R^2: -0.1424\n",
      "Epoch [170/2000]\n",
      "Train Loss: 44133532.5172\n",
      "Val Loss: 41676190.9722, MAE: 5072.1987, NMAE: 77.3298, R^2: -0.1401\n",
      "Epoch [171/2000]\n",
      "Train Loss: 44035007.1034\n",
      "Val Loss: 41594351.3083, MAE: 5071.2051, NMAE: 77.3147, R^2: -0.1379\n",
      "Epoch [172/2000]\n",
      "Train Loss: 43937657.7095\n",
      "Val Loss: 41513579.6554, MAE: 5070.2388, NMAE: 77.2999, R^2: -0.1357\n",
      "Epoch [173/2000]\n",
      "Train Loss: 43841466.7569\n",
      "Val Loss: 41433879.5505, MAE: 5069.3018, NMAE: 77.2857, R^2: -0.1335\n",
      "Epoch [174/2000]\n",
      "Train Loss: 43746410.0241\n",
      "Val Loss: 41355233.3102, MAE: 5068.3936, NMAE: 77.2718, R^2: -0.1313\n",
      "Epoch [175/2000]\n",
      "Train Loss: 43652501.3397\n",
      "Val Loss: 41277655.6118, MAE: 5067.5161, NMAE: 77.2584, R^2: -0.1292\n",
      "Epoch [176/2000]\n",
      "Train Loss: 43559722.3181\n",
      "Val Loss: 41201106.9819, MAE: 5066.6733, NMAE: 77.2456, R^2: -0.1271\n",
      "Epoch [177/2000]\n",
      "Train Loss: 43468067.2957\n",
      "Val Loss: 41125604.0425, MAE: 5065.8599, NMAE: 77.2332, R^2: -0.1251\n",
      "Epoch [178/2000]\n",
      "Train Loss: 43377522.6069\n",
      "Val Loss: 41051112.9547, MAE: 5065.0859, NMAE: 77.2214, R^2: -0.1230\n",
      "Epoch [179/2000]\n",
      "Train Loss: 43288064.6293\n",
      "Val Loss: 40977636.7573, MAE: 5064.3472, NMAE: 77.2101, R^2: -0.1210\n",
      "Epoch [180/2000]\n",
      "Train Loss: 43199712.6948\n",
      "Val Loss: 40905177.3448, MAE: 5063.6338, NMAE: 77.1993, R^2: -0.1190\n",
      "Epoch [181/2000]\n",
      "Train Loss: 43112449.6353\n",
      "Val Loss: 40833704.8312, MAE: 5062.9512, NMAE: 77.1888, R^2: -0.1171\n",
      "Epoch [182/2000]\n",
      "Train Loss: 43026258.3983\n",
      "Val Loss: 40763231.9730, MAE: 5062.3047, NMAE: 77.1790, R^2: -0.1151\n",
      "Epoch [183/2000]\n",
      "Train Loss: 42941110.1362\n",
      "Val Loss: 40693692.9788, MAE: 5061.6846, NMAE: 77.1695, R^2: -0.1132\n",
      "Epoch [184/2000]\n",
      "Train Loss: 42857016.2164\n",
      "Val Loss: 40625138.4605, MAE: 5061.0972, NMAE: 77.1606, R^2: -0.1114\n",
      "Epoch [185/2000]\n",
      "Train Loss: 42773963.9672\n",
      "Val Loss: 40557542.7956, MAE: 5060.5396, NMAE: 77.1521, R^2: -0.1095\n",
      "Epoch [186/2000]\n",
      "Train Loss: 42691948.5526\n",
      "Val Loss: 40490895.5132, MAE: 5060.0190, NMAE: 77.1441, R^2: -0.1077\n",
      "Epoch [187/2000]\n",
      "Train Loss: 42610960.6276\n",
      "Val Loss: 40425179.6844, MAE: 5059.5337, NMAE: 77.1367, R^2: -0.1059\n",
      "Epoch [188/2000]\n",
      "Train Loss: 42530968.2086\n",
      "Val Loss: 40360369.8832, MAE: 5059.0879, NMAE: 77.1299, R^2: -0.1041\n",
      "Epoch [189/2000]\n",
      "Train Loss: 42451978.9216\n",
      "Val Loss: 40296482.3450, MAE: 5058.6729, NMAE: 77.1236, R^2: -0.1024\n",
      "Epoch [190/2000]\n",
      "Train Loss: 42373980.3922\n",
      "Val Loss: 40233503.0639, MAE: 5058.2964, NMAE: 77.1179, R^2: -0.1006\n",
      "Epoch [191/2000]\n",
      "Train Loss: 42296956.8931\n",
      "Val Loss: 40171406.3022, MAE: 5057.9585, NMAE: 77.1127, R^2: -0.0989\n",
      "Epoch [192/2000]\n",
      "Train Loss: 42220904.1276\n",
      "Val Loss: 40110199.2919, MAE: 5057.6543, NMAE: 77.1081, R^2: -0.0973\n",
      "Epoch [193/2000]\n",
      "Train Loss: 42145816.6336\n",
      "Val Loss: 40049873.9793, MAE: 5057.3799, NMAE: 77.1039, R^2: -0.0956\n",
      "Epoch [194/2000]\n",
      "Train Loss: 42071678.6724\n",
      "Val Loss: 39990404.1166, MAE: 5057.1401, NMAE: 77.1003, R^2: -0.0940\n",
      "Epoch [195/2000]\n",
      "Train Loss: 41998490.2284\n",
      "Val Loss: 39931817.8752, MAE: 5056.9248, NMAE: 77.0970, R^2: -0.0924\n",
      "Epoch [196/2000]\n",
      "Train Loss: 41926246.6897\n",
      "Val Loss: 39874063.0492, MAE: 5056.7363, NMAE: 77.0941, R^2: -0.0908\n",
      "Epoch [197/2000]\n",
      "Train Loss: 41854911.7362\n",
      "Val Loss: 39817135.1183, MAE: 5056.5703, NMAE: 77.0916, R^2: -0.0893\n",
      "Epoch [198/2000]\n",
      "Train Loss: 41784500.1776\n",
      "Val Loss: 39761065.6308, MAE: 5056.4258, NMAE: 77.0894, R^2: -0.0877\n",
      "Epoch [199/2000]\n",
      "Train Loss: 41714991.2052\n",
      "Val Loss: 39705792.5829, MAE: 5056.2959, NMAE: 77.0874, R^2: -0.0862\n",
      "Epoch [200/2000]\n",
      "Train Loss: 41646370.2302\n",
      "Val Loss: 39651325.2604, MAE: 5056.1812, NMAE: 77.0856, R^2: -0.0847\n",
      "Epoch [201/2000]\n",
      "Train Loss: 41578638.2974\n",
      "Val Loss: 39597672.4793, MAE: 5056.0933, NMAE: 77.0843, R^2: -0.0833\n",
      "Epoch [202/2000]\n",
      "Train Loss: 41511781.5284\n",
      "Val Loss: 39544811.8199, MAE: 5056.0278, NMAE: 77.0833, R^2: -0.0818\n",
      "Epoch [203/2000]\n",
      "Train Loss: 41445801.4759\n",
      "Val Loss: 39492725.4067, MAE: 5055.9893, NMAE: 77.0827, R^2: -0.0804\n",
      "Epoch [204/2000]\n",
      "Train Loss: 41380677.9405\n",
      "Val Loss: 39441427.2310, MAE: 5055.9839, NMAE: 77.0826, R^2: -0.0790\n",
      "Epoch [205/2000]\n",
      "Train Loss: 41316403.6991\n",
      "Val Loss: 39390889.4672, MAE: 5055.9990, NMAE: 77.0829, R^2: -0.0776\n",
      "Epoch [206/2000]\n",
      "Train Loss: 41252973.6147\n",
      "Val Loss: 39341103.8839, MAE: 5056.0381, NMAE: 77.0834, R^2: -0.0762\n",
      "Epoch [207/2000]\n",
      "Train Loss: 41190364.0603\n",
      "Val Loss: 39292062.7906, MAE: 5056.0952, NMAE: 77.0843, R^2: -0.0749\n",
      "Epoch [208/2000]\n",
      "Train Loss: 41128581.8784\n",
      "Val Loss: 39243773.5091, MAE: 5056.1714, NMAE: 77.0855, R^2: -0.0736\n",
      "Epoch [209/2000]\n",
      "Train Loss: 41067617.8828\n",
      "Val Loss: 39196209.3674, MAE: 5056.2700, NMAE: 77.0870, R^2: -0.0723\n",
      "Epoch [210/2000]\n",
      "Train Loss: 41007449.8879\n",
      "Val Loss: 39149350.2703, MAE: 5056.3911, NMAE: 77.0888, R^2: -0.0710\n",
      "Epoch [211/2000]\n",
      "Train Loss: 40948071.7888\n",
      "Val Loss: 39103219.0324, MAE: 5056.5298, NMAE: 77.0909, R^2: -0.0697\n",
      "Epoch [212/2000]\n",
      "Train Loss: 40889492.4457\n",
      "Val Loss: 39057786.4180, MAE: 5056.6836, NMAE: 77.0933, R^2: -0.0685\n",
      "Epoch [213/2000]\n",
      "Train Loss: 40831678.1517\n",
      "Val Loss: 39013044.1395, MAE: 5056.8486, NMAE: 77.0958, R^2: -0.0673\n",
      "Epoch [214/2000]\n",
      "Train Loss: 40774633.4810\n",
      "Val Loss: 38968991.7573, MAE: 5057.0234, NMAE: 77.0985, R^2: -0.0661\n",
      "Epoch [215/2000]\n",
      "Train Loss: 40718361.4371\n",
      "Val Loss: 38925629.9495, MAE: 5057.2114, NMAE: 77.1013, R^2: -0.0649\n",
      "Epoch [216/2000]\n",
      "Train Loss: 40662843.2017\n",
      "Val Loss: 38882929.9698, MAE: 5057.4175, NMAE: 77.1045, R^2: -0.0637\n",
      "Epoch [217/2000]\n",
      "Train Loss: 40608056.1879\n",
      "Val Loss: 38840885.2876, MAE: 5057.6416, NMAE: 77.1079, R^2: -0.0626\n",
      "Epoch [218/2000]\n",
      "Train Loss: 40554008.5017\n",
      "Val Loss: 38799505.0246, MAE: 5057.8818, NMAE: 77.1116, R^2: -0.0614\n",
      "Epoch [219/2000]\n",
      "Train Loss: 40500696.9431\n",
      "Val Loss: 38758781.9672, MAE: 5058.1440, NMAE: 77.1156, R^2: -0.0603\n",
      "Epoch [220/2000]\n",
      "Train Loss: 40448097.2353\n",
      "Val Loss: 38718669.7807, MAE: 5058.4199, NMAE: 77.1198, R^2: -0.0592\n",
      "Epoch [221/2000]\n",
      "Train Loss: 40396203.2147\n",
      "Val Loss: 38679205.7275, MAE: 5058.7139, NMAE: 77.1242, R^2: -0.0581\n",
      "Epoch [222/2000]\n",
      "Train Loss: 40345006.0362\n",
      "Val Loss: 38640349.8320, MAE: 5059.0151, NMAE: 77.1288, R^2: -0.0571\n",
      "Epoch [223/2000]\n",
      "Train Loss: 40294510.7328\n",
      "Val Loss: 38602116.7552, MAE: 5059.3281, NMAE: 77.1336, R^2: -0.0560\n",
      "Epoch [224/2000]\n",
      "Train Loss: 40244707.5759\n",
      "Val Loss: 38564498.7612, MAE: 5059.6611, NMAE: 77.1387, R^2: -0.0550\n",
      "Epoch [225/2000]\n",
      "Train Loss: 40195585.9802\n",
      "Val Loss: 38527473.2992, MAE: 5060.0161, NMAE: 77.1441, R^2: -0.0540\n",
      "Epoch [226/2000]\n",
      "Train Loss: 40147128.8595\n",
      "Val Loss: 38491041.9387, MAE: 5060.3843, NMAE: 77.1497, R^2: -0.0530\n",
      "Epoch [227/2000]\n",
      "Train Loss: 40099334.0448\n",
      "Val Loss: 38455188.6762, MAE: 5060.7710, NMAE: 77.1556, R^2: -0.0520\n",
      "Epoch [228/2000]\n",
      "Train Loss: 40052190.3172\n",
      "Val Loss: 38419911.3156, MAE: 5061.1758, NMAE: 77.1618, R^2: -0.0510\n",
      "Epoch [229/2000]\n",
      "Train Loss: 40005695.4216\n",
      "Val Loss: 38385209.0151, MAE: 5061.5947, NMAE: 77.1682, R^2: -0.0501\n",
      "Epoch [230/2000]\n",
      "Train Loss: 39959833.8405\n",
      "Val Loss: 38351051.2012, MAE: 5062.0269, NMAE: 77.1748, R^2: -0.0492\n",
      "Epoch [231/2000]\n",
      "Train Loss: 39914599.7103\n",
      "Val Loss: 38317455.6770, MAE: 5062.4624, NMAE: 77.1814, R^2: -0.0482\n",
      "Epoch [232/2000]\n",
      "Train Loss: 39869998.1509\n",
      "Val Loss: 38284414.3441, MAE: 5062.9092, NMAE: 77.1882, R^2: -0.0473\n",
      "Epoch [233/2000]\n",
      "Train Loss: 39826014.5198\n",
      "Val Loss: 38251906.8092, MAE: 5063.3638, NMAE: 77.1951, R^2: -0.0464\n",
      "Epoch [234/2000]\n",
      "Train Loss: 39782628.6776\n",
      "Val Loss: 38219923.9180, MAE: 5063.8311, NMAE: 77.2023, R^2: -0.0456\n",
      "Epoch [235/2000]\n",
      "Train Loss: 39739849.3888\n",
      "Val Loss: 38188476.9767, MAE: 5064.3052, NMAE: 77.2095, R^2: -0.0447\n",
      "Epoch [236/2000]\n",
      "Train Loss: 39697672.4526\n",
      "Val Loss: 38157548.7642, MAE: 5064.7871, NMAE: 77.2168, R^2: -0.0439\n",
      "Epoch [237/2000]\n",
      "Train Loss: 39656077.7388\n",
      "Val Loss: 38127127.7513, MAE: 5065.2793, NMAE: 77.2243, R^2: -0.0430\n",
      "Epoch [238/2000]\n",
      "Train Loss: 39615053.9621\n",
      "Val Loss: 38097201.4732, MAE: 5065.7788, NMAE: 77.2320, R^2: -0.0422\n",
      "Epoch [239/2000]\n",
      "Train Loss: 39574607.4586\n",
      "Val Loss: 38067785.0181, MAE: 5066.2915, NMAE: 77.2398, R^2: -0.0414\n",
      "Epoch [240/2000]\n",
      "Train Loss: 39534729.6621\n",
      "Val Loss: 38038859.7807, MAE: 5066.8096, NMAE: 77.2477, R^2: -0.0406\n",
      "Epoch [241/2000]\n",
      "Train Loss: 39495412.2310\n",
      "Val Loss: 38010416.5751, MAE: 5067.3345, NMAE: 77.2557, R^2: -0.0398\n",
      "Epoch [242/2000]\n",
      "Train Loss: 39456649.2647\n",
      "Val Loss: 37982456.9503, MAE: 5067.8657, NMAE: 77.2638, R^2: -0.0391\n",
      "Epoch [243/2000]\n",
      "Train Loss: 39418425.6112\n",
      "Val Loss: 37954958.5898, MAE: 5068.4043, NMAE: 77.2720, R^2: -0.0383\n",
      "Epoch [244/2000]\n",
      "Train Loss: 39380741.6345\n",
      "Val Loss: 37927929.6071, MAE: 5068.9517, NMAE: 77.2803, R^2: -0.0376\n",
      "Epoch [245/2000]\n",
      "Train Loss: 39343580.6595\n",
      "Val Loss: 37901351.3187, MAE: 5069.5068, NMAE: 77.2888, R^2: -0.0368\n",
      "Epoch [246/2000]\n",
      "Train Loss: 39306952.6328\n",
      "Val Loss: 37875234.9072, MAE: 5070.0728, NMAE: 77.2974, R^2: -0.0361\n",
      "Epoch [247/2000]\n",
      "Train Loss: 39270840.3129\n",
      "Val Loss: 37849557.7655, MAE: 5070.6411, NMAE: 77.3061, R^2: -0.0354\n",
      "Epoch [248/2000]\n",
      "Train Loss: 39235238.6655\n",
      "Val Loss: 37824320.5078, MAE: 5071.2144, NMAE: 77.3148, R^2: -0.0347\n",
      "Epoch [249/2000]\n",
      "Train Loss: 39200142.8517\n",
      "Val Loss: 37799521.4581, MAE: 5071.7939, NMAE: 77.3237, R^2: -0.0341\n",
      "Epoch [250/2000]\n",
      "Train Loss: 39165547.1750\n",
      "Val Loss: 37775151.6541, MAE: 5072.3882, NMAE: 77.3327, R^2: -0.0334\n",
      "Epoch [251/2000]\n",
      "Train Loss: 39131439.8810\n",
      "Val Loss: 37751184.3921, MAE: 5072.9897, NMAE: 77.3419, R^2: -0.0327\n",
      "Epoch [252/2000]\n",
      "Train Loss: 39097816.8198\n",
      "Val Loss: 37727650.3946, MAE: 5073.5981, NMAE: 77.3512, R^2: -0.0321\n",
      "Epoch [253/2000]\n",
      "Train Loss: 39064675.3517\n",
      "Val Loss: 37704517.4482, MAE: 5074.2153, NMAE: 77.3606, R^2: -0.0315\n",
      "Epoch [254/2000]\n",
      "Train Loss: 39032006.5026\n",
      "Val Loss: 37681788.7310, MAE: 5074.8394, NMAE: 77.3701, R^2: -0.0308\n",
      "Epoch [255/2000]\n",
      "Train Loss: 38999808.3621\n",
      "Val Loss: 37659462.6792, MAE: 5075.4697, NMAE: 77.3797, R^2: -0.0302\n",
      "Epoch [256/2000]\n",
      "Train Loss: 38968064.5871\n",
      "Val Loss: 37637519.9231, MAE: 5076.1040, NMAE: 77.3894, R^2: -0.0296\n",
      "Epoch [257/2000]\n",
      "Train Loss: 38936783.3190\n",
      "Val Loss: 37615972.7073, MAE: 5076.7417, NMAE: 77.3991, R^2: -0.0290\n",
      "Epoch [258/2000]\n",
      "Train Loss: 38905945.8207\n",
      "Val Loss: 37594792.9080, MAE: 5077.3857, NMAE: 77.4089, R^2: -0.0285\n",
      "Epoch [259/2000]\n",
      "Train Loss: 38875539.5440\n",
      "Val Loss: 37573988.1196, MAE: 5078.0327, NMAE: 77.4188, R^2: -0.0279\n",
      "Epoch [260/2000]\n",
      "Train Loss: 38845583.5647\n",
      "Val Loss: 37553566.4724, MAE: 5078.6797, NMAE: 77.4286, R^2: -0.0273\n",
      "Epoch [261/2000]\n",
      "Train Loss: 38816061.5017\n",
      "Val Loss: 37533499.9940, MAE: 5079.3354, NMAE: 77.4386, R^2: -0.0268\n",
      "Epoch [262/2000]\n",
      "Train Loss: 38786958.3259\n",
      "Val Loss: 37513796.6619, MAE: 5079.9966, NMAE: 77.4487, R^2: -0.0262\n",
      "Epoch [263/2000]\n",
      "Train Loss: 38758283.4871\n",
      "Val Loss: 37494442.8951, MAE: 5080.6602, NMAE: 77.4588, R^2: -0.0257\n",
      "Epoch [264/2000]\n",
      "Train Loss: 38730017.0802\n",
      "Val Loss: 37475442.4184, MAE: 5081.3291, NMAE: 77.4690, R^2: -0.0252\n",
      "Epoch [265/2000]\n",
      "Train Loss: 38702163.3448\n",
      "Val Loss: 37456783.8312, MAE: 5082.0029, NMAE: 77.4793, R^2: -0.0247\n",
      "Epoch [266/2000]\n",
      "Train Loss: 38674716.6060\n",
      "Val Loss: 37438463.1006, MAE: 5082.6821, NMAE: 77.4897, R^2: -0.0242\n",
      "Epoch [267/2000]\n",
      "Train Loss: 38647663.8526\n",
      "Val Loss: 37420472.4823, MAE: 5083.3687, NMAE: 77.5001, R^2: -0.0237\n",
      "Epoch [268/2000]\n",
      "Train Loss: 38620997.8069\n",
      "Val Loss: 37402806.2720, MAE: 5084.0566, NMAE: 77.5106, R^2: -0.0232\n",
      "Epoch [269/2000]\n",
      "Train Loss: 38594726.5560\n",
      "Val Loss: 37385472.7129, MAE: 5084.7524, NMAE: 77.5212, R^2: -0.0227\n",
      "Epoch [270/2000]\n",
      "Train Loss: 38568831.4672\n",
      "Val Loss: 37368446.0501, MAE: 5085.4556, NMAE: 77.5319, R^2: -0.0223\n",
      "Epoch [271/2000]\n",
      "Train Loss: 38543324.7181\n",
      "Val Loss: 37351749.8139, MAE: 5086.1650, NMAE: 77.5428, R^2: -0.0218\n",
      "Epoch [272/2000]\n",
      "Train Loss: 38518189.2000\n",
      "Val Loss: 37335354.4383, MAE: 5086.8818, NMAE: 77.5537, R^2: -0.0214\n",
      "Epoch [273/2000]\n",
      "Train Loss: 38493420.4250\n",
      "Val Loss: 37319262.4737, MAE: 5087.6016, NMAE: 77.5647, R^2: -0.0209\n",
      "Epoch [274/2000]\n",
      "Train Loss: 38469008.9267\n",
      "Val Loss: 37303467.5553, MAE: 5088.3281, NMAE: 77.5757, R^2: -0.0205\n",
      "Epoch [275/2000]\n",
      "Train Loss: 38444956.4793\n",
      "Val Loss: 37287969.8299, MAE: 5089.0557, NMAE: 77.5868, R^2: -0.0201\n",
      "Epoch [276/2000]\n",
      "Train Loss: 38421264.8224\n",
      "Val Loss: 37272768.9538, MAE: 5089.7847, NMAE: 77.5979, R^2: -0.0197\n",
      "Epoch [277/2000]\n",
      "Train Loss: 38397914.7302\n",
      "Val Loss: 37257845.5255, MAE: 5090.5137, NMAE: 77.6091, R^2: -0.0192\n",
      "Epoch [278/2000]\n",
      "Train Loss: 38374908.9466\n",
      "Val Loss: 37243212.4767, MAE: 5091.2456, NMAE: 77.6202, R^2: -0.0188\n",
      "Epoch [279/2000]\n",
      "Train Loss: 38352238.9250\n",
      "Val Loss: 37228840.7655, MAE: 5091.9805, NMAE: 77.6314, R^2: -0.0185\n",
      "Epoch [280/2000]\n",
      "Train Loss: 38329895.4879\n",
      "Val Loss: 37214753.4728, MAE: 5092.7207, NMAE: 77.6427, R^2: -0.0181\n",
      "Epoch [281/2000]\n",
      "Train Loss: 38307886.2129\n",
      "Val Loss: 37200930.4309, MAE: 5093.4653, NMAE: 77.6541, R^2: -0.0177\n",
      "Epoch [282/2000]\n",
      "Train Loss: 38286197.5190\n",
      "Val Loss: 37187367.7871, MAE: 5094.2119, NMAE: 77.6654, R^2: -0.0173\n",
      "Epoch [283/2000]\n",
      "Train Loss: 38264831.2250\n",
      "Val Loss: 37174072.6364, MAE: 5094.9585, NMAE: 77.6768, R^2: -0.0170\n",
      "Epoch [284/2000]\n",
      "Train Loss: 38243779.8474\n",
      "Val Loss: 37161029.8066, MAE: 5095.7065, NMAE: 77.6882, R^2: -0.0166\n",
      "Epoch [285/2000]\n",
      "Train Loss: 38223038.2578\n",
      "Val Loss: 37148238.3895, MAE: 5096.4600, NMAE: 77.6997, R^2: -0.0162\n",
      "Epoch [286/2000]\n",
      "Train Loss: 38202603.0629\n",
      "Val Loss: 37135697.4983, MAE: 5097.2153, NMAE: 77.7112, R^2: -0.0159\n",
      "Epoch [287/2000]\n",
      "Train Loss: 38182471.3362\n",
      "Val Loss: 37123400.7409, MAE: 5097.9731, NMAE: 77.7228, R^2: -0.0156\n",
      "Epoch [288/2000]\n",
      "Train Loss: 38162646.8216\n",
      "Val Loss: 37111351.2517, MAE: 5098.7334, NMAE: 77.7344, R^2: -0.0152\n",
      "Epoch [289/2000]\n",
      "Train Loss: 38143114.2026\n",
      "Val Loss: 37099532.1848, MAE: 5099.4971, NMAE: 77.7460, R^2: -0.0149\n",
      "Epoch [290/2000]\n",
      "Train Loss: 38123860.6948\n",
      "Val Loss: 37087942.4598, MAE: 5100.2637, NMAE: 77.7577, R^2: -0.0146\n",
      "Epoch [291/2000]\n",
      "Train Loss: 38104900.2586\n",
      "Val Loss: 37076588.5060, MAE: 5101.0308, NMAE: 77.7694, R^2: -0.0143\n",
      "Epoch [292/2000]\n",
      "Train Loss: 38086219.8267\n",
      "Val Loss: 37065452.1166, MAE: 5101.7998, NMAE: 77.7811, R^2: -0.0140\n",
      "Epoch [293/2000]\n",
      "Train Loss: 38067812.1302\n",
      "Val Loss: 37054541.4693, MAE: 5102.5698, NMAE: 77.7929, R^2: -0.0137\n",
      "Epoch [294/2000]\n",
      "Train Loss: 38049690.6526\n",
      "Val Loss: 37043856.3014, MAE: 5103.3438, NMAE: 77.8047, R^2: -0.0134\n",
      "Epoch [295/2000]\n",
      "Train Loss: 38031834.2034\n",
      "Val Loss: 37033376.2142, MAE: 5104.1196, NMAE: 77.8165, R^2: -0.0131\n",
      "Epoch [296/2000]\n",
      "Train Loss: 38014241.2371\n",
      "Val Loss: 37023113.5013, MAE: 5104.8994, NMAE: 77.8284, R^2: -0.0128\n",
      "Epoch [297/2000]\n",
      "Train Loss: 37996910.1948\n",
      "Val Loss: 37013051.8597, MAE: 5105.6812, NMAE: 77.8403, R^2: -0.0125\n",
      "Epoch [298/2000]\n",
      "Train Loss: 37979836.5103\n",
      "Val Loss: 37003201.8886, MAE: 5106.4609, NMAE: 77.8522, R^2: -0.0123\n",
      "Epoch [299/2000]\n",
      "Train Loss: 37963018.9371\n",
      "Val Loss: 36993544.6442, MAE: 5107.2397, NMAE: 77.8641, R^2: -0.0120\n",
      "Epoch [300/2000]\n",
      "Train Loss: 37946451.9069\n",
      "Val Loss: 36984093.3752, MAE: 5108.0186, NMAE: 77.8759, R^2: -0.0118\n",
      "Epoch [301/2000]\n",
      "Train Loss: 37930134.5216\n",
      "Val Loss: 36974831.7824, MAE: 5108.7993, NMAE: 77.8878, R^2: -0.0115\n",
      "Epoch [302/2000]\n",
      "Train Loss: 37914060.9905\n",
      "Val Loss: 36965766.4603, MAE: 5109.5796, NMAE: 77.8997, R^2: -0.0113\n",
      "Epoch [303/2000]\n",
      "Train Loss: 37898233.2284\n",
      "Val Loss: 36956887.6269, MAE: 5110.3584, NMAE: 77.9116, R^2: -0.0110\n",
      "Epoch [304/2000]\n",
      "Train Loss: 37882632.3655\n",
      "Val Loss: 36948187.8761, MAE: 5111.1377, NMAE: 77.9235, R^2: -0.0108\n",
      "Epoch [305/2000]\n",
      "Train Loss: 37867272.5052\n",
      "Val Loss: 36939681.5147, MAE: 5111.9155, NMAE: 77.9353, R^2: -0.0105\n",
      "Epoch [306/2000]\n",
      "Train Loss: 37852147.2974\n",
      "Val Loss: 36931350.0160, MAE: 5112.6938, NMAE: 77.9472, R^2: -0.0103\n",
      "Epoch [307/2000]\n",
      "Train Loss: 37837244.2483\n",
      "Val Loss: 36923192.1382, MAE: 5113.4717, NMAE: 77.9591, R^2: -0.0101\n",
      "Epoch [308/2000]\n",
      "Train Loss: 37822568.0879\n",
      "Val Loss: 36915212.4028, MAE: 5114.2485, NMAE: 77.9709, R^2: -0.0099\n",
      "Epoch [309/2000]\n",
      "Train Loss: 37808113.5888\n",
      "Val Loss: 36907398.4339, MAE: 5115.0264, NMAE: 77.9828, R^2: -0.0097\n",
      "Epoch [310/2000]\n",
      "Train Loss: 37793873.1526\n",
      "Val Loss: 36899753.5950, MAE: 5115.8071, NMAE: 77.9947, R^2: -0.0094\n",
      "Epoch [311/2000]\n",
      "Train Loss: 37779847.0879\n",
      "Val Loss: 36892273.8355, MAE: 5116.5884, NMAE: 78.0066, R^2: -0.0092\n",
      "Epoch [312/2000]\n",
      "Train Loss: 37766036.2414\n",
      "Val Loss: 36884957.1818, MAE: 5117.3701, NMAE: 78.0185, R^2: -0.0090\n",
      "Epoch [313/2000]\n",
      "Train Loss: 37752435.9853\n",
      "Val Loss: 36877801.9521, MAE: 5118.1509, NMAE: 78.0304, R^2: -0.0088\n",
      "Epoch [314/2000]\n",
      "Train Loss: 37739036.8526\n",
      "Val Loss: 36870798.2841, MAE: 5118.9277, NMAE: 78.0423, R^2: -0.0087\n",
      "Epoch [315/2000]\n",
      "Train Loss: 37725840.2241\n",
      "Val Loss: 36863949.4668, MAE: 5119.7007, NMAE: 78.0540, R^2: -0.0085\n",
      "Epoch [316/2000]\n",
      "Train Loss: 37712842.2026\n",
      "Val Loss: 36857255.2008, MAE: 5120.4731, NMAE: 78.0658, R^2: -0.0083\n",
      "Epoch [317/2000]\n",
      "Train Loss: 37700041.0466\n",
      "Val Loss: 36850704.0177, MAE: 5121.2451, NMAE: 78.0776, R^2: -0.0081\n",
      "Epoch [318/2000]\n",
      "Train Loss: 37690651.3871\n",
      "Val Loss: 36844300.4076, MAE: 5122.0171, NMAE: 78.0894, R^2: -0.0079\n",
      "Epoch [319/2000]\n",
      "Train Loss: 37675013.0353\n",
      "Val Loss: 36838041.3299, MAE: 5122.7881, NMAE: 78.1011, R^2: -0.0078\n",
      "Epoch [320/2000]\n",
      "Train Loss: 37662782.3862\n",
      "Val Loss: 36831924.0691, MAE: 5123.5552, NMAE: 78.1128, R^2: -0.0076\n",
      "Epoch [321/2000]\n",
      "Train Loss: 37747369.2897\n",
      "Val Loss: 36905534.4188, MAE: 5114.2446, NMAE: 77.9709, R^2: -0.0096\n",
      "Epoch [322/2000]\n",
      "Train Loss: 37796657.4431\n",
      "Val Loss: 36897656.2897, MAE: 5115.0171, NMAE: 77.9826, R^2: -0.0094\n",
      "Epoch [323/2000]\n",
      "Train Loss: 37791924.1388\n",
      "Val Loss: 36889778.6528, MAE: 5115.7852, NMAE: 77.9943, R^2: -0.0092\n",
      "Epoch [324/2000]\n",
      "Train Loss: 37856202.7121\n",
      "Val Loss: 36877329.7889, MAE: 5115.9668, NMAE: 77.9971, R^2: -0.0088\n",
      "Epoch [325/2000]\n",
      "Train Loss: 37915950.6931\n",
      "Val Loss: 36954325.3851, MAE: 5107.3252, NMAE: 77.8654, R^2: -0.0109\n",
      "Epoch [326/2000]\n",
      "Train Loss: 38027351.3698\n",
      "Val Loss: 37061659.4732, MAE: 5099.4404, NMAE: 77.7452, R^2: -0.0139\n",
      "Epoch [327/2000]\n",
      "Train Loss: 38105740.7060\n",
      "Val Loss: 36779057.7388, MAE: 5127.7832, NMAE: 78.1773, R^2: -0.0061\n",
      "Epoch [328/2000]\n",
      "Train Loss: 37560443.4319\n",
      "Val Loss: 36782940.5574, MAE: 5130.0210, NMAE: 78.2114, R^2: -0.0063\n",
      "Epoch [329/2000]\n",
      "Train Loss: 37792862.4948\n",
      "Val Loss: 36784607.8044, MAE: 5110.3164, NMAE: 77.9110, R^2: -0.0063\n",
      "Epoch [330/2000]\n",
      "Train Loss: 37918100.3414\n",
      "Val Loss: 36987017.7418, MAE: 5100.6885, NMAE: 77.7642, R^2: -0.0118\n",
      "Epoch [331/2000]\n",
      "Train Loss: 37777194.6241\n",
      "Val Loss: 36833701.1563, MAE: 5121.7783, NMAE: 78.0857, R^2: -0.0076\n",
      "Epoch [332/2000]\n",
      "Train Loss: 38034013.9793\n",
      "Val Loss: 37107627.7310, MAE: 5094.3726, NMAE: 77.6679, R^2: -0.0151\n",
      "Epoch [333/2000]\n",
      "Train Loss: 38179049.2043\n",
      "Val Loss: 36988475.7405, MAE: 5103.7202, NMAE: 77.8104, R^2: -0.0119\n",
      "Epoch [334/2000]\n",
      "Train Loss: 38336028.4345\n",
      "Val Loss: 37371525.2552, MAE: 5081.0830, NMAE: 77.4653, R^2: -0.0224\n",
      "Epoch [335/2000]\n",
      "Train Loss: 38651164.9905\n",
      "Val Loss: 37290744.5613, MAE: 5069.4077, NMAE: 77.2873, R^2: -0.0201\n",
      "Epoch [336/2000]\n",
      "Train Loss: 38760532.6017\n",
      "Val Loss: 37396459.2599, MAE: 5072.3765, NMAE: 77.3325, R^2: -0.0230\n",
      "Epoch [337/2000]\n",
      "Train Loss: 38685747.9966\n",
      "Val Loss: 37306958.0872, MAE: 5078.2002, NMAE: 77.4213, R^2: -0.0206\n",
      "Epoch [338/2000]\n",
      "Train Loss: 38609055.9776\n",
      "Val Loss: 37312837.4257, MAE: 5082.9097, NMAE: 77.4931, R^2: -0.0207\n",
      "Epoch [339/2000]\n",
      "Train Loss: 38304955.7147\n",
      "Val Loss: 37047761.5255, MAE: 5099.0815, NMAE: 77.7397, R^2: -0.0135\n",
      "Epoch [340/2000]\n",
      "Train Loss: 38209408.7034\n",
      "Val Loss: 37159937.3761, MAE: 5091.5918, NMAE: 77.6255, R^2: -0.0166\n",
      "Epoch [341/2000]\n",
      "Train Loss: 38239928.7784\n",
      "Val Loss: 36934893.4737, MAE: 5097.2148, NMAE: 77.7112, R^2: -0.0104\n",
      "Epoch [342/2000]\n",
      "Train Loss: 38112435.9121\n",
      "Val Loss: 36916200.0281, MAE: 5087.1553, NMAE: 77.5579, R^2: -0.0099\n",
      "Epoch [343/2000]\n",
      "Train Loss: 38339862.9586\n",
      "Val Loss: 37402209.0220, MAE: 5078.0146, NMAE: 77.4185, R^2: -0.0232\n",
      "Epoch [344/2000]\n",
      "Train Loss: 38729348.3328\n",
      "Val Loss: 37522695.2742, MAE: 5071.4131, NMAE: 77.3179, R^2: -0.0265\n",
      "Epoch [345/2000]\n",
      "Train Loss: 38812917.6948\n",
      "Val Loss: 37427614.3087, MAE: 5069.1587, NMAE: 77.2835, R^2: -0.0239\n",
      "Epoch [346/2000]\n",
      "Train Loss: 38286880.2603\n",
      "Val Loss: 37011979.7884, MAE: 5089.5825, NMAE: 77.5949, R^2: -0.0125\n",
      "Epoch [347/2000]\n",
      "Train Loss: 37595933.7259\n",
      "Val Loss: 36663600.2858, MAE: 5128.0693, NMAE: 78.1816, R^2: -0.0030\n",
      "Epoch [348/2000]\n",
      "Train Loss: 37704265.0069\n",
      "Val Loss: 36825399.6598, MAE: 5109.9834, NMAE: 77.9059, R^2: -0.0074\n",
      "Epoch [349/2000]\n",
      "Train Loss: 37990763.5517\n",
      "Val Loss: 37048162.6231, MAE: 5095.4502, NMAE: 77.6843, R^2: -0.0135\n",
      "Epoch [350/2000]\n",
      "Train Loss: 38031894.1948\n",
      "Val Loss: 37037816.3571, MAE: 5095.6333, NMAE: 77.6871, R^2: -0.0132\n",
      "Epoch [351/2000]\n",
      "Train Loss: 38520499.3155\n",
      "Val Loss: 37487653.7677, MAE: 5074.2456, NMAE: 77.3610, R^2: -0.0255\n",
      "Epoch [352/2000]\n",
      "Train Loss: 38666189.5078\n",
      "Val Loss: 37038862.6278, MAE: 5072.0498, NMAE: 77.3276, R^2: -0.0133\n",
      "Epoch [353/2000]\n",
      "Train Loss: 38492587.3526\n",
      "Val Loss: 37277501.7388, MAE: 5078.1528, NMAE: 77.4206, R^2: -0.0198\n",
      "Epoch [354/2000]\n",
      "Train Loss: 39041889.0431\n",
      "Val Loss: 36909690.2504, MAE: 5051.5449, NMAE: 77.0149, R^2: -0.0097\n",
      "Epoch [355/2000]\n",
      "Train Loss: 38200788.2207\n",
      "Val Loss: 36624917.2470, MAE: 5068.5117, NMAE: 77.2736, R^2: -0.0019\n",
      "Epoch [356/2000]\n",
      "Train Loss: 38129399.7802\n",
      "Val Loss: 36551290.9465, MAE: 5060.4878, NMAE: 77.1513, R^2: 0.0001\n",
      "Epoch [357/2000]\n",
      "Train Loss: 38253959.2621\n",
      "Val Loss: 36799846.2150, MAE: 5021.3672, NMAE: 76.5549, R^2: -0.0067\n",
      "Epoch [358/2000]\n",
      "Train Loss: 37853812.9603\n",
      "Val Loss: 36531971.5354, MAE: 5055.3770, NMAE: 77.0734, R^2: 0.0006\n",
      "Epoch [359/2000]\n",
      "Train Loss: 37780339.4716\n",
      "Val Loss: 36527129.6118, MAE: 5032.6167, NMAE: 76.7264, R^2: 0.0007\n",
      "Epoch [360/2000]\n",
      "Train Loss: 37747874.5793\n",
      "Val Loss: 36392190.4162, MAE: 5037.3027, NMAE: 76.7978, R^2: 0.0044\n",
      "Epoch [361/2000]\n",
      "Train Loss: 37570086.3776\n",
      "Val Loss: 36333717.5419, MAE: 5070.4028, NMAE: 77.3025, R^2: 0.0060\n",
      "Epoch [362/2000]\n",
      "Train Loss: 37543117.4259\n",
      "Val Loss: 36345071.7047, MAE: 5046.4019, NMAE: 76.9365, R^2: 0.0057\n",
      "Epoch [363/2000]\n",
      "Train Loss: 37353924.7155\n",
      "Val Loss: 36274691.3420, MAE: 5071.1763, NMAE: 77.3142, R^2: 0.0077\n",
      "Epoch [364/2000]\n",
      "Train Loss: 37532575.0931\n",
      "Val Loss: 36233960.5225, MAE: 5067.7046, NMAE: 77.2613, R^2: 0.0088\n",
      "Epoch [365/2000]\n",
      "Train Loss: 37443449.3483\n",
      "Val Loss: 36277769.5246, MAE: 5080.4458, NMAE: 77.4556, R^2: 0.0076\n",
      "Epoch [366/2000]\n",
      "Train Loss: 37358949.9862\n",
      "Val Loss: 36351244.7953, MAE: 5095.1519, NMAE: 77.6798, R^2: 0.0056\n",
      "Epoch [367/2000]\n",
      "Train Loss: 37559512.2086\n",
      "Val Loss: 36331790.0695, MAE: 5093.7402, NMAE: 77.6582, R^2: 0.0061\n",
      "Epoch [368/2000]\n",
      "Train Loss: 37263916.7931\n",
      "Val Loss: 36570404.1282, MAE: 5122.9209, NMAE: 78.1031, R^2: -0.0004\n",
      "Epoch [369/2000]\n",
      "Train Loss: 37330245.7621\n",
      "Val Loss: 36494656.9633, MAE: 5100.5239, NMAE: 77.7617, R^2: 0.0016\n",
      "Epoch [370/2000]\n",
      "Train Loss: 37322405.4052\n",
      "Val Loss: 36043939.0656, MAE: 5078.2295, NMAE: 77.4218, R^2: 0.0140\n",
      "Epoch [371/2000]\n",
      "Train Loss: 37181860.1302\n",
      "Val Loss: 35803387.6015, MAE: 5068.7109, NMAE: 77.2767, R^2: 0.0205\n",
      "Epoch [372/2000]\n",
      "Train Loss: 37085912.6871\n",
      "Val Loss: 35834199.2940, MAE: 5045.5498, NMAE: 76.9235, R^2: 0.0197\n",
      "Epoch [373/2000]\n",
      "Train Loss: 38048666.3957\n",
      "Val Loss: 36268796.7150, MAE: 5010.3486, NMAE: 76.3869, R^2: 0.0078\n",
      "Epoch [374/2000]\n",
      "Train Loss: 37293155.9388\n",
      "Val Loss: 35761095.4171, MAE: 5016.7490, NMAE: 76.4845, R^2: 0.0217\n",
      "Epoch [375/2000]\n",
      "Train Loss: 37414211.6741\n",
      "Val Loss: 36070192.5717, MAE: 4979.0806, NMAE: 75.9102, R^2: 0.0132\n",
      "Epoch [376/2000]\n",
      "Train Loss: 37097620.2293\n",
      "Val Loss: 36040793.4275, MAE: 5080.2739, NMAE: 77.4529, R^2: 0.0141\n",
      "Epoch [377/2000]\n",
      "Train Loss: 36871345.8086\n",
      "Val Loss: 35976237.3320, MAE: 5083.9233, NMAE: 77.5086, R^2: 0.0158\n",
      "Epoch [378/2000]\n",
      "Train Loss: 36628217.0966\n",
      "Val Loss: 36166923.8592, MAE: 5124.7100, NMAE: 78.1304, R^2: 0.0106\n",
      "Epoch [379/2000]\n",
      "Train Loss: 36778809.7517\n",
      "Val Loss: 36054195.4771, MAE: 5102.0405, NMAE: 77.7848, R^2: 0.0137\n",
      "Epoch [380/2000]\n",
      "Train Loss: 37082482.4647\n",
      "Val Loss: 36074204.6485, MAE: 5055.9619, NMAE: 77.0823, R^2: 0.0131\n",
      "Epoch [381/2000]\n",
      "Train Loss: 37435866.3603\n",
      "Val Loss: 36130704.3800, MAE: 5049.2759, NMAE: 76.9804, R^2: 0.0116\n",
      "Epoch [382/2000]\n",
      "Train Loss: 37319867.2828\n",
      "Val Loss: 36151679.6049, MAE: 5068.6367, NMAE: 77.2755, R^2: 0.0110\n",
      "Epoch [383/2000]\n",
      "Train Loss: 37039220.8922\n",
      "Val Loss: 36260538.6701, MAE: 5092.0654, NMAE: 77.6327, R^2: 0.0080\n",
      "Epoch [384/2000]\n",
      "Train Loss: 36921357.7638\n",
      "Val Loss: 35989822.3756, MAE: 5087.9019, NMAE: 77.5692, R^2: 0.0154\n",
      "Epoch [385/2000]\n",
      "Train Loss: 37314674.8629\n",
      "Val Loss: 35918067.9106, MAE: 5034.0034, NMAE: 76.7475, R^2: 0.0174\n",
      "Epoch [386/2000]\n",
      "Train Loss: 37134698.0759\n",
      "Val Loss: 35825544.5311, MAE: 5070.7363, NMAE: 77.3075, R^2: 0.0199\n",
      "Epoch [387/2000]\n",
      "Train Loss: 36869754.6741\n",
      "Val Loss: 35832621.5453, MAE: 5065.6582, NMAE: 77.2301, R^2: 0.0197\n",
      "Epoch [388/2000]\n",
      "Train Loss: 37117254.2655\n",
      "Val Loss: 35793615.6874, MAE: 5000.7500, NMAE: 76.2405, R^2: 0.0208\n",
      "Epoch [389/2000]\n",
      "Train Loss: 37031454.0647\n",
      "Val Loss: 35852937.7953, MAE: 5053.2422, NMAE: 77.0408, R^2: 0.0192\n",
      "Epoch [390/2000]\n",
      "Train Loss: 37066390.0371\n",
      "Val Loss: 36138811.9063, MAE: 5059.5312, NMAE: 77.1367, R^2: 0.0114\n",
      "Epoch [391/2000]\n",
      "Train Loss: 36959883.6431\n",
      "Val Loss: 35912554.8152, MAE: 5037.6748, NMAE: 76.8035, R^2: 0.0176\n",
      "Epoch [392/2000]\n",
      "Train Loss: 37088424.3078\n",
      "Val Loss: 35740949.2586, MAE: 4990.1006, NMAE: 76.0782, R^2: 0.0223\n",
      "Epoch [393/2000]\n",
      "Train Loss: 37029620.1233\n",
      "Val Loss: 35811613.2094, MAE: 5028.2314, NMAE: 76.6595, R^2: 0.0203\n",
      "Epoch [394/2000]\n",
      "Train Loss: 36799409.8181\n",
      "Val Loss: 36250539.1844, MAE: 5106.0894, NMAE: 77.8465, R^2: 0.0083\n",
      "Epoch [395/2000]\n",
      "Train Loss: 37074709.3224\n",
      "Val Loss: 36463449.0773, MAE: 5114.5688, NMAE: 77.9758, R^2: 0.0025\n",
      "Epoch [396/2000]\n",
      "Train Loss: 37121713.1259\n",
      "Val Loss: 36401844.5151, MAE: 5112.2476, NMAE: 77.9404, R^2: 0.0042\n",
      "Epoch [397/2000]\n",
      "Train Loss: 36994665.9474\n",
      "Val Loss: 36288133.8644, MAE: 5116.8154, NMAE: 78.0100, R^2: 0.0073\n",
      "Epoch [398/2000]\n",
      "Train Loss: 36810445.1905\n",
      "Val Loss: 36055008.6904, MAE: 5087.3486, NMAE: 77.5608, R^2: 0.0137\n",
      "Epoch [399/2000]\n",
      "Train Loss: 36803850.0233\n",
      "Val Loss: 36076105.3549, MAE: 5084.5986, NMAE: 77.5189, R^2: 0.0131\n",
      "Epoch [400/2000]\n",
      "Train Loss: 37083617.5664\n",
      "Val Loss: 36293511.8381, MAE: 5052.9170, NMAE: 77.0359, R^2: 0.0071\n",
      "Epoch [401/2000]\n",
      "Train Loss: 37489752.2138\n",
      "Val Loss: 35853598.4715, MAE: 5004.4219, NMAE: 76.2965, R^2: 0.0192\n",
      "Epoch [402/2000]\n",
      "Train Loss: 37079454.2207\n",
      "Val Loss: 35646082.3640, MAE: 5034.5459, NMAE: 76.7558, R^2: 0.0248\n",
      "Epoch [403/2000]\n",
      "Train Loss: 36913280.4983\n",
      "Val Loss: 36127231.6451, MAE: 5095.1514, NMAE: 77.6798, R^2: 0.0117\n",
      "Epoch [404/2000]\n",
      "Train Loss: 37020468.5345\n",
      "Val Loss: 36204196.9352, MAE: 5068.3564, NMAE: 77.2713, R^2: 0.0096\n",
      "Epoch [405/2000]\n",
      "Train Loss: 37336741.3957\n",
      "Val Loss: 36502860.9918, MAE: 4992.2300, NMAE: 76.1106, R^2: 0.0014\n",
      "Epoch [406/2000]\n",
      "Train Loss: 37206012.1034\n",
      "Val Loss: 36069421.1511, MAE: 5068.6040, NMAE: 77.2750, R^2: 0.0133\n",
      "Epoch [407/2000]\n",
      "Train Loss: 36841721.7629\n",
      "Val Loss: 36185403.6943, MAE: 5060.5527, NMAE: 77.1523, R^2: 0.0101\n",
      "Epoch [408/2000]\n",
      "Train Loss: 36810468.8017\n",
      "Val Loss: 36129376.7129, MAE: 5078.1528, NMAE: 77.4206, R^2: 0.0116\n",
      "Epoch [409/2000]\n",
      "Train Loss: 36690477.3707\n",
      "Val Loss: 35859415.2107, MAE: 5059.3247, NMAE: 77.1336, R^2: 0.0190\n",
      "Epoch [410/2000]\n",
      "Train Loss: 36523816.9664\n",
      "Val Loss: 35831076.7168, MAE: 5076.2686, NMAE: 77.3919, R^2: 0.0198\n",
      "Epoch [411/2000]\n",
      "Train Loss: 36813260.2905\n",
      "Val Loss: 35535241.1429, MAE: 5001.4399, NMAE: 76.2511, R^2: 0.0279\n",
      "Epoch [412/2000]\n",
      "Train Loss: 37126180.7440\n",
      "Val Loss: 35437486.4231, MAE: 5008.3140, NMAE: 76.3559, R^2: 0.0306\n",
      "Epoch [413/2000]\n",
      "Train Loss: 36638203.2198\n",
      "Val Loss: 35499526.5769, MAE: 5021.7939, NMAE: 76.5614, R^2: 0.0289\n",
      "Epoch [414/2000]\n",
      "Train Loss: 36973153.8931\n",
      "Val Loss: 35653426.7090, MAE: 5019.0410, NMAE: 76.5194, R^2: 0.0246\n",
      "Epoch [415/2000]\n",
      "Train Loss: 36598425.3198\n",
      "Val Loss: 35453205.4322, MAE: 5048.2744, NMAE: 76.9651, R^2: 0.0301\n",
      "Epoch [416/2000]\n",
      "Train Loss: 36411338.5466\n",
      "Val Loss: 36083787.1567, MAE: 5103.0010, NMAE: 77.7994, R^2: 0.0129\n",
      "Epoch [417/2000]\n",
      "Train Loss: 36658900.0655\n",
      "Val Loss: 36311160.8061, MAE: 5154.8213, NMAE: 78.5895, R^2: 0.0067\n",
      "Epoch [418/2000]\n",
      "Train Loss: 36860681.2319\n",
      "Val Loss: 36365674.5237, MAE: 5137.4858, NMAE: 78.3252, R^2: 0.0052\n",
      "Epoch [419/2000]\n",
      "Train Loss: 36677683.2681\n",
      "Val Loss: 35978357.5415, MAE: 5144.8628, NMAE: 78.4377, R^2: 0.0158\n",
      "Epoch [420/2000]\n",
      "Train Loss: 36714659.4336\n",
      "Val Loss: 36116975.0069, MAE: 5121.9683, NMAE: 78.0886, R^2: 0.0120\n",
      "Epoch [421/2000]\n",
      "Train Loss: 36545808.0612\n",
      "Val Loss: 35934817.9456, MAE: 5108.5034, NMAE: 77.8833, R^2: 0.0169\n",
      "Epoch [422/2000]\n",
      "Train Loss: 36771108.6552\n",
      "Val Loss: 35704778.8493, MAE: 5058.3940, NMAE: 77.1194, R^2: 0.0232\n",
      "Epoch [423/2000]\n",
      "Train Loss: 36740297.0483\n",
      "Val Loss: 36450861.9768, MAE: 5120.4404, NMAE: 78.0653, R^2: 0.0028\n",
      "Epoch [424/2000]\n",
      "Train Loss: 36948683.6131\n",
      "Val Loss: 36510816.1636, MAE: 5087.3628, NMAE: 77.5610, R^2: 0.0012\n",
      "Epoch [425/2000]\n",
      "Train Loss: 36889032.7022\n",
      "Val Loss: 36305449.9806, MAE: 5035.4443, NMAE: 76.7695, R^2: 0.0068\n",
      "Epoch [426/2000]\n",
      "Train Loss: 36705769.9621\n",
      "Val Loss: 36360331.0509, MAE: 5110.0518, NMAE: 77.9069, R^2: 0.0053\n",
      "Epoch [427/2000]\n",
      "Train Loss: 36615418.8582\n",
      "Val Loss: 36211353.4401, MAE: 5047.0698, NMAE: 76.9467, R^2: 0.0094\n",
      "Epoch [428/2000]\n",
      "Train Loss: 37088906.6409\n",
      "Val Loss: 35831236.1531, MAE: 4999.8223, NMAE: 76.2264, R^2: 0.0198\n",
      "Epoch [429/2000]\n",
      "Train Loss: 36624767.3388\n",
      "Val Loss: 36181886.1205, MAE: 5102.7983, NMAE: 77.7963, R^2: 0.0102\n",
      "Epoch [430/2000]\n",
      "Train Loss: 36653586.2793\n",
      "Val Loss: 36103734.1658, MAE: 5075.2495, NMAE: 77.3763, R^2: 0.0123\n",
      "Epoch [431/2000]\n",
      "Train Loss: 36813795.8621\n",
      "Val Loss: 35945326.4840, MAE: 5077.2690, NMAE: 77.4071, R^2: 0.0167\n",
      "Epoch [432/2000]\n",
      "Train Loss: 36360867.7345\n",
      "Val Loss: 36116402.8761, MAE: 5127.1323, NMAE: 78.1673, R^2: 0.0120\n",
      "Epoch [433/2000]\n",
      "Train Loss: 36407151.4578\n",
      "Val Loss: 35681976.5436, MAE: 5056.1509, NMAE: 77.0852, R^2: 0.0239\n",
      "Epoch [434/2000]\n",
      "Train Loss: 36294331.5647\n",
      "Val Loss: 35883160.3946, MAE: 5068.5962, NMAE: 77.2749, R^2: 0.0184\n",
      "Epoch [435/2000]\n",
      "Train Loss: 36451160.4397\n",
      "Val Loss: 36015908.1066, MAE: 5076.9399, NMAE: 77.4021, R^2: 0.0147\n",
      "Epoch [436/2000]\n",
      "Train Loss: 36270911.5259\n",
      "Val Loss: 36099896.5030, MAE: 5118.2383, NMAE: 78.0317, R^2: 0.0124\n",
      "Epoch [437/2000]\n",
      "Train Loss: 36492244.0060\n",
      "Val Loss: 35988634.9160, MAE: 5074.1914, NMAE: 77.3602, R^2: 0.0155\n",
      "Epoch [438/2000]\n",
      "Train Loss: 36671313.8621\n",
      "Val Loss: 36262933.1708, MAE: 5095.5093, NMAE: 77.6852, R^2: 0.0080\n",
      "Epoch [439/2000]\n",
      "Train Loss: 36626447.6422\n",
      "Val Loss: 36207974.3070, MAE: 5086.7383, NMAE: 77.5515, R^2: 0.0095\n",
      "Epoch [440/2000]\n",
      "Train Loss: 36395679.1164\n",
      "Val Loss: 36256438.8219, MAE: 5109.8257, NMAE: 77.9035, R^2: 0.0082\n",
      "Epoch [441/2000]\n",
      "Train Loss: 36402862.9043\n",
      "Val Loss: 36202133.3873, MAE: 5106.5845, NMAE: 77.8541, R^2: 0.0096\n",
      "Epoch [442/2000]\n",
      "Train Loss: 36502175.2983\n",
      "Val Loss: 35863502.7003, MAE: 5075.0635, NMAE: 77.3735, R^2: 0.0189\n",
      "Epoch [443/2000]\n",
      "Train Loss: 36874458.9371\n",
      "Val Loss: 36047212.6064, MAE: 5032.4585, NMAE: 76.7240, R^2: 0.0139\n",
      "Epoch [444/2000]\n",
      "Train Loss: 36689943.2336\n",
      "Val Loss: 35530953.8061, MAE: 5036.4502, NMAE: 76.7848, R^2: 0.0280\n",
      "Epoch [445/2000]\n",
      "Train Loss: 36333292.5750\n",
      "Val Loss: 35964469.2884, MAE: 5120.6953, NMAE: 78.0692, R^2: 0.0161\n",
      "Epoch [446/2000]\n",
      "Train Loss: 36172284.3095\n",
      "Val Loss: 36118072.6602, MAE: 5117.9785, NMAE: 78.0278, R^2: 0.0119\n",
      "Epoch [447/2000]\n",
      "Train Loss: 36547118.6750\n",
      "Val Loss: 35812338.3592, MAE: 5050.0283, NMAE: 76.9918, R^2: 0.0203\n",
      "Epoch [448/2000]\n",
      "Train Loss: 36532175.0741\n",
      "Val Loss: 36139304.3290, MAE: 5058.3320, NMAE: 77.1184, R^2: 0.0114\n",
      "Epoch [449/2000]\n",
      "Train Loss: 36709484.7905\n",
      "Val Loss: 36270814.2884, MAE: 5126.6313, NMAE: 78.1597, R^2: 0.0078\n",
      "Epoch [450/2000]\n",
      "Train Loss: 36669439.1491\n",
      "Val Loss: 36173743.1770, MAE: 5111.9531, NMAE: 77.9359, R^2: 0.0104\n",
      "Epoch [451/2000]\n",
      "Train Loss: 36862639.4052\n",
      "Val Loss: 35993051.9154, MAE: 5034.7275, NMAE: 76.7586, R^2: 0.0154\n",
      "Epoch [452/2000]\n",
      "Train Loss: 36871928.9078\n",
      "Val Loss: 35883303.1766, MAE: 5096.0732, NMAE: 77.6938, R^2: 0.0184\n",
      "Epoch [453/2000]\n",
      "Train Loss: 36384120.4750\n",
      "Val Loss: 35542046.3100, MAE: 5073.0684, NMAE: 77.3431, R^2: 0.0277\n",
      "Epoch [454/2000]\n",
      "Train Loss: 36398396.4672\n",
      "Val Loss: 35296599.8575, MAE: 5026.7358, NMAE: 76.6367, R^2: 0.0344\n",
      "Epoch [455/2000]\n",
      "Train Loss: 36046850.5560\n",
      "Val Loss: 35745870.4771, MAE: 5091.9878, NMAE: 77.6315, R^2: 0.0221\n",
      "Epoch [456/2000]\n",
      "Train Loss: 36050365.4043\n",
      "Val Loss: 35673577.8934, MAE: 5074.6816, NMAE: 77.3677, R^2: 0.0241\n",
      "Epoch [457/2000]\n",
      "Train Loss: 36305543.3716\n",
      "Val Loss: 35467468.7677, MAE: 5049.8989, NMAE: 76.9899, R^2: 0.0297\n",
      "Epoch [458/2000]\n",
      "Train Loss: 36182219.6009\n",
      "Val Loss: 35344218.8614, MAE: 5044.3564, NMAE: 76.9054, R^2: 0.0331\n",
      "Epoch [459/2000]\n",
      "Train Loss: 36237609.8371\n",
      "Val Loss: 35638763.4434, MAE: 5045.6772, NMAE: 76.9255, R^2: 0.0250\n",
      "Epoch [460/2000]\n",
      "Train Loss: 36490415.4862\n",
      "Val Loss: 35654045.7358, MAE: 5076.4424, NMAE: 77.3945, R^2: 0.0246\n",
      "Epoch [461/2000]\n",
      "Train Loss: 36326038.1147\n",
      "Val Loss: 35278441.4965, MAE: 5014.9668, NMAE: 76.4573, R^2: 0.0349\n",
      "Epoch [462/2000]\n",
      "Train Loss: 36213540.0284\n",
      "Val Loss: 35108065.1870, MAE: 4991.5742, NMAE: 76.1006, R^2: 0.0396\n",
      "Epoch [463/2000]\n",
      "Train Loss: 36241568.4284\n",
      "Val Loss: 35388644.8981, MAE: 5051.4092, NMAE: 77.0129, R^2: 0.0319\n",
      "Epoch [464/2000]\n",
      "Train Loss: 36127259.0250\n",
      "Val Loss: 35326938.4732, MAE: 5031.0449, NMAE: 76.7024, R^2: 0.0336\n",
      "Epoch [465/2000]\n",
      "Train Loss: 36209706.4034\n",
      "Val Loss: 35239144.1075, MAE: 5020.9414, NMAE: 76.5484, R^2: 0.0360\n",
      "Epoch [466/2000]\n",
      "Train Loss: 36274726.4431\n",
      "Val Loss: 34926914.1680, MAE: 4985.5454, NMAE: 76.0087, R^2: 0.0445\n",
      "Epoch [467/2000]\n",
      "Train Loss: 36161783.6948\n",
      "Val Loss: 35447944.3273, MAE: 5069.4229, NMAE: 77.2875, R^2: 0.0303\n",
      "Epoch [468/2000]\n",
      "Train Loss: 35910707.1190\n",
      "Val Loss: 35363524.2090, MAE: 5052.8105, NMAE: 77.0342, R^2: 0.0326\n",
      "Epoch [469/2000]\n",
      "Train Loss: 35909364.6198\n",
      "Val Loss: 35560358.8411, MAE: 5072.3110, NMAE: 77.3315, R^2: 0.0272\n",
      "Epoch [470/2000]\n",
      "Train Loss: 36373115.0405\n",
      "Val Loss: 36103315.2919, MAE: 5116.0928, NMAE: 77.9990, R^2: 0.0123\n",
      "Epoch [471/2000]\n",
      "Train Loss: 36905403.8017\n",
      "Val Loss: 36032692.5367, MAE: 5074.7129, NMAE: 77.3682, R^2: 0.0143\n",
      "Epoch [472/2000]\n",
      "Train Loss: 36461834.3836\n",
      "Val Loss: 36147469.8528, MAE: 5122.5371, NMAE: 78.0973, R^2: 0.0111\n",
      "Epoch [473/2000]\n",
      "Train Loss: 36636035.0914\n",
      "Val Loss: 36139534.7999, MAE: 5083.8887, NMAE: 77.5081, R^2: 0.0113\n",
      "Epoch [474/2000]\n",
      "Train Loss: 36813455.5629\n",
      "Val Loss: 36281970.6313, MAE: 5067.9312, NMAE: 77.2648, R^2: 0.0075\n",
      "Epoch [475/2000]\n",
      "Train Loss: 36599774.3142\n",
      "Val Loss: 36027975.4893, MAE: 5079.2261, NMAE: 77.4370, R^2: 0.0144\n",
      "Epoch [476/2000]\n",
      "Train Loss: 36328590.0224\n",
      "Val Loss: 36128977.5449, MAE: 5098.0664, NMAE: 77.7242, R^2: 0.0116\n",
      "Epoch [477/2000]\n",
      "Train Loss: 36009085.0250\n",
      "Val Loss: 36074352.9999, MAE: 5098.3179, NMAE: 77.7280, R^2: 0.0131\n",
      "Epoch [478/2000]\n",
      "Train Loss: 36315534.8931\n",
      "Val Loss: 35882449.4594, MAE: 5072.7661, NMAE: 77.3385, R^2: 0.0184\n",
      "Epoch [479/2000]\n",
      "Train Loss: 36387222.8207\n",
      "Val Loss: 35351114.5864, MAE: 5028.8794, NMAE: 76.6694, R^2: 0.0329\n",
      "Epoch [480/2000]\n",
      "Train Loss: 36161967.8966\n",
      "Val Loss: 35169466.2560, MAE: 4998.4624, NMAE: 76.2057, R^2: 0.0379\n",
      "Epoch [481/2000]\n",
      "Train Loss: 36257577.3793\n",
      "Val Loss: 36102196.5447, MAE: 5097.7578, NMAE: 77.7195, R^2: 0.0124\n",
      "Epoch [482/2000]\n",
      "Train Loss: 36169647.3914\n",
      "Val Loss: 35973446.6680, MAE: 5089.9614, NMAE: 77.6006, R^2: 0.0159\n",
      "Epoch [483/2000]\n",
      "Train Loss: 36418267.2733\n",
      "Val Loss: 35402888.1680, MAE: 5021.1885, NMAE: 76.5521, R^2: 0.0315\n",
      "Epoch [484/2000]\n",
      "Train Loss: 36116661.6776\n",
      "Val Loss: 35363951.4603, MAE: 5048.2295, NMAE: 76.9644, R^2: 0.0326\n",
      "Epoch [485/2000]\n",
      "Train Loss: 35913170.3440\n",
      "Val Loss: 35581438.3964, MAE: 5075.8779, NMAE: 77.3859, R^2: 0.0266\n",
      "Epoch [486/2000]\n",
      "Train Loss: 35946493.2716\n",
      "Val Loss: 35662446.7617, MAE: 5086.0649, NMAE: 77.5412, R^2: 0.0244\n",
      "Epoch [487/2000]\n",
      "Train Loss: 36012070.3138\n",
      "Val Loss: 35603470.2720, MAE: 5094.9849, NMAE: 77.6772, R^2: 0.0260\n",
      "Epoch [488/2000]\n",
      "Train Loss: 36164620.5509\n",
      "Val Loss: 35536024.5898, MAE: 5088.3262, NMAE: 77.5757, R^2: 0.0279\n",
      "Epoch [489/2000]\n",
      "Train Loss: 36099345.1776\n",
      "Val Loss: 35495821.7681, MAE: 5038.8247, NMAE: 76.8210, R^2: 0.0290\n",
      "Epoch [490/2000]\n",
      "Train Loss: 36189081.7534\n",
      "Val Loss: 35533538.9953, MAE: 5083.7432, NMAE: 77.5058, R^2: 0.0279\n",
      "Epoch [491/2000]\n",
      "Train Loss: 36268276.5112\n",
      "Val Loss: 35516310.0592, MAE: 5057.9805, NMAE: 77.1131, R^2: 0.0284\n",
      "Epoch [492/2000]\n",
      "Train Loss: 36447340.3879\n",
      "Val Loss: 35955055.3234, MAE: 5103.2959, NMAE: 77.8039, R^2: 0.0164\n",
      "Epoch [493/2000]\n",
      "Train Loss: 36673865.7483\n",
      "Val Loss: 36078938.3407, MAE: 5090.2192, NMAE: 77.6046, R^2: 0.0130\n",
      "Epoch [494/2000]\n",
      "Train Loss: 36737334.4448\n",
      "Val Loss: 35997078.1468, MAE: 5087.8838, NMAE: 77.5690, R^2: 0.0152\n",
      "Epoch [495/2000]\n",
      "Train Loss: 36729156.6569\n",
      "Val Loss: 35927899.0168, MAE: 5087.7705, NMAE: 77.5672, R^2: 0.0171\n",
      "Epoch [496/2000]\n",
      "Train Loss: 36561413.5207\n",
      "Val Loss: 35993067.0725, MAE: 5072.4346, NMAE: 77.3334, R^2: 0.0154\n",
      "Epoch [497/2000]\n",
      "Train Loss: 36531523.2293\n",
      "Val Loss: 35581225.8441, MAE: 5039.1035, NMAE: 76.8253, R^2: 0.0266\n",
      "Epoch [498/2000]\n",
      "Train Loss: 36585754.8491\n",
      "Val Loss: 35943510.4227, MAE: 5073.0518, NMAE: 77.3428, R^2: 0.0167\n",
      "Epoch [499/2000]\n",
      "Train Loss: 36640710.2250\n",
      "Val Loss: 35899536.3161, MAE: 5054.2539, NMAE: 77.0562, R^2: 0.0179\n",
      "Epoch [500/2000]\n",
      "Train Loss: 36455141.5914\n",
      "Val Loss: 35772425.0695, MAE: 5097.6597, NMAE: 77.7180, R^2: 0.0214\n",
      "Epoch [501/2000]\n",
      "Train Loss: 36461987.8448\n",
      "Val Loss: 35595388.8415, MAE: 5042.8872, NMAE: 76.8830, R^2: 0.0262\n",
      "Epoch [502/2000]\n",
      "Train Loss: 36339406.0043\n",
      "Val Loss: 35565912.1645, MAE: 5051.3911, NMAE: 77.0126, R^2: 0.0270\n",
      "Epoch [503/2000]\n",
      "Train Loss: 36273705.4293\n",
      "Val Loss: 35309850.7375, MAE: 5011.6221, NMAE: 76.4063, R^2: 0.0340\n",
      "Epoch [504/2000]\n",
      "Train Loss: 36063828.7043\n",
      "Val Loss: 35646175.5652, MAE: 5067.2656, NMAE: 77.2546, R^2: 0.0248\n",
      "Epoch [505/2000]\n",
      "Train Loss: 36124138.3974\n",
      "Val Loss: 35147081.6231, MAE: 5004.1606, NMAE: 76.2925, R^2: 0.0385\n",
      "Epoch [506/2000]\n",
      "Train Loss: 36429332.9724\n",
      "Val Loss: 35298746.7984, MAE: 5025.0303, NMAE: 76.6107, R^2: 0.0343\n",
      "Epoch [507/2000]\n",
      "Train Loss: 36267135.2802\n",
      "Val Loss: 35800092.7170, MAE: 5082.2197, NMAE: 77.4826, R^2: 0.0206\n",
      "Epoch [508/2000]\n",
      "Train Loss: 36346499.2371\n",
      "Val Loss: 35545278.3864, MAE: 5048.6943, NMAE: 76.9715, R^2: 0.0276\n",
      "Epoch [509/2000]\n",
      "Train Loss: 36318533.8534\n",
      "Val Loss: 35726174.7841, MAE: 5057.5146, NMAE: 77.1060, R^2: 0.0227\n",
      "Epoch [510/2000]\n",
      "Train Loss: 36235767.0888\n",
      "Val Loss: 35508724.4834, MAE: 5061.7192, NMAE: 77.1701, R^2: 0.0286\n",
      "Epoch [511/2000]\n",
      "Train Loss: 35850444.4922\n",
      "Val Loss: 35312700.2465, MAE: 5082.5923, NMAE: 77.4883, R^2: 0.0340\n",
      "Epoch [512/2000]\n",
      "Train Loss: 35891150.5776\n",
      "Val Loss: 35082493.4279, MAE: 5028.6025, NMAE: 76.6652, R^2: 0.0403\n",
      "Epoch [513/2000]\n",
      "Train Loss: 35622174.5147\n",
      "Val Loss: 34947630.9866, MAE: 5018.0967, NMAE: 76.5050, R^2: 0.0440\n",
      "Epoch [514/2000]\n",
      "Train Loss: 35856351.6767\n",
      "Val Loss: 35477885.0508, MAE: 5057.3535, NMAE: 77.1035, R^2: 0.0294\n",
      "Epoch [515/2000]\n",
      "Train Loss: 35791238.1000\n",
      "Val Loss: 35662356.4564, MAE: 5136.9780, NMAE: 78.3174, R^2: 0.0244\n",
      "Epoch [516/2000]\n",
      "Train Loss: 35705363.0769\n",
      "Val Loss: 35589168.7149, MAE: 5086.7183, NMAE: 77.5512, R^2: 0.0264\n",
      "Epoch [517/2000]\n",
      "Train Loss: 36028319.7022\n",
      "Val Loss: 35641048.6287, MAE: 5085.9868, NMAE: 77.5400, R^2: 0.0250\n",
      "Epoch [518/2000]\n",
      "Train Loss: 35938436.8228\n",
      "Val Loss: 35607640.2496, MAE: 5099.8301, NMAE: 77.7511, R^2: 0.0259\n",
      "Epoch [519/2000]\n",
      "Train Loss: 36000507.7414\n",
      "Val Loss: 35509780.5424, MAE: 5069.2744, NMAE: 77.2852, R^2: 0.0286\n",
      "Epoch [520/2000]\n",
      "Train Loss: 36125924.1414\n",
      "Val Loss: 35490032.9996, MAE: 5084.0938, NMAE: 77.5112, R^2: 0.0291\n",
      "Epoch [521/2000]\n",
      "Train Loss: 35878545.0526\n",
      "Val Loss: 35762902.9048, MAE: 5087.2153, NMAE: 77.5588, R^2: 0.0217\n",
      "Epoch [522/2000]\n",
      "Train Loss: 35958406.8047\n",
      "Val Loss: 35522981.5120, MAE: 5066.8359, NMAE: 77.2481, R^2: 0.0282\n",
      "Epoch [523/2000]\n",
      "Train Loss: 35926757.2353\n",
      "Val Loss: 35391309.5666, MAE: 5039.5889, NMAE: 76.8327, R^2: 0.0318\n",
      "Epoch [524/2000]\n",
      "Train Loss: 35896037.8261\n",
      "Val Loss: 35510047.3918, MAE: 5039.2817, NMAE: 76.8280, R^2: 0.0286\n",
      "Epoch [525/2000]\n",
      "Train Loss: 36097163.4552\n",
      "Val Loss: 35816709.4955, MAE: 5050.4136, NMAE: 76.9977, R^2: 0.0202\n",
      "Epoch [526/2000]\n",
      "Train Loss: 36600222.7483\n",
      "Val Loss: 35798262.6503, MAE: 5029.2178, NMAE: 76.6746, R^2: 0.0207\n",
      "Epoch [527/2000]\n",
      "Train Loss: 36293057.2103\n",
      "Val Loss: 35875279.3714, MAE: 5070.2700, NMAE: 77.3004, R^2: 0.0186\n",
      "Epoch [528/2000]\n",
      "Train Loss: 36350619.3711\n",
      "Val Loss: 35740655.4704, MAE: 5046.8022, NMAE: 76.9426, R^2: 0.0223\n",
      "Epoch [529/2000]\n",
      "Train Loss: 36380756.9101\n",
      "Val Loss: 35851541.4540, MAE: 5081.3818, NMAE: 77.4698, R^2: 0.0192\n",
      "Epoch [530/2000]\n",
      "Train Loss: 35965981.5149\n",
      "Val Loss: 35446246.2497, MAE: 5066.0532, NMAE: 77.2361, R^2: 0.0303\n",
      "Epoch [531/2000]\n",
      "Train Loss: 35866145.6933\n",
      "Val Loss: 35506353.1999, MAE: 5068.6768, NMAE: 77.2761, R^2: 0.0287\n",
      "Epoch [532/2000]\n",
      "Train Loss: 35974631.8699\n",
      "Val Loss: 36002339.1553, MAE: 5125.0190, NMAE: 78.1351, R^2: 0.0151\n",
      "Epoch [533/2000]\n",
      "Train Loss: 36117347.4027\n",
      "Val Loss: 35097324.6580, MAE: 5004.4194, NMAE: 76.2965, R^2: 0.0399\n",
      "Epoch [534/2000]\n",
      "Train Loss: 35882002.2541\n",
      "Val Loss: 35950591.5437, MAE: 5136.1694, NMAE: 78.3051, R^2: 0.0165\n",
      "Epoch [535/2000]\n",
      "Train Loss: 36350375.8584\n",
      "Val Loss: 35931961.7810, MAE: 5086.1992, NMAE: 77.5433, R^2: 0.0170\n",
      "Epoch [536/2000]\n",
      "Train Loss: 36082439.3644\n",
      "Val Loss: 35626871.4592, MAE: 5108.5127, NMAE: 77.8835, R^2: 0.0254\n",
      "Epoch [537/2000]\n",
      "Train Loss: 36233582.4528\n",
      "Val Loss: 36077226.7699, MAE: 5144.9766, NMAE: 78.4394, R^2: 0.0131\n",
      "Epoch [538/2000]\n",
      "Train Loss: 36175084.5002\n",
      "Val Loss: 36045430.1149, MAE: 5155.8477, NMAE: 78.6051, R^2: 0.0139\n",
      "Epoch [539/2000]\n",
      "Train Loss: 35987817.2023\n",
      "Val Loss: 35925554.4911, MAE: 5109.4067, NMAE: 77.8971, R^2: 0.0172\n",
      "Epoch [540/2000]\n",
      "Train Loss: 36087066.9052\n",
      "Val Loss: 35443191.6158, MAE: 5053.3647, NMAE: 77.0427, R^2: 0.0304\n",
      "Epoch [541/2000]\n",
      "Train Loss: 36285015.5429\n",
      "Val Loss: 35125748.0760, MAE: 4993.3921, NMAE: 76.1284, R^2: 0.0391\n",
      "Epoch [542/2000]\n",
      "Train Loss: 36402803.1294\n",
      "Val Loss: 35441680.2889, MAE: 5044.8818, NMAE: 76.9134, R^2: 0.0304\n",
      "Epoch [543/2000]\n",
      "Train Loss: 36068264.5453\n",
      "Val Loss: 35746312.2444, MAE: 5078.9561, NMAE: 77.4329, R^2: 0.0221\n",
      "Epoch [544/2000]\n",
      "Train Loss: 36046096.9638\n",
      "Val Loss: 35814720.7983, MAE: 5095.1895, NMAE: 77.6803, R^2: 0.0202\n",
      "Epoch [545/2000]\n",
      "Train Loss: 36294117.6362\n",
      "Val Loss: 35626600.7410, MAE: 5014.5894, NMAE: 76.4515, R^2: 0.0254\n",
      "Epoch [546/2000]\n",
      "Train Loss: 35911985.5657\n",
      "Val Loss: 35090015.0638, MAE: 4981.1260, NMAE: 75.9414, R^2: 0.0401\n",
      "Epoch [547/2000]\n",
      "Train Loss: 35538670.9250\n",
      "Val Loss: 34891580.9766, MAE: 4988.6748, NMAE: 76.0564, R^2: 0.0455\n",
      "Epoch [548/2000]\n",
      "Train Loss: 35651436.6767\n",
      "Val Loss: 35075631.7519, MAE: 5023.0835, NMAE: 76.5810, R^2: 0.0405\n",
      "Epoch [549/2000]\n",
      "Train Loss: 35435931.3961\n",
      "Val Loss: 35042195.8013, MAE: 5026.7607, NMAE: 76.6371, R^2: 0.0414\n",
      "Epoch [550/2000]\n",
      "Train Loss: 35576167.8358\n",
      "Val Loss: 35183504.0582, MAE: 5018.1333, NMAE: 76.5056, R^2: 0.0375\n",
      "Epoch [551/2000]\n",
      "Train Loss: 35369804.1176\n",
      "Val Loss: 35050327.7147, MAE: 5065.0664, NMAE: 77.2211, R^2: 0.0411\n",
      "Epoch [552/2000]\n",
      "Train Loss: 35434314.2279\n",
      "Val Loss: 34999911.7515, MAE: 5057.1597, NMAE: 77.1005, R^2: 0.0425\n",
      "Epoch [553/2000]\n",
      "Train Loss: 35291943.6990\n",
      "Val Loss: 35141930.6239, MAE: 5079.0708, NMAE: 77.4346, R^2: 0.0386\n",
      "Epoch [554/2000]\n",
      "Train Loss: 35525039.6011\n",
      "Val Loss: 35229871.9834, MAE: 5073.7661, NMAE: 77.3537, R^2: 0.0362\n",
      "Epoch [555/2000]\n",
      "Train Loss: 35644705.8233\n",
      "Val Loss: 35051943.4257, MAE: 5042.0146, NMAE: 76.8696, R^2: 0.0411\n",
      "Epoch [556/2000]\n",
      "Train Loss: 35470752.0754\n",
      "Val Loss: 34943046.2770, MAE: 5047.6860, NMAE: 76.9561, R^2: 0.0441\n",
      "Epoch [557/2000]\n",
      "Train Loss: 35440587.7013\n",
      "Val Loss: 34947327.0872, MAE: 5018.3037, NMAE: 76.5082, R^2: 0.0440\n",
      "Epoch [558/2000]\n",
      "Train Loss: 35499237.7298\n",
      "Val Loss: 35067399.5732, MAE: 5033.0391, NMAE: 76.7328, R^2: 0.0407\n",
      "Epoch [559/2000]\n",
      "Train Loss: 35638155.0738\n",
      "Val Loss: 35249872.6948, MAE: 5049.0469, NMAE: 76.9769, R^2: 0.0357\n",
      "Epoch [560/2000]\n",
      "Train Loss: 35331141.0096\n",
      "Val Loss: 35123225.6632, MAE: 5086.2930, NMAE: 77.5447, R^2: 0.0392\n",
      "Epoch [561/2000]\n",
      "Train Loss: 35545341.5862\n",
      "Val Loss: 35224607.4482, MAE: 5064.4238, NMAE: 77.2113, R^2: 0.0364\n",
      "Epoch [562/2000]\n",
      "Train Loss: 35480657.7431\n",
      "Val Loss: 35114532.8951, MAE: 5058.9497, NMAE: 77.1278, R^2: 0.0394\n",
      "Epoch [563/2000]\n",
      "Train Loss: 35678691.5733\n",
      "Val Loss: 35178892.1729, MAE: 5003.8486, NMAE: 76.2878, R^2: 0.0376\n",
      "Epoch [564/2000]\n",
      "Train Loss: 36036328.9069\n",
      "Val Loss: 35336870.9262, MAE: 5054.4746, NMAE: 77.0596, R^2: 0.0333\n",
      "Epoch [565/2000]\n",
      "Train Loss: 35787336.3052\n",
      "Val Loss: 35121094.0730, MAE: 5034.6616, NMAE: 76.7575, R^2: 0.0392\n",
      "Epoch [566/2000]\n",
      "Train Loss: 35592880.3560\n",
      "Val Loss: 35105590.3009, MAE: 5008.0771, NMAE: 76.3522, R^2: 0.0396\n",
      "Epoch [567/2000]\n",
      "Train Loss: 35379608.8103\n",
      "Val Loss: 35265171.6818, MAE: 5034.2485, NMAE: 76.7512, R^2: 0.0353\n",
      "Epoch [568/2000]\n",
      "Train Loss: 35204836.4828\n",
      "Val Loss: 34939067.2988, MAE: 5080.5376, NMAE: 77.4570, R^2: 0.0442\n",
      "Epoch [569/2000]\n",
      "Train Loss: 36279961.4784\n",
      "Val Loss: 35601283.4603, MAE: 5042.4658, NMAE: 76.8765, R^2: 0.0261\n",
      "Epoch [570/2000]\n",
      "Train Loss: 36262475.2397\n",
      "Val Loss: 35569488.8661, MAE: 5061.3428, NMAE: 77.1643, R^2: 0.0269\n",
      "Epoch [571/2000]\n",
      "Train Loss: 35644415.3612\n",
      "Val Loss: 35768543.2107, MAE: 5016.8179, NMAE: 76.4855, R^2: 0.0215\n",
      "Epoch [572/2000]\n",
      "Train Loss: 36214812.1310\n",
      "Val Loss: 35340314.4139, MAE: 5031.9644, NMAE: 76.7164, R^2: 0.0332\n",
      "Epoch [573/2000]\n",
      "Train Loss: 35552419.0888\n",
      "Val Loss: 35447601.9538, MAE: 5070.7134, NMAE: 77.3072, R^2: 0.0303\n",
      "Epoch [574/2000]\n",
      "Train Loss: 35457156.4362\n",
      "Val Loss: 35462108.7660, MAE: 5083.6670, NMAE: 77.5047, R^2: 0.0299\n",
      "Epoch [575/2000]\n",
      "Train Loss: 35271348.6879\n",
      "Val Loss: 35256978.8012, MAE: 5084.1904, NMAE: 77.5127, R^2: 0.0355\n",
      "Epoch [576/2000]\n",
      "Train Loss: 35262669.1319\n",
      "Val Loss: 35071477.4279, MAE: 5075.5537, NMAE: 77.3810, R^2: 0.0406\n",
      "Epoch [577/2000]\n",
      "Train Loss: 34985534.9466\n",
      "Val Loss: 35254078.6630, MAE: 5067.0806, NMAE: 77.2518, R^2: 0.0356\n",
      "Epoch [578/2000]\n",
      "Train Loss: 35311460.4414\n",
      "Val Loss: 35272912.2701, MAE: 5013.1157, NMAE: 76.4291, R^2: 0.0351\n",
      "Epoch [579/2000]\n",
      "Train Loss: 35365958.2948\n",
      "Val Loss: 35138663.1149, MAE: 5044.2715, NMAE: 76.9041, R^2: 0.0387\n",
      "Epoch [580/2000]\n",
      "Train Loss: 35279627.2517\n",
      "Val Loss: 34965799.4590, MAE: 5027.5557, NMAE: 76.6492, R^2: 0.0435\n",
      "Epoch [581/2000]\n",
      "Train Loss: 35059595.5103\n",
      "Val Loss: 34949551.4378, MAE: 5015.7007, NMAE: 76.4685, R^2: 0.0439\n",
      "Epoch [582/2000]\n",
      "Train Loss: 35418245.8672\n",
      "Val Loss: 35034617.8882, MAE: 5028.5649, NMAE: 76.6646, R^2: 0.0416\n",
      "Epoch [583/2000]\n",
      "Train Loss: 35631547.2414\n",
      "Val Loss: 34790698.3584, MAE: 5007.8130, NMAE: 76.3482, R^2: 0.0482\n",
      "Epoch [584/2000]\n",
      "Train Loss: 35918838.1172\n",
      "Val Loss: 35479184.9020, MAE: 5053.9951, NMAE: 77.0523, R^2: 0.0294\n",
      "Epoch [585/2000]\n",
      "Train Loss: 35641552.2457\n",
      "Val Loss: 35321801.9834, MAE: 5038.0127, NMAE: 76.8086, R^2: 0.0337\n",
      "Epoch [586/2000]\n",
      "Train Loss: 35622827.6026\n",
      "Val Loss: 35102717.9763, MAE: 5048.3511, NMAE: 76.9663, R^2: 0.0397\n",
      "Epoch [587/2000]\n",
      "Train Loss: 35319498.5181\n",
      "Val Loss: 35024592.1611, MAE: 5037.9814, NMAE: 76.8082, R^2: 0.0418\n",
      "Epoch [588/2000]\n",
      "Train Loss: 35332699.8517\n",
      "Val Loss: 34978129.7902, MAE: 5052.2603, NMAE: 77.0259, R^2: 0.0431\n",
      "Epoch [589/2000]\n",
      "Train Loss: 35269681.3819\n",
      "Val Loss: 34929712.9106, MAE: 5035.0532, NMAE: 76.7635, R^2: 0.0444\n",
      "Epoch [590/2000]\n",
      "Train Loss: 35559703.6328\n",
      "Val Loss: 35318533.3316, MAE: 5019.0991, NMAE: 76.5203, R^2: 0.0338\n",
      "Epoch [591/2000]\n",
      "Train Loss: 35656212.6560\n",
      "Val Loss: 35144929.4342, MAE: 5032.3345, NMAE: 76.7221, R^2: 0.0386\n",
      "Epoch [592/2000]\n",
      "Train Loss: 35769873.5129\n",
      "Val Loss: 35046600.3273, MAE: 5038.4438, NMAE: 76.8152, R^2: 0.0412\n",
      "Epoch [593/2000]\n",
      "Train Loss: 35509360.3621\n",
      "Val Loss: 35168912.0684, MAE: 5030.0415, NMAE: 76.6871, R^2: 0.0379\n",
      "Epoch [594/2000]\n",
      "Train Loss: 35715530.3862\n",
      "Val Loss: 35310200.7060, MAE: 5019.2339, NMAE: 76.5223, R^2: 0.0340\n",
      "Epoch [595/2000]\n",
      "Train Loss: 35364003.3543\n",
      "Val Loss: 35178910.7489, MAE: 5015.1602, NMAE: 76.4602, R^2: 0.0376\n",
      "Epoch [596/2000]\n",
      "Train Loss: 35439025.4647\n",
      "Val Loss: 35133264.0624, MAE: 5005.3770, NMAE: 76.3111, R^2: 0.0389\n",
      "Epoch [597/2000]\n",
      "Train Loss: 35523318.0129\n",
      "Val Loss: 35287644.0887, MAE: 4997.6582, NMAE: 76.1934, R^2: 0.0347\n",
      "Epoch [598/2000]\n",
      "Train Loss: 35878772.7034\n",
      "Val Loss: 35165086.7483, MAE: 4985.7397, NMAE: 76.0117, R^2: 0.0380\n",
      "Epoch [599/2000]\n",
      "Train Loss: 35843460.7920\n",
      "Val Loss: 35654599.6981, MAE: 5031.0317, NMAE: 76.7022, R^2: 0.0246\n",
      "Epoch [600/2000]\n",
      "Train Loss: 35464026.0905\n",
      "Val Loss: 35210522.2975, MAE: 5035.0659, NMAE: 76.7637, R^2: 0.0368\n",
      "Epoch [601/2000]\n",
      "Train Loss: 35204547.9543\n",
      "Val Loss: 34785929.3230, MAE: 5043.7310, NMAE: 76.8958, R^2: 0.0484\n",
      "Epoch [602/2000]\n",
      "Train Loss: 35015576.5310\n",
      "Val Loss: 34550386.3426, MAE: 4943.9771, NMAE: 75.3750, R^2: 0.0548\n",
      "Epoch [603/2000]\n",
      "Train Loss: 35458375.2793\n",
      "Val Loss: 34423874.5216, MAE: 4967.4790, NMAE: 75.7333, R^2: 0.0583\n",
      "Epoch [604/2000]\n",
      "Train Loss: 35192815.1448\n",
      "Val Loss: 34580966.6153, MAE: 4980.1396, NMAE: 75.9263, R^2: 0.0540\n",
      "Epoch [605/2000]\n",
      "Train Loss: 34960235.4621\n",
      "Val Loss: 34553191.8472, MAE: 4994.1572, NMAE: 76.1400, R^2: 0.0547\n",
      "Epoch [606/2000]\n",
      "Train Loss: 34848655.2397\n",
      "Val Loss: 34757033.1468, MAE: 5011.1660, NMAE: 76.3993, R^2: 0.0492\n",
      "Epoch [607/2000]\n",
      "Train Loss: 35219049.5405\n",
      "Val Loss: 34744240.8623, MAE: 5000.1802, NMAE: 76.2318, R^2: 0.0495\n",
      "Epoch [608/2000]\n",
      "Train Loss: 34931322.0681\n",
      "Val Loss: 34854336.3117, MAE: 5074.2134, NMAE: 77.3605, R^2: 0.0465\n",
      "Epoch [609/2000]\n",
      "Train Loss: 34875316.6431\n",
      "Val Loss: 34796505.5911, MAE: 5078.9038, NMAE: 77.4321, R^2: 0.0481\n",
      "Epoch [610/2000]\n",
      "Train Loss: 34795549.7129\n",
      "Val Loss: 34844689.8031, MAE: 5090.9385, NMAE: 77.6155, R^2: 0.0468\n",
      "Epoch [611/2000]\n",
      "Train Loss: 34639924.7802\n",
      "Val Loss: 34555330.3472, MAE: 5055.4526, NMAE: 77.0745, R^2: 0.0547\n",
      "Epoch [612/2000]\n",
      "Train Loss: 34712037.5741\n",
      "Val Loss: 34408629.4996, MAE: 5006.9058, NMAE: 76.3344, R^2: 0.0587\n",
      "Epoch [613/2000]\n",
      "Train Loss: 34625515.5603\n",
      "Val Loss: 34385539.6351, MAE: 5027.5542, NMAE: 76.6492, R^2: 0.0593\n",
      "Epoch [614/2000]\n",
      "Train Loss: 34296146.2034\n",
      "Val Loss: 34521830.6537, MAE: 5042.3784, NMAE: 76.8752, R^2: 0.0556\n",
      "Epoch [615/2000]\n",
      "Train Loss: 34359176.4388\n",
      "Val Loss: 34549254.8191, MAE: 5025.6665, NMAE: 76.6204, R^2: 0.0549\n",
      "Epoch [616/2000]\n",
      "Train Loss: 34933386.7724\n",
      "Val Loss: 34487016.7595, MAE: 4975.7461, NMAE: 75.8593, R^2: 0.0566\n",
      "Epoch [617/2000]\n",
      "Train Loss: 34746754.5534\n",
      "Val Loss: 34285545.3674, MAE: 5004.5308, NMAE: 76.2982, R^2: 0.0621\n",
      "Epoch [618/2000]\n",
      "Train Loss: 34670747.4017\n",
      "Val Loss: 34257091.5488, MAE: 4997.7515, NMAE: 76.1948, R^2: 0.0628\n",
      "Epoch [619/2000]\n",
      "Train Loss: 34611869.9147\n",
      "Val Loss: 34335535.4033, MAE: 4995.9404, NMAE: 76.1672, R^2: 0.0607\n",
      "Epoch [620/2000]\n",
      "Train Loss: 34558029.8629\n",
      "Val Loss: 34388625.6826, MAE: 5017.1294, NMAE: 76.4903, R^2: 0.0592\n",
      "Epoch [621/2000]\n",
      "Train Loss: 34525067.5793\n",
      "Val Loss: 34410835.3048, MAE: 5027.8135, NMAE: 76.6531, R^2: 0.0586\n",
      "Epoch [622/2000]\n",
      "Train Loss: 34635260.9836\n",
      "Val Loss: 34095008.9175, MAE: 4987.2437, NMAE: 76.0346, R^2: 0.0673\n",
      "Epoch [623/2000]\n",
      "Train Loss: 34815182.5276\n",
      "Val Loss: 34588631.6287, MAE: 5018.8696, NMAE: 76.5168, R^2: 0.0538\n",
      "Epoch [624/2000]\n",
      "Train Loss: 35232855.9586\n",
      "Val Loss: 34393306.1490, MAE: 4959.3779, NMAE: 75.6098, R^2: 0.0591\n",
      "Epoch [625/2000]\n",
      "Train Loss: 35115289.8784\n",
      "Val Loss: 34513591.2478, MAE: 4984.8032, NMAE: 75.9974, R^2: 0.0558\n",
      "Epoch [626/2000]\n",
      "Train Loss: 35323681.3483\n",
      "Val Loss: 34654439.0410, MAE: 4976.8159, NMAE: 75.8756, R^2: 0.0520\n",
      "Epoch [627/2000]\n",
      "Train Loss: 35355208.8767\n",
      "Val Loss: 34759718.4834, MAE: 4992.3130, NMAE: 76.1119, R^2: 0.0491\n",
      "Epoch [628/2000]\n",
      "Train Loss: 35306992.1190\n",
      "Val Loss: 34558497.5518, MAE: 5006.4956, NMAE: 76.3281, R^2: 0.0546\n",
      "Epoch [629/2000]\n",
      "Train Loss: 35254717.4948\n",
      "Val Loss: 34777780.5082, MAE: 5006.0034, NMAE: 76.3206, R^2: 0.0486\n",
      "Epoch [630/2000]\n",
      "Train Loss: 35047888.7009\n",
      "Val Loss: 35020220.3566, MAE: 4985.0962, NMAE: 76.0019, R^2: 0.0420\n",
      "Epoch [631/2000]\n",
      "Train Loss: 35626475.0216\n",
      "Val Loss: 35975259.5123, MAE: 5096.7695, NMAE: 77.7044, R^2: 0.0158\n",
      "Epoch [632/2000]\n",
      "Train Loss: 35781548.8578\n",
      "Val Loss: 35689368.5371, MAE: 5088.1001, NMAE: 77.5723, R^2: 0.0237\n",
      "Epoch [633/2000]\n",
      "Train Loss: 35668556.9655\n",
      "Val Loss: 35207417.0259, MAE: 5016.1606, NMAE: 76.4755, R^2: 0.0368\n",
      "Epoch [634/2000]\n",
      "Train Loss: 35154014.5871\n",
      "Val Loss: 34952733.6788, MAE: 5022.1108, NMAE: 76.5662, R^2: 0.0438\n",
      "Epoch [635/2000]\n",
      "Train Loss: 34804328.9457\n",
      "Val Loss: 34896655.1464, MAE: 5058.7295, NMAE: 77.1245, R^2: 0.0453\n",
      "Epoch [636/2000]\n",
      "Train Loss: 34621925.3328\n",
      "Val Loss: 34643340.6973, MAE: 5027.8579, NMAE: 76.6538, R^2: 0.0523\n",
      "Epoch [637/2000]\n",
      "Train Loss: 34616317.0397\n",
      "Val Loss: 34779327.9566, MAE: 5038.5479, NMAE: 76.8168, R^2: 0.0486\n",
      "Epoch [638/2000]\n",
      "Train Loss: 34680897.5155\n",
      "Val Loss: 34825210.3197, MAE: 5076.9087, NMAE: 77.4016, R^2: 0.0473\n",
      "Epoch [639/2000]\n",
      "Train Loss: 34654933.6466\n",
      "Val Loss: 34699684.6034, MAE: 5058.8628, NMAE: 77.1265, R^2: 0.0507\n",
      "Epoch [640/2000]\n",
      "Train Loss: 34823246.2517\n",
      "Val Loss: 34705740.3735, MAE: 5045.7168, NMAE: 76.9261, R^2: 0.0506\n",
      "Epoch [641/2000]\n",
      "Train Loss: 34586216.5431\n",
      "Val Loss: 34693436.9020, MAE: 5058.3633, NMAE: 77.1189, R^2: 0.0509\n",
      "Epoch [642/2000]\n",
      "Train Loss: 34478235.9534\n",
      "Val Loss: 34552463.5518, MAE: 5037.5171, NMAE: 76.8011, R^2: 0.0548\n",
      "Epoch [643/2000]\n",
      "Train Loss: 34592411.2802\n",
      "Val Loss: 34633567.5855, MAE: 5035.5029, NMAE: 76.7704, R^2: 0.0525\n",
      "Epoch [644/2000]\n",
      "Train Loss: 34711726.8828\n",
      "Val Loss: 34522964.8608, MAE: 5005.8301, NMAE: 76.3180, R^2: 0.0556\n",
      "Epoch [645/2000]\n",
      "Train Loss: 34828581.7724\n",
      "Val Loss: 34302429.2550, MAE: 4991.4102, NMAE: 76.0981, R^2: 0.0616\n",
      "Epoch [646/2000]\n",
      "Train Loss: 34662839.5957\n",
      "Val Loss: 34546832.8383, MAE: 5029.1187, NMAE: 76.6730, R^2: 0.0549\n",
      "Epoch [647/2000]\n",
      "Train Loss: 34735685.9905\n",
      "Val Loss: 34513931.4244, MAE: 4997.8052, NMAE: 76.1956, R^2: 0.0558\n",
      "Epoch [648/2000]\n",
      "Train Loss: 34569801.6181\n",
      "Val Loss: 34438496.5432, MAE: 5027.5674, NMAE: 76.6494, R^2: 0.0579\n",
      "Epoch [649/2000]\n",
      "Train Loss: 36149043.4371\n",
      "Val Loss: 34830520.5173, MAE: 5016.8442, NMAE: 76.4859, R^2: 0.0472\n",
      "Epoch [650/2000]\n",
      "Train Loss: 35403506.0293\n",
      "Val Loss: 34641520.6887, MAE: 4979.2480, NMAE: 75.9127, R^2: 0.0523\n",
      "Epoch [651/2000]\n",
      "Train Loss: 34992174.7905\n",
      "Val Loss: 34429302.1321, MAE: 4959.3438, NMAE: 75.6093, R^2: 0.0581\n",
      "Epoch [652/2000]\n",
      "Train Loss: 34731071.1871\n",
      "Val Loss: 34562957.5635, MAE: 4968.8892, NMAE: 75.7548, R^2: 0.0545\n",
      "Epoch [653/2000]\n",
      "Train Loss: 34610446.6750\n",
      "Val Loss: 34386425.1684, MAE: 4964.6821, NMAE: 75.6907, R^2: 0.0593\n",
      "Epoch [654/2000]\n",
      "Train Loss: 34888668.1922\n",
      "Val Loss: 34245764.2547, MAE: 4938.8936, NMAE: 75.2975, R^2: 0.0632\n",
      "Epoch [655/2000]\n",
      "Train Loss: 34787095.9457\n",
      "Val Loss: 33771849.3497, MAE: 4889.3945, NMAE: 74.5428, R^2: 0.0761\n",
      "Epoch [656/2000]\n",
      "Train Loss: 35090801.3793\n",
      "Val Loss: 33821719.6224, MAE: 4931.8203, NMAE: 75.1896, R^2: 0.0748\n",
      "Epoch [657/2000]\n",
      "Train Loss: 34769371.0190\n",
      "Val Loss: 33945640.4981, MAE: 4965.4673, NMAE: 75.7026, R^2: 0.0714\n",
      "Epoch [658/2000]\n",
      "Train Loss: 35005794.9793\n",
      "Val Loss: 34047105.6336, MAE: 4899.7266, NMAE: 74.7004, R^2: 0.0686\n",
      "Epoch [659/2000]\n",
      "Train Loss: 35359255.1767\n",
      "Val Loss: 33973571.4361, MAE: 4923.8125, NMAE: 75.0676, R^2: 0.0706\n",
      "Epoch [660/2000]\n",
      "Train Loss: 34579564.9224\n",
      "Val Loss: 33946157.5561, MAE: 4964.6216, NMAE: 75.6897, R^2: 0.0714\n",
      "Epoch [661/2000]\n",
      "Train Loss: 35149526.2267\n",
      "Val Loss: 34365797.5712, MAE: 4920.6299, NMAE: 75.0190, R^2: 0.0599\n",
      "Epoch [662/2000]\n",
      "Train Loss: 35021234.2172\n",
      "Val Loss: 34220984.1300, MAE: 4907.6367, NMAE: 74.8209, R^2: 0.0638\n",
      "Epoch [663/2000]\n",
      "Train Loss: 34760934.4000\n",
      "Val Loss: 34275790.0928, MAE: 4946.5239, NMAE: 75.4138, R^2: 0.0623\n",
      "Epoch [664/2000]\n",
      "Train Loss: 35047588.1672\n",
      "Val Loss: 34191009.6904, MAE: 4936.7075, NMAE: 75.2642, R^2: 0.0647\n",
      "Epoch [665/2000]\n",
      "Train Loss: 34349295.8034\n",
      "Val Loss: 33942541.3018, MAE: 4989.5615, NMAE: 76.0700, R^2: 0.0715\n",
      "Epoch [666/2000]\n",
      "Train Loss: 34544754.0431\n",
      "Val Loss: 33928794.4167, MAE: 4961.4731, NMAE: 75.6417, R^2: 0.0718\n",
      "Epoch [667/2000]\n",
      "Train Loss: 34572921.2716\n",
      "Val Loss: 33970791.1572, MAE: 4974.0039, NMAE: 75.8328, R^2: 0.0707\n",
      "Epoch [668/2000]\n",
      "Train Loss: 34423080.3810\n",
      "Val Loss: 34028703.4849, MAE: 5003.0024, NMAE: 76.2749, R^2: 0.0691\n",
      "Epoch [669/2000]\n",
      "Train Loss: 34904320.4802\n",
      "Val Loss: 33755433.1071, MAE: 4935.5630, NMAE: 75.2467, R^2: 0.0766\n",
      "Epoch [670/2000]\n",
      "Train Loss: 34542483.8905\n",
      "Val Loss: 33975326.2802, MAE: 4936.0503, NMAE: 75.2541, R^2: 0.0706\n",
      "Epoch [671/2000]\n",
      "Train Loss: 34334834.2103\n",
      "Val Loss: 33921118.1524, MAE: 4952.0049, NMAE: 75.4974, R^2: 0.0720\n",
      "Epoch [672/2000]\n",
      "Train Loss: 34257603.7207\n",
      "Val Loss: 34023826.3765, MAE: 4981.3706, NMAE: 75.9451, R^2: 0.0692\n",
      "Epoch [673/2000]\n",
      "Train Loss: 33841518.4129\n",
      "Val Loss: 33944477.1239, MAE: 4971.3770, NMAE: 75.7927, R^2: 0.0714\n",
      "Epoch [674/2000]\n",
      "Train Loss: 34398367.7560\n",
      "Val Loss: 33775964.1891, MAE: 4941.0718, NMAE: 75.3307, R^2: 0.0760\n",
      "Epoch [675/2000]\n",
      "Train Loss: 33799515.7655\n",
      "Val Loss: 33667607.7405, MAE: 4944.0234, NMAE: 75.3757, R^2: 0.0790\n",
      "Epoch [676/2000]\n",
      "Train Loss: 34208531.1241\n",
      "Val Loss: 33935953.3286, MAE: 4972.5898, NMAE: 75.8112, R^2: 0.0716\n",
      "Epoch [677/2000]\n",
      "Train Loss: 34164189.5828\n",
      "Val Loss: 33754231.2284, MAE: 4903.6729, NMAE: 74.7605, R^2: 0.0766\n",
      "Epoch [678/2000]\n",
      "Train Loss: 33862012.9060\n",
      "Val Loss: 33919587.0332, MAE: 4972.5718, NMAE: 75.8109, R^2: 0.0721\n",
      "Epoch [679/2000]\n",
      "Train Loss: 33853252.7172\n",
      "Val Loss: 33797373.5328, MAE: 4973.5347, NMAE: 75.8256, R^2: 0.0754\n",
      "Epoch [680/2000]\n",
      "Train Loss: 33512195.5086\n",
      "Val Loss: 33805601.9335, MAE: 4967.2100, NMAE: 75.7292, R^2: 0.0752\n",
      "Epoch [681/2000]\n",
      "Train Loss: 33591828.9991\n",
      "Val Loss: 33991166.5479, MAE: 4970.4434, NMAE: 75.7785, R^2: 0.0701\n",
      "Epoch [682/2000]\n",
      "Train Loss: 33795554.9103\n",
      "Val Loss: 33744793.9974, MAE: 4944.3403, NMAE: 75.3805, R^2: 0.0769\n",
      "Epoch [683/2000]\n",
      "Train Loss: 33693130.1172\n",
      "Val Loss: 33917500.2530, MAE: 4952.4971, NMAE: 75.5049, R^2: 0.0721\n",
      "Epoch [684/2000]\n",
      "Train Loss: 33817452.4750\n",
      "Val Loss: 33749741.7174, MAE: 4979.2881, NMAE: 75.9133, R^2: 0.0767\n",
      "Epoch [685/2000]\n",
      "Train Loss: 34143020.8784\n",
      "Val Loss: 33951799.2449, MAE: 4970.5469, NMAE: 75.7801, R^2: 0.0712\n",
      "Epoch [686/2000]\n",
      "Train Loss: 34667647.2463\n",
      "Val Loss: 33861976.6662, MAE: 4941.6392, NMAE: 75.3393, R^2: 0.0737\n",
      "Epoch [687/2000]\n",
      "Train Loss: 34038125.9362\n",
      "Val Loss: 33803522.2314, MAE: 4998.2515, NMAE: 76.2024, R^2: 0.0753\n",
      "Epoch [688/2000]\n",
      "Train Loss: 34055337.1672\n",
      "Val Loss: 33856667.6595, MAE: 4989.9570, NMAE: 76.0760, R^2: 0.0738\n",
      "Epoch [689/2000]\n",
      "Train Loss: 34038827.0000\n",
      "Val Loss: 33821559.3245, MAE: 4979.2119, NMAE: 75.9122, R^2: 0.0748\n",
      "Epoch [690/2000]\n",
      "Train Loss: 33905285.4241\n",
      "Val Loss: 33653175.8396, MAE: 4960.8164, NMAE: 75.6317, R^2: 0.0794\n",
      "Epoch [691/2000]\n",
      "Train Loss: 33799014.0319\n",
      "Val Loss: 33787231.0248, MAE: 4991.2656, NMAE: 76.0959, R^2: 0.0757\n",
      "Epoch [692/2000]\n",
      "Train Loss: 34243750.1151\n",
      "Val Loss: 33684248.3592, MAE: 4969.0391, NMAE: 75.7571, R^2: 0.0785\n",
      "Epoch [693/2000]\n",
      "Train Loss: 33960516.9707\n",
      "Val Loss: 33960169.9655, MAE: 4995.3071, NMAE: 76.1576, R^2: 0.0710\n",
      "Epoch [694/2000]\n",
      "Train Loss: 33766995.3983\n",
      "Val Loss: 33955486.1652, MAE: 4997.4194, NMAE: 76.1898, R^2: 0.0711\n",
      "Epoch [695/2000]\n",
      "Train Loss: 33692437.4629\n",
      "Val Loss: 33801401.4765, MAE: 4979.2983, NMAE: 75.9135, R^2: 0.0753\n",
      "Epoch [696/2000]\n",
      "Train Loss: 33854143.6267\n",
      "Val Loss: 33639449.8117, MAE: 4977.9077, NMAE: 75.8923, R^2: 0.0797\n",
      "Epoch [697/2000]\n",
      "Train Loss: 34043918.2448\n",
      "Val Loss: 33489457.4978, MAE: 4942.2417, NMAE: 75.3485, R^2: 0.0838\n",
      "Epoch [698/2000]\n",
      "Train Loss: 34079065.0681\n",
      "Val Loss: 33447698.4555, MAE: 4939.3276, NMAE: 75.3041, R^2: 0.0850\n",
      "Epoch [699/2000]\n",
      "Train Loss: 34064293.0879\n",
      "Val Loss: 33714943.4452, MAE: 4942.7847, NMAE: 75.3568, R^2: 0.0777\n",
      "Epoch [700/2000]\n",
      "Train Loss: 34183109.2681\n",
      "Val Loss: 33687236.1967, MAE: 4941.1919, NMAE: 75.3325, R^2: 0.0784\n",
      "Epoch [701/2000]\n",
      "Train Loss: 34329501.9009\n",
      "Val Loss: 33799962.8793, MAE: 4939.6245, NMAE: 75.3086, R^2: 0.0754\n",
      "Epoch [702/2000]\n",
      "Train Loss: 34372085.3552\n",
      "Val Loss: 33839495.5138, MAE: 4937.8379, NMAE: 75.2814, R^2: 0.0743\n",
      "Epoch [703/2000]\n",
      "Train Loss: 34391078.2388\n",
      "Val Loss: 33914672.0000, MAE: 4943.8433, NMAE: 75.3729, R^2: 0.0722\n",
      "Epoch [704/2000]\n",
      "Train Loss: 34102498.0047\n",
      "Val Loss: 33842894.5317, MAE: 4941.7925, NMAE: 75.3417, R^2: 0.0742\n",
      "Epoch [705/2000]\n",
      "Train Loss: 33809583.7190\n",
      "Val Loss: 33974471.1984, MAE: 4984.0669, NMAE: 75.9862, R^2: 0.0706\n",
      "Epoch [706/2000]\n",
      "Train Loss: 33864081.0629\n",
      "Val Loss: 33927738.6969, MAE: 4948.0620, NMAE: 75.4373, R^2: 0.0719\n",
      "Epoch [707/2000]\n",
      "Train Loss: 33856857.2142\n",
      "Val Loss: 33825732.3324, MAE: 4940.0220, NMAE: 75.3147, R^2: 0.0746\n",
      "Epoch [708/2000]\n",
      "Train Loss: 33640703.2931\n",
      "Val Loss: 33954309.5520, MAE: 4976.9946, NMAE: 75.8784, R^2: 0.0711\n",
      "Epoch [709/2000]\n",
      "Train Loss: 33717260.8069\n",
      "Val Loss: 33767150.5513, MAE: 4945.5405, NMAE: 75.3988, R^2: 0.0762\n",
      "Epoch [710/2000]\n",
      "Train Loss: 33688275.4672\n",
      "Val Loss: 33741292.9075, MAE: 4951.2090, NMAE: 75.4852, R^2: 0.0770\n",
      "Epoch [711/2000]\n",
      "Train Loss: 33537949.4362\n",
      "Val Loss: 33786101.6576, MAE: 4963.3013, NMAE: 75.6696, R^2: 0.0757\n",
      "Epoch [712/2000]\n",
      "Train Loss: 33680055.1181\n",
      "Val Loss: 33757542.4399, MAE: 4938.2373, NMAE: 75.2875, R^2: 0.0765\n",
      "Epoch [713/2000]\n",
      "Train Loss: 33637329.7683\n",
      "Val Loss: 34069694.6184, MAE: 4994.4155, NMAE: 76.1440, R^2: 0.0680\n",
      "Epoch [714/2000]\n",
      "Train Loss: 33496466.1323\n",
      "Val Loss: 33754974.8418, MAE: 4936.5981, NMAE: 75.2625, R^2: 0.0766\n",
      "Epoch [715/2000]\n",
      "Train Loss: 33471806.9994\n",
      "Val Loss: 34191908.0391, MAE: 5016.8716, NMAE: 76.4863, R^2: 0.0646\n",
      "Epoch [716/2000]\n",
      "Train Loss: 33410596.6362\n",
      "Val Loss: 33920934.3144, MAE: 4970.5210, NMAE: 75.7797, R^2: 0.0720\n",
      "Epoch [717/2000]\n",
      "Train Loss: 33708833.8241\n",
      "Val Loss: 33759274.7966, MAE: 4911.8208, NMAE: 74.8847, R^2: 0.0765\n",
      "Epoch [718/2000]\n",
      "Train Loss: 33875506.5336\n",
      "Val Loss: 34018479.4600, MAE: 4948.4419, NMAE: 75.4431, R^2: 0.0694\n",
      "Epoch [719/2000]\n",
      "Train Loss: 33656327.2968\n",
      "Val Loss: 33912614.3194, MAE: 4947.4922, NMAE: 75.4286, R^2: 0.0723\n",
      "Epoch [720/2000]\n",
      "Train Loss: 33675601.1121\n",
      "Val Loss: 34217270.0663, MAE: 4995.0571, NMAE: 76.1537, R^2: 0.0639\n",
      "Epoch [721/2000]\n",
      "Train Loss: 33539539.1687\n",
      "Val Loss: 34326416.1700, MAE: 5021.5449, NMAE: 76.5576, R^2: 0.0609\n",
      "Epoch [722/2000]\n",
      "Train Loss: 33405400.8972\n",
      "Val Loss: 34201427.0123, MAE: 5008.7305, NMAE: 76.3622, R^2: 0.0644\n",
      "Epoch [723/2000]\n",
      "Train Loss: 33682493.9054\n",
      "Val Loss: 34069523.6876, MAE: 4992.1924, NMAE: 76.1101, R^2: 0.0680\n",
      "Epoch [724/2000]\n",
      "Train Loss: 33324270.8060\n",
      "Val Loss: 34071674.5600, MAE: 4993.0718, NMAE: 76.1235, R^2: 0.0679\n",
      "Epoch [725/2000]\n",
      "Train Loss: 33601661.3381\n",
      "Val Loss: 34238127.5839, MAE: 5041.7178, NMAE: 76.8651, R^2: 0.0634\n",
      "Epoch [726/2000]\n",
      "Train Loss: 33051879.8031\n",
      "Val Loss: 34087905.9767, MAE: 5003.1436, NMAE: 76.2770, R^2: 0.0675\n",
      "Epoch [727/2000]\n",
      "Train Loss: 32866692.5841\n",
      "Val Loss: 34154415.9191, MAE: 5020.9839, NMAE: 76.5490, R^2: 0.0657\n",
      "Epoch [728/2000]\n",
      "Train Loss: 32880593.8912\n",
      "Val Loss: 34117208.5020, MAE: 5009.5283, NMAE: 76.3744, R^2: 0.0667\n",
      "Epoch [729/2000]\n",
      "Train Loss: 32986306.5088\n",
      "Val Loss: 34555724.0539, MAE: 5078.4902, NMAE: 77.4257, R^2: 0.0547\n",
      "Epoch [730/2000]\n",
      "Train Loss: 33020794.2511\n",
      "Val Loss: 34122968.0893, MAE: 5020.3384, NMAE: 76.5392, R^2: 0.0665\n",
      "Epoch [731/2000]\n",
      "Train Loss: 33276911.9893\n",
      "Val Loss: 33872815.4833, MAE: 4995.3340, NMAE: 76.1580, R^2: 0.0734\n",
      "Epoch [732/2000]\n",
      "Train Loss: 33250178.4615\n",
      "Val Loss: 33885573.3634, MAE: 4983.1924, NMAE: 75.9729, R^2: 0.0730\n",
      "Epoch [733/2000]\n",
      "Train Loss: 33037940.6927\n",
      "Val Loss: 33881906.2445, MAE: 4938.9102, NMAE: 75.2977, R^2: 0.0731\n",
      "Epoch [734/2000]\n",
      "Train Loss: 33166644.0363\n",
      "Val Loss: 33858075.4242, MAE: 4998.3330, NMAE: 76.2037, R^2: 0.0738\n",
      "Epoch [735/2000]\n",
      "Train Loss: 32986538.6814\n",
      "Val Loss: 34104107.6616, MAE: 5020.6011, NMAE: 76.5432, R^2: 0.0670\n",
      "Epoch [736/2000]\n",
      "Train Loss: 32665860.2645\n",
      "Val Loss: 34240333.7871, MAE: 5040.0601, NMAE: 76.8399, R^2: 0.0633\n",
      "Epoch [737/2000]\n",
      "Train Loss: 33293533.8208\n",
      "Val Loss: 33607326.5077, MAE: 4949.8301, NMAE: 75.4642, R^2: 0.0806\n",
      "Epoch [738/2000]\n",
      "Train Loss: 33039669.3204\n",
      "Val Loss: 33560222.0460, MAE: 4957.9653, NMAE: 75.5882, R^2: 0.0819\n",
      "Epoch [739/2000]\n",
      "Train Loss: 32886633.4100\n",
      "Val Loss: 34150231.0549, MAE: 5030.6387, NMAE: 76.6962, R^2: 0.0658\n",
      "Epoch [740/2000]\n",
      "Train Loss: 32851048.8375\n",
      "Val Loss: 33881478.8646, MAE: 4995.1938, NMAE: 76.1558, R^2: 0.0731\n",
      "Epoch [741/2000]\n",
      "Train Loss: 32886541.6289\n",
      "Val Loss: 34043335.8331, MAE: 5021.6216, NMAE: 76.5587, R^2: 0.0687\n",
      "Epoch [742/2000]\n",
      "Train Loss: 32883572.5949\n",
      "Val Loss: 34189240.8929, MAE: 5024.9897, NMAE: 76.6101, R^2: 0.0647\n",
      "Epoch [743/2000]\n",
      "Train Loss: 33136173.8224\n",
      "Val Loss: 33533760.5942, MAE: 4933.4194, NMAE: 75.2140, R^2: 0.0826\n",
      "Epoch [744/2000]\n",
      "Train Loss: 33359506.1414\n",
      "Val Loss: 34395552.8437, MAE: 4921.0376, NMAE: 75.0253, R^2: 0.0591\n",
      "Epoch [745/2000]\n",
      "Train Loss: 33362881.4026\n",
      "Val Loss: 33430156.9231, MAE: 4917.9487, NMAE: 74.9782, R^2: 0.0855\n",
      "Epoch [746/2000]\n",
      "Train Loss: 33916021.4043\n",
      "Val Loss: 33372806.2647, MAE: 4873.8799, NMAE: 74.3063, R^2: 0.0870\n",
      "Epoch [747/2000]\n",
      "Train Loss: 34135505.7905\n",
      "Val Loss: 33309019.5980, MAE: 4914.5273, NMAE: 74.9260, R^2: 0.0888\n",
      "Epoch [748/2000]\n",
      "Train Loss: 33338900.5448\n",
      "Val Loss: 33465904.5099, MAE: 4950.7363, NMAE: 75.4780, R^2: 0.0845\n",
      "Epoch [749/2000]\n",
      "Train Loss: 32811456.3172\n",
      "Val Loss: 33503767.0959, MAE: 4950.0527, NMAE: 75.4676, R^2: 0.0835\n",
      "Epoch [750/2000]\n",
      "Train Loss: 32836204.7724\n",
      "Val Loss: 33666736.8502, MAE: 4973.6128, NMAE: 75.8268, R^2: 0.0790\n",
      "Epoch [751/2000]\n",
      "Train Loss: 32620084.2241\n",
      "Val Loss: 33775459.7720, MAE: 4986.7324, NMAE: 76.0268, R^2: 0.0760\n",
      "Epoch [752/2000]\n",
      "Train Loss: 32751110.1043\n",
      "Val Loss: 33579910.7465, MAE: 4963.6216, NMAE: 75.6745, R^2: 0.0814\n",
      "Epoch [753/2000]\n",
      "Train Loss: 32429354.8138\n",
      "Val Loss: 33842717.8506, MAE: 5001.2075, NMAE: 76.2475, R^2: 0.0742\n",
      "Epoch [754/2000]\n",
      "Train Loss: 32712026.2543\n",
      "Val Loss: 34086707.2090, MAE: 5021.9263, NMAE: 76.5634, R^2: 0.0675\n",
      "Epoch [755/2000]\n",
      "Train Loss: 32526059.5319\n",
      "Val Loss: 34068243.0583, MAE: 4998.8779, NMAE: 76.2120, R^2: 0.0680\n",
      "Epoch [756/2000]\n",
      "Train Loss: 32573118.2897\n",
      "Val Loss: 34206244.5980, MAE: 4963.4565, NMAE: 75.6720, R^2: 0.0642\n",
      "Epoch [757/2000]\n",
      "Train Loss: 32540138.8776\n",
      "Val Loss: 34122684.9236, MAE: 4995.0566, NMAE: 76.1537, R^2: 0.0665\n",
      "Epoch [758/2000]\n",
      "Train Loss: 32660213.5474\n",
      "Val Loss: 34312937.7910, MAE: 5027.4883, NMAE: 76.6482, R^2: 0.0613\n",
      "Epoch [759/2000]\n",
      "Train Loss: 32439634.5802\n",
      "Val Loss: 33908137.2129, MAE: 5026.9922, NMAE: 76.6406, R^2: 0.0724\n",
      "Epoch [760/2000]\n",
      "Train Loss: 32535916.8086\n",
      "Val Loss: 34018273.0579, MAE: 5045.0269, NMAE: 76.9156, R^2: 0.0694\n",
      "Epoch [761/2000]\n",
      "Train Loss: 32539447.8310\n",
      "Val Loss: 33544331.0371, MAE: 4970.5581, NMAE: 75.7802, R^2: 0.0823\n",
      "Epoch [762/2000]\n",
      "Train Loss: 32151812.7879\n",
      "Val Loss: 33920103.2215, MAE: 5001.8872, NMAE: 76.2579, R^2: 0.0721\n",
      "Epoch [763/2000]\n",
      "Train Loss: 32273108.1647\n",
      "Val Loss: 33382461.6442, MAE: 4932.7910, NMAE: 75.2044, R^2: 0.0868\n",
      "Epoch [764/2000]\n",
      "Train Loss: 32181572.8216\n",
      "Val Loss: 34104734.2875, MAE: 5022.8076, NMAE: 76.5768, R^2: 0.0670\n",
      "Epoch [765/2000]\n",
      "Train Loss: 32158378.1438\n",
      "Val Loss: 33754100.7311, MAE: 5002.9565, NMAE: 76.2742, R^2: 0.0766\n",
      "Epoch [766/2000]\n",
      "Train Loss: 32224253.6948\n",
      "Val Loss: 33825513.0611, MAE: 4990.5635, NMAE: 76.0852, R^2: 0.0747\n",
      "Epoch [767/2000]\n",
      "Train Loss: 32299963.8901\n",
      "Val Loss: 33264870.3339, MAE: 4906.1426, NMAE: 74.7982, R^2: 0.0900\n",
      "Epoch [768/2000]\n",
      "Train Loss: 32838680.3759\n",
      "Val Loss: 33217214.6634, MAE: 4920.3809, NMAE: 75.0152, R^2: 0.0913\n",
      "Epoch [769/2000]\n",
      "Train Loss: 32720619.8534\n",
      "Val Loss: 33124420.5095, MAE: 4911.2388, NMAE: 74.8759, R^2: 0.0938\n",
      "Epoch [770/2000]\n",
      "Train Loss: 32674511.8810\n",
      "Val Loss: 33020535.1170, MAE: 4879.9106, NMAE: 74.3982, R^2: 0.0967\n",
      "Epoch [771/2000]\n",
      "Train Loss: 32752704.0853\n",
      "Val Loss: 33367193.0184, MAE: 4958.5078, NMAE: 75.5965, R^2: 0.0872\n",
      "Epoch [772/2000]\n",
      "Train Loss: 32511360.3060\n",
      "Val Loss: 33309487.6883, MAE: 4914.2456, NMAE: 74.9217, R^2: 0.0888\n",
      "Epoch [773/2000]\n",
      "Train Loss: 32389759.8569\n",
      "Val Loss: 33389376.6010, MAE: 4934.1855, NMAE: 75.2257, R^2: 0.0866\n",
      "Epoch [774/2000]\n",
      "Train Loss: 32880893.2655\n",
      "Val Loss: 32906515.3109, MAE: 4904.1318, NMAE: 74.7675, R^2: 0.0998\n",
      "Epoch [775/2000]\n",
      "Train Loss: 32697101.4207\n",
      "Val Loss: 33138266.1278, MAE: 4927.6104, NMAE: 75.1255, R^2: 0.0935\n",
      "Epoch [776/2000]\n",
      "Train Loss: 32389601.3034\n",
      "Val Loss: 33230123.1528, MAE: 4953.1553, NMAE: 75.5149, R^2: 0.0909\n",
      "Epoch [777/2000]\n",
      "Train Loss: 32216410.3112\n",
      "Val Loss: 33520559.7625, MAE: 4983.3838, NMAE: 75.9758, R^2: 0.0830\n",
      "Epoch [778/2000]\n",
      "Train Loss: 32090277.9802\n",
      "Val Loss: 32958899.5101, MAE: 4891.7148, NMAE: 74.5782, R^2: 0.0984\n",
      "Epoch [779/2000]\n",
      "Train Loss: 32248883.4362\n",
      "Val Loss: 33448179.6575, MAE: 4971.8540, NMAE: 75.8000, R^2: 0.0850\n",
      "Epoch [780/2000]\n",
      "Train Loss: 32298665.7440\n",
      "Val Loss: 33379745.5440, MAE: 4963.3467, NMAE: 75.6703, R^2: 0.0868\n",
      "Epoch [781/2000]\n",
      "Train Loss: 32134211.2078\n",
      "Val Loss: 33323540.1280, MAE: 4954.8682, NMAE: 75.5410, R^2: 0.0884\n",
      "Epoch [782/2000]\n",
      "Train Loss: 31984869.9302\n",
      "Val Loss: 33463785.8508, MAE: 4974.0015, NMAE: 75.8327, R^2: 0.0845\n",
      "Epoch [783/2000]\n",
      "Train Loss: 32079183.2095\n",
      "Val Loss: 33585220.8830, MAE: 4986.8989, NMAE: 76.0294, R^2: 0.0812\n",
      "Epoch [784/2000]\n",
      "Train Loss: 31986076.8741\n",
      "Val Loss: 33611428.5386, MAE: 4988.1670, NMAE: 76.0487, R^2: 0.0805\n",
      "Epoch [785/2000]\n",
      "Train Loss: 31999987.5172\n",
      "Val Loss: 33407084.3148, MAE: 4966.4683, NMAE: 75.7179, R^2: 0.0861\n",
      "Epoch [786/2000]\n",
      "Train Loss: 32456130.5302\n",
      "Val Loss: 33169836.2655, MAE: 4933.8569, NMAE: 75.2207, R^2: 0.0926\n",
      "Epoch [787/2000]\n",
      "Train Loss: 32478993.8414\n",
      "Val Loss: 33221301.1550, MAE: 4935.9468, NMAE: 75.2526, R^2: 0.0912\n",
      "Epoch [788/2000]\n",
      "Train Loss: 32629445.2940\n",
      "Val Loss: 33368821.4683, MAE: 4972.0566, NMAE: 75.8031, R^2: 0.0871\n",
      "Epoch [789/2000]\n",
      "Train Loss: 32324991.7845\n",
      "Val Loss: 33263042.0311, MAE: 4919.3413, NMAE: 74.9994, R^2: 0.0900\n",
      "Epoch [790/2000]\n",
      "Train Loss: 32139400.0698\n",
      "Val Loss: 33354478.7958, MAE: 4944.0225, NMAE: 75.3757, R^2: 0.0875\n",
      "Epoch [791/2000]\n",
      "Train Loss: 32303224.1991\n",
      "Val Loss: 33336974.3066, MAE: 4924.4707, NMAE: 75.0776, R^2: 0.0880\n",
      "Epoch [792/2000]\n",
      "Train Loss: 32020251.0116\n",
      "Val Loss: 33676025.5093, MAE: 4977.5879, NMAE: 75.8874, R^2: 0.0787\n",
      "Epoch [793/2000]\n",
      "Train Loss: 32132310.2353\n",
      "Val Loss: 33134934.6205, MAE: 4924.8618, NMAE: 75.0836, R^2: 0.0935\n",
      "Epoch [794/2000]\n",
      "Train Loss: 32009526.7353\n",
      "Val Loss: 33187657.3687, MAE: 4940.9604, NMAE: 75.3290, R^2: 0.0921\n",
      "Epoch [795/2000]\n",
      "Train Loss: 33028652.0379\n",
      "Val Loss: 33510921.8286, MAE: 4997.2109, NMAE: 76.1866, R^2: 0.0833\n",
      "Epoch [796/2000]\n",
      "Train Loss: 32599700.4966\n",
      "Val Loss: 33403362.3120, MAE: 4973.7681, NMAE: 75.8292, R^2: 0.0862\n",
      "Epoch [797/2000]\n",
      "Train Loss: 32241695.9388\n",
      "Val Loss: 33268252.5229, MAE: 4962.8931, NMAE: 75.6634, R^2: 0.0899\n",
      "Epoch [798/2000]\n",
      "Train Loss: 32367748.6664\n",
      "Val Loss: 32998529.5225, MAE: 4926.4790, NMAE: 75.1082, R^2: 0.0973\n",
      "Epoch [799/2000]\n",
      "Train Loss: 32112125.7457\n",
      "Val Loss: 33114839.4994, MAE: 4944.9639, NMAE: 75.3900, R^2: 0.0941\n",
      "Epoch [800/2000]\n",
      "Train Loss: 32101411.0845\n",
      "Val Loss: 33230604.9495, MAE: 4955.3379, NMAE: 75.5482, R^2: 0.0909\n",
      "Epoch [801/2000]\n",
      "Train Loss: 32248513.7388\n",
      "Val Loss: 33004029.8005, MAE: 4920.5054, NMAE: 75.0171, R^2: 0.0971\n",
      "Epoch [802/2000]\n",
      "Train Loss: 32138140.4216\n",
      "Val Loss: 32643668.8517, MAE: 4878.2612, NMAE: 74.3731, R^2: 0.1070\n",
      "Epoch [803/2000]\n",
      "Train Loss: 32147883.0862\n",
      "Val Loss: 33248740.2837, MAE: 4891.4028, NMAE: 74.5734, R^2: 0.0904\n",
      "Epoch [804/2000]\n",
      "Train Loss: 32030967.2707\n",
      "Val Loss: 33259248.6373, MAE: 4912.2119, NMAE: 74.8907, R^2: 0.0901\n",
      "Epoch [805/2000]\n",
      "Train Loss: 31857856.6371\n",
      "Val Loss: 33454998.8667, MAE: 4965.4219, NMAE: 75.7019, R^2: 0.0848\n",
      "Epoch [806/2000]\n",
      "Train Loss: 32419895.1851\n",
      "Val Loss: 33571032.2682, MAE: 4916.2061, NMAE: 74.9516, R^2: 0.0816\n",
      "Epoch [807/2000]\n",
      "Train Loss: 32074813.7065\n",
      "Val Loss: 33193498.8386, MAE: 4920.7041, NMAE: 75.0202, R^2: 0.0919\n",
      "Epoch [808/2000]\n",
      "Train Loss: 31776494.0272\n",
      "Val Loss: 33036518.1366, MAE: 4921.6284, NMAE: 75.0343, R^2: 0.0962\n",
      "Epoch [809/2000]\n",
      "Train Loss: 31663443.3129\n",
      "Val Loss: 32951893.2393, MAE: 4916.4463, NMAE: 74.9553, R^2: 0.0986\n",
      "Epoch [810/2000]\n",
      "Train Loss: 31600434.2379\n",
      "Val Loss: 33022779.0352, MAE: 4909.8228, NMAE: 74.8543, R^2: 0.0966\n",
      "Epoch [811/2000]\n",
      "Train Loss: 31699499.6474\n",
      "Val Loss: 33458093.1457, MAE: 4988.5698, NMAE: 76.0548, R^2: 0.0847\n",
      "Epoch [812/2000]\n",
      "Train Loss: 31831611.0606\n",
      "Val Loss: 33046613.9517, MAE: 4924.6152, NMAE: 75.0798, R^2: 0.0960\n",
      "Epoch [813/2000]\n",
      "Train Loss: 31562857.5543\n",
      "Val Loss: 33662778.7418, MAE: 4976.1880, NMAE: 75.8661, R^2: 0.0791\n",
      "Epoch [814/2000]\n",
      "Train Loss: 31476435.4790\n",
      "Val Loss: 33630860.0698, MAE: 4961.5288, NMAE: 75.6426, R^2: 0.0800\n",
      "Epoch [815/2000]\n",
      "Train Loss: 31680169.6914\n",
      "Val Loss: 33418865.9499, MAE: 4938.2837, NMAE: 75.2882, R^2: 0.0858\n",
      "Epoch [816/2000]\n",
      "Train Loss: 31556116.9802\n",
      "Val Loss: 33303731.5413, MAE: 4928.1992, NMAE: 75.1344, R^2: 0.0889\n",
      "Epoch [817/2000]\n",
      "Train Loss: 32061361.8821\n",
      "Val Loss: 33142546.3054, MAE: 4933.0005, NMAE: 75.2076, R^2: 0.0933\n",
      "Epoch [818/2000]\n",
      "Train Loss: 32174456.9042\n",
      "Val Loss: 33430696.5104, MAE: 4955.3950, NMAE: 75.5491, R^2: 0.0855\n",
      "Epoch [819/2000]\n",
      "Train Loss: 32223454.6379\n",
      "Val Loss: 33342761.6625, MAE: 4960.9175, NMAE: 75.6333, R^2: 0.0879\n",
      "Epoch [820/2000]\n",
      "Train Loss: 32140731.6888\n",
      "Val Loss: 33312987.4733, MAE: 4966.0566, NMAE: 75.7116, R^2: 0.0887\n",
      "Epoch [821/2000]\n",
      "Train Loss: 32142988.2095\n",
      "Val Loss: 32834348.1736, MAE: 4912.0449, NMAE: 74.8882, R^2: 0.1018\n",
      "Epoch [822/2000]\n",
      "Train Loss: 31885382.9556\n",
      "Val Loss: 33440493.4569, MAE: 4989.0186, NMAE: 76.0617, R^2: 0.0852\n",
      "Epoch [823/2000]\n",
      "Train Loss: 31915045.9629\n",
      "Val Loss: 32925694.0036, MAE: 4920.1362, NMAE: 75.0115, R^2: 0.0993\n",
      "Epoch [824/2000]\n",
      "Train Loss: 31889587.8060\n",
      "Val Loss: 33214125.3379, MAE: 4957.8140, NMAE: 75.5859, R^2: 0.0914\n",
      "Epoch [825/2000]\n",
      "Train Loss: 31762192.3719\n",
      "Val Loss: 33291841.5087, MAE: 4923.6304, NMAE: 75.0648, R^2: 0.0893\n",
      "Epoch [826/2000]\n",
      "Train Loss: 31685639.0759\n",
      "Val Loss: 33206578.5987, MAE: 4954.6909, NMAE: 75.5383, R^2: 0.0916\n",
      "Epoch [827/2000]\n",
      "Train Loss: 31738766.8259\n",
      "Val Loss: 33215948.2111, MAE: 4963.4165, NMAE: 75.6714, R^2: 0.0913\n",
      "Epoch [828/2000]\n",
      "Train Loss: 31773843.0776\n",
      "Val Loss: 33359779.9309, MAE: 4981.0547, NMAE: 75.9403, R^2: 0.0874\n",
      "Epoch [829/2000]\n",
      "Train Loss: 31833696.1491\n",
      "Val Loss: 33684064.3752, MAE: 5021.3003, NMAE: 76.5538, R^2: 0.0785\n",
      "Epoch [830/2000]\n",
      "Train Loss: 31585094.8323\n",
      "Val Loss: 33113952.5222, MAE: 4949.3696, NMAE: 75.4572, R^2: 0.0941\n",
      "Epoch [831/2000]\n",
      "Train Loss: 31725961.1431\n",
      "Val Loss: 33194269.3530, MAE: 4971.8418, NMAE: 75.7998, R^2: 0.0919\n",
      "Epoch [832/2000]\n",
      "Train Loss: 31478860.8750\n",
      "Val Loss: 33154796.4465, MAE: 4950.5840, NMAE: 75.4757, R^2: 0.0930\n",
      "Epoch [833/2000]\n",
      "Train Loss: 31380208.1776\n",
      "Val Loss: 33097411.1401, MAE: 4950.7227, NMAE: 75.4778, R^2: 0.0946\n",
      "Epoch [834/2000]\n",
      "Train Loss: 31533602.7724\n",
      "Val Loss: 33670292.3172, MAE: 5018.1807, NMAE: 76.5063, R^2: 0.0789\n",
      "Epoch [835/2000]\n",
      "Train Loss: 31456478.6998\n",
      "Val Loss: 33311296.7917, MAE: 4969.2944, NMAE: 75.7610, R^2: 0.0887\n",
      "Epoch [836/2000]\n",
      "Train Loss: 31391945.3440\n",
      "Val Loss: 33150592.7002, MAE: 4946.5864, NMAE: 75.4148, R^2: 0.0931\n",
      "Epoch [837/2000]\n",
      "Train Loss: 31591129.1795\n",
      "Val Loss: 33088059.8606, MAE: 4936.4673, NMAE: 75.2605, R^2: 0.0948\n",
      "Epoch [838/2000]\n",
      "Train Loss: 31622400.5777\n",
      "Val Loss: 33105396.4865, MAE: 4937.1475, NMAE: 75.2709, R^2: 0.0944\n",
      "Epoch [839/2000]\n",
      "Train Loss: 31757482.5555\n",
      "Val Loss: 32529892.7405, MAE: 4870.4678, NMAE: 74.2543, R^2: 0.1101\n",
      "Epoch [840/2000]\n",
      "Train Loss: 31588762.4648\n",
      "Val Loss: 33317718.0483, MAE: 4959.5464, NMAE: 75.6124, R^2: 0.0885\n",
      "Epoch [841/2000]\n",
      "Train Loss: 31481803.6409\n",
      "Val Loss: 33500706.5324, MAE: 4985.8882, NMAE: 76.0140, R^2: 0.0835\n",
      "Epoch [842/2000]\n",
      "Train Loss: 31356979.3595\n",
      "Val Loss: 33318356.0749, MAE: 4978.3145, NMAE: 75.8985, R^2: 0.0885\n",
      "Epoch [843/2000]\n",
      "Train Loss: 31353567.4297\n",
      "Val Loss: 33338058.8353, MAE: 4975.3281, NMAE: 75.8530, R^2: 0.0880\n",
      "Epoch [844/2000]\n",
      "Train Loss: 31377717.7853\n",
      "Val Loss: 33269954.4173, MAE: 4967.8438, NMAE: 75.7389, R^2: 0.0899\n",
      "Epoch [845/2000]\n",
      "Train Loss: 31521674.8418\n",
      "Val Loss: 32910802.8341, MAE: 4920.1543, NMAE: 75.0118, R^2: 0.0997\n",
      "Epoch [846/2000]\n",
      "Train Loss: 31448864.4409\n",
      "Val Loss: 33174466.1381, MAE: 4946.1216, NMAE: 75.4077, R^2: 0.0925\n",
      "Epoch [847/2000]\n",
      "Train Loss: 31371138.7610\n",
      "Val Loss: 33094793.8156, MAE: 4944.2407, NMAE: 75.3790, R^2: 0.0946\n",
      "Epoch [848/2000]\n",
      "Train Loss: 31526925.2621\n",
      "Val Loss: 33518013.8201, MAE: 5007.9912, NMAE: 76.3509, R^2: 0.0831\n",
      "Epoch [849/2000]\n",
      "Train Loss: 31473724.0916\n",
      "Val Loss: 33297913.4793, MAE: 4978.3301, NMAE: 75.8987, R^2: 0.0891\n",
      "Epoch [850/2000]\n",
      "Train Loss: 31426751.8727\n",
      "Val Loss: 33180848.5644, MAE: 4953.4927, NMAE: 75.5201, R^2: 0.0923\n",
      "Epoch [851/2000]\n",
      "Train Loss: 31681742.6659\n",
      "Val Loss: 32812031.4217, MAE: 4912.8887, NMAE: 74.9010, R^2: 0.1024\n",
      "Epoch [852/2000]\n",
      "Train Loss: 31489887.5148\n",
      "Val Loss: 33294137.3407, MAE: 4967.1440, NMAE: 75.7282, R^2: 0.0892\n",
      "Epoch [853/2000]\n",
      "Train Loss: 31446201.5125\n",
      "Val Loss: 33000963.1980, MAE: 4943.3506, NMAE: 75.3654, R^2: 0.0972\n",
      "Epoch [854/2000]\n",
      "Train Loss: 31437555.6216\n",
      "Val Loss: 33171138.3439, MAE: 4952.0591, NMAE: 75.4982, R^2: 0.0926\n",
      "Epoch [855/2000]\n",
      "Train Loss: 31259366.7552\n",
      "Val Loss: 33239972.9003, MAE: 4962.5679, NMAE: 75.6584, R^2: 0.0907\n",
      "Epoch [856/2000]\n",
      "Train Loss: 31160841.7494\n",
      "Val Loss: 33021665.6405, MAE: 4940.5254, NMAE: 75.3224, R^2: 0.0966\n",
      "Epoch [857/2000]\n",
      "Train Loss: 31163374.0155\n",
      "Val Loss: 33459205.4901, MAE: 4988.4507, NMAE: 76.0530, R^2: 0.0847\n",
      "Epoch [858/2000]\n",
      "Train Loss: 31659340.0205\n",
      "Val Loss: 33464812.6624, MAE: 4997.4033, NMAE: 76.1895, R^2: 0.0845\n",
      "Epoch [859/2000]\n",
      "Train Loss: 31283124.1597\n",
      "Val Loss: 32868809.0318, MAE: 4922.4351, NMAE: 75.0466, R^2: 0.1008\n",
      "Epoch [860/2000]\n",
      "Train Loss: 31230752.2350\n",
      "Val Loss: 33137483.0101, MAE: 4945.6709, NMAE: 75.4008, R^2: 0.0935\n",
      "Epoch [861/2000]\n",
      "Train Loss: 31155054.4221\n",
      "Val Loss: 32904874.2055, MAE: 4917.8770, NMAE: 74.9771, R^2: 0.0998\n",
      "Epoch [862/2000]\n",
      "Train Loss: 31360842.7881\n",
      "Val Loss: 32821564.3534, MAE: 4884.0815, NMAE: 74.4618, R^2: 0.1021\n",
      "Epoch [863/2000]\n",
      "Train Loss: 31132608.2431\n",
      "Val Loss: 32994281.8123, MAE: 4930.5029, NMAE: 75.1696, R^2: 0.0974\n",
      "Epoch [864/2000]\n",
      "Train Loss: 30760514.0603\n",
      "Val Loss: 33231365.4079, MAE: 4950.9756, NMAE: 75.4817, R^2: 0.0909\n",
      "Epoch [865/2000]\n",
      "Train Loss: 31095515.6006\n",
      "Val Loss: 33120285.7569, MAE: 4950.7051, NMAE: 75.4776, R^2: 0.0939\n",
      "Epoch [866/2000]\n",
      "Train Loss: 31180924.8450\n",
      "Val Loss: 33237769.9509, MAE: 4948.8267, NMAE: 75.4489, R^2: 0.0907\n",
      "Epoch [867/2000]\n",
      "Train Loss: 30706934.2758\n",
      "Val Loss: 33775561.6839, MAE: 5017.7485, NMAE: 76.4997, R^2: 0.0760\n",
      "Epoch [868/2000]\n",
      "Train Loss: 30863565.3053\n",
      "Val Loss: 33325514.9501, MAE: 4948.8789, NMAE: 75.4497, R^2: 0.0883\n",
      "Epoch [869/2000]\n",
      "Train Loss: 30684105.6919\n",
      "Val Loss: 33420978.2825, MAE: 4971.5928, NMAE: 75.7960, R^2: 0.0857\n",
      "Epoch [870/2000]\n",
      "Train Loss: 30841601.4448\n",
      "Val Loss: 33039326.9209, MAE: 4928.5850, NMAE: 75.1403, R^2: 0.0962\n",
      "Epoch [871/2000]\n",
      "Train Loss: 31331865.0284\n",
      "Val Loss: 32292461.9829, MAE: 4864.9458, NMAE: 74.1701, R^2: 0.1166\n",
      "Epoch [872/2000]\n",
      "Train Loss: 32689792.0267\n",
      "Val Loss: 32355607.5519, MAE: 4843.1128, NMAE: 73.8372, R^2: 0.1149\n",
      "Epoch [873/2000]\n",
      "Train Loss: 31882156.0995\n",
      "Val Loss: 32853588.7361, MAE: 4889.4985, NMAE: 74.5444, R^2: 0.1012\n",
      "Epoch [874/2000]\n",
      "Train Loss: 31765609.1088\n",
      "Val Loss: 32662748.4102, MAE: 4849.3325, NMAE: 73.9321, R^2: 0.1065\n",
      "Epoch [875/2000]\n",
      "Train Loss: 31864888.9017\n",
      "Val Loss: 32618978.0168, MAE: 4875.1870, NMAE: 74.3262, R^2: 0.1077\n",
      "Epoch [876/2000]\n",
      "Train Loss: 31916255.3315\n",
      "Val Loss: 32958659.7753, MAE: 4922.6191, NMAE: 75.0494, R^2: 0.0984\n",
      "Epoch [877/2000]\n",
      "Train Loss: 31365502.9991\n",
      "Val Loss: 32731327.2907, MAE: 4878.3892, NMAE: 74.3750, R^2: 0.1046\n",
      "Epoch [878/2000]\n",
      "Train Loss: 31451558.2494\n",
      "Val Loss: 32710679.3006, MAE: 4890.0815, NMAE: 74.5533, R^2: 0.1052\n",
      "Epoch [879/2000]\n",
      "Train Loss: 31945672.4578\n",
      "Val Loss: 32559886.5775, MAE: 4878.3223, NMAE: 74.3740, R^2: 0.1093\n",
      "Epoch [880/2000]\n",
      "Train Loss: 31670328.6099\n",
      "Val Loss: 32493955.5846, MAE: 4854.5918, NMAE: 74.0122, R^2: 0.1111\n",
      "Epoch [881/2000]\n",
      "Train Loss: 31150455.1170\n",
      "Val Loss: 32529581.9873, MAE: 4866.4131, NMAE: 74.1925, R^2: 0.1101\n",
      "Epoch [882/2000]\n",
      "Train Loss: 30990279.9297\n",
      "Val Loss: 32578424.9143, MAE: 4869.7026, NMAE: 74.2426, R^2: 0.1088\n",
      "Epoch [883/2000]\n",
      "Train Loss: 30816955.3043\n",
      "Val Loss: 32891329.1263, MAE: 4916.4316, NMAE: 74.9550, R^2: 0.1002\n",
      "Epoch [884/2000]\n",
      "Train Loss: 31192520.1586\n",
      "Val Loss: 33128368.1813, MAE: 4928.9756, NMAE: 75.1463, R^2: 0.0937\n",
      "Epoch [885/2000]\n",
      "Train Loss: 31196461.0634\n",
      "Val Loss: 32310029.0273, MAE: 4836.7412, NMAE: 73.7401, R^2: 0.1161\n",
      "Epoch [886/2000]\n",
      "Train Loss: 31199105.1241\n",
      "Val Loss: 33026005.2509, MAE: 4907.0781, NMAE: 74.8124, R^2: 0.0965\n",
      "Epoch [887/2000]\n",
      "Train Loss: 31428052.7241\n",
      "Val Loss: 32743181.6749, MAE: 4894.6221, NMAE: 74.6225, R^2: 0.1043\n",
      "Epoch [888/2000]\n",
      "Train Loss: 30896691.2741\n",
      "Val Loss: 33141878.3627, MAE: 4943.0425, NMAE: 75.3607, R^2: 0.0934\n",
      "Epoch [889/2000]\n",
      "Train Loss: 31503612.0741\n",
      "Val Loss: 32454493.3548, MAE: 4880.2290, NMAE: 74.4031, R^2: 0.1122\n",
      "Epoch [890/2000]\n",
      "Train Loss: 31013473.4838\n",
      "Val Loss: 33571671.2128, MAE: 5000.8774, NMAE: 76.2425, R^2: 0.0816\n",
      "Epoch [891/2000]\n",
      "Train Loss: 31190191.9469\n",
      "Val Loss: 33192091.7619, MAE: 4906.3462, NMAE: 74.8013, R^2: 0.0920\n",
      "Epoch [892/2000]\n",
      "Train Loss: 30973312.7319\n",
      "Val Loss: 33253253.4291, MAE: 4933.5444, NMAE: 75.2159, R^2: 0.0903\n",
      "Epoch [893/2000]\n",
      "Train Loss: 31150216.7069\n",
      "Val Loss: 33492582.3333, MAE: 4987.2065, NMAE: 76.0341, R^2: 0.0838\n",
      "Epoch [894/2000]\n",
      "Train Loss: 31446065.8405\n",
      "Val Loss: 32874385.2893, MAE: 4853.6587, NMAE: 73.9980, R^2: 0.1007\n",
      "Epoch [895/2000]\n",
      "Train Loss: 30760602.1991\n",
      "Val Loss: 32902268.1169, MAE: 4902.4443, NMAE: 74.7418, R^2: 0.0999\n",
      "Epoch [896/2000]\n",
      "Train Loss: 30894944.6448\n",
      "Val Loss: 32777540.7067, MAE: 4891.8164, NMAE: 74.5798, R^2: 0.1033\n",
      "Epoch [897/2000]\n",
      "Train Loss: 31207136.7595\n",
      "Val Loss: 32455418.5347, MAE: 4858.5737, NMAE: 74.0729, R^2: 0.1121\n",
      "Epoch [898/2000]\n",
      "Train Loss: 30903041.8112\n",
      "Val Loss: 32563879.4398, MAE: 4883.9985, NMAE: 74.4606, R^2: 0.1092\n",
      "Epoch [899/2000]\n",
      "Train Loss: 30749817.2233\n",
      "Val Loss: 33114237.1247, MAE: 4945.5815, NMAE: 75.3994, R^2: 0.0941\n",
      "Epoch [900/2000]\n",
      "Train Loss: 30857942.0595\n",
      "Val Loss: 32413332.9383, MAE: 4872.5957, NMAE: 74.2867, R^2: 0.1133\n",
      "Epoch [901/2000]\n",
      "Train Loss: 31089844.2845\n",
      "Val Loss: 32404737.3048, MAE: 4881.2759, NMAE: 74.4191, R^2: 0.1135\n",
      "Epoch [902/2000]\n",
      "Train Loss: 30976322.0500\n",
      "Val Loss: 32375192.3722, MAE: 4887.6948, NMAE: 74.5169, R^2: 0.1143\n",
      "Epoch [903/2000]\n",
      "Train Loss: 31000187.0086\n",
      "Val Loss: 32517452.5831, MAE: 4895.1948, NMAE: 74.6313, R^2: 0.1104\n",
      "Epoch [904/2000]\n",
      "Train Loss: 30748063.2586\n",
      "Val Loss: 33310414.5188, MAE: 4987.9736, NMAE: 76.0458, R^2: 0.0887\n",
      "Epoch [905/2000]\n",
      "Train Loss: 30775566.6198\n",
      "Val Loss: 32557396.9257, MAE: 4882.1709, NMAE: 74.4327, R^2: 0.1093\n",
      "Epoch [906/2000]\n",
      "Train Loss: 30523686.3147\n",
      "Val Loss: 33363171.4629, MAE: 4985.6021, NMAE: 76.0096, R^2: 0.0873\n",
      "Epoch [907/2000]\n",
      "Train Loss: 30454678.3483\n",
      "Val Loss: 33340229.4167, MAE: 4956.0459, NMAE: 75.5590, R^2: 0.0879\n",
      "Epoch [908/2000]\n",
      "Train Loss: 30700449.0991\n",
      "Val Loss: 33049447.8217, MAE: 4935.0649, NMAE: 75.2391, R^2: 0.0959\n",
      "Epoch [909/2000]\n",
      "Train Loss: 30694644.2388\n",
      "Val Loss: 33121978.5013, MAE: 4961.9058, NMAE: 75.6483, R^2: 0.0939\n",
      "Epoch [910/2000]\n",
      "Train Loss: 31018896.9000\n",
      "Val Loss: 33064099.1813, MAE: 4940.3979, NMAE: 75.3204, R^2: 0.0955\n",
      "Epoch [911/2000]\n",
      "Train Loss: 30977126.2862\n",
      "Val Loss: 32881819.2168, MAE: 4901.7764, NMAE: 74.7316, R^2: 0.1005\n",
      "Epoch [912/2000]\n",
      "Train Loss: 30703648.0345\n",
      "Val Loss: 32729122.7593, MAE: 4882.2495, NMAE: 74.4339, R^2: 0.1046\n",
      "Epoch [913/2000]\n",
      "Train Loss: 31477807.0483\n",
      "Val Loss: 32908408.8262, MAE: 4890.8521, NMAE: 74.5651, R^2: 0.0997\n",
      "Epoch [914/2000]\n",
      "Train Loss: 31222710.5405\n",
      "Val Loss: 33039721.9616, MAE: 4912.9961, NMAE: 74.9027, R^2: 0.0961\n",
      "Epoch [915/2000]\n",
      "Train Loss: 30712732.1629\n",
      "Val Loss: 33400168.9087, MAE: 4960.0195, NMAE: 75.6196, R^2: 0.0863\n",
      "Epoch [916/2000]\n",
      "Train Loss: 30790321.2828\n",
      "Val Loss: 33053943.8998, MAE: 4929.4160, NMAE: 75.1530, R^2: 0.0958\n",
      "Epoch [917/2000]\n",
      "Train Loss: 31246125.6491\n",
      "Val Loss: 32681466.2644, MAE: 4855.1323, NMAE: 74.0205, R^2: 0.1059\n",
      "Epoch [918/2000]\n",
      "Train Loss: 31389193.5793\n",
      "Val Loss: 32782519.3291, MAE: 4882.8008, NMAE: 74.4423, R^2: 0.1032\n",
      "Epoch [919/2000]\n",
      "Train Loss: 30990606.4250\n",
      "Val Loss: 32676589.4277, MAE: 4890.0386, NMAE: 74.5526, R^2: 0.1061\n",
      "Epoch [920/2000]\n",
      "Train Loss: 30777014.5810\n",
      "Val Loss: 32838210.4930, MAE: 4889.0996, NMAE: 74.5383, R^2: 0.1017\n",
      "Epoch [921/2000]\n",
      "Train Loss: 31189505.0474\n",
      "Val Loss: 32398040.1421, MAE: 4849.7075, NMAE: 73.9378, R^2: 0.1137\n",
      "Epoch [922/2000]\n",
      "Train Loss: 30647116.5907\n",
      "Val Loss: 32978861.1168, MAE: 4916.0298, NMAE: 74.9489, R^2: 0.0978\n",
      "Epoch [923/2000]\n",
      "Train Loss: 30556368.5409\n",
      "Val Loss: 32996332.7384, MAE: 4906.1567, NMAE: 74.7984, R^2: 0.0973\n",
      "Epoch [924/2000]\n",
      "Train Loss: 30495317.7241\n",
      "Val Loss: 32820384.3617, MAE: 4896.4248, NMAE: 74.6500, R^2: 0.1021\n",
      "Epoch [925/2000]\n",
      "Train Loss: 30221495.5026\n",
      "Val Loss: 32730044.8424, MAE: 4883.8291, NMAE: 74.4580, R^2: 0.1046\n",
      "Epoch [926/2000]\n",
      "Train Loss: 30468481.0866\n",
      "Val Loss: 32694146.1953, MAE: 4878.1729, NMAE: 74.3717, R^2: 0.1056\n",
      "Epoch [927/2000]\n",
      "Train Loss: 30377292.9968\n",
      "Val Loss: 32959194.1231, MAE: 4935.5566, NMAE: 75.2466, R^2: 0.0984\n",
      "Epoch [928/2000]\n",
      "Train Loss: 31360964.2754\n",
      "Val Loss: 33289752.5076, MAE: 4978.4819, NMAE: 75.9010, R^2: 0.0893\n",
      "Epoch [929/2000]\n",
      "Train Loss: 31712994.0343\n",
      "Val Loss: 32784029.4795, MAE: 4902.0581, NMAE: 74.7359, R^2: 0.1031\n",
      "Epoch [930/2000]\n",
      "Train Loss: 32356037.2629\n",
      "Val Loss: 32195020.0548, MAE: 4801.1250, NMAE: 73.1971, R^2: 0.1193\n",
      "Epoch [931/2000]\n",
      "Train Loss: 31540678.8974\n",
      "Val Loss: 32659039.7871, MAE: 4867.2378, NMAE: 74.2050, R^2: 0.1066\n",
      "Epoch [932/2000]\n",
      "Train Loss: 31051985.0474\n",
      "Val Loss: 32864261.1798, MAE: 4922.3535, NMAE: 75.0453, R^2: 0.1009\n",
      "Epoch [933/2000]\n",
      "Train Loss: 31210898.0853\n",
      "Val Loss: 32753325.5058, MAE: 4903.4849, NMAE: 74.7576, R^2: 0.1040\n",
      "Epoch [934/2000]\n",
      "Train Loss: 30828369.5414\n",
      "Val Loss: 32968679.8884, MAE: 4957.0942, NMAE: 75.5750, R^2: 0.0981\n",
      "Epoch [935/2000]\n",
      "Train Loss: 30941330.0336\n",
      "Val Loss: 33318651.8133, MAE: 4976.6313, NMAE: 75.8728, R^2: 0.0885\n",
      "Epoch [936/2000]\n",
      "Train Loss: 30795242.6216\n",
      "Val Loss: 32723174.4348, MAE: 4903.6260, NMAE: 74.7598, R^2: 0.1048\n",
      "Epoch [937/2000]\n",
      "Train Loss: 30648641.4655\n",
      "Val Loss: 33200714.6138, MAE: 4955.2129, NMAE: 75.5463, R^2: 0.0917\n",
      "Epoch [938/2000]\n",
      "Train Loss: 30536059.9345\n",
      "Val Loss: 32740933.8247, MAE: 4896.6729, NMAE: 74.6538, R^2: 0.1043\n",
      "Epoch [939/2000]\n",
      "Train Loss: 30451397.6103\n",
      "Val Loss: 32778963.7696, MAE: 4873.2910, NMAE: 74.2973, R^2: 0.1033\n",
      "Epoch [940/2000]\n",
      "Train Loss: 30486726.1226\n",
      "Val Loss: 32926870.7820, MAE: 4912.4126, NMAE: 74.8938, R^2: 0.0992\n",
      "Epoch [941/2000]\n",
      "Train Loss: 31323053.9798\n",
      "Val Loss: 33369412.3318, MAE: 4942.8101, NMAE: 75.3572, R^2: 0.0871\n",
      "Epoch [942/2000]\n",
      "Train Loss: 31191075.0769\n",
      "Val Loss: 33466303.4722, MAE: 4957.5645, NMAE: 75.5821, R^2: 0.0845\n",
      "Epoch [943/2000]\n",
      "Train Loss: 30380722.4017\n",
      "Val Loss: 33008294.6564, MAE: 4908.1792, NMAE: 74.8292, R^2: 0.0970\n",
      "Epoch [944/2000]\n",
      "Train Loss: 30771732.8817\n",
      "Val Loss: 32826714.6695, MAE: 4912.3970, NMAE: 74.8935, R^2: 0.1020\n",
      "Epoch [945/2000]\n",
      "Train Loss: 30500157.1806\n",
      "Val Loss: 32824412.7246, MAE: 4890.3481, NMAE: 74.5574, R^2: 0.1020\n",
      "Epoch [946/2000]\n",
      "Train Loss: 30342990.7394\n",
      "Val Loss: 32843815.0670, MAE: 4905.2832, NMAE: 74.7851, R^2: 0.1015\n",
      "Epoch [947/2000]\n",
      "Train Loss: 30861922.2161\n",
      "Val Loss: 32388396.1599, MAE: 4837.9243, NMAE: 73.7581, R^2: 0.1140\n",
      "Epoch [948/2000]\n",
      "Train Loss: 30769357.9634\n",
      "Val Loss: 32475977.9391, MAE: 4865.6753, NMAE: 74.1812, R^2: 0.1116\n",
      "Epoch [949/2000]\n",
      "Train Loss: 30832015.5897\n",
      "Val Loss: 32603946.1095, MAE: 4892.7246, NMAE: 74.5936, R^2: 0.1081\n",
      "Epoch [950/2000]\n",
      "Train Loss: 30146886.0953\n",
      "Val Loss: 32751561.7118, MAE: 4920.2466, NMAE: 75.0132, R^2: 0.1040\n",
      "Epoch [951/2000]\n",
      "Train Loss: 30440014.0242\n",
      "Val Loss: 33157001.1568, MAE: 4961.3447, NMAE: 75.6398, R^2: 0.0929\n",
      "Epoch [952/2000]\n",
      "Train Loss: 30295359.4998\n",
      "Val Loss: 32786281.2841, MAE: 4915.6479, NMAE: 74.9431, R^2: 0.1031\n",
      "Epoch [953/2000]\n",
      "Train Loss: 30452460.0538\n",
      "Val Loss: 33676995.8617, MAE: 5009.5801, NMAE: 76.3752, R^2: 0.0787\n",
      "Epoch [954/2000]\n",
      "Train Loss: 31014397.1591\n",
      "Val Loss: 33159900.1585, MAE: 4950.4009, NMAE: 75.4729, R^2: 0.0929\n",
      "Epoch [955/2000]\n",
      "Train Loss: 30811383.3935\n",
      "Val Loss: 33497189.9893, MAE: 4999.6157, NMAE: 76.2232, R^2: 0.0836\n",
      "Epoch [956/2000]\n",
      "Train Loss: 30526336.3253\n",
      "Val Loss: 32297174.2125, MAE: 4842.4995, NMAE: 73.8279, R^2: 0.1165\n",
      "Epoch [957/2000]\n",
      "Train Loss: 30289597.2843\n",
      "Val Loss: 32911361.0726, MAE: 4897.6064, NMAE: 74.6680, R^2: 0.0997\n",
      "Epoch [958/2000]\n",
      "Train Loss: 30567108.3119\n",
      "Val Loss: 32956069.3030, MAE: 4933.5967, NMAE: 75.2167, R^2: 0.0984\n",
      "Epoch [959/2000]\n",
      "Train Loss: 30456047.5838\n",
      "Val Loss: 32459856.4956, MAE: 4879.7529, NMAE: 74.3958, R^2: 0.1120\n",
      "Epoch [960/2000]\n",
      "Train Loss: 30141991.4030\n",
      "Val Loss: 33406823.0343, MAE: 4956.2725, NMAE: 75.5624, R^2: 0.0861\n",
      "Epoch [961/2000]\n",
      "Train Loss: 30137547.1884\n",
      "Val Loss: 32982519.9035, MAE: 4906.3032, NMAE: 74.8006, R^2: 0.0977\n",
      "Epoch [962/2000]\n",
      "Train Loss: 30476969.5422\n",
      "Val Loss: 32637994.6486, MAE: 4861.7954, NMAE: 74.1221, R^2: 0.1071\n",
      "Epoch [963/2000]\n",
      "Train Loss: 30309872.9335\n",
      "Val Loss: 33000117.6263, MAE: 4877.1982, NMAE: 74.3569, R^2: 0.0972\n",
      "Epoch [964/2000]\n",
      "Train Loss: 30056259.6212\n",
      "Val Loss: 32639952.4177, MAE: 4896.7593, NMAE: 74.6551, R^2: 0.1071\n",
      "Epoch [965/2000]\n",
      "Train Loss: 30302694.6828\n",
      "Val Loss: 32386065.5982, MAE: 4824.0454, NMAE: 73.5465, R^2: 0.1140\n",
      "Epoch [966/2000]\n",
      "Train Loss: 30956649.4474\n",
      "Val Loss: 32482816.6250, MAE: 4877.7651, NMAE: 74.3655, R^2: 0.1114\n",
      "Epoch [967/2000]\n",
      "Train Loss: 29859728.6069\n",
      "Val Loss: 32794714.5434, MAE: 4896.3813, NMAE: 74.6494, R^2: 0.1029\n",
      "Epoch [968/2000]\n",
      "Train Loss: 29863742.5784\n",
      "Val Loss: 33738103.9575, MAE: 5005.5806, NMAE: 76.3142, R^2: 0.0770\n",
      "Epoch [969/2000]\n",
      "Train Loss: 32317437.4948\n",
      "Val Loss: 32595319.0426, MAE: 4873.7129, NMAE: 74.3038, R^2: 0.1083\n",
      "Epoch [970/2000]\n",
      "Train Loss: 29862378.0802\n",
      "Val Loss: 32677935.7816, MAE: 4862.5054, NMAE: 74.1329, R^2: 0.1060\n",
      "Epoch [971/2000]\n",
      "Train Loss: 29705803.9554\n",
      "Val Loss: 33217582.4831, MAE: 4934.6621, NMAE: 75.2330, R^2: 0.0913\n",
      "Epoch [972/2000]\n",
      "Train Loss: 30004228.2968\n",
      "Val Loss: 32840536.5293, MAE: 4889.2949, NMAE: 74.5413, R^2: 0.1016\n",
      "Epoch [973/2000]\n",
      "Train Loss: 29907260.8328\n",
      "Val Loss: 32941110.2164, MAE: 4912.2505, NMAE: 74.8913, R^2: 0.0988\n",
      "Epoch [974/2000]\n",
      "Train Loss: 30362877.3569\n",
      "Val Loss: 32986365.6237, MAE: 4941.3110, NMAE: 75.3343, R^2: 0.0976\n",
      "Epoch [975/2000]\n",
      "Train Loss: 30346698.7254\n",
      "Val Loss: 32418150.0662, MAE: 4847.4390, NMAE: 73.9032, R^2: 0.1132\n",
      "Epoch [976/2000]\n",
      "Train Loss: 30281197.0171\n",
      "Val Loss: 32866980.4564, MAE: 4873.9517, NMAE: 74.3074, R^2: 0.1009\n",
      "Epoch [977/2000]\n",
      "Train Loss: 30580006.1252\n",
      "Val Loss: 33093591.7962, MAE: 4881.7700, NMAE: 74.4266, R^2: 0.0947\n",
      "Epoch [978/2000]\n",
      "Train Loss: 30085687.7207\n",
      "Val Loss: 32727713.2891, MAE: 4835.6421, NMAE: 73.7233, R^2: 0.1047\n",
      "Epoch [979/2000]\n",
      "Train Loss: 30616372.6789\n",
      "Val Loss: 32430108.6034, MAE: 4806.6973, NMAE: 73.2820, R^2: 0.1128\n",
      "Epoch [980/2000]\n",
      "Train Loss: 30513247.4957\n",
      "Val Loss: 32915917.2791, MAE: 4877.0513, NMAE: 74.3546, R^2: 0.0995\n",
      "Epoch [981/2000]\n",
      "Train Loss: 29910272.9560\n",
      "Val Loss: 32974801.1753, MAE: 4906.6543, NMAE: 74.8060, R^2: 0.0979\n",
      "Epoch [982/2000]\n",
      "Train Loss: 30238387.5103\n",
      "Val Loss: 33370657.6259, MAE: 4902.1694, NMAE: 74.7376, R^2: 0.0871\n",
      "Epoch [983/2000]\n",
      "Train Loss: 30148812.9172\n",
      "Val Loss: 33154662.2269, MAE: 4945.4253, NMAE: 75.3971, R^2: 0.0930\n",
      "Epoch [984/2000]\n",
      "Train Loss: 29540520.2733\n",
      "Val Loss: 33557678.1213, MAE: 4978.4883, NMAE: 75.9011, R^2: 0.0820\n",
      "Epoch [985/2000]\n",
      "Train Loss: 30506641.9621\n",
      "Val Loss: 32615159.5525, MAE: 4880.8306, NMAE: 74.4123, R^2: 0.1078\n",
      "Epoch [986/2000]\n",
      "Train Loss: 29964180.7509\n",
      "Val Loss: 33266766.1082, MAE: 4943.7056, NMAE: 75.3708, R^2: 0.0899\n",
      "Epoch [987/2000]\n",
      "Train Loss: 29977694.1741\n",
      "Val Loss: 32672010.7420, MAE: 4887.1846, NMAE: 74.5091, R^2: 0.1062\n",
      "Epoch [988/2000]\n",
      "Train Loss: 30016511.6608\n",
      "Val Loss: 32818329.3862, MAE: 4879.5151, NMAE: 74.3922, R^2: 0.1022\n",
      "Epoch [989/2000]\n",
      "Train Loss: 29720331.6414\n",
      "Val Loss: 32983996.8679, MAE: 4893.3833, NMAE: 74.6036, R^2: 0.0977\n",
      "Epoch [990/2000]\n",
      "Train Loss: 29801660.9056\n",
      "Val Loss: 33109974.5073, MAE: 4932.2129, NMAE: 75.1956, R^2: 0.0942\n",
      "Epoch [991/2000]\n",
      "Train Loss: 30260032.0228\n",
      "Val Loss: 32673159.9564, MAE: 4857.8828, NMAE: 74.0624, R^2: 0.1062\n",
      "Epoch [992/2000]\n",
      "Train Loss: 30003012.0058\n",
      "Val Loss: 32902954.4766, MAE: 4829.4478, NMAE: 73.6289, R^2: 0.0999\n",
      "Epoch [993/2000]\n",
      "Train Loss: 30546281.2970\n",
      "Val Loss: 33017042.7323, MAE: 4825.4922, NMAE: 73.5686, R^2: 0.0968\n",
      "Epoch [994/2000]\n",
      "Train Loss: 29789867.9888\n",
      "Val Loss: 33507242.2229, MAE: 4916.1807, NMAE: 74.9512, R^2: 0.0834\n",
      "Epoch [995/2000]\n",
      "Train Loss: 30633295.3944\n",
      "Val Loss: 32951878.0361, MAE: 4869.6782, NMAE: 74.2422, R^2: 0.0986\n",
      "Epoch [996/2000]\n",
      "Train Loss: 30146517.2457\n",
      "Val Loss: 32583414.9508, MAE: 4842.5786, NMAE: 73.8291, R^2: 0.1086\n",
      "Epoch [997/2000]\n",
      "Train Loss: 30038410.5595\n",
      "Val Loss: 32468070.8532, MAE: 4815.3955, NMAE: 73.4147, R^2: 0.1118\n",
      "Epoch [998/2000]\n",
      "Train Loss: 29433585.1440\n",
      "Val Loss: 32465182.8666, MAE: 4819.8091, NMAE: 73.4819, R^2: 0.1119\n",
      "Epoch [999/2000]\n",
      "Train Loss: 29225219.8276\n",
      "Val Loss: 33152369.1220, MAE: 4914.9307, NMAE: 74.9322, R^2: 0.0931\n",
      "Epoch [1000/2000]\n",
      "Train Loss: 29774536.4142\n",
      "Val Loss: 33265998.9154, MAE: 4879.5518, NMAE: 74.3928, R^2: 0.0900\n",
      "Epoch [1001/2000]\n",
      "Train Loss: 29415242.4259\n",
      "Val Loss: 33320135.2187, MAE: 5005.2427, NMAE: 76.3090, R^2: 0.0885\n",
      "Epoch [1002/2000]\n",
      "Train Loss: 30776260.1741\n",
      "Val Loss: 32320487.1798, MAE: 4824.7139, NMAE: 73.5567, R^2: 0.1158\n",
      "Epoch [1003/2000]\n",
      "Train Loss: 29890484.3612\n",
      "Val Loss: 32734749.6945, MAE: 4870.0117, NMAE: 74.2473, R^2: 0.1045\n",
      "Epoch [1004/2000]\n",
      "Train Loss: 29649657.5207\n",
      "Val Loss: 32351357.2075, MAE: 4807.8452, NMAE: 73.2995, R^2: 0.1150\n",
      "Epoch [1005/2000]\n",
      "Train Loss: 29910824.3819\n",
      "Val Loss: 33500675.7280, MAE: 4811.0127, NMAE: 73.3478, R^2: 0.0835\n",
      "Epoch [1006/2000]\n",
      "Train Loss: 30790363.6336\n",
      "Val Loss: 32796618.1503, MAE: 4800.6030, NMAE: 73.1891, R^2: 0.1028\n",
      "Epoch [1007/2000]\n",
      "Train Loss: 30222534.7922\n",
      "Val Loss: 32890075.1959, MAE: 4813.7510, NMAE: 73.3896, R^2: 0.1002\n",
      "Epoch [1008/2000]\n",
      "Train Loss: 29813054.2241\n",
      "Val Loss: 32894075.0261, MAE: 4847.0332, NMAE: 73.8970, R^2: 0.1001\n",
      "Epoch [1009/2000]\n",
      "Train Loss: 29935166.9405\n",
      "Val Loss: 33403816.8821, MAE: 4929.0830, NMAE: 75.1479, R^2: 0.0862\n",
      "Epoch [1010/2000]\n",
      "Train Loss: 29631729.6897\n",
      "Val Loss: 32998419.0319, MAE: 4840.4272, NMAE: 73.7963, R^2: 0.0973\n",
      "Epoch [1011/2000]\n",
      "Train Loss: 30017924.4336\n",
      "Val Loss: 32801381.2325, MAE: 4862.3696, NMAE: 74.1308, R^2: 0.1027\n",
      "Epoch [1012/2000]\n",
      "Train Loss: 30569781.4802\n",
      "Val Loss: 32543673.7729, MAE: 4782.8125, NMAE: 72.9179, R^2: 0.1097\n",
      "Epoch [1013/2000]\n",
      "Train Loss: 29848727.3069\n",
      "Val Loss: 32882811.5332, MAE: 4828.9292, NMAE: 73.6210, R^2: 0.1004\n",
      "Epoch [1014/2000]\n",
      "Train Loss: 29798795.5034\n",
      "Val Loss: 32569009.8208, MAE: 4838.5015, NMAE: 73.7669, R^2: 0.1090\n",
      "Epoch [1015/2000]\n",
      "Train Loss: 30342368.8871\n",
      "Val Loss: 32742887.4037, MAE: 4847.6431, NMAE: 73.9063, R^2: 0.1043\n",
      "Epoch [1016/2000]\n",
      "Train Loss: 29915391.2914\n",
      "Val Loss: 32659466.8901, MAE: 4829.8315, NMAE: 73.6347, R^2: 0.1066\n",
      "Epoch [1017/2000]\n",
      "Train Loss: 29950109.7069\n",
      "Val Loss: 33004577.0497, MAE: 4885.5762, NMAE: 74.4846, R^2: 0.0971\n",
      "Epoch [1018/2000]\n",
      "Train Loss: 31762070.6414\n",
      "Val Loss: 32367008.2327, MAE: 4848.1489, NMAE: 73.9140, R^2: 0.1146\n",
      "Epoch [1019/2000]\n",
      "Train Loss: 31002522.7638\n",
      "Val Loss: 31773402.4763, MAE: 4768.3350, NMAE: 72.6972, R^2: 0.1308\n",
      "Epoch [1020/2000]\n",
      "Train Loss: 30532445.4172\n",
      "Val Loss: 32521516.4288, MAE: 4833.3691, NMAE: 73.6887, R^2: 0.1103\n",
      "Epoch [1021/2000]\n",
      "Train Loss: 30482369.5560\n",
      "Val Loss: 33058357.3504, MAE: 4944.5127, NMAE: 75.3832, R^2: 0.0956\n",
      "Epoch [1022/2000]\n",
      "Train Loss: 30257451.7879\n",
      "Val Loss: 31924005.8735, MAE: 4805.7539, NMAE: 73.2677, R^2: 0.1267\n",
      "Epoch [1023/2000]\n",
      "Train Loss: 29874426.8151\n",
      "Val Loss: 32540318.0881, MAE: 4801.8848, NMAE: 73.2087, R^2: 0.1098\n",
      "Epoch [1024/2000]\n",
      "Train Loss: 29803395.2466\n",
      "Val Loss: 33165371.2606, MAE: 4908.2349, NMAE: 74.8301, R^2: 0.0927\n",
      "Epoch [1025/2000]\n",
      "Train Loss: 30045736.5388\n",
      "Val Loss: 32744381.3731, MAE: 4796.5083, NMAE: 73.1267, R^2: 0.1042\n",
      "Epoch [1026/2000]\n",
      "Train Loss: 31207873.5350\n",
      "Val Loss: 31957268.3998, MAE: 4750.8647, NMAE: 72.4308, R^2: 0.1258\n",
      "Epoch [1027/2000]\n",
      "Train Loss: 31291488.7698\n",
      "Val Loss: 32215356.2426, MAE: 4833.8276, NMAE: 73.6957, R^2: 0.1187\n",
      "Epoch [1028/2000]\n",
      "Train Loss: 30437504.6411\n",
      "Val Loss: 32321309.7872, MAE: 4825.8721, NMAE: 73.5744, R^2: 0.1158\n",
      "Epoch [1029/2000]\n",
      "Train Loss: 30336997.9745\n",
      "Val Loss: 32500566.6219, MAE: 4804.9004, NMAE: 73.2546, R^2: 0.1109\n",
      "Epoch [1030/2000]\n",
      "Train Loss: 30283459.3961\n",
      "Val Loss: 32434983.8520, MAE: 4870.8413, NMAE: 74.2600, R^2: 0.1127\n",
      "Epoch [1031/2000]\n",
      "Train Loss: 29956527.1375\n",
      "Val Loss: 32503618.5905, MAE: 4860.5181, NMAE: 74.1026, R^2: 0.1108\n",
      "Epoch [1032/2000]\n",
      "Train Loss: 31070151.8198\n",
      "Val Loss: 31705787.0266, MAE: 4755.9321, NMAE: 72.5081, R^2: 0.1326\n",
      "Epoch [1033/2000]\n",
      "Train Loss: 30368716.8570\n",
      "Val Loss: 32167474.9964, MAE: 4809.9858, NMAE: 73.3322, R^2: 0.1200\n",
      "Epoch [1034/2000]\n",
      "Train Loss: 29734935.6222\n",
      "Val Loss: 32497435.6680, MAE: 4840.9194, NMAE: 73.8038, R^2: 0.1110\n",
      "Epoch [1035/2000]\n",
      "Train Loss: 29938107.6985\n",
      "Val Loss: 32289247.8746, MAE: 4765.1123, NMAE: 72.6480, R^2: 0.1167\n",
      "Epoch [1036/2000]\n",
      "Train Loss: 29424683.6250\n",
      "Val Loss: 32883164.5479, MAE: 4841.7578, NMAE: 73.8166, R^2: 0.1004\n",
      "Epoch [1037/2000]\n",
      "Train Loss: 29964959.9647\n",
      "Val Loss: 32363205.4126, MAE: 4830.0254, NMAE: 73.6377, R^2: 0.1147\n",
      "Epoch [1038/2000]\n",
      "Train Loss: 30341948.3371\n",
      "Val Loss: 31821411.1528, MAE: 4807.8770, NMAE: 73.3000, R^2: 0.1295\n",
      "Epoch [1039/2000]\n",
      "Train Loss: 30514263.2431\n",
      "Val Loss: 31943460.9810, MAE: 4808.0142, NMAE: 73.3021, R^2: 0.1261\n",
      "Epoch [1040/2000]\n",
      "Train Loss: 29939529.7267\n",
      "Val Loss: 31872025.4024, MAE: 4779.8477, NMAE: 72.8727, R^2: 0.1281\n",
      "Epoch [1041/2000]\n",
      "Train Loss: 29881379.8448\n",
      "Val Loss: 33031638.2064, MAE: 4929.8193, NMAE: 75.1591, R^2: 0.0964\n",
      "Epoch [1042/2000]\n",
      "Train Loss: 29824926.5991\n",
      "Val Loss: 32443843.6051, MAE: 4836.2075, NMAE: 73.7320, R^2: 0.1125\n",
      "Epoch [1043/2000]\n",
      "Train Loss: 29514639.3190\n",
      "Val Loss: 32501738.3661, MAE: 4843.5659, NMAE: 73.8441, R^2: 0.1109\n",
      "Epoch [1044/2000]\n",
      "Train Loss: 30667458.1862\n",
      "Val Loss: 32292678.2737, MAE: 4676.7344, NMAE: 71.3007, R^2: 0.1166\n",
      "Epoch [1045/2000]\n",
      "Train Loss: 30615705.1422\n",
      "Val Loss: 33234261.4059, MAE: 4976.6909, NMAE: 75.8737, R^2: 0.0908\n",
      "Epoch [1046/2000]\n",
      "Train Loss: 29904472.7397\n",
      "Val Loss: 32575541.4911, MAE: 4881.3296, NMAE: 74.4199, R^2: 0.1088\n",
      "Epoch [1047/2000]\n",
      "Train Loss: 29241415.4491\n",
      "Val Loss: 33404401.5699, MAE: 4955.7319, NMAE: 75.5542, R^2: 0.0862\n",
      "Epoch [1048/2000]\n",
      "Train Loss: 29753660.9940\n",
      "Val Loss: 32504739.1019, MAE: 4856.8496, NMAE: 74.0467, R^2: 0.1108\n",
      "Epoch [1049/2000]\n",
      "Train Loss: 29203276.5638\n",
      "Val Loss: 33214136.6703, MAE: 4935.2690, NMAE: 75.2422, R^2: 0.0914\n",
      "Epoch [1050/2000]\n",
      "Train Loss: 30176518.9940\n",
      "Val Loss: 32009131.6347, MAE: 4787.9888, NMAE: 72.9968, R^2: 0.1243\n",
      "Epoch [1051/2000]\n",
      "Train Loss: 31293914.0207\n",
      "Val Loss: 32488073.6321, MAE: 4862.4722, NMAE: 74.1324, R^2: 0.1112\n",
      "Epoch [1052/2000]\n",
      "Train Loss: 30285302.7802\n",
      "Val Loss: 32891462.2515, MAE: 4927.6108, NMAE: 75.1255, R^2: 0.1002\n",
      "Epoch [1053/2000]\n",
      "Train Loss: 30003236.1871\n",
      "Val Loss: 32615231.3990, MAE: 4877.1079, NMAE: 74.3555, R^2: 0.1078\n",
      "Epoch [1054/2000]\n",
      "Train Loss: 29859917.2871\n",
      "Val Loss: 32917914.4989, MAE: 4918.6650, NMAE: 74.9891, R^2: 0.0995\n",
      "Epoch [1055/2000]\n",
      "Train Loss: 31905572.3595\n",
      "Val Loss: 34642709.7576, MAE: 4762.8613, NMAE: 72.6137, R^2: 0.0523\n",
      "Epoch [1056/2000]\n",
      "Train Loss: 31502634.9181\n",
      "Val Loss: 32781137.5438, MAE: 4809.2070, NMAE: 73.3203, R^2: 0.1032\n",
      "Epoch [1057/2000]\n",
      "Train Loss: 30760867.6707\n",
      "Val Loss: 32280470.4398, MAE: 4790.8135, NMAE: 73.0399, R^2: 0.1169\n",
      "Epoch [1058/2000]\n",
      "Train Loss: 30608773.4302\n",
      "Val Loss: 31980829.3895, MAE: 4774.7798, NMAE: 72.7954, R^2: 0.1251\n",
      "Epoch [1059/2000]\n",
      "Train Loss: 30175013.5672\n",
      "Val Loss: 32132272.7863, MAE: 4811.8477, NMAE: 73.3606, R^2: 0.1210\n",
      "Epoch [1060/2000]\n",
      "Train Loss: 30622097.7888\n",
      "Val Loss: 32177161.6973, MAE: 4836.0835, NMAE: 73.7301, R^2: 0.1197\n",
      "Epoch [1061/2000]\n",
      "Train Loss: 29786635.0974\n",
      "Val Loss: 32591098.9111, MAE: 4842.6592, NMAE: 73.8303, R^2: 0.1084\n",
      "Epoch [1062/2000]\n",
      "Train Loss: 29981063.7629\n",
      "Val Loss: 32252585.6330, MAE: 4796.6982, NMAE: 73.1296, R^2: 0.1177\n",
      "Epoch [1063/2000]\n",
      "Train Loss: 29647467.6026\n",
      "Val Loss: 32490108.3856, MAE: 4828.7920, NMAE: 73.6189, R^2: 0.1112\n",
      "Epoch [1064/2000]\n",
      "Train Loss: 29757113.1224\n",
      "Val Loss: 32566797.9380, MAE: 4849.4849, NMAE: 73.9344, R^2: 0.1091\n",
      "Epoch [1065/2000]\n",
      "Train Loss: 29645385.5310\n",
      "Val Loss: 32626399.9853, MAE: 4832.3813, NMAE: 73.6736, R^2: 0.1075\n",
      "Epoch [1066/2000]\n",
      "Train Loss: 29776822.2914\n",
      "Val Loss: 32658351.3528, MAE: 4853.4238, NMAE: 73.9944, R^2: 0.1066\n",
      "Epoch [1067/2000]\n",
      "Train Loss: 29815413.2767\n",
      "Val Loss: 32325612.9434, MAE: 4800.7930, NMAE: 73.1920, R^2: 0.1157\n",
      "Epoch [1068/2000]\n",
      "Train Loss: 29724430.2164\n",
      "Val Loss: 32475921.9998, MAE: 4849.3511, NMAE: 73.9323, R^2: 0.1116\n",
      "Epoch [1069/2000]\n",
      "Train Loss: 29615205.3310\n",
      "Val Loss: 32802081.4034, MAE: 4841.0518, NMAE: 73.8058, R^2: 0.1027\n",
      "Epoch [1070/2000]\n",
      "Train Loss: 29941380.0534\n",
      "Val Loss: 33157292.3913, MAE: 4916.5640, NMAE: 74.9571, R^2: 0.0929\n",
      "Epoch [1071/2000]\n",
      "Train Loss: 29820999.6569\n",
      "Val Loss: 32991663.0123, MAE: 4859.1333, NMAE: 74.0815, R^2: 0.0975\n",
      "Epoch [1072/2000]\n",
      "Train Loss: 29161590.6603\n",
      "Val Loss: 32757105.8147, MAE: 4866.4956, NMAE: 74.1937, R^2: 0.1039\n",
      "Epoch [1073/2000]\n",
      "Train Loss: 29276420.8017\n",
      "Val Loss: 32746610.9752, MAE: 4850.2163, NMAE: 73.9455, R^2: 0.1042\n",
      "Epoch [1074/2000]\n",
      "Train Loss: 29574491.9397\n",
      "Val Loss: 32540789.1422, MAE: 4814.9702, NMAE: 73.4082, R^2: 0.1098\n",
      "Epoch [1075/2000]\n",
      "Train Loss: 29277150.5155\n",
      "Val Loss: 32798993.1169, MAE: 4909.7490, NMAE: 74.8532, R^2: 0.1027\n",
      "Epoch [1076/2000]\n",
      "Train Loss: 29458512.0652\n",
      "Val Loss: 33604729.1780, MAE: 4983.7358, NMAE: 75.9811, R^2: 0.0807\n",
      "Epoch [1077/2000]\n",
      "Train Loss: 29250742.1718\n",
      "Val Loss: 32708672.0271, MAE: 4872.7729, NMAE: 74.2894, R^2: 0.1052\n",
      "Epoch [1078/2000]\n",
      "Train Loss: 28774307.9551\n",
      "Val Loss: 33435331.3395, MAE: 4941.1548, NMAE: 75.3320, R^2: 0.0853\n",
      "Epoch [1079/2000]\n",
      "Train Loss: 29051307.7161\n",
      "Val Loss: 33028887.3723, MAE: 4904.1357, NMAE: 74.7676, R^2: 0.0964\n",
      "Epoch [1080/2000]\n",
      "Train Loss: 28949705.6290\n",
      "Val Loss: 33011063.0737, MAE: 4904.2241, NMAE: 74.7689, R^2: 0.0969\n",
      "Epoch [1081/2000]\n",
      "Train Loss: 29629211.5827\n",
      "Val Loss: 32722022.5869, MAE: 4907.5532, NMAE: 74.8197, R^2: 0.1048\n",
      "Epoch [1082/2000]\n",
      "Train Loss: 30486328.0831\n",
      "Val Loss: 32830120.2025, MAE: 4867.1855, NMAE: 74.2042, R^2: 0.1019\n",
      "Epoch [1083/2000]\n",
      "Train Loss: 29803676.0603\n",
      "Val Loss: 32971387.4404, MAE: 4901.0688, NMAE: 74.7208, R^2: 0.0980\n",
      "Epoch [1084/2000]\n",
      "Train Loss: 29177005.7776\n",
      "Val Loss: 34152234.7556, MAE: 5042.7700, NMAE: 76.8812, R^2: 0.0657\n",
      "Epoch [1085/2000]\n",
      "Train Loss: 29178720.4940\n",
      "Val Loss: 34095809.5460, MAE: 4986.9248, NMAE: 76.0298, R^2: 0.0673\n",
      "Epoch [1086/2000]\n",
      "Train Loss: 29189208.6569\n",
      "Val Loss: 32942166.4778, MAE: 4904.2148, NMAE: 74.7688, R^2: 0.0988\n",
      "Epoch [1087/2000]\n",
      "Train Loss: 29486712.0612\n",
      "Val Loss: 32847909.9553, MAE: 4886.2788, NMAE: 74.4953, R^2: 0.1014\n",
      "Epoch [1088/2000]\n",
      "Train Loss: 29295005.6362\n",
      "Val Loss: 33346149.5315, MAE: 4953.9609, NMAE: 75.5272, R^2: 0.0878\n",
      "Epoch [1089/2000]\n",
      "Train Loss: 28926971.2931\n",
      "Val Loss: 33269789.8465, MAE: 4972.0713, NMAE: 75.8033, R^2: 0.0899\n",
      "Epoch [1090/2000]\n",
      "Train Loss: 31690776.7155\n",
      "Val Loss: 31914428.2554, MAE: 4734.5737, NMAE: 72.1825, R^2: 0.1269\n",
      "Epoch [1091/2000]\n",
      "Train Loss: 30504946.0871\n",
      "Val Loss: 31868362.3813, MAE: 4783.5264, NMAE: 72.9288, R^2: 0.1282\n",
      "Epoch [1092/2000]\n",
      "Train Loss: 30077037.4603\n",
      "Val Loss: 32470855.1775, MAE: 4869.9399, NMAE: 74.2462, R^2: 0.1117\n",
      "Epoch [1093/2000]\n",
      "Train Loss: 29952007.8379\n",
      "Val Loss: 32513706.0466, MAE: 4876.1904, NMAE: 74.3415, R^2: 0.1105\n",
      "Epoch [1094/2000]\n",
      "Train Loss: 29580306.8603\n",
      "Val Loss: 33347220.0172, MAE: 4954.4106, NMAE: 75.5341, R^2: 0.0877\n",
      "Epoch [1095/2000]\n",
      "Train Loss: 30025550.3828\n",
      "Val Loss: 31901779.5478, MAE: 4762.5767, NMAE: 72.6094, R^2: 0.1273\n",
      "Epoch [1096/2000]\n",
      "Train Loss: 29692650.1235\n",
      "Val Loss: 31963342.2129, MAE: 4778.2720, NMAE: 72.8487, R^2: 0.1256\n",
      "Epoch [1097/2000]\n",
      "Train Loss: 29506980.0915\n",
      "Val Loss: 33172582.7490, MAE: 4926.0830, NMAE: 75.1022, R^2: 0.0925\n",
      "Epoch [1098/2000]\n",
      "Train Loss: 29992870.6245\n",
      "Val Loss: 32421190.8896, MAE: 4851.2471, NMAE: 73.9612, R^2: 0.1131\n",
      "Epoch [1099/2000]\n",
      "Train Loss: 29958416.5457\n",
      "Val Loss: 32298445.8452, MAE: 4843.0684, NMAE: 73.8366, R^2: 0.1164\n",
      "Epoch [1100/2000]\n",
      "Train Loss: 29116112.7919\n",
      "Val Loss: 32617368.5854, MAE: 4884.4062, NMAE: 74.4668, R^2: 0.1077\n",
      "Epoch [1101/2000]\n",
      "Train Loss: 29456261.7448\n",
      "Val Loss: 32128934.9357, MAE: 4818.8442, NMAE: 73.4672, R^2: 0.1211\n",
      "Epoch [1102/2000]\n",
      "Train Loss: 30690413.7440\n",
      "Val Loss: 31639266.0691, MAE: 4787.4336, NMAE: 72.9884, R^2: 0.1345\n",
      "Epoch [1103/2000]\n",
      "Train Loss: 30075130.7741\n",
      "Val Loss: 32784031.2923, MAE: 4909.6074, NMAE: 74.8510, R^2: 0.1031\n",
      "Epoch [1104/2000]\n",
      "Train Loss: 30030092.6017\n",
      "Val Loss: 33029898.6993, MAE: 4934.0933, NMAE: 75.2243, R^2: 0.0964\n",
      "Epoch [1105/2000]\n",
      "Train Loss: 29412718.9060\n",
      "Val Loss: 32028538.1807, MAE: 4813.4497, NMAE: 73.3850, R^2: 0.1238\n",
      "Epoch [1106/2000]\n",
      "Train Loss: 29466272.3397\n",
      "Val Loss: 32822631.9305, MAE: 4916.9326, NMAE: 74.9627, R^2: 0.1021\n",
      "Epoch [1107/2000]\n",
      "Train Loss: 29597681.8983\n",
      "Val Loss: 33039218.8698, MAE: 4933.3105, NMAE: 75.2124, R^2: 0.0962\n",
      "Epoch [1108/2000]\n",
      "Train Loss: 30311591.7448\n",
      "Val Loss: 32822354.0654, MAE: 4884.9087, NMAE: 74.4744, R^2: 0.1021\n",
      "Epoch [1109/2000]\n",
      "Train Loss: 29503562.6552\n",
      "Val Loss: 32595754.5080, MAE: 4905.2290, NMAE: 74.7842, R^2: 0.1083\n",
      "Epoch [1110/2000]\n",
      "Train Loss: 29290278.4483\n",
      "Val Loss: 32714658.0445, MAE: 4896.7725, NMAE: 74.6553, R^2: 0.1050\n",
      "Epoch [1111/2000]\n",
      "Train Loss: 29160300.3164\n",
      "Val Loss: 32638574.6246, MAE: 4852.8037, NMAE: 73.9850, R^2: 0.1071\n",
      "Epoch [1112/2000]\n",
      "Train Loss: 28711633.1819\n",
      "Val Loss: 33700373.3354, MAE: 5005.6880, NMAE: 76.3158, R^2: 0.0781\n",
      "Epoch [1113/2000]\n",
      "Train Loss: 29940941.1693\n",
      "Val Loss: 33006241.5604, MAE: 4936.7002, NMAE: 75.2640, R^2: 0.0971\n",
      "Epoch [1114/2000]\n",
      "Train Loss: 29932232.0902\n",
      "Val Loss: 32741621.7264, MAE: 4862.0498, NMAE: 74.1259, R^2: 0.1043\n",
      "Epoch [1115/2000]\n",
      "Train Loss: 30299036.1027\n",
      "Val Loss: 32114383.3572, MAE: 4807.7095, NMAE: 73.2975, R^2: 0.1215\n",
      "Epoch [1116/2000]\n",
      "Train Loss: 29635064.5220\n",
      "Val Loss: 33216874.4503, MAE: 4942.2915, NMAE: 75.3493, R^2: 0.0913\n",
      "Epoch [1117/2000]\n",
      "Train Loss: 29675651.0031\n",
      "Val Loss: 32481791.6125, MAE: 4825.6289, NMAE: 73.5707, R^2: 0.1114\n",
      "Epoch [1118/2000]\n",
      "Train Loss: 29569417.0285\n",
      "Val Loss: 32788112.5862, MAE: 4875.9839, NMAE: 74.3384, R^2: 0.1030\n",
      "Epoch [1119/2000]\n",
      "Train Loss: 29372644.3900\n",
      "Val Loss: 32743259.7237, MAE: 4820.4419, NMAE: 73.4916, R^2: 0.1043\n",
      "Epoch [1120/2000]\n",
      "Train Loss: 29644795.4863\n",
      "Val Loss: 32164069.7110, MAE: 4804.7153, NMAE: 73.2518, R^2: 0.1201\n",
      "Epoch [1121/2000]\n",
      "Train Loss: 29658732.7926\n",
      "Val Loss: 32393861.7856, MAE: 4845.6401, NMAE: 73.8758, R^2: 0.1138\n",
      "Epoch [1122/2000]\n",
      "Train Loss: 30897565.5645\n",
      "Val Loss: 32880704.8224, MAE: 4901.8022, NMAE: 74.7320, R^2: 0.1005\n",
      "Epoch [1123/2000]\n",
      "Train Loss: 30643381.6009\n",
      "Val Loss: 32335677.0362, MAE: 4877.0562, NMAE: 74.3547, R^2: 0.1154\n",
      "Epoch [1124/2000]\n",
      "Train Loss: 29981723.8867\n",
      "Val Loss: 32631053.7883, MAE: 4876.1304, NMAE: 74.3406, R^2: 0.1073\n",
      "Epoch [1125/2000]\n",
      "Train Loss: 30027858.3085\n",
      "Val Loss: 34012697.2072, MAE: 5050.8843, NMAE: 77.0049, R^2: 0.0695\n",
      "Epoch [1126/2000]\n",
      "Train Loss: 30364873.2850\n",
      "Val Loss: 32554397.1615, MAE: 4905.0825, NMAE: 74.7820, R^2: 0.1094\n",
      "Epoch [1127/2000]\n",
      "Train Loss: 29859943.6609\n",
      "Val Loss: 33284941.7521, MAE: 4927.8252, NMAE: 75.1287, R^2: 0.0894\n",
      "Epoch [1128/2000]\n",
      "Train Loss: 30068058.9200\n",
      "Val Loss: 32886379.6023, MAE: 4900.5269, NMAE: 74.7126, R^2: 0.1003\n",
      "Epoch [1129/2000]\n",
      "Train Loss: 29598760.6087\n",
      "Val Loss: 33173028.8994, MAE: 4886.6421, NMAE: 74.5009, R^2: 0.0925\n",
      "Epoch [1130/2000]\n",
      "Train Loss: 29812640.7505\n",
      "Val Loss: 32511945.6534, MAE: 4837.0415, NMAE: 73.7447, R^2: 0.1106\n",
      "Epoch [1131/2000]\n",
      "Train Loss: 30035541.9018\n",
      "Val Loss: 32608746.4947, MAE: 4885.4355, NMAE: 74.4825, R^2: 0.1079\n",
      "Epoch [1132/2000]\n",
      "Train Loss: 30037611.3666\n",
      "Val Loss: 31527681.9554, MAE: 4736.4502, NMAE: 72.2111, R^2: 0.1375\n",
      "Epoch [1133/2000]\n",
      "Train Loss: 29615980.8640\n",
      "Val Loss: 32091269.7664, MAE: 4793.5894, NMAE: 73.0822, R^2: 0.1221\n",
      "Epoch [1134/2000]\n",
      "Train Loss: 29524741.0086\n",
      "Val Loss: 31916466.4719, MAE: 4793.8540, NMAE: 73.0862, R^2: 0.1269\n",
      "Epoch [1135/2000]\n",
      "Train Loss: 30151133.6146\n",
      "Val Loss: 33076337.8914, MAE: 4939.6587, NMAE: 75.3091, R^2: 0.0951\n",
      "Epoch [1136/2000]\n",
      "Train Loss: 29668160.2156\n",
      "Val Loss: 33769997.0260, MAE: 5039.4976, NMAE: 76.8313, R^2: 0.0762\n",
      "Epoch [1137/2000]\n",
      "Train Loss: 29657230.3287\n",
      "Val Loss: 32581669.1233, MAE: 4857.0278, NMAE: 74.0494, R^2: 0.1087\n",
      "Epoch [1138/2000]\n",
      "Train Loss: 30728289.8730\n",
      "Val Loss: 33244987.3306, MAE: 4943.2993, NMAE: 75.3647, R^2: 0.0905\n",
      "Epoch [1139/2000]\n",
      "Train Loss: 29405377.5446\n",
      "Val Loss: 33682472.8423, MAE: 5018.7246, NMAE: 76.5146, R^2: 0.0786\n",
      "Epoch [1140/2000]\n",
      "Train Loss: 29282765.2798\n",
      "Val Loss: 32396047.1523, MAE: 4828.6982, NMAE: 73.6175, R^2: 0.1138\n",
      "Epoch [1141/2000]\n",
      "Train Loss: 29015665.4518\n",
      "Val Loss: 32959564.6422, MAE: 4920.3369, NMAE: 75.0146, R^2: 0.0983\n",
      "Epoch [1142/2000]\n",
      "Train Loss: 29170470.8534\n",
      "Val Loss: 32967798.0937, MAE: 4937.6309, NMAE: 75.2782, R^2: 0.0981\n",
      "Epoch [1143/2000]\n",
      "Train Loss: 28739730.6361\n",
      "Val Loss: 32931675.3026, MAE: 4903.3862, NMAE: 74.7561, R^2: 0.0991\n",
      "Epoch [1144/2000]\n",
      "Train Loss: 28963190.0937\n",
      "Val Loss: 33041119.1886, MAE: 4862.6260, NMAE: 74.1347, R^2: 0.0961\n",
      "Epoch [1145/2000]\n",
      "Train Loss: 29314003.2506\n",
      "Val Loss: 32685996.0742, MAE: 4872.6465, NMAE: 74.2875, R^2: 0.1058\n",
      "Epoch [1146/2000]\n",
      "Train Loss: 30394092.5912\n",
      "Val Loss: 32195798.2667, MAE: 4870.5713, NMAE: 74.2559, R^2: 0.1192\n",
      "Epoch [1147/2000]\n",
      "Train Loss: 30545293.8463\n",
      "Val Loss: 32237186.4033, MAE: 4837.0825, NMAE: 73.7453, R^2: 0.1181\n",
      "Epoch [1148/2000]\n",
      "Train Loss: 28900849.6169\n",
      "Val Loss: 32493702.4276, MAE: 4843.9517, NMAE: 73.8500, R^2: 0.1111\n",
      "Epoch [1149/2000]\n",
      "Train Loss: 28801436.8190\n",
      "Val Loss: 32439273.5549, MAE: 4863.4321, NMAE: 74.1470, R^2: 0.1126\n",
      "Epoch [1150/2000]\n",
      "Train Loss: 28826287.9697\n",
      "Val Loss: 32281313.2673, MAE: 4816.1187, NMAE: 73.4257, R^2: 0.1169\n",
      "Epoch [1151/2000]\n",
      "Train Loss: 28729657.5256\n",
      "Val Loss: 33323842.6670, MAE: 4952.2046, NMAE: 75.5004, R^2: 0.0884\n",
      "Epoch [1152/2000]\n",
      "Train Loss: 29049716.9654\n",
      "Val Loss: 32820503.7085, MAE: 4885.5312, NMAE: 74.4839, R^2: 0.1021\n",
      "Epoch [1153/2000]\n",
      "Train Loss: 28546653.2980\n",
      "Val Loss: 34485971.6430, MAE: 5060.4419, NMAE: 77.1506, R^2: 0.0566\n",
      "Epoch [1154/2000]\n",
      "Train Loss: 29872275.9765\n",
      "Val Loss: 32382927.2667, MAE: 4793.8633, NMAE: 73.0864, R^2: 0.1141\n",
      "Epoch [1155/2000]\n",
      "Train Loss: 28791151.8421\n",
      "Val Loss: 32798720.6443, MAE: 4834.7236, NMAE: 73.7093, R^2: 0.1027\n",
      "Epoch [1156/2000]\n",
      "Train Loss: 29091366.6135\n",
      "Val Loss: 31655966.3266, MAE: 4733.5469, NMAE: 72.1668, R^2: 0.1340\n",
      "Epoch [1157/2000]\n",
      "Train Loss: 29246189.2014\n",
      "Val Loss: 31797163.7219, MAE: 4791.5391, NMAE: 73.0509, R^2: 0.1301\n",
      "Epoch [1158/2000]\n",
      "Train Loss: 28495723.3037\n",
      "Val Loss: 32602065.5905, MAE: 4836.1284, NMAE: 73.7307, R^2: 0.1081\n",
      "Epoch [1159/2000]\n",
      "Train Loss: 28496876.6284\n",
      "Val Loss: 33200783.4499, MAE: 4913.8643, NMAE: 74.9159, R^2: 0.0917\n",
      "Epoch [1160/2000]\n",
      "Train Loss: 28406777.6267\n",
      "Val Loss: 32619233.5215, MAE: 4846.2310, NMAE: 73.8848, R^2: 0.1077\n",
      "Epoch [1161/2000]\n",
      "Train Loss: 28404568.2435\n",
      "Val Loss: 32642556.3017, MAE: 4844.7769, NMAE: 73.8626, R^2: 0.1070\n",
      "Epoch [1162/2000]\n",
      "Train Loss: 28166937.6939\n",
      "Val Loss: 33490487.7499, MAE: 4929.8379, NMAE: 75.1594, R^2: 0.0838\n",
      "Epoch [1163/2000]\n",
      "Train Loss: 28631286.0417\n",
      "Val Loss: 32539340.0821, MAE: 4816.2651, NMAE: 73.4279, R^2: 0.1098\n",
      "Epoch [1164/2000]\n",
      "Train Loss: 28443698.6698\n",
      "Val Loss: 32890188.8400, MAE: 4870.1836, NMAE: 74.2499, R^2: 0.1002\n",
      "Epoch [1165/2000]\n",
      "Train Loss: 28166023.0203\n",
      "Val Loss: 32337101.6383, MAE: 4825.6519, NMAE: 73.5710, R^2: 0.1154\n",
      "Epoch [1166/2000]\n",
      "Train Loss: 28461438.3520\n",
      "Val Loss: 34348816.1417, MAE: 5034.7300, NMAE: 76.7586, R^2: 0.0603\n",
      "Epoch [1167/2000]\n",
      "Train Loss: 29738933.0153\n",
      "Val Loss: 32812861.7965, MAE: 4877.9761, NMAE: 74.3687, R^2: 0.1024\n",
      "Epoch [1168/2000]\n",
      "Train Loss: 29272083.6216\n",
      "Val Loss: 32959530.8154, MAE: 4864.9932, NMAE: 74.1708, R^2: 0.0983\n",
      "Epoch [1169/2000]\n",
      "Train Loss: 28932497.7626\n",
      "Val Loss: 32529487.2783, MAE: 4821.1143, NMAE: 73.5018, R^2: 0.1101\n",
      "Epoch [1170/2000]\n",
      "Train Loss: 28577891.1144\n",
      "Val Loss: 33481472.3417, MAE: 4936.7778, NMAE: 75.2652, R^2: 0.0841\n",
      "Epoch [1171/2000]\n",
      "Train Loss: 28343548.1303\n",
      "Val Loss: 33235948.0791, MAE: 4882.5137, NMAE: 74.4379, R^2: 0.0908\n",
      "Epoch [1172/2000]\n",
      "Train Loss: 28600994.7348\n",
      "Val Loss: 33731714.7288, MAE: 4964.7817, NMAE: 75.6922, R^2: 0.0772\n",
      "Epoch [1173/2000]\n",
      "Train Loss: 28067353.0699\n",
      "Val Loss: 33623565.0600, MAE: 4940.6040, NMAE: 75.3236, R^2: 0.0802\n",
      "Epoch [1174/2000]\n",
      "Train Loss: 28346877.0306\n",
      "Val Loss: 33358822.6456, MAE: 4902.1318, NMAE: 74.7370, R^2: 0.0874\n",
      "Epoch [1175/2000]\n",
      "Train Loss: 28310391.6622\n",
      "Val Loss: 33521830.9984, MAE: 4903.7153, NMAE: 74.7612, R^2: 0.0830\n",
      "Epoch [1176/2000]\n",
      "Train Loss: 29338925.7772\n",
      "Val Loss: 32675466.3958, MAE: 4830.1079, NMAE: 73.6390, R^2: 0.1061\n",
      "Epoch [1177/2000]\n",
      "Train Loss: 29214246.2374\n",
      "Val Loss: 32480714.7381, MAE: 4799.6768, NMAE: 73.1750, R^2: 0.1114\n",
      "Epoch [1178/2000]\n",
      "Train Loss: 29384005.8095\n",
      "Val Loss: 32220004.1815, MAE: 4733.4897, NMAE: 72.1659, R^2: 0.1186\n",
      "Epoch [1179/2000]\n",
      "Train Loss: 29252272.5037\n",
      "Val Loss: 32994243.9318, MAE: 4907.5723, NMAE: 74.8200, R^2: 0.0974\n",
      "Epoch [1180/2000]\n",
      "Train Loss: 28933558.7922\n",
      "Val Loss: 32676693.8549, MAE: 4821.8838, NMAE: 73.5136, R^2: 0.1061\n",
      "Epoch [1181/2000]\n",
      "Train Loss: 28081795.4409\n",
      "Val Loss: 32854832.0722, MAE: 4817.6675, NMAE: 73.4493, R^2: 0.1012\n",
      "Epoch [1182/2000]\n",
      "Train Loss: 28310309.0188\n",
      "Val Loss: 32632372.8857, MAE: 4799.8628, NMAE: 73.1778, R^2: 0.1073\n",
      "Epoch [1183/2000]\n",
      "Train Loss: 29124278.8525\n",
      "Val Loss: 33293033.4543, MAE: 4894.7646, NMAE: 74.6247, R^2: 0.0892\n",
      "Epoch [1184/2000]\n",
      "Train Loss: 28560502.3829\n",
      "Val Loss: 32943262.0709, MAE: 4873.5337, NMAE: 74.3010, R^2: 0.0988\n",
      "Epoch [1185/2000]\n",
      "Train Loss: 28120709.5291\n",
      "Val Loss: 33528107.9932, MAE: 4916.5825, NMAE: 74.9573, R^2: 0.0828\n",
      "Epoch [1186/2000]\n",
      "Train Loss: 27848499.0466\n",
      "Val Loss: 33052734.6962, MAE: 4846.0166, NMAE: 73.8815, R^2: 0.0958\n",
      "Epoch [1187/2000]\n",
      "Train Loss: 28231187.4098\n",
      "Val Loss: 33132268.6184, MAE: 4867.0693, NMAE: 74.2025, R^2: 0.0936\n",
      "Epoch [1188/2000]\n",
      "Train Loss: 27590013.4388\n",
      "Val Loss: 33422105.5582, MAE: 4908.3643, NMAE: 74.8320, R^2: 0.0857\n",
      "Epoch [1189/2000]\n",
      "Train Loss: 27730214.1055\n",
      "Val Loss: 33345046.5127, MAE: 4878.6699, NMAE: 74.3793, R^2: 0.0878\n",
      "Epoch [1190/2000]\n",
      "Train Loss: 28429179.7375\n",
      "Val Loss: 32890461.0371, MAE: 4912.0161, NMAE: 74.8877, R^2: 0.1002\n",
      "Epoch [1191/2000]\n",
      "Train Loss: 28490242.3226\n",
      "Val Loss: 33974183.1371, MAE: 5005.0972, NMAE: 76.3068, R^2: 0.0706\n",
      "Epoch [1192/2000]\n",
      "Train Loss: 29092884.2483\n",
      "Val Loss: 32562010.3566, MAE: 4759.4272, NMAE: 72.5614, R^2: 0.1092\n",
      "Epoch [1193/2000]\n",
      "Train Loss: 29147546.5603\n",
      "Val Loss: 32552957.5009, MAE: 4849.1035, NMAE: 73.9286, R^2: 0.1095\n",
      "Epoch [1194/2000]\n",
      "Train Loss: 28430707.2836\n",
      "Val Loss: 32790092.8741, MAE: 4833.7969, NMAE: 73.6952, R^2: 0.1030\n",
      "Epoch [1195/2000]\n",
      "Train Loss: 28014711.1121\n",
      "Val Loss: 32141374.1516, MAE: 4770.1636, NMAE: 72.7251, R^2: 0.1207\n",
      "Epoch [1196/2000]\n",
      "Train Loss: 28346347.3578\n",
      "Val Loss: 32042091.1403, MAE: 4790.1982, NMAE: 73.0305, R^2: 0.1234\n",
      "Epoch [1197/2000]\n",
      "Train Loss: 28872727.8310\n",
      "Val Loss: 31759882.1056, MAE: 4712.2046, NMAE: 71.8414, R^2: 0.1312\n",
      "Epoch [1198/2000]\n",
      "Train Loss: 28324618.9466\n",
      "Val Loss: 32503143.6753, MAE: 4827.0371, NMAE: 73.5921, R^2: 0.1108\n",
      "Epoch [1199/2000]\n",
      "Train Loss: 28031165.3440\n",
      "Val Loss: 32306841.7502, MAE: 4772.3774, NMAE: 72.7588, R^2: 0.1162\n",
      "Epoch [1200/2000]\n",
      "Train Loss: 27993136.4259\n",
      "Val Loss: 33231287.9827, MAE: 4902.7192, NMAE: 74.7460, R^2: 0.0909\n",
      "Epoch [1201/2000]\n",
      "Train Loss: 27813116.1341\n",
      "Val Loss: 33025291.6731, MAE: 4903.1802, NMAE: 74.7530, R^2: 0.0965\n",
      "Epoch [1202/2000]\n",
      "Train Loss: 27876827.7614\n",
      "Val Loss: 34158365.2202, MAE: 4994.2090, NMAE: 76.1408, R^2: 0.0655\n",
      "Epoch [1203/2000]\n",
      "Train Loss: 28241701.3970\n",
      "Val Loss: 33044465.9351, MAE: 4845.0942, NMAE: 73.8674, R^2: 0.0960\n",
      "Epoch [1204/2000]\n",
      "Train Loss: 27741791.1819\n",
      "Val Loss: 33933923.5751, MAE: 4967.3389, NMAE: 75.7312, R^2: 0.0717\n",
      "Epoch [1205/2000]\n",
      "Train Loss: 28305607.4388\n",
      "Val Loss: 33736223.3067, MAE: 4962.8604, NMAE: 75.6629, R^2: 0.0771\n",
      "Epoch [1206/2000]\n",
      "Train Loss: 27953866.1450\n",
      "Val Loss: 33088420.8263, MAE: 4898.5762, NMAE: 74.6828, R^2: 0.0948\n",
      "Epoch [1207/2000]\n",
      "Train Loss: 27692027.2435\n",
      "Val Loss: 32858588.2870, MAE: 4844.3970, NMAE: 73.8568, R^2: 0.1011\n",
      "Epoch [1208/2000]\n",
      "Train Loss: 28081193.2409\n",
      "Val Loss: 32894943.3491, MAE: 4842.6421, NMAE: 73.8301, R^2: 0.1001\n",
      "Epoch [1209/2000]\n",
      "Train Loss: 28591305.3244\n",
      "Val Loss: 32386374.1512, MAE: 4753.2852, NMAE: 72.4677, R^2: 0.1140\n",
      "Epoch [1210/2000]\n",
      "Train Loss: 28592364.8841\n",
      "Val Loss: 32975291.5488, MAE: 4824.0557, NMAE: 73.5467, R^2: 0.0979\n",
      "Epoch [1211/2000]\n",
      "Train Loss: 27987097.9791\n",
      "Val Loss: 32959710.1178, MAE: 4881.8481, NMAE: 74.4278, R^2: 0.0983\n",
      "Epoch [1212/2000]\n",
      "Train Loss: 28209436.9599\n",
      "Val Loss: 32900862.4105, MAE: 4770.3003, NMAE: 72.7271, R^2: 0.0999\n",
      "Epoch [1213/2000]\n",
      "Train Loss: 27223468.8032\n",
      "Val Loss: 33251069.6411, MAE: 4856.3794, NMAE: 74.0395, R^2: 0.0904\n",
      "Epoch [1214/2000]\n",
      "Train Loss: 27978952.1525\n",
      "Val Loss: 32565764.7040, MAE: 4772.8560, NMAE: 72.7661, R^2: 0.1091\n",
      "Epoch [1215/2000]\n",
      "Train Loss: 27985203.4529\n",
      "Val Loss: 32837062.1232, MAE: 4880.1909, NMAE: 74.4025, R^2: 0.1017\n",
      "Epoch [1216/2000]\n",
      "Train Loss: 28572461.6938\n",
      "Val Loss: 33081647.0847, MAE: 4835.1465, NMAE: 73.7158, R^2: 0.0950\n",
      "Epoch [1217/2000]\n",
      "Train Loss: 27335362.0455\n",
      "Val Loss: 33437658.0761, MAE: 4890.7349, NMAE: 74.5633, R^2: 0.0853\n",
      "Epoch [1218/2000]\n",
      "Train Loss: 27760938.7825\n",
      "Val Loss: 34310091.6658, MAE: 4997.9834, NMAE: 76.1984, R^2: 0.0614\n",
      "Epoch [1219/2000]\n",
      "Train Loss: 27357476.1149\n",
      "Val Loss: 33281827.3487, MAE: 4882.3354, NMAE: 74.4352, R^2: 0.0895\n",
      "Epoch [1220/2000]\n",
      "Train Loss: 27357273.4603\n",
      "Val Loss: 32796432.2123, MAE: 4820.6177, NMAE: 73.4943, R^2: 0.1028\n",
      "Epoch [1221/2000]\n",
      "Train Loss: 27054093.3481\n",
      "Val Loss: 33339286.9686, MAE: 4871.3745, NMAE: 74.2681, R^2: 0.0880\n",
      "Epoch [1222/2000]\n",
      "Train Loss: 27235387.2478\n",
      "Val Loss: 32848209.8011, MAE: 4818.4136, NMAE: 73.4607, R^2: 0.1014\n",
      "Epoch [1223/2000]\n",
      "Train Loss: 28923853.8138\n",
      "Val Loss: 34566977.1000, MAE: 5052.0806, NMAE: 77.0231, R^2: 0.0544\n",
      "Epoch [1224/2000]\n",
      "Train Loss: 29022242.1884\n",
      "Val Loss: 32737939.5331, MAE: 4888.2344, NMAE: 74.5251, R^2: 0.1044\n",
      "Epoch [1225/2000]\n",
      "Train Loss: 28062180.9289\n",
      "Val Loss: 32571704.2968, MAE: 4816.3330, NMAE: 73.4289, R^2: 0.1090\n",
      "Epoch [1226/2000]\n",
      "Train Loss: 28429158.2948\n",
      "Val Loss: 32344813.6723, MAE: 4822.9932, NMAE: 73.5305, R^2: 0.1152\n",
      "Epoch [1227/2000]\n",
      "Train Loss: 28040495.6125\n",
      "Val Loss: 32494455.5022, MAE: 4796.1768, NMAE: 73.1216, R^2: 0.1111\n",
      "Epoch [1228/2000]\n",
      "Train Loss: 28341485.0578\n",
      "Val Loss: 32943468.9672, MAE: 4909.7324, NMAE: 74.8529, R^2: 0.0988\n",
      "Epoch [1229/2000]\n",
      "Train Loss: 28217930.3612\n",
      "Val Loss: 32357522.5750, MAE: 4735.2666, NMAE: 72.1930, R^2: 0.1148\n",
      "Epoch [1230/2000]\n",
      "Train Loss: 28185789.0392\n",
      "Val Loss: 33170253.1514, MAE: 4836.7036, NMAE: 73.7395, R^2: 0.0926\n",
      "Epoch [1231/2000]\n",
      "Train Loss: 27610663.9461\n",
      "Val Loss: 32224671.6899, MAE: 4762.7173, NMAE: 72.6115, R^2: 0.1184\n",
      "Epoch [1232/2000]\n",
      "Train Loss: 27514123.3649\n",
      "Val Loss: 32770489.8513, MAE: 4858.3823, NMAE: 74.0700, R^2: 0.1035\n",
      "Epoch [1233/2000]\n",
      "Train Loss: 27479806.0541\n",
      "Val Loss: 33014981.9983, MAE: 4869.4224, NMAE: 74.2383, R^2: 0.0968\n",
      "Epoch [1234/2000]\n",
      "Train Loss: 27828557.8190\n",
      "Val Loss: 32787535.4924, MAE: 4855.0947, NMAE: 74.0199, R^2: 0.1030\n",
      "Epoch [1235/2000]\n",
      "Train Loss: 29167859.1558\n",
      "Val Loss: 32656501.2122, MAE: 4797.8579, NMAE: 73.1473, R^2: 0.1066\n",
      "Epoch [1236/2000]\n",
      "Train Loss: 28595507.7151\n",
      "Val Loss: 32727151.4408, MAE: 4823.6255, NMAE: 73.5401, R^2: 0.1047\n",
      "Epoch [1237/2000]\n",
      "Train Loss: 28634142.1429\n",
      "Val Loss: 33008734.2228, MAE: 4823.7812, NMAE: 73.5425, R^2: 0.0970\n",
      "Epoch [1238/2000]\n",
      "Train Loss: 28645910.1800\n",
      "Val Loss: 33298158.3007, MAE: 4880.2402, NMAE: 74.4033, R^2: 0.0891\n",
      "Epoch [1239/2000]\n",
      "Train Loss: 28114583.8591\n",
      "Val Loss: 32108378.1792, MAE: 4785.5674, NMAE: 72.9599, R^2: 0.1216\n",
      "Epoch [1240/2000]\n",
      "Train Loss: 27833033.6099\n",
      "Val Loss: 33125264.9656, MAE: 4891.2163, NMAE: 74.5706, R^2: 0.0938\n",
      "Epoch [1241/2000]\n",
      "Train Loss: 28296840.5679\n",
      "Val Loss: 32943885.1385, MAE: 4850.8398, NMAE: 73.9550, R^2: 0.0988\n",
      "Epoch [1242/2000]\n",
      "Train Loss: 28008757.5991\n",
      "Val Loss: 33122827.8447, MAE: 4855.6045, NMAE: 74.0277, R^2: 0.0939\n",
      "Epoch [1243/2000]\n",
      "Train Loss: 28389189.4575\n",
      "Val Loss: 33399142.9909, MAE: 4881.9683, NMAE: 74.4296, R^2: 0.0863\n",
      "Epoch [1244/2000]\n",
      "Train Loss: 27888748.3237\n",
      "Val Loss: 33264407.6943, MAE: 4894.5869, NMAE: 74.6220, R^2: 0.0900\n",
      "Epoch [1245/2000]\n",
      "Train Loss: 28301255.5892\n",
      "Val Loss: 32943556.3248, MAE: 4838.2354, NMAE: 73.7629, R^2: 0.0988\n",
      "Epoch [1246/2000]\n",
      "Train Loss: 27852110.8838\n",
      "Val Loss: 33288812.7171, MAE: 4837.3286, NMAE: 73.7490, R^2: 0.0893\n",
      "Epoch [1247/2000]\n",
      "Train Loss: 27498219.3963\n",
      "Val Loss: 33875709.6577, MAE: 4954.7334, NMAE: 75.5390, R^2: 0.0733\n",
      "Epoch [1248/2000]\n",
      "Train Loss: 27620606.2898\n",
      "Val Loss: 33413141.9149, MAE: 4913.8647, NMAE: 74.9159, R^2: 0.0859\n",
      "Epoch [1249/2000]\n",
      "Train Loss: 27632914.1337\n",
      "Val Loss: 32735963.3946, MAE: 4840.4180, NMAE: 73.7961, R^2: 0.1045\n",
      "Epoch [1250/2000]\n",
      "Train Loss: 28532289.1515\n",
      "Val Loss: 32451837.7059, MAE: 4754.7686, NMAE: 72.4903, R^2: 0.1122\n",
      "Epoch [1251/2000]\n",
      "Train Loss: 27329934.0759\n",
      "Val Loss: 33566903.2891, MAE: 4869.0181, NMAE: 74.2322, R^2: 0.0817\n",
      "Epoch [1252/2000]\n",
      "Train Loss: 27700247.8047\n",
      "Val Loss: 33411996.5286, MAE: 4890.5601, NMAE: 74.5606, R^2: 0.0860\n",
      "Epoch [1253/2000]\n",
      "Train Loss: 27606314.4595\n",
      "Val Loss: 33374833.6452, MAE: 4871.4971, NMAE: 74.2700, R^2: 0.0870\n",
      "Epoch [1254/2000]\n",
      "Train Loss: 27364765.5547\n",
      "Val Loss: 32828202.8795, MAE: 4854.3853, NMAE: 74.0091, R^2: 0.1019\n",
      "Epoch [1255/2000]\n",
      "Train Loss: 27890775.1057\n",
      "Val Loss: 33727370.8080, MAE: 4930.6914, NMAE: 75.1724, R^2: 0.0773\n",
      "Epoch [1256/2000]\n",
      "Train Loss: 28896473.7102\n",
      "Val Loss: 32757715.3615, MAE: 4857.4683, NMAE: 74.0561, R^2: 0.1039\n",
      "Epoch [1257/2000]\n",
      "Train Loss: 28786364.2029\n",
      "Val Loss: 33410843.5977, MAE: 4886.4653, NMAE: 74.4982, R^2: 0.0860\n",
      "Epoch [1258/2000]\n",
      "Train Loss: 28009769.2871\n",
      "Val Loss: 33719236.9812, MAE: 4934.5513, NMAE: 75.2313, R^2: 0.0776\n",
      "Epoch [1259/2000]\n",
      "Train Loss: 28415260.4309\n",
      "Val Loss: 32550290.5862, MAE: 4830.9009, NMAE: 73.6510, R^2: 0.1095\n",
      "Epoch [1260/2000]\n",
      "Train Loss: 28077223.9948\n",
      "Val Loss: 32845679.8032, MAE: 4811.4629, NMAE: 73.3547, R^2: 0.1015\n",
      "Epoch [1261/2000]\n",
      "Train Loss: 27291665.0761\n",
      "Val Loss: 33300039.7362, MAE: 4829.2925, NMAE: 73.6265, R^2: 0.0890\n",
      "Epoch [1262/2000]\n",
      "Train Loss: 27326646.7167\n",
      "Val Loss: 35117404.6290, MAE: 5108.1055, NMAE: 77.8773, R^2: 0.0393\n",
      "Epoch [1263/2000]\n",
      "Train Loss: 29061607.9726\n",
      "Val Loss: 32780522.0514, MAE: 4851.7290, NMAE: 73.9686, R^2: 0.1032\n",
      "Epoch [1264/2000]\n",
      "Train Loss: 27534078.6413\n",
      "Val Loss: 33818037.1893, MAE: 4912.0874, NMAE: 74.8888, R^2: 0.0749\n",
      "Epoch [1265/2000]\n",
      "Train Loss: 28410419.4740\n",
      "Val Loss: 33559099.1431, MAE: 4929.6099, NMAE: 75.1559, R^2: 0.0819\n",
      "Epoch [1266/2000]\n",
      "Train Loss: 29317087.4871\n",
      "Val Loss: 32927685.1887, MAE: 4776.7085, NMAE: 72.8248, R^2: 0.0992\n",
      "Epoch [1267/2000]\n",
      "Train Loss: 28096997.4362\n",
      "Val Loss: 33002771.7546, MAE: 4831.4409, NMAE: 73.6593, R^2: 0.0972\n",
      "Epoch [1268/2000]\n",
      "Train Loss: 28062667.3949\n",
      "Val Loss: 32606591.9301, MAE: 4817.5786, NMAE: 73.4479, R^2: 0.1080\n",
      "Epoch [1269/2000]\n",
      "Train Loss: 28060874.9328\n",
      "Val Loss: 32370250.4447, MAE: 4783.6299, NMAE: 72.9304, R^2: 0.1145\n",
      "Epoch [1270/2000]\n",
      "Train Loss: 27886778.4496\n",
      "Val Loss: 32856078.8634, MAE: 4865.9136, NMAE: 74.1848, R^2: 0.1012\n",
      "Epoch [1271/2000]\n",
      "Train Loss: 27412998.9401\n",
      "Val Loss: 32955369.2397, MAE: 4792.6670, NMAE: 73.0681, R^2: 0.0985\n",
      "Epoch [1272/2000]\n",
      "Train Loss: 26992299.1821\n",
      "Val Loss: 32533229.2835, MAE: 4809.6890, NMAE: 73.3277, R^2: 0.1100\n",
      "Epoch [1273/2000]\n",
      "Train Loss: 27080464.3991\n",
      "Val Loss: 33843171.8983, MAE: 4911.6211, NMAE: 74.8817, R^2: 0.0742\n",
      "Epoch [1274/2000]\n",
      "Train Loss: 26927610.2784\n",
      "Val Loss: 34122620.8887, MAE: 4965.6245, NMAE: 75.7050, R^2: 0.0665\n",
      "Epoch [1275/2000]\n",
      "Train Loss: 27139844.8817\n",
      "Val Loss: 32829615.4644, MAE: 4804.1245, NMAE: 73.2428, R^2: 0.1019\n",
      "Epoch [1276/2000]\n",
      "Train Loss: 28049199.9086\n",
      "Val Loss: 33330910.6048, MAE: 4879.3604, NMAE: 74.3899, R^2: 0.0882\n",
      "Epoch [1277/2000]\n",
      "Train Loss: 27496284.2573\n",
      "Val Loss: 33884153.9268, MAE: 4908.2573, NMAE: 74.8304, R^2: 0.0730\n",
      "Epoch [1278/2000]\n",
      "Train Loss: 27369010.4200\n",
      "Val Loss: 32768675.0967, MAE: 4745.7227, NMAE: 72.3524, R^2: 0.1036\n",
      "Epoch [1279/2000]\n",
      "Train Loss: 27197284.8593\n",
      "Val Loss: 32817864.2865, MAE: 4830.2944, NMAE: 73.6418, R^2: 0.1022\n",
      "Epoch [1280/2000]\n",
      "Train Loss: 27533491.1603\n",
      "Val Loss: 33754722.9142, MAE: 4934.4165, NMAE: 75.2292, R^2: 0.0766\n",
      "Epoch [1281/2000]\n",
      "Train Loss: 27237191.7325\n",
      "Val Loss: 32778073.7974, MAE: 4773.9707, NMAE: 72.7831, R^2: 0.1033\n",
      "Epoch [1282/2000]\n",
      "Train Loss: 26918264.9006\n",
      "Val Loss: 35080427.2252, MAE: 5111.8154, NMAE: 77.9338, R^2: 0.0403\n",
      "Epoch [1283/2000]\n",
      "Train Loss: 28519661.8287\n",
      "Val Loss: 32472922.5049, MAE: 4791.0249, NMAE: 73.0431, R^2: 0.1117\n",
      "Epoch [1284/2000]\n",
      "Train Loss: 27110859.9006\n",
      "Val Loss: 33216889.8911, MAE: 4868.7920, NMAE: 74.2287, R^2: 0.0913\n",
      "Epoch [1285/2000]\n",
      "Train Loss: 27235316.2474\n",
      "Val Loss: 32288275.2606, MAE: 4743.9839, NMAE: 72.3259, R^2: 0.1167\n",
      "Epoch [1286/2000]\n",
      "Train Loss: 29245692.8709\n",
      "Val Loss: 32685902.4307, MAE: 4816.8154, NMAE: 73.4363, R^2: 0.1058\n",
      "Epoch [1287/2000]\n",
      "Train Loss: 30386437.4933\n",
      "Val Loss: 33104291.8343, MAE: 4904.8325, NMAE: 74.7782, R^2: 0.0944\n",
      "Epoch [1288/2000]\n",
      "Train Loss: 29023356.3136\n",
      "Val Loss: 33470899.8231, MAE: 4952.9380, NMAE: 75.5116, R^2: 0.0844\n",
      "Epoch [1289/2000]\n",
      "Train Loss: 28316083.9213\n",
      "Val Loss: 32915548.5892, MAE: 4852.1992, NMAE: 73.9758, R^2: 0.0995\n",
      "Epoch [1290/2000]\n",
      "Train Loss: 27161437.1330\n",
      "Val Loss: 32605082.6759, MAE: 4772.3154, NMAE: 72.7579, R^2: 0.1080\n",
      "Epoch [1291/2000]\n",
      "Train Loss: 27196268.6675\n",
      "Val Loss: 33043128.5052, MAE: 4866.3608, NMAE: 74.1917, R^2: 0.0961\n",
      "Epoch [1292/2000]\n",
      "Train Loss: 27694029.6597\n",
      "Val Loss: 32285066.9653, MAE: 4765.8364, NMAE: 72.6591, R^2: 0.1168\n",
      "Epoch [1293/2000]\n",
      "Train Loss: 27033275.8079\n",
      "Val Loss: 32689714.3204, MAE: 4802.0146, NMAE: 73.2107, R^2: 0.1057\n",
      "Epoch [1294/2000]\n",
      "Train Loss: 26481343.8228\n",
      "Val Loss: 33161477.5046, MAE: 4847.5728, NMAE: 73.9052, R^2: 0.0928\n",
      "Epoch [1295/2000]\n",
      "Train Loss: 26749630.4865\n",
      "Val Loss: 34079915.7078, MAE: 4943.5864, NMAE: 75.3690, R^2: 0.0677\n",
      "Epoch [1296/2000]\n",
      "Train Loss: 26760027.8829\n",
      "Val Loss: 33649869.2261, MAE: 4903.5596, NMAE: 74.7588, R^2: 0.0795\n",
      "Epoch [1297/2000]\n",
      "Train Loss: 26575504.5696\n",
      "Val Loss: 34457472.9936, MAE: 4977.2573, NMAE: 75.8824, R^2: 0.0574\n",
      "Epoch [1298/2000]\n",
      "Train Loss: 26521568.5078\n",
      "Val Loss: 33178197.0489, MAE: 4784.8896, NMAE: 72.9496, R^2: 0.0924\n",
      "Epoch [1299/2000]\n",
      "Train Loss: 27226272.6558\n",
      "Val Loss: 33272804.8541, MAE: 4842.4956, NMAE: 73.8278, R^2: 0.0898\n",
      "Epoch [1300/2000]\n",
      "Train Loss: 27517564.4582\n",
      "Val Loss: 32807373.0022, MAE: 4792.1191, NMAE: 73.0598, R^2: 0.1025\n",
      "Epoch [1301/2000]\n",
      "Train Loss: 26684554.4741\n",
      "Val Loss: 32887595.5164, MAE: 4824.0850, NMAE: 73.5471, R^2: 0.1003\n",
      "Epoch [1302/2000]\n",
      "Train Loss: 26760302.8612\n",
      "Val Loss: 33484501.5298, MAE: 4857.8774, NMAE: 74.0623, R^2: 0.0840\n",
      "Epoch [1303/2000]\n",
      "Train Loss: 27316053.4284\n",
      "Val Loss: 32685932.6351, MAE: 4785.8628, NMAE: 72.9644, R^2: 0.1058\n",
      "Epoch [1304/2000]\n",
      "Train Loss: 26773376.2862\n",
      "Val Loss: 32990104.1323, MAE: 4819.9067, NMAE: 73.4834, R^2: 0.0975\n",
      "Epoch [1305/2000]\n",
      "Train Loss: 27142465.7940\n",
      "Val Loss: 33274505.2168, MAE: 4842.2026, NMAE: 73.8234, R^2: 0.0897\n",
      "Epoch [1306/2000]\n",
      "Train Loss: 27019075.7228\n",
      "Val Loss: 33309459.9767, MAE: 4861.6431, NMAE: 74.1197, R^2: 0.0888\n",
      "Epoch [1307/2000]\n",
      "Train Loss: 26596256.0672\n",
      "Val Loss: 32625184.7504, MAE: 4791.4292, NMAE: 73.0493, R^2: 0.1075\n",
      "Epoch [1308/2000]\n",
      "Train Loss: 26780805.4534\n",
      "Val Loss: 33039575.5259, MAE: 4857.1196, NMAE: 74.0508, R^2: 0.0962\n",
      "Epoch [1309/2000]\n",
      "Train Loss: 27148600.8586\n",
      "Val Loss: 33732154.1742, MAE: 4957.0830, NMAE: 75.5748, R^2: 0.0772\n",
      "Epoch [1310/2000]\n",
      "Train Loss: 28762519.5043\n",
      "Val Loss: 33355713.2727, MAE: 4826.8784, NMAE: 73.5897, R^2: 0.0875\n",
      "Epoch [1311/2000]\n",
      "Train Loss: 28148315.7440\n",
      "Val Loss: 33680156.2509, MAE: 4846.3921, NMAE: 73.8872, R^2: 0.0786\n",
      "Epoch [1312/2000]\n",
      "Train Loss: 27386819.1069\n",
      "Val Loss: 32990328.0356, MAE: 4793.7480, NMAE: 73.0846, R^2: 0.0975\n",
      "Epoch [1313/2000]\n",
      "Train Loss: 27884248.5776\n",
      "Val Loss: 32964848.1958, MAE: 4819.1465, NMAE: 73.4718, R^2: 0.0982\n",
      "Epoch [1314/2000]\n",
      "Train Loss: 27402163.7194\n",
      "Val Loss: 33391687.8752, MAE: 4906.1196, NMAE: 74.7978, R^2: 0.0865\n",
      "Epoch [1315/2000]\n",
      "Train Loss: 27814069.3543\n",
      "Val Loss: 33481233.2375, MAE: 4926.8843, NMAE: 75.1144, R^2: 0.0841\n",
      "Epoch [1316/2000]\n",
      "Train Loss: 28849519.2289\n",
      "Val Loss: 32134017.4542, MAE: 4766.6572, NMAE: 72.6716, R^2: 0.1209\n",
      "Epoch [1317/2000]\n",
      "Train Loss: 27829846.4306\n",
      "Val Loss: 33071953.7686, MAE: 4842.5918, NMAE: 73.8293, R^2: 0.0953\n",
      "Epoch [1318/2000]\n",
      "Train Loss: 27242593.8172\n",
      "Val Loss: 33244642.0078, MAE: 4866.7056, NMAE: 74.1969, R^2: 0.0905\n",
      "Epoch [1319/2000]\n",
      "Train Loss: 27034382.9750\n",
      "Val Loss: 33151970.3644, MAE: 4844.6128, NMAE: 73.8601, R^2: 0.0931\n",
      "Epoch [1320/2000]\n",
      "Train Loss: 27837179.4371\n",
      "Val Loss: 32659683.3221, MAE: 4788.2842, NMAE: 73.0013, R^2: 0.1065\n",
      "Epoch [1321/2000]\n",
      "Train Loss: 27234942.7216\n",
      "Val Loss: 33036414.3167, MAE: 4794.7949, NMAE: 73.1006, R^2: 0.0962\n",
      "Epoch [1322/2000]\n",
      "Train Loss: 27742640.7069\n",
      "Val Loss: 33187981.9663, MAE: 4842.4995, NMAE: 73.8279, R^2: 0.0921\n",
      "Epoch [1323/2000]\n",
      "Train Loss: 27551047.7121\n",
      "Val Loss: 32677935.4324, MAE: 4784.0688, NMAE: 72.9371, R^2: 0.1060\n",
      "Epoch [1324/2000]\n",
      "Train Loss: 27618595.7026\n",
      "Val Loss: 32726777.7616, MAE: 4819.5479, NMAE: 73.4780, R^2: 0.1047\n",
      "Epoch [1325/2000]\n",
      "Train Loss: 28072101.0384\n",
      "Val Loss: 32147352.2938, MAE: 4758.1035, NMAE: 72.5412, R^2: 0.1206\n",
      "Epoch [1326/2000]\n",
      "Train Loss: 28179907.9651\n",
      "Val Loss: 32695753.6933, MAE: 4853.5850, NMAE: 73.9969, R^2: 0.1056\n",
      "Epoch [1327/2000]\n",
      "Train Loss: 28634409.8940\n",
      "Val Loss: 32337495.6174, MAE: 4807.6323, NMAE: 73.2963, R^2: 0.1154\n",
      "Epoch [1328/2000]\n",
      "Train Loss: 28041459.6177\n",
      "Val Loss: 32282740.7270, MAE: 4756.6113, NMAE: 72.5184, R^2: 0.1169\n",
      "Epoch [1329/2000]\n",
      "Train Loss: 27933128.2711\n",
      "Val Loss: 32718021.3687, MAE: 4785.5273, NMAE: 72.9593, R^2: 0.1049\n",
      "Epoch [1330/2000]\n",
      "Train Loss: 27887583.1315\n",
      "Val Loss: 34372474.9553, MAE: 4929.6655, NMAE: 75.1568, R^2: 0.0597\n",
      "Epoch [1331/2000]\n",
      "Train Loss: 27994545.4491\n",
      "Val Loss: 33192073.9253, MAE: 4844.3042, NMAE: 73.8554, R^2: 0.0920\n",
      "Epoch [1332/2000]\n",
      "Train Loss: 26735505.8560\n",
      "Val Loss: 32776280.9430, MAE: 4765.9287, NMAE: 72.6605, R^2: 0.1034\n",
      "Epoch [1333/2000]\n",
      "Train Loss: 27059136.1052\n",
      "Val Loss: 32424662.2258, MAE: 4795.1729, NMAE: 73.1063, R^2: 0.1130\n",
      "Epoch [1334/2000]\n",
      "Train Loss: 26829833.4966\n",
      "Val Loss: 32652879.6041, MAE: 4772.2866, NMAE: 72.7574, R^2: 0.1067\n",
      "Epoch [1335/2000]\n",
      "Train Loss: 26637491.3776\n",
      "Val Loss: 33594060.7566, MAE: 4839.2954, NMAE: 73.7790, R^2: 0.0810\n",
      "Epoch [1336/2000]\n",
      "Train Loss: 26893113.4041\n",
      "Val Loss: 33441177.9861, MAE: 4834.5479, NMAE: 73.7066, R^2: 0.0852\n",
      "Epoch [1337/2000]\n",
      "Train Loss: 26699173.7341\n",
      "Val Loss: 33201079.2737, MAE: 4789.7725, NMAE: 73.0240, R^2: 0.0917\n",
      "Epoch [1338/2000]\n",
      "Train Loss: 26691430.8625\n",
      "Val Loss: 33225786.0630, MAE: 4794.9507, NMAE: 73.1030, R^2: 0.0911\n",
      "Epoch [1339/2000]\n",
      "Train Loss: 26197024.4892\n",
      "Val Loss: 34018233.9104, MAE: 4883.9795, NMAE: 74.4603, R^2: 0.0694\n",
      "Epoch [1340/2000]\n",
      "Train Loss: 26421903.5901\n",
      "Val Loss: 34005591.7116, MAE: 4900.7412, NMAE: 74.7158, R^2: 0.0697\n",
      "Epoch [1341/2000]\n",
      "Train Loss: 26845834.8190\n",
      "Val Loss: 34208734.3247, MAE: 4926.6934, NMAE: 75.1115, R^2: 0.0642\n",
      "Epoch [1342/2000]\n",
      "Train Loss: 25922872.0595\n",
      "Val Loss: 34298558.8653, MAE: 4953.5010, NMAE: 75.5202, R^2: 0.0617\n",
      "Epoch [1343/2000]\n",
      "Train Loss: 26179138.4530\n",
      "Val Loss: 34328469.6960, MAE: 4942.4136, NMAE: 75.3511, R^2: 0.0609\n",
      "Epoch [1344/2000]\n",
      "Train Loss: 28537421.8784\n",
      "Val Loss: 33988505.3210, MAE: 4932.0933, NMAE: 75.1938, R^2: 0.0702\n",
      "Epoch [1345/2000]\n",
      "Train Loss: 27555038.5517\n",
      "Val Loss: 33290044.7159, MAE: 4815.4106, NMAE: 73.4149, R^2: 0.0893\n",
      "Epoch [1346/2000]\n",
      "Train Loss: 26418916.8392\n",
      "Val Loss: 33907877.7375, MAE: 4868.8740, NMAE: 74.2300, R^2: 0.0724\n",
      "Epoch [1347/2000]\n",
      "Train Loss: 26655573.0634\n",
      "Val Loss: 33798583.0296, MAE: 4932.0571, NMAE: 75.1933, R^2: 0.0754\n",
      "Epoch [1348/2000]\n",
      "Train Loss: 26678504.5147\n",
      "Val Loss: 33776284.8139, MAE: 4894.9414, NMAE: 74.6274, R^2: 0.0760\n",
      "Epoch [1349/2000]\n",
      "Train Loss: 27460320.6185\n",
      "Val Loss: 33419727.7675, MAE: 4797.3481, NMAE: 73.1395, R^2: 0.0858\n",
      "Epoch [1350/2000]\n",
      "Train Loss: 28498522.9371\n",
      "Val Loss: 33659774.5728, MAE: 4853.6694, NMAE: 73.9982, R^2: 0.0792\n",
      "Epoch [1351/2000]\n",
      "Train Loss: 29481943.7716\n",
      "Val Loss: 32495219.5773, MAE: 4799.6392, NMAE: 73.1744, R^2: 0.1110\n",
      "Epoch [1352/2000]\n",
      "Train Loss: 27534526.7121\n",
      "Val Loss: 32703764.6462, MAE: 4840.8760, NMAE: 73.8031, R^2: 0.1053\n",
      "Epoch [1353/2000]\n",
      "Train Loss: 28568590.0655\n",
      "Val Loss: 32648163.2958, MAE: 4762.4546, NMAE: 72.6075, R^2: 0.1069\n",
      "Epoch [1354/2000]\n",
      "Train Loss: 27210171.0728\n",
      "Val Loss: 33342948.5887, MAE: 4784.5098, NMAE: 72.9438, R^2: 0.0879\n",
      "Epoch [1355/2000]\n",
      "Train Loss: 27177682.7940\n",
      "Val Loss: 33285765.4059, MAE: 4865.4316, NMAE: 74.1775, R^2: 0.0894\n",
      "Epoch [1356/2000]\n",
      "Train Loss: 27426880.6147\n",
      "Val Loss: 32766889.7597, MAE: 4752.6875, NMAE: 72.4586, R^2: 0.1036\n",
      "Epoch [1357/2000]\n",
      "Train Loss: 26339786.5810\n",
      "Val Loss: 33141749.3571, MAE: 4824.8789, NMAE: 73.5592, R^2: 0.0934\n",
      "Epoch [1358/2000]\n",
      "Train Loss: 26239005.5586\n",
      "Val Loss: 33524722.4927, MAE: 4851.6997, NMAE: 73.9681, R^2: 0.0829\n",
      "Epoch [1359/2000]\n",
      "Train Loss: 26329497.8112\n",
      "Val Loss: 33336525.3981, MAE: 4823.6138, NMAE: 73.5399, R^2: 0.0880\n",
      "Epoch [1360/2000]\n",
      "Train Loss: 26517165.2026\n",
      "Val Loss: 33279489.4076, MAE: 4842.2388, NMAE: 73.8239, R^2: 0.0896\n",
      "Epoch [1361/2000]\n",
      "Train Loss: 26399098.1707\n",
      "Val Loss: 33051234.8655, MAE: 4798.7886, NMAE: 73.1615, R^2: 0.0958\n",
      "Epoch [1362/2000]\n",
      "Train Loss: 26359282.6716\n",
      "Val Loss: 33622610.2506, MAE: 4868.1177, NMAE: 74.2184, R^2: 0.0802\n",
      "Epoch [1363/2000]\n",
      "Train Loss: 26150477.9310\n",
      "Val Loss: 33634643.5218, MAE: 4881.6030, NMAE: 74.4240, R^2: 0.0799\n",
      "Epoch [1364/2000]\n",
      "Train Loss: 26147145.8931\n",
      "Val Loss: 33143029.1116, MAE: 4767.3242, NMAE: 72.6818, R^2: 0.0933\n",
      "Epoch [1365/2000]\n",
      "Train Loss: 28045296.2302\n",
      "Val Loss: 32659952.1913, MAE: 4793.5391, NMAE: 73.0814, R^2: 0.1065\n",
      "Epoch [1366/2000]\n",
      "Train Loss: 28760355.5957\n",
      "Val Loss: 32489761.2595, MAE: 4805.7163, NMAE: 73.2671, R^2: 0.1112\n",
      "Epoch [1367/2000]\n",
      "Train Loss: 28749355.4336\n",
      "Val Loss: 32491920.7312, MAE: 4754.2993, NMAE: 72.4832, R^2: 0.1111\n",
      "Epoch [1368/2000]\n",
      "Train Loss: 28203687.1892\n",
      "Val Loss: 33578701.2081, MAE: 4905.5762, NMAE: 74.7895, R^2: 0.0814\n",
      "Epoch [1369/2000]\n",
      "Train Loss: 28080769.7009\n",
      "Val Loss: 33381057.4616, MAE: 4840.6284, NMAE: 73.7994, R^2: 0.0868\n",
      "Epoch [1370/2000]\n",
      "Train Loss: 26817770.2565\n",
      "Val Loss: 33352851.7763, MAE: 4857.4424, NMAE: 74.0557, R^2: 0.0876\n",
      "Epoch [1371/2000]\n",
      "Train Loss: 27217392.6858\n",
      "Val Loss: 32574091.8541, MAE: 4749.5386, NMAE: 72.4106, R^2: 0.1089\n",
      "Epoch [1372/2000]\n",
      "Train Loss: 26843429.7832\n",
      "Val Loss: 32564918.0134, MAE: 4799.7061, NMAE: 73.1755, R^2: 0.1091\n",
      "Epoch [1373/2000]\n",
      "Train Loss: 27154160.5565\n",
      "Val Loss: 32614186.6092, MAE: 4753.6104, NMAE: 72.4727, R^2: 0.1078\n",
      "Epoch [1374/2000]\n",
      "Train Loss: 26803844.5776\n",
      "Val Loss: 32296584.4028, MAE: 4712.4458, NMAE: 71.8451, R^2: 0.1165\n",
      "Epoch [1375/2000]\n",
      "Train Loss: 26729840.8772\n",
      "Val Loss: 32543438.2891, MAE: 4756.2661, NMAE: 72.5132, R^2: 0.1097\n",
      "Epoch [1376/2000]\n",
      "Train Loss: 26569428.3034\n",
      "Val Loss: 33437273.6913, MAE: 4845.2930, NMAE: 73.8705, R^2: 0.0853\n",
      "Epoch [1377/2000]\n",
      "Train Loss: 26488593.7500\n",
      "Val Loss: 33106138.2124, MAE: 4813.8970, NMAE: 73.3918, R^2: 0.0943\n",
      "Epoch [1378/2000]\n",
      "Train Loss: 27037209.1009\n",
      "Val Loss: 32999440.9039, MAE: 4756.1670, NMAE: 72.5117, R^2: 0.0973\n",
      "Epoch [1379/2000]\n",
      "Train Loss: 26552007.6983\n",
      "Val Loss: 33408500.2418, MAE: 4833.5166, NMAE: 73.6909, R^2: 0.0861\n",
      "Epoch [1380/2000]\n",
      "Train Loss: 27497297.9746\n",
      "Val Loss: 32105160.2845, MAE: 4749.6533, NMAE: 72.4124, R^2: 0.1217\n",
      "Epoch [1381/2000]\n",
      "Train Loss: 27728891.6047\n",
      "Val Loss: 32681727.6783, MAE: 4778.8027, NMAE: 72.8568, R^2: 0.1059\n",
      "Epoch [1382/2000]\n",
      "Train Loss: 26912586.6427\n",
      "Val Loss: 32287781.3143, MAE: 4746.9897, NMAE: 72.3718, R^2: 0.1167\n",
      "Epoch [1383/2000]\n",
      "Train Loss: 27122956.0534\n",
      "Val Loss: 32841287.5304, MAE: 4808.2583, NMAE: 73.3058, R^2: 0.1016\n",
      "Epoch [1384/2000]\n",
      "Train Loss: 27300368.1922\n",
      "Val Loss: 34335016.9210, MAE: 4958.6230, NMAE: 75.5983, R^2: 0.0607\n",
      "Epoch [1385/2000]\n",
      "Train Loss: 27449669.5388\n",
      "Val Loss: 33013490.6254, MAE: 4837.1079, NMAE: 73.7457, R^2: 0.0969\n",
      "Epoch [1386/2000]\n",
      "Train Loss: 27085697.5784\n",
      "Val Loss: 34445352.0574, MAE: 4967.8750, NMAE: 75.7393, R^2: 0.0577\n",
      "Epoch [1387/2000]\n",
      "Train Loss: 27143667.5190\n",
      "Val Loss: 32252483.3970, MAE: 4715.6606, NMAE: 71.8941, R^2: 0.1177\n",
      "Epoch [1388/2000]\n",
      "Train Loss: 27019263.5629\n",
      "Val Loss: 32798912.9756, MAE: 4780.2715, NMAE: 72.8792, R^2: 0.1027\n",
      "Epoch [1389/2000]\n",
      "Train Loss: 27020736.0017\n",
      "Val Loss: 32582741.9441, MAE: 4776.8721, NMAE: 72.8273, R^2: 0.1087\n",
      "Epoch [1390/2000]\n",
      "Train Loss: 26744467.6496\n",
      "Val Loss: 32386736.9383, MAE: 4707.3477, NMAE: 71.7674, R^2: 0.1140\n",
      "Epoch [1391/2000]\n",
      "Train Loss: 29859021.6375\n",
      "Val Loss: 33626898.7556, MAE: 4930.9619, NMAE: 75.1766, R^2: 0.0801\n",
      "Epoch [1392/2000]\n",
      "Train Loss: 28117488.5185\n",
      "Val Loss: 33089899.2107, MAE: 4852.5088, NMAE: 73.9805, R^2: 0.0948\n",
      "Epoch [1393/2000]\n",
      "Train Loss: 28556864.5983\n",
      "Val Loss: 33423258.5084, MAE: 4905.8828, NMAE: 74.7942, R^2: 0.0857\n",
      "Epoch [1394/2000]\n",
      "Train Loss: 26741938.9060\n",
      "Val Loss: 34241428.2243, MAE: 4955.2578, NMAE: 75.5470, R^2: 0.0633\n",
      "Epoch [1395/2000]\n",
      "Train Loss: 26888761.9470\n",
      "Val Loss: 34123478.5274, MAE: 4939.3550, NMAE: 75.3045, R^2: 0.0665\n",
      "Epoch [1396/2000]\n",
      "Train Loss: 27623033.3784\n",
      "Val Loss: 34119333.3338, MAE: 4939.5674, NMAE: 75.3078, R^2: 0.0666\n",
      "Epoch [1397/2000]\n",
      "Train Loss: 27128565.5560\n",
      "Val Loss: 34340486.4488, MAE: 4983.5229, NMAE: 75.9779, R^2: 0.0606\n",
      "Epoch [1398/2000]\n",
      "Train Loss: 27197087.5991\n",
      "Val Loss: 33710318.2794, MAE: 4890.8794, NMAE: 74.5655, R^2: 0.0778\n",
      "Epoch [1399/2000]\n",
      "Train Loss: 27640490.7043\n",
      "Val Loss: 34151697.8009, MAE: 4941.4468, NMAE: 75.3364, R^2: 0.0657\n",
      "Epoch [1400/2000]\n",
      "Train Loss: 28138993.0836\n",
      "Val Loss: 32727192.2496, MAE: 4822.3457, NMAE: 73.5206, R^2: 0.1047\n",
      "Epoch [1401/2000]\n",
      "Train Loss: 27750749.2000\n",
      "Val Loss: 32806145.4292, MAE: 4802.1968, NMAE: 73.2134, R^2: 0.1025\n",
      "Epoch [1402/2000]\n",
      "Train Loss: 28396458.4500\n",
      "Val Loss: 32738611.4402, MAE: 4768.1987, NMAE: 72.6951, R^2: 0.1044\n",
      "Epoch [1403/2000]\n",
      "Train Loss: 27714891.8888\n",
      "Val Loss: 33158070.4989, MAE: 4847.4263, NMAE: 73.9030, R^2: 0.0929\n",
      "Epoch [1404/2000]\n",
      "Train Loss: 27759818.1879\n",
      "Val Loss: 32023923.1269, MAE: 4735.9727, NMAE: 72.2038, R^2: 0.1239\n",
      "Epoch [1405/2000]\n",
      "Train Loss: 26649014.7487\n",
      "Val Loss: 32189344.7224, MAE: 4736.5063, NMAE: 72.2119, R^2: 0.1194\n",
      "Epoch [1406/2000]\n",
      "Train Loss: 27616891.3375\n",
      "Val Loss: 32872515.8437, MAE: 4763.9995, NMAE: 72.6311, R^2: 0.1007\n",
      "Epoch [1407/2000]\n",
      "Train Loss: 27449097.9905\n",
      "Val Loss: 32936293.4907, MAE: 4793.0200, NMAE: 73.0735, R^2: 0.0990\n",
      "Epoch [1408/2000]\n",
      "Train Loss: 27029153.1741\n",
      "Val Loss: 33077734.0086, MAE: 4823.5269, NMAE: 73.5386, R^2: 0.0951\n",
      "Epoch [1409/2000]\n",
      "Train Loss: 26295678.7534\n",
      "Val Loss: 32989923.7360, MAE: 4800.4233, NMAE: 73.1864, R^2: 0.0975\n",
      "Epoch [1410/2000]\n",
      "Train Loss: 27599775.1078\n",
      "Val Loss: 33555565.9035, MAE: 4897.3188, NMAE: 74.6636, R^2: 0.0820\n",
      "Epoch [1411/2000]\n",
      "Train Loss: 26162410.8345\n",
      "Val Loss: 34206099.5276, MAE: 4851.6665, NMAE: 73.9676, R^2: 0.0642\n",
      "Epoch [1412/2000]\n",
      "Train Loss: 26585907.4543\n",
      "Val Loss: 33958453.2862, MAE: 4866.7500, NMAE: 74.1976, R^2: 0.0710\n",
      "Epoch [1413/2000]\n",
      "Train Loss: 28330873.9319\n",
      "Val Loss: 33187418.4709, MAE: 4848.1699, NMAE: 73.9143, R^2: 0.0921\n",
      "Epoch [1414/2000]\n",
      "Train Loss: 28565187.4129\n",
      "Val Loss: 33020617.8791, MAE: 4822.9351, NMAE: 73.5296, R^2: 0.0967\n",
      "Epoch [1415/2000]\n",
      "Train Loss: 27578214.1845\n",
      "Val Loss: 32872282.2524, MAE: 4804.8042, NMAE: 73.2532, R^2: 0.1007\n",
      "Epoch [1416/2000]\n",
      "Train Loss: 26981652.7026\n",
      "Val Loss: 33086471.9769, MAE: 4799.6992, NMAE: 73.1754, R^2: 0.0949\n",
      "Epoch [1417/2000]\n",
      "Train Loss: 26366637.0112\n",
      "Val Loss: 33464621.8182, MAE: 4839.8613, NMAE: 73.7877, R^2: 0.0845\n",
      "Epoch [1418/2000]\n",
      "Train Loss: 26535261.8112\n",
      "Val Loss: 33428969.4950, MAE: 4856.1338, NMAE: 74.0357, R^2: 0.0855\n",
      "Epoch [1419/2000]\n",
      "Train Loss: 27491910.5991\n",
      "Val Loss: 33635747.6181, MAE: 4843.2437, NMAE: 73.8392, R^2: 0.0798\n",
      "Epoch [1420/2000]\n",
      "Train Loss: 28308660.0332\n",
      "Val Loss: 32783065.7904, MAE: 4818.3511, NMAE: 73.4597, R^2: 0.1032\n",
      "Epoch [1421/2000]\n",
      "Train Loss: 27226370.0043\n",
      "Val Loss: 32944351.1615, MAE: 4826.8901, NMAE: 73.5899, R^2: 0.0988\n",
      "Epoch [1422/2000]\n",
      "Train Loss: 26510405.4371\n",
      "Val Loss: 32967978.0320, MAE: 4816.1050, NMAE: 73.4255, R^2: 0.0981\n",
      "Epoch [1423/2000]\n",
      "Train Loss: 26657128.8474\n",
      "Val Loss: 33762635.7707, MAE: 4914.1040, NMAE: 74.9195, R^2: 0.0764\n",
      "Epoch [1424/2000]\n",
      "Train Loss: 26287209.6177\n",
      "Val Loss: 33008755.3094, MAE: 4884.4072, NMAE: 74.4668, R^2: 0.0970\n",
      "Epoch [1425/2000]\n",
      "Train Loss: 27017960.7698\n",
      "Val Loss: 32877449.6355, MAE: 4768.2734, NMAE: 72.6962, R^2: 0.1006\n",
      "Epoch [1426/2000]\n",
      "Train Loss: 27380815.9125\n",
      "Val Loss: 32642815.4577, MAE: 4761.2856, NMAE: 72.5897, R^2: 0.1070\n",
      "Epoch [1427/2000]\n",
      "Train Loss: 26343188.1655\n",
      "Val Loss: 33049676.2060, MAE: 4802.4292, NMAE: 73.2170, R^2: 0.0959\n",
      "Epoch [1428/2000]\n",
      "Train Loss: 27825378.4845\n",
      "Val Loss: 32822013.2066, MAE: 4751.9482, NMAE: 72.4473, R^2: 0.1021\n",
      "Epoch [1429/2000]\n",
      "Train Loss: 27215913.1095\n",
      "Val Loss: 32699701.1939, MAE: 4809.7222, NMAE: 73.3282, R^2: 0.1055\n",
      "Epoch [1430/2000]\n",
      "Train Loss: 26670985.8147\n",
      "Val Loss: 32974768.1464, MAE: 4771.7324, NMAE: 72.7490, R^2: 0.0979\n",
      "Epoch [1431/2000]\n",
      "Train Loss: 26356688.7026\n",
      "Val Loss: 32993919.1647, MAE: 4789.0767, NMAE: 73.0134, R^2: 0.0974\n",
      "Epoch [1432/2000]\n",
      "Train Loss: 28195406.1431\n",
      "Val Loss: 33260283.6636, MAE: 4952.0854, NMAE: 75.4986, R^2: 0.0901\n",
      "Epoch [1433/2000]\n",
      "Train Loss: 28500695.0000\n",
      "Val Loss: 32636366.2992, MAE: 4838.5576, NMAE: 73.7678, R^2: 0.1072\n",
      "Epoch [1434/2000]\n",
      "Train Loss: 27136081.8224\n",
      "Val Loss: 32200735.3014, MAE: 4771.9570, NMAE: 72.7524, R^2: 0.1191\n",
      "Epoch [1435/2000]\n",
      "Train Loss: 26494352.1362\n",
      "Val Loss: 33241998.5881, MAE: 4839.0088, NMAE: 73.7747, R^2: 0.0906\n",
      "Epoch [1436/2000]\n",
      "Train Loss: 26223773.0034\n",
      "Val Loss: 33076871.7925, MAE: 4784.8662, NMAE: 72.9492, R^2: 0.0951\n",
      "Epoch [1437/2000]\n",
      "Train Loss: 26059169.7216\n",
      "Val Loss: 33304763.7984, MAE: 4820.3335, NMAE: 73.4899, R^2: 0.0889\n",
      "Epoch [1438/2000]\n",
      "Train Loss: 25767316.2914\n",
      "Val Loss: 33464071.8027, MAE: 4830.4878, NMAE: 73.6447, R^2: 0.0845\n",
      "Epoch [1439/2000]\n",
      "Train Loss: 26441688.4707\n",
      "Val Loss: 33246799.9849, MAE: 4830.8467, NMAE: 73.6502, R^2: 0.0905\n",
      "Epoch [1440/2000]\n",
      "Train Loss: 26440241.1586\n",
      "Val Loss: 32501464.0367, MAE: 4659.6245, NMAE: 71.0398, R^2: 0.1109\n",
      "Epoch [1441/2000]\n",
      "Train Loss: 26593661.7862\n",
      "Val Loss: 33201713.2545, MAE: 4821.6030, NMAE: 73.5093, R^2: 0.0917\n",
      "Epoch [1442/2000]\n",
      "Train Loss: 26516790.2616\n",
      "Val Loss: 31895180.5190, MAE: 4727.1782, NMAE: 72.0697, R^2: 0.1275\n",
      "Epoch [1443/2000]\n",
      "Train Loss: 27118579.0047\n",
      "Val Loss: 32605445.7226, MAE: 4724.8105, NMAE: 72.0336, R^2: 0.1080\n",
      "Epoch [1444/2000]\n",
      "Train Loss: 25778618.6409\n",
      "Val Loss: 32934604.2325, MAE: 4742.5991, NMAE: 72.3048, R^2: 0.0990\n",
      "Epoch [1445/2000]\n",
      "Train Loss: 28282274.8293\n",
      "Val Loss: 33148079.2109, MAE: 4750.2671, NMAE: 72.4217, R^2: 0.0932\n",
      "Epoch [1446/2000]\n",
      "Train Loss: 31068023.6845\n",
      "Val Loss: 32907898.6444, MAE: 4714.5474, NMAE: 71.8771, R^2: 0.0998\n",
      "Epoch [1447/2000]\n",
      "Train Loss: 29207295.5616\n",
      "Val Loss: 32263629.1220, MAE: 4738.3696, NMAE: 72.2403, R^2: 0.1174\n",
      "Epoch [1448/2000]\n",
      "Train Loss: 28482552.0362\n",
      "Val Loss: 32735019.2865, MAE: 4799.0996, NMAE: 73.1662, R^2: 0.1045\n",
      "Epoch [1449/2000]\n",
      "Train Loss: 26941109.6565\n",
      "Val Loss: 33133897.3797, MAE: 4808.0957, NMAE: 73.3034, R^2: 0.0936\n",
      "Epoch [1450/2000]\n",
      "Train Loss: 26856030.5082\n",
      "Val Loss: 32641648.0162, MAE: 4692.1152, NMAE: 71.5351, R^2: 0.1070\n",
      "Epoch [1451/2000]\n",
      "Train Loss: 26220819.5957\n",
      "Val Loss: 32875193.1908, MAE: 4805.3984, NMAE: 73.2622, R^2: 0.1007\n",
      "Epoch [1452/2000]\n",
      "Train Loss: 25983739.6616\n",
      "Val Loss: 32412180.9199, MAE: 4717.2910, NMAE: 71.9190, R^2: 0.1133\n",
      "Epoch [1453/2000]\n",
      "Train Loss: 25481611.5185\n",
      "Val Loss: 33477483.1660, MAE: 4842.4336, NMAE: 73.8269, R^2: 0.0842\n",
      "Epoch [1454/2000]\n",
      "Train Loss: 25886815.5759\n",
      "Val Loss: 33911301.0307, MAE: 4895.4673, NMAE: 74.6354, R^2: 0.0723\n",
      "Epoch [1455/2000]\n",
      "Train Loss: 25533408.2224\n",
      "Val Loss: 33266050.9965, MAE: 4810.2178, NMAE: 73.3357, R^2: 0.0900\n",
      "Epoch [1456/2000]\n",
      "Train Loss: 25406589.6776\n",
      "Val Loss: 33183269.1483, MAE: 4830.6514, NMAE: 73.6472, R^2: 0.0922\n",
      "Epoch [1457/2000]\n",
      "Train Loss: 25967170.8625\n",
      "Val Loss: 33116745.4301, MAE: 4799.0747, NMAE: 73.1658, R^2: 0.0940\n",
      "Epoch [1458/2000]\n",
      "Train Loss: 25788562.2862\n",
      "Val Loss: 33043149.6811, MAE: 4746.1758, NMAE: 72.3593, R^2: 0.0961\n",
      "Epoch [1459/2000]\n",
      "Train Loss: 30037494.2759\n",
      "Val Loss: 32389500.7470, MAE: 4720.5244, NMAE: 71.9683, R^2: 0.1139\n",
      "Epoch [1460/2000]\n",
      "Train Loss: 28252426.2328\n",
      "Val Loss: 32664062.8346, MAE: 4741.0166, NMAE: 72.2807, R^2: 0.1064\n",
      "Epoch [1461/2000]\n",
      "Train Loss: 27145656.4371\n",
      "Val Loss: 33250559.2830, MAE: 4836.1802, NMAE: 73.7315, R^2: 0.0904\n",
      "Epoch [1462/2000]\n",
      "Train Loss: 26861839.9914\n",
      "Val Loss: 33420163.4437, MAE: 4872.1313, NMAE: 74.2796, R^2: 0.0857\n",
      "Epoch [1463/2000]\n",
      "Train Loss: 27013112.7168\n",
      "Val Loss: 33235324.9493, MAE: 4831.1318, NMAE: 73.6546, R^2: 0.0908\n",
      "Epoch [1464/2000]\n",
      "Train Loss: 27723732.4504\n",
      "Val Loss: 33088102.3247, MAE: 4860.8696, NMAE: 74.1079, R^2: 0.0948\n",
      "Epoch [1465/2000]\n",
      "Train Loss: 27021820.8784\n",
      "Val Loss: 33207749.3750, MAE: 4831.4268, NMAE: 73.6591, R^2: 0.0916\n",
      "Epoch [1466/2000]\n",
      "Train Loss: 27179550.3655\n",
      "Val Loss: 33363730.8670, MAE: 4823.9795, NMAE: 73.5455, R^2: 0.0873\n",
      "Epoch [1467/2000]\n",
      "Train Loss: 26078791.0091\n",
      "Val Loss: 33135935.1860, MAE: 4803.1494, NMAE: 73.2280, R^2: 0.0935\n",
      "Epoch [1468/2000]\n",
      "Train Loss: 25856187.6772\n",
      "Val Loss: 33688460.3833, MAE: 4839.2505, NMAE: 73.7783, R^2: 0.0784\n",
      "Epoch [1469/2000]\n",
      "Train Loss: 26176665.4509\n",
      "Val Loss: 33910153.6023, MAE: 4882.1548, NMAE: 74.4325, R^2: 0.0723\n",
      "Epoch [1470/2000]\n",
      "Train Loss: 26501606.2996\n",
      "Val Loss: 34022039.5848, MAE: 4964.6719, NMAE: 75.6905, R^2: 0.0693\n",
      "Epoch [1471/2000]\n",
      "Train Loss: 27013621.7280\n",
      "Val Loss: 32761730.0728, MAE: 4775.7915, NMAE: 72.8109, R^2: 0.1038\n",
      "Epoch [1472/2000]\n",
      "Train Loss: 25822944.6435\n",
      "Val Loss: 33716567.2707, MAE: 4866.4360, NMAE: 74.1928, R^2: 0.0776\n",
      "Epoch [1473/2000]\n",
      "Train Loss: 26998521.2552\n",
      "Val Loss: 32797029.4914, MAE: 4777.1855, NMAE: 72.8321, R^2: 0.1028\n",
      "Epoch [1474/2000]\n",
      "Train Loss: 27540729.4733\n",
      "Val Loss: 33169957.6013, MAE: 4786.0420, NMAE: 72.9671, R^2: 0.0926\n",
      "Epoch [1475/2000]\n",
      "Train Loss: 26080466.0961\n",
      "Val Loss: 32349100.6550, MAE: 4750.4434, NMAE: 72.4244, R^2: 0.1150\n",
      "Epoch [1476/2000]\n",
      "Train Loss: 26179483.8836\n",
      "Val Loss: 32257018.7748, MAE: 4684.4893, NMAE: 71.4189, R^2: 0.1176\n",
      "Epoch [1477/2000]\n",
      "Train Loss: 26795940.7819\n",
      "Val Loss: 33071626.3791, MAE: 4755.2456, NMAE: 72.4976, R^2: 0.0953\n",
      "Epoch [1478/2000]\n",
      "Train Loss: 26427502.1953\n",
      "Val Loss: 32698507.0242, MAE: 4743.0220, NMAE: 72.3113, R^2: 0.1055\n",
      "Epoch [1479/2000]\n",
      "Train Loss: 25773963.8414\n",
      "Val Loss: 33218717.0130, MAE: 4765.4854, NMAE: 72.6537, R^2: 0.0913\n",
      "Epoch [1480/2000]\n",
      "Train Loss: 25871786.9353\n",
      "Val Loss: 33809437.1852, MAE: 4859.3657, NMAE: 74.0850, R^2: 0.0751\n",
      "Epoch [1481/2000]\n",
      "Train Loss: 25902056.9116\n",
      "Val Loss: 33286124.3668, MAE: 4830.0972, NMAE: 73.6388, R^2: 0.0894\n",
      "Epoch [1482/2000]\n",
      "Train Loss: 26945041.7522\n",
      "Val Loss: 32835774.9820, MAE: 4743.6919, NMAE: 72.3215, R^2: 0.1017\n",
      "Epoch [1483/2000]\n",
      "Train Loss: 27696192.4392\n",
      "Val Loss: 33320935.3683, MAE: 4863.4741, NMAE: 74.1477, R^2: 0.0885\n",
      "Epoch [1484/2000]\n",
      "Train Loss: 25880363.8940\n",
      "Val Loss: 33770025.6804, MAE: 4887.9570, NMAE: 74.5209, R^2: 0.0762\n",
      "Epoch [1485/2000]\n",
      "Train Loss: 26323275.9022\n",
      "Val Loss: 33781196.2571, MAE: 4899.9048, NMAE: 74.7031, R^2: 0.0759\n",
      "Epoch [1486/2000]\n",
      "Train Loss: 25971168.4847\n",
      "Val Loss: 33840361.2662, MAE: 4929.2246, NMAE: 75.1501, R^2: 0.0742\n",
      "Epoch [1487/2000]\n",
      "Train Loss: 25687908.3599\n",
      "Val Loss: 34249784.1269, MAE: 4957.6826, NMAE: 75.5839, R^2: 0.0630\n",
      "Epoch [1488/2000]\n",
      "Train Loss: 27091139.2405\n",
      "Val Loss: 33394160.9462, MAE: 4860.8960, NMAE: 74.1083, R^2: 0.0865\n",
      "Epoch [1489/2000]\n",
      "Train Loss: 27485326.8418\n",
      "Val Loss: 32958884.2941, MAE: 4776.3555, NMAE: 72.8195, R^2: 0.0984\n",
      "Epoch [1490/2000]\n",
      "Train Loss: 27015623.5875\n",
      "Val Loss: 33010248.7414, MAE: 4772.7446, NMAE: 72.7644, R^2: 0.0970\n",
      "Epoch [1491/2000]\n",
      "Train Loss: 26770616.6422\n",
      "Val Loss: 33934004.1287, MAE: 4900.2305, NMAE: 74.7080, R^2: 0.0717\n",
      "Epoch [1492/2000]\n",
      "Train Loss: 26936633.0987\n",
      "Val Loss: 33441267.6250, MAE: 4835.0513, NMAE: 73.7143, R^2: 0.0852\n",
      "Epoch [1493/2000]\n",
      "Train Loss: 26388566.8879\n",
      "Val Loss: 33006334.3228, MAE: 4726.9883, NMAE: 72.0668, R^2: 0.0971\n",
      "Epoch [1494/2000]\n",
      "Train Loss: 26065631.3457\n",
      "Val Loss: 32695950.7361, MAE: 4785.1172, NMAE: 72.9530, R^2: 0.1056\n",
      "Epoch [1495/2000]\n",
      "Train Loss: 26862885.3457\n",
      "Val Loss: 33220992.9823, MAE: 4780.5728, NMAE: 72.8838, R^2: 0.0912\n",
      "Epoch [1496/2000]\n",
      "Train Loss: 27200690.4802\n",
      "Val Loss: 34220851.0833, MAE: 4936.5947, NMAE: 75.2624, R^2: 0.0638\n",
      "Epoch [1497/2000]\n",
      "Train Loss: 27803724.1267\n",
      "Val Loss: 34990647.4268, MAE: 4999.3760, NMAE: 76.2196, R^2: 0.0428\n",
      "Epoch [1498/2000]\n",
      "Train Loss: 29072931.5388\n",
      "Val Loss: 34032092.9381, MAE: 4872.8843, NMAE: 74.2911, R^2: 0.0690\n",
      "Epoch [1499/2000]\n",
      "Train Loss: 28419594.5228\n",
      "Val Loss: 33335594.4779, MAE: 4824.2817, NMAE: 73.5501, R^2: 0.0881\n",
      "Epoch [1500/2000]\n",
      "Train Loss: 26561417.9112\n",
      "Val Loss: 33164736.3262, MAE: 4819.5522, NMAE: 73.4780, R^2: 0.0927\n",
      "Epoch [1501/2000]\n",
      "Train Loss: 25643657.2659\n",
      "Val Loss: 33442261.8901, MAE: 4852.7603, NMAE: 73.9843, R^2: 0.0851\n",
      "Epoch [1502/2000]\n",
      "Train Loss: 25617425.2647\n",
      "Val Loss: 33662133.3251, MAE: 4857.3838, NMAE: 74.0548, R^2: 0.0791\n",
      "Epoch [1503/2000]\n",
      "Train Loss: 25789396.6103\n",
      "Val Loss: 33218067.1600, MAE: 4833.3174, NMAE: 73.6879, R^2: 0.0913\n",
      "Epoch [1504/2000]\n",
      "Train Loss: 27078739.7280\n",
      "Val Loss: 32729188.4544, MAE: 4794.1899, NMAE: 73.0914, R^2: 0.1046\n",
      "Epoch [1505/2000]\n",
      "Train Loss: 26198576.3737\n",
      "Val Loss: 33197352.0014, MAE: 4782.8438, NMAE: 72.9184, R^2: 0.0918\n",
      "Epoch [1506/2000]\n",
      "Train Loss: 26231569.3690\n",
      "Val Loss: 33457120.5553, MAE: 4878.0996, NMAE: 74.3706, R^2: 0.0847\n",
      "Epoch [1507/2000]\n",
      "Train Loss: 26016941.8612\n",
      "Val Loss: 33154347.1794, MAE: 4823.7637, NMAE: 73.5422, R^2: 0.0930\n",
      "Epoch [1508/2000]\n",
      "Train Loss: 26649619.9905\n",
      "Val Loss: 32786488.2297, MAE: 4746.7002, NMAE: 72.3673, R^2: 0.1031\n",
      "Epoch [1509/2000]\n",
      "Train Loss: 25532840.3069\n",
      "Val Loss: 33187172.0779, MAE: 4813.7202, NMAE: 73.3891, R^2: 0.0921\n",
      "Epoch [1510/2000]\n",
      "Train Loss: 25283840.9082\n",
      "Val Loss: 33568575.7815, MAE: 4821.6172, NMAE: 73.5095, R^2: 0.0817\n",
      "Epoch [1511/2000]\n",
      "Train Loss: 25785666.1797\n",
      "Val Loss: 32860216.2114, MAE: 4762.5127, NMAE: 72.6084, R^2: 0.1011\n",
      "Epoch [1512/2000]\n",
      "Train Loss: 26382291.9409\n",
      "Val Loss: 32098785.1849, MAE: 4677.5020, NMAE: 71.3124, R^2: 0.1219\n",
      "Epoch [1513/2000]\n",
      "Train Loss: 25832518.1091\n",
      "Val Loss: 33391385.5575, MAE: 4834.3232, NMAE: 73.7032, R^2: 0.0865\n",
      "Epoch [1514/2000]\n",
      "Train Loss: 25424898.8690\n",
      "Val Loss: 33121826.7191, MAE: 4762.8105, NMAE: 72.6130, R^2: 0.0939\n",
      "Epoch [1515/2000]\n",
      "Train Loss: 25495195.8358\n",
      "Val Loss: 34092958.0471, MAE: 4923.5557, NMAE: 75.0636, R^2: 0.0673\n",
      "Epoch [1516/2000]\n",
      "Train Loss: 25875859.7125\n",
      "Val Loss: 33656116.0168, MAE: 4853.1250, NMAE: 73.9899, R^2: 0.0793\n",
      "Epoch [1517/2000]\n",
      "Train Loss: 25786475.8897\n",
      "Val Loss: 33884636.1344, MAE: 4888.0771, NMAE: 74.5227, R^2: 0.0730\n",
      "Epoch [1518/2000]\n",
      "Train Loss: 26203245.7034\n",
      "Val Loss: 33633741.2619, MAE: 4841.7061, NMAE: 73.8158, R^2: 0.0799\n",
      "Epoch [1519/2000]\n",
      "Train Loss: 25275363.3358\n",
      "Val Loss: 34080463.8955, MAE: 4870.4893, NMAE: 74.2546, R^2: 0.0677\n",
      "Epoch [1520/2000]\n",
      "Train Loss: 25068983.1929\n",
      "Val Loss: 34613921.2954, MAE: 4939.3633, NMAE: 75.3046, R^2: 0.0531\n",
      "Epoch [1521/2000]\n",
      "Train Loss: 25261801.9373\n",
      "Val Loss: 33191003.4308, MAE: 4828.1328, NMAE: 73.6088, R^2: 0.0920\n",
      "Epoch [1522/2000]\n",
      "Train Loss: 25006869.7185\n",
      "Val Loss: 34016090.7409, MAE: 4818.8115, NMAE: 73.4667, R^2: 0.0694\n",
      "Epoch [1523/2000]\n",
      "Train Loss: 27475797.9961\n",
      "Val Loss: 33625146.9700, MAE: 4860.2607, NMAE: 74.0987, R^2: 0.0801\n",
      "Epoch [1524/2000]\n",
      "Train Loss: 27899587.9664\n",
      "Val Loss: 33081098.9499, MAE: 4796.1133, NMAE: 73.1207, R^2: 0.0950\n",
      "Epoch [1525/2000]\n",
      "Train Loss: 26295986.6056\n",
      "Val Loss: 34044036.6539, MAE: 4927.9326, NMAE: 75.1304, R^2: 0.0687\n",
      "Epoch [1526/2000]\n",
      "Train Loss: 27011832.5866\n",
      "Val Loss: 32418521.9169, MAE: 4751.9360, NMAE: 72.4472, R^2: 0.1131\n",
      "Epoch [1527/2000]\n",
      "Train Loss: 26579260.1444\n",
      "Val Loss: 33247216.8388, MAE: 4814.5942, NMAE: 73.4024, R^2: 0.0905\n",
      "Epoch [1528/2000]\n",
      "Train Loss: 27981967.2698\n",
      "Val Loss: 33631736.9437, MAE: 4861.9946, NMAE: 74.1251, R^2: 0.0800\n",
      "Epoch [1529/2000]\n",
      "Train Loss: 26261685.5237\n",
      "Val Loss: 33066254.0604, MAE: 4767.5640, NMAE: 72.6854, R^2: 0.0954\n",
      "Epoch [1530/2000]\n",
      "Train Loss: 25698486.3875\n",
      "Val Loss: 33255905.4528, MAE: 4775.7700, NMAE: 72.8105, R^2: 0.0902\n",
      "Epoch [1531/2000]\n",
      "Train Loss: 26043077.3575\n",
      "Val Loss: 33678948.6036, MAE: 4832.2896, NMAE: 73.6722, R^2: 0.0787\n",
      "Epoch [1532/2000]\n",
      "Train Loss: 25412253.0045\n",
      "Val Loss: 33201949.7555, MAE: 4806.8174, NMAE: 73.2839, R^2: 0.0917\n",
      "Epoch [1533/2000]\n",
      "Train Loss: 25589756.5927\n",
      "Val Loss: 33101625.7384, MAE: 4809.7173, NMAE: 73.3281, R^2: 0.0945\n",
      "Epoch [1534/2000]\n",
      "Train Loss: 25878470.7659\n",
      "Val Loss: 33407828.6703, MAE: 4816.1602, NMAE: 73.4263, R^2: 0.0861\n",
      "Epoch [1535/2000]\n",
      "Train Loss: 26834141.8476\n",
      "Val Loss: 32647306.8900, MAE: 4772.8643, NMAE: 72.7662, R^2: 0.1069\n",
      "Epoch [1536/2000]\n",
      "Train Loss: 26763713.3392\n",
      "Val Loss: 33704022.0493, MAE: 4855.9727, NMAE: 74.0333, R^2: 0.0780\n",
      "Epoch [1537/2000]\n",
      "Train Loss: 26442440.3968\n",
      "Val Loss: 33021116.6710, MAE: 4774.8081, NMAE: 72.7959, R^2: 0.0967\n",
      "Epoch [1538/2000]\n",
      "Train Loss: 25903454.7759\n",
      "Val Loss: 33687412.0919, MAE: 4831.8213, NMAE: 73.6651, R^2: 0.0784\n",
      "Epoch [1539/2000]\n",
      "Train Loss: 25963311.9097\n",
      "Val Loss: 34440858.7589, MAE: 4916.6104, NMAE: 74.9578, R^2: 0.0578\n",
      "Epoch [1540/2000]\n",
      "Train Loss: 25625264.5963\n",
      "Val Loss: 33644724.4175, MAE: 4822.8975, NMAE: 73.5290, R^2: 0.0796\n",
      "Epoch [1541/2000]\n",
      "Train Loss: 25869635.8985\n",
      "Val Loss: 34075612.6899, MAE: 4852.2290, NMAE: 73.9762, R^2: 0.0678\n",
      "Epoch [1542/2000]\n",
      "Train Loss: 25271895.7644\n",
      "Val Loss: 34703607.7212, MAE: 4912.3906, NMAE: 74.8934, R^2: 0.0506\n",
      "Epoch [1543/2000]\n",
      "Train Loss: 26431522.5315\n",
      "Val Loss: 33537946.5784, MAE: 4789.5049, NMAE: 73.0199, R^2: 0.0825\n",
      "Epoch [1544/2000]\n",
      "Train Loss: 28088171.9280\n",
      "Val Loss: 34020355.9149, MAE: 4925.6958, NMAE: 75.0963, R^2: 0.0693\n",
      "Epoch [1545/2000]\n",
      "Train Loss: 27103462.5750\n",
      "Val Loss: 33000950.2002, MAE: 4809.2900, NMAE: 73.3216, R^2: 0.0972\n",
      "Epoch [1546/2000]\n",
      "Train Loss: 26123068.5000\n",
      "Val Loss: 33514476.2374, MAE: 4812.3008, NMAE: 73.3675, R^2: 0.0832\n",
      "Epoch [1547/2000]\n",
      "Train Loss: 26299834.7802\n",
      "Val Loss: 32861762.7244, MAE: 4780.1978, NMAE: 72.8780, R^2: 0.1010\n",
      "Epoch [1548/2000]\n",
      "Train Loss: 25537470.0552\n",
      "Val Loss: 32811834.9913, MAE: 4733.6289, NMAE: 72.1681, R^2: 0.1024\n",
      "Epoch [1549/2000]\n",
      "Train Loss: 25871960.6517\n",
      "Val Loss: 33138884.6794, MAE: 4785.3931, NMAE: 72.9572, R^2: 0.0934\n",
      "Epoch [1550/2000]\n",
      "Train Loss: 25020271.6060\n",
      "Val Loss: 33658913.1142, MAE: 4828.2168, NMAE: 73.6101, R^2: 0.0792\n",
      "Epoch [1551/2000]\n",
      "Train Loss: 26023996.4220\n",
      "Val Loss: 33529801.0040, MAE: 4834.6147, NMAE: 73.7077, R^2: 0.0827\n",
      "Epoch [1552/2000]\n",
      "Train Loss: 26840869.8810\n",
      "Val Loss: 32177669.8867, MAE: 4693.0796, NMAE: 71.5498, R^2: 0.1197\n",
      "Epoch [1553/2000]\n",
      "Train Loss: 26543434.7349\n",
      "Val Loss: 32384067.2810, MAE: 4731.7363, NMAE: 72.1392, R^2: 0.1141\n",
      "Epoch [1554/2000]\n",
      "Train Loss: 25629983.2556\n",
      "Val Loss: 33501276.0327, MAE: 4830.3296, NMAE: 73.6423, R^2: 0.0835\n",
      "Epoch [1555/2000]\n",
      "Train Loss: 25428383.2013\n",
      "Val Loss: 34561288.4895, MAE: 4882.1167, NMAE: 74.4319, R^2: 0.0545\n",
      "Epoch [1556/2000]\n",
      "Train Loss: 25401951.1853\n",
      "Val Loss: 32755781.9607, MAE: 4743.5161, NMAE: 72.3188, R^2: 0.1039\n",
      "Epoch [1557/2000]\n",
      "Train Loss: 25313345.2392\n",
      "Val Loss: 33232075.3007, MAE: 4757.3491, NMAE: 72.5297, R^2: 0.0909\n",
      "Epoch [1558/2000]\n",
      "Train Loss: 27482639.2069\n",
      "Val Loss: 32320535.9054, MAE: 4733.8857, NMAE: 72.1720, R^2: 0.1158\n",
      "Epoch [1559/2000]\n",
      "Train Loss: 26946436.7138\n",
      "Val Loss: 33482163.0255, MAE: 4849.5068, NMAE: 73.9347, R^2: 0.0840\n",
      "Epoch [1560/2000]\n",
      "Train Loss: 26570991.3440\n",
      "Val Loss: 33993583.1826, MAE: 4914.9409, NMAE: 74.9323, R^2: 0.0701\n",
      "Epoch [1561/2000]\n",
      "Train Loss: 26486936.5871\n",
      "Val Loss: 32551145.3554, MAE: 4715.4136, NMAE: 71.8903, R^2: 0.1095\n",
      "Epoch [1562/2000]\n",
      "Train Loss: 25574541.4267\n",
      "Val Loss: 33428588.4378, MAE: 4842.3647, NMAE: 73.8258, R^2: 0.0855\n",
      "Epoch [1563/2000]\n",
      "Train Loss: 25221308.9250\n",
      "Val Loss: 33121569.0734, MAE: 4788.7456, NMAE: 73.0084, R^2: 0.0939\n",
      "Epoch [1564/2000]\n",
      "Train Loss: 24944892.3845\n",
      "Val Loss: 32844897.0866, MAE: 4749.9619, NMAE: 72.4171, R^2: 0.1015\n",
      "Epoch [1565/2000]\n",
      "Train Loss: 25184616.6207\n",
      "Val Loss: 34428217.3074, MAE: 4999.3838, NMAE: 76.2197, R^2: 0.0582\n",
      "Epoch [1566/2000]\n",
      "Train Loss: 25610581.9216\n",
      "Val Loss: 33057136.7310, MAE: 4792.9341, NMAE: 73.0722, R^2: 0.0957\n",
      "Epoch [1567/2000]\n",
      "Train Loss: 24728403.2379\n",
      "Val Loss: 33593123.5730, MAE: 4789.4062, NMAE: 73.0184, R^2: 0.0810\n",
      "Epoch [1568/2000]\n",
      "Train Loss: 26211214.4711\n",
      "Val Loss: 33216564.2500, MAE: 4792.4512, NMAE: 73.0648, R^2: 0.0913\n",
      "Epoch [1569/2000]\n",
      "Train Loss: 25292032.4784\n",
      "Val Loss: 33912371.9441, MAE: 4826.4375, NMAE: 73.5830, R^2: 0.0723\n",
      "Epoch [1570/2000]\n",
      "Train Loss: 26694826.4142\n",
      "Val Loss: 32876093.3521, MAE: 4756.6338, NMAE: 72.5188, R^2: 0.1006\n",
      "Epoch [1571/2000]\n",
      "Train Loss: 26607939.8547\n",
      "Val Loss: 33346001.6848, MAE: 4880.9775, NMAE: 74.4145, R^2: 0.0878\n",
      "Epoch [1572/2000]\n",
      "Train Loss: 25650314.1776\n",
      "Val Loss: 34377343.4136, MAE: 4957.6533, NMAE: 75.5835, R^2: 0.0596\n",
      "Epoch [1573/2000]\n",
      "Train Loss: 25598727.1147\n",
      "Val Loss: 33994250.1570, MAE: 4876.2651, NMAE: 74.3427, R^2: 0.0700\n",
      "Epoch [1574/2000]\n",
      "Train Loss: 24914201.2716\n",
      "Val Loss: 34495532.6485, MAE: 4877.2930, NMAE: 74.3583, R^2: 0.0563\n",
      "Epoch [1575/2000]\n",
      "Train Loss: 25874467.6366\n",
      "Val Loss: 33744113.7753, MAE: 4838.2354, NMAE: 73.7629, R^2: 0.0769\n",
      "Epoch [1576/2000]\n",
      "Train Loss: 25795662.2052\n",
      "Val Loss: 33235114.7291, MAE: 4812.5298, NMAE: 73.3710, R^2: 0.0908\n",
      "Epoch [1577/2000]\n",
      "Train Loss: 25443219.6612\n",
      "Val Loss: 33311822.6546, MAE: 4776.0605, NMAE: 72.8150, R^2: 0.0887\n",
      "Epoch [1578/2000]\n",
      "Train Loss: 25645707.9517\n",
      "Val Loss: 33486751.3113, MAE: 4826.7637, NMAE: 73.5880, R^2: 0.0839\n",
      "Epoch [1579/2000]\n",
      "Train Loss: 25216071.0358\n",
      "Val Loss: 33334406.2965, MAE: 4804.6680, NMAE: 73.2511, R^2: 0.0881\n",
      "Epoch [1580/2000]\n",
      "Train Loss: 25045673.5789\n",
      "Val Loss: 33748373.1300, MAE: 4835.6831, NMAE: 73.7240, R^2: 0.0768\n",
      "Epoch [1581/2000]\n",
      "Train Loss: 25268496.1879\n",
      "Val Loss: 32943541.0882, MAE: 4765.8008, NMAE: 72.6585, R^2: 0.0988\n",
      "Epoch [1582/2000]\n",
      "Train Loss: 25135723.9647\n",
      "Val Loss: 33542900.6714, MAE: 4823.8843, NMAE: 73.5441, R^2: 0.0824\n",
      "Epoch [1583/2000]\n",
      "Train Loss: 24843450.4065\n",
      "Val Loss: 33723992.1293, MAE: 4847.8398, NMAE: 73.9093, R^2: 0.0774\n",
      "Epoch [1584/2000]\n",
      "Train Loss: 25036569.7358\n",
      "Val Loss: 33978897.7198, MAE: 4806.4961, NMAE: 73.2790, R^2: 0.0705\n",
      "Epoch [1585/2000]\n",
      "Train Loss: 25975341.8776\n",
      "Val Loss: 34356216.9532, MAE: 4856.6313, NMAE: 74.0433, R^2: 0.0601\n",
      "Epoch [1586/2000]\n",
      "Train Loss: 25968909.1509\n",
      "Val Loss: 34197577.6032, MAE: 4810.6084, NMAE: 73.3417, R^2: 0.0645\n",
      "Epoch [1587/2000]\n",
      "Train Loss: 26121279.8483\n",
      "Val Loss: 34340772.1168, MAE: 4904.1040, NMAE: 74.7671, R^2: 0.0606\n",
      "Epoch [1588/2000]\n",
      "Train Loss: 25483353.3261\n",
      "Val Loss: 34325444.1764, MAE: 4915.1289, NMAE: 74.9352, R^2: 0.0610\n",
      "Epoch [1589/2000]\n",
      "Train Loss: 26696856.0000\n",
      "Val Loss: 36587052.8652, MAE: 5203.9453, NMAE: 79.3384, R^2: -0.0009\n",
      "Epoch [1590/2000]\n",
      "Train Loss: 29393221.5629\n",
      "Val Loss: 33326427.3234, MAE: 4885.0288, NMAE: 74.4763, R^2: 0.0883\n",
      "Epoch [1591/2000]\n",
      "Train Loss: 27510821.1595\n",
      "Val Loss: 33527303.9270, MAE: 4879.5649, NMAE: 74.3930, R^2: 0.0828\n",
      "Epoch [1592/2000]\n",
      "Train Loss: 27698741.8103\n",
      "Val Loss: 32703689.6500, MAE: 4834.1211, NMAE: 73.7001, R^2: 0.1053\n",
      "Epoch [1593/2000]\n",
      "Train Loss: 26809584.7810\n",
      "Val Loss: 33070626.9555, MAE: 4781.9985, NMAE: 72.9055, R^2: 0.0953\n",
      "Epoch [1594/2000]\n",
      "Train Loss: 26290656.4569\n",
      "Val Loss: 32954587.7681, MAE: 4769.1655, NMAE: 72.7098, R^2: 0.0985\n",
      "Epoch [1595/2000]\n",
      "Train Loss: 25526446.2586\n",
      "Val Loss: 33889942.8936, MAE: 4842.5273, NMAE: 73.8283, R^2: 0.0729\n",
      "Epoch [1596/2000]\n",
      "Train Loss: 25525491.8043\n",
      "Val Loss: 33412854.0052, MAE: 4832.9854, NMAE: 73.6828, R^2: 0.0859\n",
      "Epoch [1597/2000]\n",
      "Train Loss: 24976310.9323\n",
      "Val Loss: 33536379.4536, MAE: 4826.0122, NMAE: 73.5765, R^2: 0.0826\n",
      "Epoch [1598/2000]\n",
      "Train Loss: 25080764.8741\n",
      "Val Loss: 33913182.6349, MAE: 4816.7383, NMAE: 73.4351, R^2: 0.0723\n",
      "Epoch [1599/2000]\n",
      "Train Loss: 25086408.3172\n",
      "Val Loss: 34529542.2159, MAE: 4965.6128, NMAE: 75.7048, R^2: 0.0554\n",
      "Epoch [1600/2000]\n",
      "Train Loss: 26416352.5940\n",
      "Val Loss: 33604098.5953, MAE: 4857.4956, NMAE: 74.0565, R^2: 0.0807\n",
      "Epoch [1601/2000]\n",
      "Train Loss: 25276014.2250\n",
      "Val Loss: 33812260.7285, MAE: 4872.9634, NMAE: 74.2923, R^2: 0.0750\n",
      "Epoch [1602/2000]\n",
      "Train Loss: 25925527.1966\n",
      "Val Loss: 34690921.3731, MAE: 4978.1978, NMAE: 75.8967, R^2: 0.0510\n",
      "Epoch [1603/2000]\n",
      "Train Loss: 31134958.0250\n",
      "Val Loss: 32180340.1007, MAE: 4676.5132, NMAE: 71.2973, R^2: 0.1197\n",
      "Epoch [1604/2000]\n",
      "Train Loss: 27304596.4026\n",
      "Val Loss: 32642807.1030, MAE: 4779.9365, NMAE: 72.8741, R^2: 0.1070\n",
      "Epoch [1605/2000]\n",
      "Train Loss: 26724260.8181\n",
      "Val Loss: 33366219.9305, MAE: 4827.2705, NMAE: 73.5957, R^2: 0.0872\n",
      "Epoch [1606/2000]\n",
      "Train Loss: 26525700.4724\n",
      "Val Loss: 34745501.9134, MAE: 5002.5059, NMAE: 76.2673, R^2: 0.0495\n",
      "Epoch [1607/2000]\n",
      "Train Loss: 25886262.7741\n",
      "Val Loss: 33038406.8703, MAE: 4807.7847, NMAE: 73.2986, R^2: 0.0962\n",
      "Epoch [1608/2000]\n",
      "Train Loss: 24907291.7129\n",
      "Val Loss: 33422027.7229, MAE: 4803.1538, NMAE: 73.2280, R^2: 0.0857\n",
      "Epoch [1609/2000]\n",
      "Train Loss: 24785000.0690\n",
      "Val Loss: 33080381.7392, MAE: 4788.1792, NMAE: 72.9997, R^2: 0.0950\n",
      "Epoch [1610/2000]\n",
      "Train Loss: 24343508.8207\n",
      "Val Loss: 33956203.6238, MAE: 4867.7222, NMAE: 74.2124, R^2: 0.0711\n",
      "Epoch [1611/2000]\n",
      "Train Loss: 24990712.4224\n",
      "Val Loss: 34235087.3187, MAE: 4948.7188, NMAE: 75.4473, R^2: 0.0634\n",
      "Epoch [1612/2000]\n",
      "Train Loss: 24579910.2198\n",
      "Val Loss: 33082043.5067, MAE: 4766.1021, NMAE: 72.6631, R^2: 0.0950\n",
      "Epoch [1613/2000]\n",
      "Train Loss: 24326858.4970\n",
      "Val Loss: 33557459.4859, MAE: 4763.5469, NMAE: 72.6242, R^2: 0.0820\n",
      "Epoch [1614/2000]\n",
      "Train Loss: 25785942.5125\n",
      "Val Loss: 33653156.2223, MAE: 4803.3262, NMAE: 73.2306, R^2: 0.0794\n",
      "Epoch [1615/2000]\n",
      "Train Loss: 27104470.9884\n",
      "Val Loss: 33191674.0490, MAE: 4828.6367, NMAE: 73.6165, R^2: 0.0920\n",
      "Epoch [1616/2000]\n",
      "Train Loss: 26881917.7871\n",
      "Val Loss: 33695431.5743, MAE: 4831.0034, NMAE: 73.6526, R^2: 0.0782\n",
      "Epoch [1617/2000]\n",
      "Train Loss: 26723315.2595\n",
      "Val Loss: 32779719.5222, MAE: 4779.0259, NMAE: 72.8602, R^2: 0.1033\n",
      "Epoch [1618/2000]\n",
      "Train Loss: 29331318.7922\n",
      "Val Loss: 34313648.7737, MAE: 4860.2788, NMAE: 74.0989, R^2: 0.0613\n",
      "Epoch [1619/2000]\n",
      "Train Loss: 31877054.8216\n",
      "Val Loss: 33231622.4758, MAE: 4808.4321, NMAE: 73.3085, R^2: 0.0909\n",
      "Epoch [1620/2000]\n",
      "Train Loss: 29984850.9569\n",
      "Val Loss: 33220265.8651, MAE: 4866.0127, NMAE: 74.1864, R^2: 0.0912\n",
      "Epoch [1621/2000]\n",
      "Train Loss: 28740806.7384\n",
      "Val Loss: 32816078.5706, MAE: 4738.9487, NMAE: 72.2492, R^2: 0.1023\n",
      "Epoch [1622/2000]\n",
      "Train Loss: 27284066.6957\n",
      "Val Loss: 32719586.1103, MAE: 4775.8755, NMAE: 72.8121, R^2: 0.1049\n",
      "Epoch [1623/2000]\n",
      "Train Loss: 25955912.1707\n",
      "Val Loss: 33226313.5961, MAE: 4825.5664, NMAE: 73.5697, R^2: 0.0910\n",
      "Epoch [1624/2000]\n",
      "Train Loss: 27285885.6647\n",
      "Val Loss: 33191734.0282, MAE: 4797.8501, NMAE: 73.1472, R^2: 0.0920\n",
      "Epoch [1625/2000]\n",
      "Train Loss: 26498670.6810\n",
      "Val Loss: 33296192.5120, MAE: 4763.0073, NMAE: 72.6160, R^2: 0.0891\n",
      "Epoch [1626/2000]\n",
      "Train Loss: 26082724.8140\n",
      "Val Loss: 34635133.2220, MAE: 4793.2637, NMAE: 73.0772, R^2: 0.0525\n",
      "Epoch [1627/2000]\n",
      "Train Loss: 27354522.7362\n",
      "Val Loss: 33670414.2590, MAE: 4836.3789, NMAE: 73.7346, R^2: 0.0789\n",
      "Epoch [1628/2000]\n",
      "Train Loss: 26192422.1653\n",
      "Val Loss: 33664089.9678, MAE: 4813.1465, NMAE: 73.3804, R^2: 0.0791\n",
      "Epoch [1629/2000]\n",
      "Train Loss: 25818940.6237\n",
      "Val Loss: 33742349.9460, MAE: 4876.8779, NMAE: 74.3520, R^2: 0.0769\n",
      "Epoch [1630/2000]\n",
      "Train Loss: 25744981.0043\n",
      "Val Loss: 32738961.1639, MAE: 4736.8887, NMAE: 72.2178, R^2: 0.1044\n",
      "Epoch [1631/2000]\n",
      "Train Loss: 25136297.0039\n",
      "Val Loss: 33237642.8232, MAE: 4810.5522, NMAE: 73.3408, R^2: 0.0907\n",
      "Epoch [1632/2000]\n",
      "Train Loss: 26621370.2578\n",
      "Val Loss: 33152797.3414, MAE: 4810.7036, NMAE: 73.3431, R^2: 0.0931\n",
      "Epoch [1633/2000]\n",
      "Train Loss: 25555634.6418\n",
      "Val Loss: 33489021.5449, MAE: 4830.0342, NMAE: 73.6378, R^2: 0.0839\n",
      "Epoch [1634/2000]\n",
      "Train Loss: 25470059.2815\n",
      "Val Loss: 33381247.4892, MAE: 4826.4937, NMAE: 73.5839, R^2: 0.0868\n",
      "Epoch [1635/2000]\n",
      "Train Loss: 25950275.9323\n",
      "Val Loss: 32851155.3703, MAE: 4701.6919, NMAE: 71.6812, R^2: 0.1013\n",
      "Epoch [1636/2000]\n",
      "Train Loss: 26606716.1543\n",
      "Val Loss: 34263541.9485, MAE: 4978.9395, NMAE: 75.9080, R^2: 0.0627\n",
      "Epoch [1637/2000]\n",
      "Train Loss: 26293939.3362\n",
      "Val Loss: 33024411.8479, MAE: 4794.7163, NMAE: 73.0994, R^2: 0.0966\n",
      "Epoch [1638/2000]\n",
      "Train Loss: 25827375.5392\n",
      "Val Loss: 33490887.6928, MAE: 4847.0723, NMAE: 73.8976, R^2: 0.0838\n",
      "Epoch [1639/2000]\n",
      "Train Loss: 25895443.6149\n",
      "Val Loss: 33082556.1574, MAE: 4780.2642, NMAE: 72.8790, R^2: 0.0950\n",
      "Epoch [1640/2000]\n",
      "Train Loss: 26038879.5420\n",
      "Val Loss: 33261189.9070, MAE: 4808.0044, NMAE: 73.3020, R^2: 0.0901\n",
      "Epoch [1641/2000]\n",
      "Train Loss: 26917730.5905\n",
      "Val Loss: 34777853.2604, MAE: 4937.8647, NMAE: 75.2818, R^2: 0.0486\n",
      "Epoch [1642/2000]\n",
      "Train Loss: 27890092.5125\n",
      "Val Loss: 33654629.1170, MAE: 4836.7310, NMAE: 73.7399, R^2: 0.0793\n",
      "Epoch [1643/2000]\n",
      "Train Loss: 26282062.2696\n",
      "Val Loss: 33580805.9005, MAE: 4814.0225, NMAE: 73.3937, R^2: 0.0813\n",
      "Epoch [1644/2000]\n",
      "Train Loss: 26539153.7043\n",
      "Val Loss: 33151554.5807, MAE: 4692.7852, NMAE: 71.5454, R^2: 0.0931\n",
      "Epoch [1645/2000]\n",
      "Train Loss: 31912896.3125\n",
      "Val Loss: 33650000.6336, MAE: 4826.9717, NMAE: 73.5911, R^2: 0.0795\n",
      "Epoch [1646/2000]\n",
      "Train Loss: 30548969.7254\n",
      "Val Loss: 33238816.8508, MAE: 4821.3193, NMAE: 73.5050, R^2: 0.0907\n",
      "Epoch [1647/2000]\n",
      "Train Loss: 29799943.7418\n",
      "Val Loss: 33254882.2959, MAE: 4747.6704, NMAE: 72.3821, R^2: 0.0903\n",
      "Epoch [1648/2000]\n",
      "Train Loss: 29682769.8935\n",
      "Val Loss: 33437238.0509, MAE: 4845.7241, NMAE: 73.8770, R^2: 0.0853\n",
      "Epoch [1649/2000]\n",
      "Train Loss: 28858323.9108\n",
      "Val Loss: 33428509.0872, MAE: 4861.6177, NMAE: 74.1193, R^2: 0.0855\n",
      "Epoch [1650/2000]\n",
      "Train Loss: 27834715.3095\n",
      "Val Loss: 31859816.9657, MAE: 4698.9282, NMAE: 71.6390, R^2: 0.1284\n",
      "Epoch [1651/2000]\n",
      "Train Loss: 27054703.1231\n",
      "Val Loss: 32567064.2699, MAE: 4750.8599, NMAE: 72.4308, R^2: 0.1091\n",
      "Epoch [1652/2000]\n",
      "Train Loss: 26981350.0224\n",
      "Val Loss: 34266698.3905, MAE: 4938.0244, NMAE: 75.2842, R^2: 0.0626\n",
      "Epoch [1653/2000]\n",
      "Train Loss: 26820856.2200\n",
      "Val Loss: 33255624.7789, MAE: 4880.7612, NMAE: 74.4112, R^2: 0.0902\n",
      "Epoch [1654/2000]\n",
      "Train Loss: 26949158.2211\n",
      "Val Loss: 32432108.1902, MAE: 4688.9961, NMAE: 71.4876, R^2: 0.1128\n",
      "Epoch [1655/2000]\n",
      "Train Loss: 27008883.6985\n",
      "Val Loss: 32691030.4387, MAE: 4815.5186, NMAE: 73.4165, R^2: 0.1057\n",
      "Epoch [1656/2000]\n",
      "Train Loss: 27993950.9422\n",
      "Val Loss: 32459043.4011, MAE: 4742.1079, NMAE: 72.2973, R^2: 0.1120\n",
      "Epoch [1657/2000]\n",
      "Train Loss: 27164348.8190\n",
      "Val Loss: 33168686.0531, MAE: 4828.8804, NMAE: 73.6202, R^2: 0.0926\n",
      "Epoch [1658/2000]\n",
      "Train Loss: 29427566.8017\n",
      "Val Loss: 32519420.4578, MAE: 4678.8286, NMAE: 71.3326, R^2: 0.1104\n",
      "Epoch [1659/2000]\n",
      "Train Loss: 28008172.8147\n",
      "Val Loss: 33033322.7064, MAE: 4821.0312, NMAE: 73.5006, R^2: 0.0963\n",
      "Epoch [1660/2000]\n",
      "Train Loss: 28378446.4280\n",
      "Val Loss: 32147376.1511, MAE: 4710.6758, NMAE: 71.8181, R^2: 0.1206\n",
      "Epoch [1661/2000]\n",
      "Train Loss: 28067145.9144\n",
      "Val Loss: 33372495.0391, MAE: 4874.8535, NMAE: 74.3211, R^2: 0.0870\n",
      "Epoch [1662/2000]\n",
      "Train Loss: 26888710.0336\n",
      "Val Loss: 34333813.6751, MAE: 4940.2930, NMAE: 75.3188, R^2: 0.0607\n",
      "Epoch [1663/2000]\n",
      "Train Loss: 26614174.2987\n",
      "Val Loss: 34868109.7431, MAE: 4991.3955, NMAE: 76.0979, R^2: 0.0461\n",
      "Epoch [1664/2000]\n",
      "Train Loss: 28665303.7116\n",
      "Val Loss: 32599446.7891, MAE: 4830.5020, NMAE: 73.6450, R^2: 0.1082\n",
      "Epoch [1665/2000]\n",
      "Train Loss: 28219937.2185\n",
      "Val Loss: 33008082.5037, MAE: 4874.8315, NMAE: 74.3208, R^2: 0.0970\n",
      "Epoch [1666/2000]\n",
      "Train Loss: 27578078.9810\n",
      "Val Loss: 32314690.1783, MAE: 4786.1792, NMAE: 72.9692, R^2: 0.1160\n",
      "Epoch [1667/2000]\n",
      "Train Loss: 27652171.9293\n",
      "Val Loss: 32684612.9741, MAE: 4819.9028, NMAE: 73.4834, R^2: 0.1059\n",
      "Epoch [1668/2000]\n",
      "Train Loss: 27582491.6655\n",
      "Val Loss: 32769904.1613, MAE: 4777.8027, NMAE: 72.8415, R^2: 0.1035\n",
      "Epoch [1669/2000]\n",
      "Train Loss: 28332708.4918\n",
      "Val Loss: 33003016.4398, MAE: 4836.2041, NMAE: 73.7319, R^2: 0.0972\n",
      "Epoch [1670/2000]\n",
      "Train Loss: 28766794.7315\n",
      "Val Loss: 32171499.4794, MAE: 4719.7153, NMAE: 71.9559, R^2: 0.1199\n",
      "Epoch [1671/2000]\n",
      "Train Loss: 27511312.5233\n",
      "Val Loss: 34002131.3627, MAE: 4926.5723, NMAE: 75.1096, R^2: 0.0698\n",
      "Epoch [1672/2000]\n",
      "Train Loss: 28238028.0487\n",
      "Val Loss: 33170425.2984, MAE: 4865.3247, NMAE: 74.1759, R^2: 0.0926\n",
      "Epoch [1673/2000]\n",
      "Train Loss: 27558225.2310\n",
      "Val Loss: 33940440.7272, MAE: 4864.8960, NMAE: 74.1693, R^2: 0.0715\n",
      "Epoch [1674/2000]\n",
      "Train Loss: 28363944.2690\n",
      "Val Loss: 32379104.0471, MAE: 4797.0020, NMAE: 73.1342, R^2: 0.1142\n",
      "Epoch [1675/2000]\n",
      "Train Loss: 27467078.5522\n",
      "Val Loss: 33692669.7094, MAE: 4916.0518, NMAE: 74.9492, R^2: 0.0783\n",
      "Epoch [1676/2000]\n",
      "Train Loss: 29340985.1241\n",
      "Val Loss: 33620378.8812, MAE: 4979.7437, NMAE: 75.9203, R^2: 0.0803\n",
      "Epoch [1677/2000]\n",
      "Train Loss: 29082454.0388\n",
      "Val Loss: 32860227.7679, MAE: 4849.1724, NMAE: 73.9296, R^2: 0.1011\n",
      "Epoch [1678/2000]\n",
      "Train Loss: 28498099.4282\n",
      "Val Loss: 33159852.1781, MAE: 4908.9326, NMAE: 74.8407, R^2: 0.0929\n",
      "Epoch [1679/2000]\n",
      "Train Loss: 28091517.2220\n",
      "Val Loss: 33154691.8753, MAE: 4835.7568, NMAE: 73.7251, R^2: 0.0930\n",
      "Epoch [1680/2000]\n",
      "Train Loss: 27538178.1694\n",
      "Val Loss: 32987379.1160, MAE: 4860.7969, NMAE: 74.1068, R^2: 0.0976\n",
      "Epoch [1681/2000]\n",
      "Train Loss: 27090224.6806\n",
      "Val Loss: 32937547.6627, MAE: 4813.0654, NMAE: 73.3791, R^2: 0.0989\n",
      "Epoch [1682/2000]\n",
      "Train Loss: 28224005.6110\n",
      "Val Loss: 32751142.8880, MAE: 4759.2764, NMAE: 72.5591, R^2: 0.1040\n",
      "Epoch [1683/2000]\n",
      "Train Loss: 29269361.7233\n",
      "Val Loss: 33033615.9100, MAE: 4846.6851, NMAE: 73.8917, R^2: 0.0963\n",
      "Epoch [1684/2000]\n",
      "Train Loss: 27661160.6940\n",
      "Val Loss: 32862308.2175, MAE: 4799.9209, NMAE: 73.1787, R^2: 0.1010\n",
      "Epoch [1685/2000]\n",
      "Train Loss: 27312307.4603\n",
      "Val Loss: 33375048.7666, MAE: 4849.6309, NMAE: 73.9366, R^2: 0.0870\n",
      "Epoch [1686/2000]\n",
      "Train Loss: 26495370.5037\n",
      "Val Loss: 33165872.1580, MAE: 4800.6343, NMAE: 73.1896, R^2: 0.0927\n",
      "Epoch [1687/2000]\n",
      "Train Loss: 26662322.3647\n",
      "Val Loss: 33424494.9605, MAE: 4821.4839, NMAE: 73.5075, R^2: 0.0856\n",
      "Epoch [1688/2000]\n",
      "Train Loss: 25460464.8822\n",
      "Val Loss: 34163279.4035, MAE: 4896.5889, NMAE: 74.6525, R^2: 0.0654\n",
      "Epoch [1689/2000]\n",
      "Train Loss: 26505056.0172\n",
      "Val Loss: 33902139.1418, MAE: 4909.9424, NMAE: 74.8561, R^2: 0.0726\n",
      "Epoch [1690/2000]\n",
      "Train Loss: 26617141.5601\n",
      "Val Loss: 33288037.4093, MAE: 4850.8267, NMAE: 73.9548, R^2: 0.0894\n",
      "Epoch [1691/2000]\n",
      "Train Loss: 26132828.8287\n",
      "Val Loss: 33760610.6822, MAE: 4860.4668, NMAE: 74.1018, R^2: 0.0764\n",
      "Epoch [1692/2000]\n",
      "Train Loss: 25764049.8069\n",
      "Val Loss: 34075243.2695, MAE: 4966.8887, NMAE: 75.7243, R^2: 0.0678\n",
      "Epoch [1693/2000]\n",
      "Train Loss: 25706492.2884\n",
      "Val Loss: 34333728.3551, MAE: 4898.0703, NMAE: 74.6751, R^2: 0.0607\n",
      "Epoch [1694/2000]\n",
      "Train Loss: 27289084.2017\n",
      "Val Loss: 35052194.7383, MAE: 4982.8989, NMAE: 75.9684, R^2: 0.0411\n",
      "Epoch [1695/2000]\n",
      "Train Loss: 26801174.2935\n",
      "Val Loss: 33782346.1931, MAE: 4864.8618, NMAE: 74.1688, R^2: 0.0758\n",
      "Epoch [1696/2000]\n",
      "Train Loss: 25821730.6112\n",
      "Val Loss: 34411632.2394, MAE: 4940.8652, NMAE: 75.3275, R^2: 0.0586\n",
      "Epoch [1697/2000]\n",
      "Train Loss: 26831948.7280\n",
      "Val Loss: 34214187.3300, MAE: 4956.3623, NMAE: 75.5638, R^2: 0.0640\n",
      "Epoch [1698/2000]\n",
      "Train Loss: 28054204.5377\n",
      "Val Loss: 33399470.0568, MAE: 4836.6895, NMAE: 73.7393, R^2: 0.0863\n",
      "Epoch [1699/2000]\n",
      "Train Loss: 27369455.1856\n",
      "Val Loss: 33539058.0567, MAE: 4847.1396, NMAE: 73.8986, R^2: 0.0825\n",
      "Epoch [1700/2000]\n",
      "Train Loss: 27305730.8566\n",
      "Val Loss: 33307980.0259, MAE: 4840.3228, NMAE: 73.7947, R^2: 0.0888\n",
      "Epoch [1701/2000]\n",
      "Train Loss: 26983666.9276\n",
      "Val Loss: 33538570.4528, MAE: 4836.7407, NMAE: 73.7401, R^2: 0.0825\n",
      "Epoch [1702/2000]\n",
      "Train Loss: 26877002.1371\n",
      "Val Loss: 35267792.2925, MAE: 4968.4946, NMAE: 75.7488, R^2: 0.0352\n",
      "Epoch [1703/2000]\n",
      "Train Loss: 27496554.2332\n",
      "Val Loss: 33797449.1392, MAE: 4910.2676, NMAE: 74.8611, R^2: 0.0754\n",
      "Epoch [1704/2000]\n",
      "Train Loss: 26804890.1989\n",
      "Val Loss: 34663270.3645, MAE: 4933.3203, NMAE: 75.2125, R^2: 0.0517\n",
      "Epoch [1705/2000]\n",
      "Train Loss: 27868407.2888\n",
      "Val Loss: 34049768.8446, MAE: 4904.9448, NMAE: 74.7799, R^2: 0.0685\n",
      "Epoch [1706/2000]\n",
      "Train Loss: 28106089.3362\n",
      "Val Loss: 33285537.9491, MAE: 4780.2412, NMAE: 72.8787, R^2: 0.0894\n",
      "Epoch [1707/2000]\n",
      "Train Loss: 27396846.3483\n",
      "Val Loss: 33630815.1123, MAE: 4933.2832, NMAE: 75.2119, R^2: 0.0800\n",
      "Epoch [1708/2000]\n",
      "Train Loss: 26657483.0970\n",
      "Val Loss: 33782428.9365, MAE: 4894.2158, NMAE: 74.6163, R^2: 0.0758\n",
      "Epoch [1709/2000]\n",
      "Train Loss: 26487578.7530\n",
      "Val Loss: 33479085.9819, MAE: 4820.6558, NMAE: 73.4949, R^2: 0.0841\n",
      "Epoch [1710/2000]\n",
      "Train Loss: 25856794.2996\n",
      "Val Loss: 34707795.1122, MAE: 4936.1709, NMAE: 75.2560, R^2: 0.0505\n",
      "Epoch [1711/2000]\n",
      "Train Loss: 26125250.2892\n",
      "Val Loss: 33167428.3681, MAE: 4786.2393, NMAE: 72.9701, R^2: 0.0927\n",
      "Epoch [1712/2000]\n",
      "Train Loss: 26446469.4647\n",
      "Val Loss: 33692871.2865, MAE: 4877.5156, NMAE: 74.3617, R^2: 0.0783\n",
      "Epoch [1713/2000]\n",
      "Train Loss: 28307513.3621\n",
      "Val Loss: 33197621.2096, MAE: 4862.1279, NMAE: 74.1271, R^2: 0.0918\n",
      "Epoch [1714/2000]\n",
      "Train Loss: 27475989.4821\n",
      "Val Loss: 33201248.0540, MAE: 4860.9512, NMAE: 74.1092, R^2: 0.0917\n",
      "Epoch [1715/2000]\n",
      "Train Loss: 26964407.2078\n",
      "Val Loss: 33543600.2975, MAE: 4821.1665, NMAE: 73.5026, R^2: 0.0824\n",
      "Epoch [1716/2000]\n",
      "Train Loss: 26438413.1565\n",
      "Val Loss: 33262393.1984, MAE: 4778.8315, NMAE: 72.8572, R^2: 0.0901\n",
      "Epoch [1717/2000]\n",
      "Train Loss: 26468209.6263\n",
      "Val Loss: 34877558.4305, MAE: 4945.7920, NMAE: 75.4027, R^2: 0.0459\n",
      "Epoch [1718/2000]\n",
      "Train Loss: 26920872.9659\n",
      "Val Loss: 33603065.6211, MAE: 4792.0151, NMAE: 73.0582, R^2: 0.0807\n",
      "Epoch [1719/2000]\n",
      "Train Loss: 25658584.5366\n",
      "Val Loss: 34802095.7778, MAE: 4923.2471, NMAE: 75.0589, R^2: 0.0479\n",
      "Epoch [1720/2000]\n",
      "Train Loss: 26046566.9707\n",
      "Val Loss: 33614660.8538, MAE: 4824.0952, NMAE: 73.5473, R^2: 0.0804\n",
      "Epoch [1721/2000]\n",
      "Train Loss: 26740881.5431\n",
      "Val Loss: 32744523.0868, MAE: 4756.7354, NMAE: 72.5203, R^2: 0.1042\n",
      "Epoch [1722/2000]\n",
      "Train Loss: 27427771.0899\n",
      "Val Loss: 32418263.4538, MAE: 4746.7554, NMAE: 72.3682, R^2: 0.1131\n",
      "Epoch [1723/2000]\n",
      "Train Loss: 26808255.5379\n",
      "Val Loss: 34087894.7766, MAE: 4900.3691, NMAE: 74.7101, R^2: 0.0675\n",
      "Epoch [1724/2000]\n",
      "Train Loss: 27365311.1190\n",
      "Val Loss: 35228606.9111, MAE: 5009.6401, NMAE: 76.3761, R^2: 0.0363\n",
      "Epoch [1725/2000]\n",
      "Train Loss: 27401642.7547\n",
      "Val Loss: 33159169.4169, MAE: 4778.2290, NMAE: 72.8480, R^2: 0.0929\n",
      "Epoch [1726/2000]\n",
      "Train Loss: 27030981.7073\n",
      "Val Loss: 33744105.7986, MAE: 4905.0205, NMAE: 74.7811, R^2: 0.0769\n",
      "Epoch [1727/2000]\n",
      "Train Loss: 26675005.6440\n",
      "Val Loss: 35657892.4827, MAE: 5054.7676, NMAE: 77.0641, R^2: 0.0245\n",
      "Epoch [1728/2000]\n",
      "Train Loss: 27627350.8397\n",
      "Val Loss: 34511375.6788, MAE: 4970.2324, NMAE: 75.7753, R^2: 0.0559\n",
      "Epoch [1729/2000]\n",
      "Train Loss: 28110167.4509\n",
      "Val Loss: 33560367.1008, MAE: 4889.2041, NMAE: 74.5399, R^2: 0.0819\n",
      "Epoch [1730/2000]\n",
      "Train Loss: 26728612.8724\n",
      "Val Loss: 34320931.4380, MAE: 4918.4644, NMAE: 74.9860, R^2: 0.0611\n",
      "Epoch [1731/2000]\n",
      "Train Loss: 27165214.8457\n",
      "Val Loss: 33180923.9180, MAE: 4812.2314, NMAE: 73.3664, R^2: 0.0923\n",
      "Epoch [1732/2000]\n",
      "Train Loss: 28083505.9237\n",
      "Val Loss: 34023312.2964, MAE: 4819.7012, NMAE: 73.4803, R^2: 0.0692\n",
      "Epoch [1733/2000]\n",
      "Train Loss: 26533301.0151\n",
      "Val Loss: 35141034.3113, MAE: 5044.7344, NMAE: 76.9111, R^2: 0.0387\n",
      "Epoch [1734/2000]\n",
      "Train Loss: 29676482.5358\n",
      "Val Loss: 33967193.9655, MAE: 4781.1621, NMAE: 72.8927, R^2: 0.0708\n",
      "Epoch [1735/2000]\n",
      "Train Loss: 29273027.7216\n",
      "Val Loss: 33143715.7688, MAE: 4870.2632, NMAE: 74.2512, R^2: 0.0933\n",
      "Epoch [1736/2000]\n",
      "Train Loss: 28408098.9453\n",
      "Val Loss: 32645816.3115, MAE: 4849.9785, NMAE: 73.9419, R^2: 0.1069\n",
      "Epoch [1737/2000]\n",
      "Train Loss: 28239398.9802\n",
      "Val Loss: 31404906.4130, MAE: 4687.3696, NMAE: 71.4628, R^2: 0.1409\n",
      "Epoch [1738/2000]\n",
      "Train Loss: 28228588.1690\n",
      "Val Loss: 32926039.5529, MAE: 4884.8452, NMAE: 74.4735, R^2: 0.0993\n",
      "Epoch [1739/2000]\n",
      "Train Loss: 28344938.4272\n",
      "Val Loss: 32635887.3228, MAE: 4870.0059, NMAE: 74.2472, R^2: 0.1072\n",
      "Epoch [1740/2000]\n",
      "Train Loss: 28167581.9810\n",
      "Val Loss: 32113663.7487, MAE: 4729.7231, NMAE: 72.1085, R^2: 0.1215\n",
      "Epoch [1741/2000]\n",
      "Train Loss: 28327928.4638\n",
      "Val Loss: 33291884.4156, MAE: 4875.4019, NMAE: 74.3295, R^2: 0.0893\n",
      "Epoch [1742/2000]\n",
      "Train Loss: 27795769.4754\n",
      "Val Loss: 32799384.3219, MAE: 4815.4087, NMAE: 73.4149, R^2: 0.1027\n",
      "Epoch [1743/2000]\n",
      "Train Loss: 26777073.3362\n",
      "Val Loss: 33518180.8737, MAE: 4870.6714, NMAE: 74.2574, R^2: 0.0831\n",
      "Epoch [1744/2000]\n",
      "Train Loss: 26812012.2147\n",
      "Val Loss: 33149833.0242, MAE: 4885.2534, NMAE: 74.4797, R^2: 0.0931\n",
      "Epoch [1745/2000]\n",
      "Train Loss: 27379612.9772\n",
      "Val Loss: 32720924.9842, MAE: 4792.5396, NMAE: 73.0662, R^2: 0.1049\n",
      "Epoch [1746/2000]\n",
      "Train Loss: 26470997.7017\n",
      "Val Loss: 32394280.5084, MAE: 4760.4409, NMAE: 72.5768, R^2: 0.1138\n",
      "Epoch [1747/2000]\n",
      "Train Loss: 26901446.4884\n",
      "Val Loss: 32539211.4596, MAE: 4778.7637, NMAE: 72.8562, R^2: 0.1098\n",
      "Epoch [1748/2000]\n",
      "Train Loss: 26466657.5280\n",
      "Val Loss: 33461321.3230, MAE: 4838.9961, NMAE: 73.7745, R^2: 0.0846\n",
      "Epoch [1749/2000]\n",
      "Train Loss: 26164818.0914\n",
      "Val Loss: 33683269.8081, MAE: 4933.5991, NMAE: 75.2168, R^2: 0.0785\n",
      "Epoch [1750/2000]\n",
      "Train Loss: 26312106.6435\n",
      "Val Loss: 33258553.1423, MAE: 4864.1890, NMAE: 74.1586, R^2: 0.0902\n",
      "Epoch [1751/2000]\n",
      "Train Loss: 26377049.3901\n",
      "Val Loss: 33166364.0956, MAE: 4831.7964, NMAE: 73.6647, R^2: 0.0927\n",
      "Epoch [1752/2000]\n",
      "Train Loss: 26401650.8849\n",
      "Val Loss: 33456831.9132, MAE: 4783.4658, NMAE: 72.9279, R^2: 0.0847\n",
      "Epoch [1753/2000]\n",
      "Train Loss: 26246499.1578\n",
      "Val Loss: 33591369.5138, MAE: 4820.0083, NMAE: 73.4850, R^2: 0.0811\n",
      "Epoch [1754/2000]\n",
      "Train Loss: 25501719.6310\n",
      "Val Loss: 33194036.7269, MAE: 4813.1558, NMAE: 73.3805, R^2: 0.0919\n",
      "Epoch [1755/2000]\n",
      "Train Loss: 25825220.8328\n",
      "Val Loss: 34052066.7336, MAE: 4946.6230, NMAE: 75.4153, R^2: 0.0685\n",
      "Epoch [1756/2000]\n",
      "Train Loss: 26587788.3328\n",
      "Val Loss: 34922452.8917, MAE: 4980.5054, NMAE: 75.9319, R^2: 0.0446\n",
      "Epoch [1757/2000]\n",
      "Train Loss: 26924209.6224\n",
      "Val Loss: 32527485.8780, MAE: 4680.8926, NMAE: 71.3640, R^2: 0.1102\n",
      "Epoch [1758/2000]\n",
      "Train Loss: 26592690.5030\n",
      "Val Loss: 32870585.6843, MAE: 4733.3730, NMAE: 72.1642, R^2: 0.1008\n",
      "Epoch [1759/2000]\n",
      "Train Loss: 26237358.2039\n",
      "Val Loss: 33500104.0830, MAE: 4848.7017, NMAE: 73.9224, R^2: 0.0836\n",
      "Epoch [1760/2000]\n",
      "Train Loss: 26933767.4560\n",
      "Val Loss: 33313117.9376, MAE: 4834.3560, NMAE: 73.7037, R^2: 0.0887\n",
      "Epoch [1761/2000]\n",
      "Train Loss: 25318681.0259\n",
      "Val Loss: 34050961.0445, MAE: 4850.4429, NMAE: 73.9490, R^2: 0.0685\n",
      "Epoch [1762/2000]\n",
      "Train Loss: 26073906.5009\n",
      "Val Loss: 33616174.9203, MAE: 4782.1479, NMAE: 72.9078, R^2: 0.0804\n",
      "Epoch [1763/2000]\n",
      "Train Loss: 25669275.1703\n",
      "Val Loss: 33755016.3504, MAE: 4804.9263, NMAE: 73.2550, R^2: 0.0766\n",
      "Epoch [1764/2000]\n",
      "Train Loss: 25515234.2578\n",
      "Val Loss: 33271358.3055, MAE: 4813.0356, NMAE: 73.3787, R^2: 0.0898\n",
      "Epoch [1765/2000]\n",
      "Train Loss: 25510027.2978\n",
      "Val Loss: 33385310.8977, MAE: 4849.4609, NMAE: 73.9340, R^2: 0.0867\n",
      "Epoch [1766/2000]\n",
      "Train Loss: 25649498.6759\n",
      "Val Loss: 32997364.8704, MAE: 4713.9360, NMAE: 71.8678, R^2: 0.0973\n",
      "Epoch [1767/2000]\n",
      "Train Loss: 25792600.9155\n",
      "Val Loss: 35284062.6712, MAE: 5015.2905, NMAE: 76.4622, R^2: 0.0348\n",
      "Epoch [1768/2000]\n",
      "Train Loss: 25334853.7819\n",
      "Val Loss: 34103264.1910, MAE: 4862.6162, NMAE: 74.1346, R^2: 0.0671\n",
      "Epoch [1769/2000]\n",
      "Train Loss: 25581594.9427\n",
      "Val Loss: 34269641.8513, MAE: 4917.1997, NMAE: 74.9667, R^2: 0.0625\n",
      "Epoch [1770/2000]\n",
      "Train Loss: 26200516.9103\n",
      "Val Loss: 33174053.0957, MAE: 4791.2959, NMAE: 73.0472, R^2: 0.0925\n",
      "Epoch [1771/2000]\n",
      "Train Loss: 25576090.8603\n",
      "Val Loss: 34356413.6709, MAE: 4939.1543, NMAE: 75.3015, R^2: 0.0601\n",
      "Epoch [1772/2000]\n",
      "Train Loss: 26410382.2017\n",
      "Val Loss: 32798320.6620, MAE: 4777.1001, NMAE: 72.8308, R^2: 0.1028\n",
      "Epoch [1773/2000]\n",
      "Train Loss: 25524336.2634\n",
      "Val Loss: 33854215.0878, MAE: 4814.3589, NMAE: 73.3989, R^2: 0.0739\n",
      "Epoch [1774/2000]\n",
      "Train Loss: 26103364.0431\n",
      "Val Loss: 34194054.2422, MAE: 4874.1489, NMAE: 74.3104, R^2: 0.0646\n",
      "Epoch [1775/2000]\n",
      "Train Loss: 25073050.3263\n",
      "Val Loss: 34442595.1082, MAE: 4882.2109, NMAE: 74.4333, R^2: 0.0578\n",
      "Epoch [1776/2000]\n",
      "Train Loss: 25313571.6319\n",
      "Val Loss: 33854403.4127, MAE: 4721.3022, NMAE: 71.9801, R^2: 0.0739\n",
      "Epoch [1777/2000]\n",
      "Train Loss: 26214019.3716\n",
      "Val Loss: 34186855.2679, MAE: 4840.3423, NMAE: 73.7950, R^2: 0.0648\n",
      "Epoch [1778/2000]\n",
      "Train Loss: 25715237.6565\n",
      "Val Loss: 33512979.1899, MAE: 4828.9150, NMAE: 73.6208, R^2: 0.0832\n",
      "Epoch [1779/2000]\n",
      "Train Loss: 26023708.1836\n",
      "Val Loss: 33024601.5239, MAE: 4788.2651, NMAE: 73.0010, R^2: 0.0966\n",
      "Epoch [1780/2000]\n",
      "Train Loss: 25324262.0629\n",
      "Val Loss: 35360251.7363, MAE: 4949.6304, NMAE: 75.4612, R^2: 0.0327\n",
      "Epoch [1781/2000]\n",
      "Train Loss: 25848552.3216\n",
      "Val Loss: 35025785.6653, MAE: 4945.5986, NMAE: 75.3997, R^2: 0.0418\n",
      "Epoch [1782/2000]\n",
      "Train Loss: 25912438.6685\n",
      "Val Loss: 34130689.6679, MAE: 4899.3354, NMAE: 74.6944, R^2: 0.0663\n",
      "Epoch [1783/2000]\n",
      "Train Loss: 25274313.1095\n",
      "Val Loss: 33704935.1356, MAE: 4857.0889, NMAE: 74.0503, R^2: 0.0780\n",
      "Epoch [1784/2000]\n",
      "Train Loss: 25057199.2172\n",
      "Val Loss: 34816809.7034, MAE: 4985.6406, NMAE: 76.0102, R^2: 0.0475\n",
      "Epoch [1785/2000]\n",
      "Train Loss: 25363089.8272\n",
      "Val Loss: 34363197.8815, MAE: 4933.8130, NMAE: 75.2200, R^2: 0.0599\n",
      "Epoch [1786/2000]\n",
      "Train Loss: 26086787.3694\n",
      "Val Loss: 33959281.2658, MAE: 4868.1533, NMAE: 74.2190, R^2: 0.0710\n",
      "Epoch [1787/2000]\n",
      "Train Loss: 24676346.1871\n",
      "Val Loss: 34262061.7214, MAE: 4874.4854, NMAE: 74.3155, R^2: 0.0627\n",
      "Epoch [1788/2000]\n",
      "Train Loss: 25172797.4065\n",
      "Val Loss: 33364038.3817, MAE: 4758.5352, NMAE: 72.5478, R^2: 0.0873\n",
      "Epoch [1789/2000]\n",
      "Train Loss: 27085118.7017\n",
      "Val Loss: 33785655.7278, MAE: 4897.0859, NMAE: 74.6601, R^2: 0.0757\n",
      "Epoch [1790/2000]\n",
      "Train Loss: 27324644.2526\n",
      "Val Loss: 33154168.5030, MAE: 4813.4868, NMAE: 73.3856, R^2: 0.0930\n",
      "Epoch [1791/2000]\n",
      "Train Loss: 25617610.5647\n",
      "Val Loss: 34726480.2433, MAE: 4934.3047, NMAE: 75.2275, R^2: 0.0500\n",
      "Epoch [1792/2000]\n",
      "Train Loss: 26606471.1905\n",
      "Val Loss: 32862923.4243, MAE: 4782.8208, NMAE: 72.9180, R^2: 0.1010\n",
      "Epoch [1793/2000]\n",
      "Train Loss: 25890648.0478\n",
      "Val Loss: 33685632.0363, MAE: 4783.8208, NMAE: 72.9333, R^2: 0.0785\n",
      "Epoch [1794/2000]\n",
      "Train Loss: 26334099.4147\n",
      "Val Loss: 32860128.0903, MAE: 4755.0171, NMAE: 72.4941, R^2: 0.1011\n",
      "Epoch [1795/2000]\n",
      "Train Loss: 27151815.3466\n",
      "Val Loss: 32676041.6905, MAE: 4695.2690, NMAE: 71.5832, R^2: 0.1061\n",
      "Epoch [1796/2000]\n",
      "Train Loss: 26375107.9405\n",
      "Val Loss: 32897105.1083, MAE: 4738.7090, NMAE: 72.2455, R^2: 0.1001\n",
      "Epoch [1797/2000]\n",
      "Train Loss: 26097551.6022\n",
      "Val Loss: 33735969.6322, MAE: 4832.0039, NMAE: 73.6679, R^2: 0.0771\n",
      "Epoch [1798/2000]\n",
      "Train Loss: 26568782.1711\n",
      "Val Loss: 33048232.2644, MAE: 4772.2056, NMAE: 72.7562, R^2: 0.0959\n",
      "Epoch [1799/2000]\n",
      "Train Loss: 26419811.8991\n",
      "Val Loss: 34058342.9928, MAE: 4905.1157, NMAE: 74.7825, R^2: 0.0683\n",
      "Epoch [1800/2000]\n",
      "Train Loss: 26308982.0901\n",
      "Val Loss: 33281754.1933, MAE: 4786.6943, NMAE: 72.9771, R^2: 0.0895\n",
      "Epoch [1801/2000]\n",
      "Train Loss: 27265093.9103\n",
      "Val Loss: 32764881.8232, MAE: 4752.5220, NMAE: 72.4561, R^2: 0.1037\n",
      "Epoch [1802/2000]\n",
      "Train Loss: 25638879.9336\n",
      "Val Loss: 33784632.9458, MAE: 4854.5786, NMAE: 74.0120, R^2: 0.0758\n",
      "Epoch [1803/2000]\n",
      "Train Loss: 26038600.0427\n",
      "Val Loss: 32877925.3581, MAE: 4818.7539, NMAE: 73.4659, R^2: 0.1006\n",
      "Epoch [1804/2000]\n",
      "Train Loss: 25479898.1741\n",
      "Val Loss: 33084851.9525, MAE: 4788.9702, NMAE: 73.0118, R^2: 0.0949\n",
      "Epoch [1805/2000]\n",
      "Train Loss: 26161010.5444\n",
      "Val Loss: 34086977.0934, MAE: 4853.8691, NMAE: 74.0012, R^2: 0.0675\n",
      "Epoch [1806/2000]\n",
      "Train Loss: 27789348.1272\n",
      "Val Loss: 32663030.3754, MAE: 4768.7666, NMAE: 72.7038, R^2: 0.1065\n",
      "Epoch [1807/2000]\n",
      "Train Loss: 27963653.4392\n",
      "Val Loss: 33634872.0593, MAE: 4759.0513, NMAE: 72.5556, R^2: 0.0799\n",
      "Epoch [1808/2000]\n",
      "Train Loss: 26739085.3496\n",
      "Val Loss: 33595516.5974, MAE: 4865.4819, NMAE: 74.1783, R^2: 0.0809\n",
      "Epoch [1809/2000]\n",
      "Train Loss: 26079100.4280\n",
      "Val Loss: 33353703.9866, MAE: 4806.9844, NMAE: 73.2864, R^2: 0.0876\n",
      "Epoch [1810/2000]\n",
      "Train Loss: 25190504.8095\n",
      "Val Loss: 33636072.7606, MAE: 4812.5327, NMAE: 73.3710, R^2: 0.0798\n",
      "Epoch [1811/2000]\n",
      "Train Loss: 25094762.1578\n",
      "Val Loss: 34118403.8683, MAE: 4895.0454, NMAE: 74.6290, R^2: 0.0666\n",
      "Epoch [1812/2000]\n",
      "Train Loss: 25193599.0177\n",
      "Val Loss: 33307244.0653, MAE: 4786.8457, NMAE: 72.9794, R^2: 0.0888\n",
      "Epoch [1813/2000]\n",
      "Train Loss: 24768187.7935\n",
      "Val Loss: 33264935.5255, MAE: 4780.5698, NMAE: 72.8837, R^2: 0.0900\n",
      "Epoch [1814/2000]\n",
      "Train Loss: 25892433.0185\n",
      "Val Loss: 34433970.6224, MAE: 4896.3853, NMAE: 74.6494, R^2: 0.0580\n",
      "Epoch [1815/2000]\n",
      "Train Loss: 27065933.2595\n",
      "Val Loss: 32363580.7586, MAE: 4753.0010, NMAE: 72.4634, R^2: 0.1146\n",
      "Epoch [1816/2000]\n",
      "Train Loss: 26492320.7634\n",
      "Val Loss: 33351547.6054, MAE: 4759.5693, NMAE: 72.5635, R^2: 0.0876\n",
      "Epoch [1817/2000]\n",
      "Train Loss: 25758770.8754\n",
      "Val Loss: 32845132.4965, MAE: 4780.8105, NMAE: 72.8874, R^2: 0.1015\n",
      "Epoch [1818/2000]\n",
      "Train Loss: 25571651.5280\n",
      "Val Loss: 32885340.3285, MAE: 4713.0020, NMAE: 71.8536, R^2: 0.1004\n",
      "Epoch [1819/2000]\n",
      "Train Loss: 25289688.4151\n",
      "Val Loss: 33919041.7675, MAE: 4862.2148, NMAE: 74.1285, R^2: 0.0721\n",
      "Epoch [1820/2000]\n",
      "Train Loss: 24736905.2453\n",
      "Val Loss: 34215728.6427, MAE: 4906.9751, NMAE: 74.8109, R^2: 0.0640\n",
      "Epoch [1821/2000]\n",
      "Train Loss: 24828571.1056\n",
      "Val Loss: 33959790.7589, MAE: 4889.5889, NMAE: 74.5458, R^2: 0.0710\n",
      "Epoch [1822/2000]\n",
      "Train Loss: 24923325.5362\n",
      "Val Loss: 33747736.8080, MAE: 4818.3096, NMAE: 73.4591, R^2: 0.0768\n",
      "Epoch [1823/2000]\n",
      "Train Loss: 24906086.9978\n",
      "Val Loss: 33553425.6973, MAE: 4796.1880, NMAE: 73.1218, R^2: 0.0821\n",
      "Epoch [1824/2000]\n",
      "Train Loss: 25886766.7733\n",
      "Val Loss: 33802270.5429, MAE: 4871.0850, NMAE: 74.2637, R^2: 0.0753\n",
      "Epoch [1825/2000]\n",
      "Train Loss: 24796632.2659\n",
      "Val Loss: 33664499.8610, MAE: 4805.1719, NMAE: 73.2588, R^2: 0.0791\n",
      "Epoch [1826/2000]\n",
      "Train Loss: 24776920.8974\n",
      "Val Loss: 33688267.4949, MAE: 4846.3975, NMAE: 73.8873, R^2: 0.0784\n",
      "Epoch [1827/2000]\n",
      "Train Loss: 25300929.2388\n",
      "Val Loss: 34240631.2903, MAE: 4933.5928, NMAE: 75.2167, R^2: 0.0633\n",
      "Epoch [1828/2000]\n",
      "Train Loss: 25806839.7457\n",
      "Val Loss: 32973438.5114, MAE: 4786.9321, NMAE: 72.9807, R^2: 0.0980\n",
      "Epoch [1829/2000]\n",
      "Train Loss: 25499763.5599\n",
      "Val Loss: 33904111.4672, MAE: 4887.6235, NMAE: 74.5158, R^2: 0.0725\n",
      "Epoch [1830/2000]\n",
      "Train Loss: 25632582.0164\n",
      "Val Loss: 34199888.8706, MAE: 4887.4160, NMAE: 74.5127, R^2: 0.0644\n",
      "Epoch [1831/2000]\n",
      "Train Loss: 25063145.7547\n",
      "Val Loss: 33670742.3115, MAE: 4820.4575, NMAE: 73.4918, R^2: 0.0789\n",
      "Epoch [1832/2000]\n",
      "Train Loss: 25329089.1750\n",
      "Val Loss: 34542323.9678, MAE: 4861.9648, NMAE: 74.1246, R^2: 0.0550\n",
      "Epoch [1833/2000]\n",
      "Train Loss: 25303981.1681\n",
      "Val Loss: 34945114.9062, MAE: 4999.1406, NMAE: 76.2160, R^2: 0.0440\n",
      "Epoch [1834/2000]\n",
      "Train Loss: 26031325.8517\n",
      "Val Loss: 33996647.2300, MAE: 4829.8457, NMAE: 73.6350, R^2: 0.0700\n",
      "Epoch [1835/2000]\n",
      "Train Loss: 25532492.2698\n",
      "Val Loss: 34753452.5660, MAE: 4959.7510, NMAE: 75.6155, R^2: 0.0493\n",
      "Epoch [1836/2000]\n",
      "Train Loss: 27196544.5444\n",
      "Val Loss: 34462632.9006, MAE: 4954.0942, NMAE: 75.5292, R^2: 0.0572\n",
      "Epoch [1837/2000]\n",
      "Train Loss: 26435771.0909\n",
      "Val Loss: 34029081.2247, MAE: 4860.9160, NMAE: 74.1087, R^2: 0.0691\n",
      "Epoch [1838/2000]\n",
      "Train Loss: 26340193.4470\n",
      "Val Loss: 34195501.6847, MAE: 4919.8477, NMAE: 75.0071, R^2: 0.0645\n",
      "Epoch [1839/2000]\n",
      "Train Loss: 25591737.7379\n",
      "Val Loss: 34425538.8085, MAE: 4878.2598, NMAE: 74.3731, R^2: 0.0582\n",
      "Epoch [1840/2000]\n",
      "Train Loss: 26477779.0121\n",
      "Val Loss: 33609557.6879, MAE: 4747.7998, NMAE: 72.3841, R^2: 0.0806\n",
      "Epoch [1841/2000]\n",
      "Train Loss: 27267969.3073\n",
      "Val Loss: 33663014.6925, MAE: 4797.5483, NMAE: 73.1426, R^2: 0.0791\n",
      "Epoch [1842/2000]\n",
      "Train Loss: 27292123.6129\n",
      "Val Loss: 33147254.1700, MAE: 4737.2056, NMAE: 72.2226, R^2: 0.0932\n",
      "Epoch [1843/2000]\n",
      "Train Loss: 25936405.7966\n",
      "Val Loss: 33738811.1156, MAE: 4812.8496, NMAE: 73.3758, R^2: 0.0770\n",
      "Epoch [1844/2000]\n",
      "Train Loss: 27188323.6668\n",
      "Val Loss: 33374934.0352, MAE: 4786.2529, NMAE: 72.9704, R^2: 0.0870\n",
      "Epoch [1845/2000]\n",
      "Train Loss: 27424001.7616\n",
      "Val Loss: 33276879.7869, MAE: 4793.3018, NMAE: 73.0778, R^2: 0.0897\n",
      "Epoch [1846/2000]\n",
      "Train Loss: 26513693.5595\n",
      "Val Loss: 33553763.1487, MAE: 4803.1196, NMAE: 73.2275, R^2: 0.0821\n",
      "Epoch [1847/2000]\n",
      "Train Loss: 26424059.6414\n",
      "Val Loss: 33828601.8626, MAE: 4834.4858, NMAE: 73.7057, R^2: 0.0746\n",
      "Epoch [1848/2000]\n",
      "Train Loss: 26651044.9724\n",
      "Val Loss: 34737063.6222, MAE: 4928.0518, NMAE: 75.1322, R^2: 0.0497\n",
      "Epoch [1849/2000]\n",
      "Train Loss: 27057473.8759\n",
      "Val Loss: 33927507.8009, MAE: 4822.3730, NMAE: 73.5210, R^2: 0.0719\n",
      "Epoch [1850/2000]\n",
      "Train Loss: 26689276.4272\n",
      "Val Loss: 33718364.1118, MAE: 4902.9751, NMAE: 74.7499, R^2: 0.0776\n",
      "Epoch [1851/2000]\n",
      "Train Loss: 27444828.7181\n",
      "Val Loss: 33742768.9087, MAE: 4879.5161, NMAE: 74.3922, R^2: 0.0769\n",
      "Epoch [1852/2000]\n",
      "Train Loss: 28425811.4560\n",
      "Val Loss: 34333895.6472, MAE: 4905.7935, NMAE: 74.7928, R^2: 0.0607\n",
      "Epoch [1853/2000]\n",
      "Train Loss: 29419384.8957\n",
      "Val Loss: 33996616.4972, MAE: 4930.9053, NMAE: 75.1757, R^2: 0.0700\n",
      "Epoch [1854/2000]\n",
      "Train Loss: 27624436.0129\n",
      "Val Loss: 34765496.4998, MAE: 4985.7251, NMAE: 76.0115, R^2: 0.0489\n",
      "Epoch [1855/2000]\n",
      "Train Loss: 28084875.9543\n",
      "Val Loss: 33991111.5201, MAE: 4979.9434, NMAE: 75.9233, R^2: 0.0701\n",
      "Epoch [1856/2000]\n",
      "Train Loss: 28552542.2940\n",
      "Val Loss: 34736627.4814, MAE: 5050.3662, NMAE: 76.9970, R^2: 0.0497\n",
      "Epoch [1857/2000]\n",
      "Train Loss: 27902025.8147\n",
      "Val Loss: 34589381.3983, MAE: 5014.8618, NMAE: 76.4557, R^2: 0.0538\n",
      "Epoch [1858/2000]\n",
      "Train Loss: 27204105.5319\n",
      "Val Loss: 34899889.9644, MAE: 4969.6279, NMAE: 75.7661, R^2: 0.0453\n",
      "Epoch [1859/2000]\n",
      "Train Loss: 26721517.4134\n",
      "Val Loss: 34790676.1128, MAE: 4969.5005, NMAE: 75.7641, R^2: 0.0482\n",
      "Epoch [1860/2000]\n",
      "Train Loss: 26668846.9073\n",
      "Val Loss: 33649963.8640, MAE: 4840.1055, NMAE: 73.7914, R^2: 0.0795\n",
      "Epoch [1861/2000]\n",
      "Train Loss: 25942651.2138\n",
      "Val Loss: 34386956.9731, MAE: 4900.9741, NMAE: 74.7194, R^2: 0.0593\n",
      "Epoch [1862/2000]\n",
      "Train Loss: 26223749.5405\n",
      "Val Loss: 34262607.0078, MAE: 4932.7173, NMAE: 75.2033, R^2: 0.0627\n",
      "Epoch [1863/2000]\n",
      "Train Loss: 26023375.4435\n",
      "Val Loss: 33705338.5417, MAE: 4851.5947, NMAE: 73.9665, R^2: 0.0779\n",
      "Epoch [1864/2000]\n",
      "Train Loss: 26734962.3004\n",
      "Val Loss: 33215502.8139, MAE: 4857.8867, NMAE: 74.0625, R^2: 0.0913\n",
      "Epoch [1865/2000]\n",
      "Train Loss: 26451811.9573\n",
      "Val Loss: 34322058.1939, MAE: 4867.0850, NMAE: 74.2027, R^2: 0.0611\n",
      "Epoch [1866/2000]\n",
      "Train Loss: 26150494.0306\n",
      "Val Loss: 34019088.7390, MAE: 4860.6016, NMAE: 74.1039, R^2: 0.0694\n",
      "Epoch [1867/2000]\n",
      "Train Loss: 25997796.0129\n",
      "Val Loss: 34408104.0448, MAE: 4900.8906, NMAE: 74.7181, R^2: 0.0587\n",
      "Epoch [1868/2000]\n",
      "Train Loss: 26243550.4496\n",
      "Val Loss: 33458668.5978, MAE: 4875.4800, NMAE: 74.3307, R^2: 0.0847\n",
      "Epoch [1869/2000]\n",
      "Train Loss: 27685247.2677\n",
      "Val Loss: 32572993.5287, MAE: 4685.1846, NMAE: 71.4295, R^2: 0.1089\n",
      "Epoch [1870/2000]\n",
      "Train Loss: 26206693.9168\n",
      "Val Loss: 33058188.3313, MAE: 4826.7783, NMAE: 73.5882, R^2: 0.0956\n",
      "Epoch [1871/2000]\n",
      "Train Loss: 26019684.6543\n",
      "Val Loss: 32657638.5499, MAE: 4819.3770, NMAE: 73.4754, R^2: 0.1066\n",
      "Epoch [1872/2000]\n",
      "Train Loss: 25858426.5181\n",
      "Val Loss: 34350382.6345, MAE: 4927.0337, NMAE: 75.1167, R^2: 0.0603\n",
      "Epoch [1873/2000]\n",
      "Train Loss: 27285520.5487\n",
      "Val Loss: 33513855.1636, MAE: 4750.3076, NMAE: 72.4223, R^2: 0.0832\n",
      "Epoch [1874/2000]\n",
      "Train Loss: 29504341.7647\n",
      "Val Loss: 33371593.8387, MAE: 4823.9858, NMAE: 73.5456, R^2: 0.0871\n",
      "Epoch [1875/2000]\n",
      "Train Loss: 29283977.8332\n",
      "Val Loss: 33114961.5961, MAE: 4783.1074, NMAE: 72.9224, R^2: 0.0941\n",
      "Epoch [1876/2000]\n",
      "Train Loss: 29662784.7181\n",
      "Val Loss: 32771017.3035, MAE: 4811.3486, NMAE: 73.3530, R^2: 0.1035\n",
      "Epoch [1877/2000]\n",
      "Train Loss: 27594793.7698\n",
      "Val Loss: 33867067.2394, MAE: 4772.8711, NMAE: 72.7663, R^2: 0.0735\n",
      "Epoch [1878/2000]\n",
      "Train Loss: 27572240.9427\n",
      "Val Loss: 31927853.8301, MAE: 4709.8750, NMAE: 71.8059, R^2: 0.1266\n",
      "Epoch [1879/2000]\n",
      "Train Loss: 27108869.9707\n",
      "Val Loss: 33147373.2828, MAE: 4814.2295, NMAE: 73.3969, R^2: 0.0932\n",
      "Epoch [1880/2000]\n",
      "Train Loss: 26662462.9453\n",
      "Val Loss: 32770369.6457, MAE: 4747.1602, NMAE: 72.3744, R^2: 0.1035\n",
      "Epoch [1881/2000]\n",
      "Train Loss: 26839371.0108\n",
      "Val Loss: 32501600.9266, MAE: 4703.9053, NMAE: 71.7149, R^2: 0.1109\n",
      "Epoch [1882/2000]\n",
      "Train Loss: 27807904.6043\n",
      "Val Loss: 32590718.4095, MAE: 4751.7319, NMAE: 72.4441, R^2: 0.1084\n",
      "Epoch [1883/2000]\n",
      "Train Loss: 26830301.2457\n",
      "Val Loss: 32891648.8241, MAE: 4762.5762, NMAE: 72.6094, R^2: 0.1002\n",
      "Epoch [1884/2000]\n",
      "Train Loss: 26341733.4125\n",
      "Val Loss: 32531953.2179, MAE: 4695.1807, NMAE: 71.5819, R^2: 0.1100\n",
      "Epoch [1885/2000]\n",
      "Train Loss: 25679104.6931\n",
      "Val Loss: 33484430.8558, MAE: 4830.1099, NMAE: 73.6390, R^2: 0.0840\n",
      "Epoch [1886/2000]\n",
      "Train Loss: 27583574.4909\n",
      "Val Loss: 32501035.0885, MAE: 4754.3086, NMAE: 72.4833, R^2: 0.1109\n",
      "Epoch [1887/2000]\n",
      "Train Loss: 26707732.3922\n",
      "Val Loss: 33251734.1269, MAE: 4811.8179, NMAE: 73.3601, R^2: 0.0903\n",
      "Epoch [1888/2000]\n",
      "Train Loss: 26274938.6233\n",
      "Val Loss: 32806475.9687, MAE: 4807.5337, NMAE: 73.2948, R^2: 0.1025\n",
      "Epoch [1889/2000]\n",
      "Train Loss: 25718455.8336\n",
      "Val Loss: 34791319.3150, MAE: 4986.1592, NMAE: 76.0181, R^2: 0.0482\n",
      "Epoch [1890/2000]\n",
      "Train Loss: 26825504.9216\n",
      "Val Loss: 33913528.8547, MAE: 4875.8813, NMAE: 74.3368, R^2: 0.0722\n",
      "Epoch [1891/2000]\n",
      "Train Loss: 26746928.9237\n",
      "Val Loss: 33629061.0756, MAE: 4853.5654, NMAE: 73.9966, R^2: 0.0800\n",
      "Epoch [1892/2000]\n",
      "Train Loss: 26813972.3698\n",
      "Val Loss: 33161738.4282, MAE: 4813.5776, NMAE: 73.3869, R^2: 0.0928\n",
      "Epoch [1893/2000]\n",
      "Train Loss: 25895697.4784\n",
      "Val Loss: 33293629.2968, MAE: 4872.6812, NMAE: 74.2880, R^2: 0.0892\n",
      "Epoch [1894/2000]\n",
      "Train Loss: 25930468.6414\n",
      "Val Loss: 32592546.6920, MAE: 4742.2778, NMAE: 72.2999, R^2: 0.1084\n",
      "Epoch [1895/2000]\n",
      "Train Loss: 26002546.5612\n",
      "Val Loss: 33697259.2157, MAE: 4909.5088, NMAE: 74.8495, R^2: 0.0782\n",
      "Epoch [1896/2000]\n",
      "Train Loss: 26611169.9466\n",
      "Val Loss: 33604488.0293, MAE: 4902.3223, NMAE: 74.7399, R^2: 0.0807\n",
      "Epoch [1897/2000]\n",
      "Train Loss: 26517205.4931\n",
      "Val Loss: 33620064.8424, MAE: 4838.5063, NMAE: 73.7670, R^2: 0.0803\n",
      "Epoch [1898/2000]\n",
      "Train Loss: 26933431.1716\n",
      "Val Loss: 33681448.3700, MAE: 4898.5718, NMAE: 74.6827, R^2: 0.0786\n",
      "Epoch [1899/2000]\n",
      "Train Loss: 27597578.1332\n",
      "Val Loss: 31570366.2023, MAE: 4659.7056, NMAE: 71.0410, R^2: 0.1363\n",
      "Epoch [1900/2000]\n",
      "Train Loss: 26748435.1888\n",
      "Val Loss: 33108272.4227, MAE: 4849.0801, NMAE: 73.9282, R^2: 0.0943\n",
      "Epoch [1901/2000]\n",
      "Train Loss: 26316381.7112\n",
      "Val Loss: 34946249.1916, MAE: 4982.2241, NMAE: 75.9581, R^2: 0.0440\n",
      "Epoch [1902/2000]\n",
      "Train Loss: 27047703.4694\n",
      "Val Loss: 34283429.0022, MAE: 5011.5747, NMAE: 76.4056, R^2: 0.0621\n",
      "Epoch [1903/2000]\n",
      "Train Loss: 26892895.0534\n",
      "Val Loss: 34238295.2358, MAE: 4946.7617, NMAE: 75.4174, R^2: 0.0634\n",
      "Epoch [1904/2000]\n",
      "Train Loss: 26172395.3142\n",
      "Val Loss: 33963630.9427, MAE: 4869.9150, NMAE: 74.2459, R^2: 0.0709\n",
      "Epoch [1905/2000]\n",
      "Train Loss: 25739652.8931\n",
      "Val Loss: 33527358.2242, MAE: 4822.7710, NMAE: 73.5271, R^2: 0.0828\n",
      "Epoch [1906/2000]\n",
      "Train Loss: 25745603.8332\n",
      "Val Loss: 33392480.7768, MAE: 4852.9224, NMAE: 73.9868, R^2: 0.0865\n",
      "Epoch [1907/2000]\n",
      "Train Loss: 26576264.8978\n",
      "Val Loss: 33032606.0417, MAE: 4809.8833, NMAE: 73.3306, R^2: 0.0963\n",
      "Epoch [1908/2000]\n",
      "Train Loss: 26281649.8948\n",
      "Val Loss: 33142403.5707, MAE: 4860.9688, NMAE: 74.1095, R^2: 0.0933\n",
      "Epoch [1909/2000]\n",
      "Train Loss: 27034894.9638\n",
      "Val Loss: 35213582.6407, MAE: 5038.9526, NMAE: 76.8230, R^2: 0.0367\n",
      "Epoch [1910/2000]\n",
      "Train Loss: 27305798.3280\n",
      "Val Loss: 33092947.5341, MAE: 4856.0791, NMAE: 74.0349, R^2: 0.0947\n",
      "Epoch [1911/2000]\n",
      "Train Loss: 26620460.5332\n",
      "Val Loss: 33808853.6823, MAE: 4904.9688, NMAE: 74.7803, R^2: 0.0751\n",
      "Epoch [1912/2000]\n",
      "Train Loss: 26754083.3060\n",
      "Val Loss: 33607116.7298, MAE: 4860.7534, NMAE: 74.1062, R^2: 0.0806\n",
      "Epoch [1913/2000]\n",
      "Train Loss: 26553804.3517\n",
      "Val Loss: 32678404.8219, MAE: 4770.7095, NMAE: 72.7334, R^2: 0.1060\n",
      "Epoch [1914/2000]\n",
      "Train Loss: 26008665.5522\n",
      "Val Loss: 33625532.0230, MAE: 4881.4780, NMAE: 74.4221, R^2: 0.0801\n",
      "Epoch [1915/2000]\n",
      "Train Loss: 26377258.2591\n",
      "Val Loss: 33527375.2911, MAE: 4820.4858, NMAE: 73.4923, R^2: 0.0828\n",
      "Epoch [1916/2000]\n",
      "Train Loss: 26767827.8427\n",
      "Val Loss: 33935571.9822, MAE: 4854.7080, NMAE: 74.0140, R^2: 0.0716\n",
      "Epoch [1917/2000]\n",
      "Train Loss: 26838634.7047\n",
      "Val Loss: 33945653.8110, MAE: 4894.9604, NMAE: 74.6277, R^2: 0.0714\n",
      "Epoch [1918/2000]\n",
      "Train Loss: 27109843.6746\n",
      "Val Loss: 34180758.5274, MAE: 4907.9150, NMAE: 74.8252, R^2: 0.0649\n",
      "Epoch [1919/2000]\n",
      "Train Loss: 26743804.4879\n",
      "Val Loss: 33777391.8000, MAE: 4862.3530, NMAE: 74.1306, R^2: 0.0760\n",
      "Epoch [1920/2000]\n",
      "Train Loss: 26301462.2190\n",
      "Val Loss: 34171330.8263, MAE: 4912.3662, NMAE: 74.8931, R^2: 0.0652\n",
      "Epoch [1921/2000]\n",
      "Train Loss: 26024773.7422\n",
      "Val Loss: 34908456.2445, MAE: 5003.8472, NMAE: 76.2878, R^2: 0.0450\n",
      "Epoch [1922/2000]\n",
      "Train Loss: 26727342.4879\n",
      "Val Loss: 33529192.1422, MAE: 4887.7266, NMAE: 74.5174, R^2: 0.0828\n",
      "Epoch [1923/2000]\n",
      "Train Loss: 26115120.8966\n",
      "Val Loss: 34832183.5283, MAE: 4998.6880, NMAE: 76.2091, R^2: 0.0471\n",
      "Epoch [1924/2000]\n",
      "Train Loss: 26723024.3164\n",
      "Val Loss: 33653302.5410, MAE: 4839.7847, NMAE: 73.7865, R^2: 0.0794\n",
      "Epoch [1925/2000]\n",
      "Train Loss: 25910650.5659\n",
      "Val Loss: 33751605.2543, MAE: 4875.6514, NMAE: 74.3333, R^2: 0.0767\n",
      "Epoch [1926/2000]\n",
      "Train Loss: 26116328.2931\n",
      "Val Loss: 34291247.7802, MAE: 4887.0303, NMAE: 74.5068, R^2: 0.0619\n",
      "Epoch [1927/2000]\n",
      "Train Loss: 25661646.7784\n",
      "Val Loss: 33886938.4629, MAE: 4800.1406, NMAE: 73.1821, R^2: 0.0730\n",
      "Epoch [1928/2000]\n",
      "Train Loss: 25788827.5341\n",
      "Val Loss: 33730657.4160, MAE: 4821.6543, NMAE: 73.5101, R^2: 0.0772\n",
      "Epoch [1929/2000]\n",
      "Train Loss: 25186830.8435\n",
      "Val Loss: 33791250.0263, MAE: 4891.6992, NMAE: 74.5780, R^2: 0.0756\n",
      "Epoch [1930/2000]\n",
      "Train Loss: 25362839.2845\n",
      "Val Loss: 33723394.3905, MAE: 4868.6289, NMAE: 74.2262, R^2: 0.0774\n",
      "Epoch [1931/2000]\n",
      "Train Loss: 24842303.9517\n",
      "Val Loss: 34115982.1717, MAE: 4867.7974, NMAE: 74.2136, R^2: 0.0667\n",
      "Epoch [1932/2000]\n",
      "Train Loss: 25730517.1034\n",
      "Val Loss: 32874039.9720, MAE: 4792.8423, NMAE: 73.0708, R^2: 0.1007\n",
      "Epoch [1933/2000]\n",
      "Train Loss: 25823835.1513\n",
      "Val Loss: 33409309.3420, MAE: 4798.6602, NMAE: 73.1595, R^2: 0.0860\n",
      "Epoch [1934/2000]\n",
      "Train Loss: 26179015.7720\n",
      "Val Loss: 33505367.0417, MAE: 4777.5054, NMAE: 72.8370, R^2: 0.0834\n",
      "Epoch [1935/2000]\n",
      "Train Loss: 25344373.9517\n",
      "Val Loss: 33107634.5233, MAE: 4766.8589, NMAE: 72.6747, R^2: 0.0943\n",
      "Epoch [1936/2000]\n",
      "Train Loss: 25369782.0526\n",
      "Val Loss: 32639773.1561, MAE: 4668.2212, NMAE: 71.1709, R^2: 0.1071\n",
      "Epoch [1937/2000]\n",
      "Train Loss: 28671654.5530\n",
      "Val Loss: 33574348.4948, MAE: 4897.4272, NMAE: 74.6653, R^2: 0.0815\n",
      "Epoch [1938/2000]\n",
      "Train Loss: 29638413.3866\n",
      "Val Loss: 32416016.2320, MAE: 4740.4258, NMAE: 72.2717, R^2: 0.1132\n",
      "Epoch [1939/2000]\n",
      "Train Loss: 28645985.3091\n",
      "Val Loss: 32047517.5805, MAE: 4723.2891, NMAE: 72.0104, R^2: 0.1233\n",
      "Epoch [1940/2000]\n",
      "Train Loss: 28028383.6000\n",
      "Val Loss: 32158286.2893, MAE: 4797.1890, NMAE: 73.1371, R^2: 0.1203\n",
      "Epoch [1941/2000]\n",
      "Train Loss: 27369651.1052\n",
      "Val Loss: 31845575.3579, MAE: 4695.4946, NMAE: 71.5867, R^2: 0.1288\n",
      "Epoch [1942/2000]\n",
      "Train Loss: 26121065.5582\n",
      "Val Loss: 32606900.8389, MAE: 4781.8940, NMAE: 72.9039, R^2: 0.1080\n",
      "Epoch [1943/2000]\n",
      "Train Loss: 26526250.2414\n",
      "Val Loss: 32607565.2161, MAE: 4783.6992, NMAE: 72.9314, R^2: 0.1080\n",
      "Epoch [1944/2000]\n",
      "Train Loss: 25773277.6190\n",
      "Val Loss: 33758646.5350, MAE: 4870.2246, NMAE: 74.2506, R^2: 0.0765\n",
      "Epoch [1945/2000]\n",
      "Train Loss: 26330627.8341\n",
      "Val Loss: 33048643.0548, MAE: 4819.4404, NMAE: 73.4763, R^2: 0.0959\n",
      "Epoch [1946/2000]\n",
      "Train Loss: 25647122.7690\n",
      "Val Loss: 34277580.6351, MAE: 4943.5840, NMAE: 75.3690, R^2: 0.0623\n",
      "Epoch [1947/2000]\n",
      "Train Loss: 29878955.7017\n",
      "Val Loss: 32897529.6891, MAE: 4807.5381, NMAE: 73.2949, R^2: 0.1000\n",
      "Epoch [1948/2000]\n",
      "Train Loss: 28082105.5927\n",
      "Val Loss: 36330182.2880, MAE: 5132.7729, NMAE: 78.2533, R^2: 0.0061\n",
      "Epoch [1949/2000]\n",
      "Train Loss: 28333457.7172\n",
      "Val Loss: 33577761.9491, MAE: 4868.8691, NMAE: 74.2299, R^2: 0.0814\n",
      "Epoch [1950/2000]\n",
      "Train Loss: 28089935.2431\n",
      "Val Loss: 34590658.8117, MAE: 5024.0186, NMAE: 76.5953, R^2: 0.0537\n",
      "Epoch [1951/2000]\n",
      "Train Loss: 28386576.1078\n",
      "Val Loss: 33794746.5456, MAE: 4923.5591, NMAE: 75.0637, R^2: 0.0755\n",
      "Epoch [1952/2000]\n",
      "Train Loss: 27235244.5690\n",
      "Val Loss: 33902672.4806, MAE: 4893.1777, NMAE: 74.6005, R^2: 0.0725\n",
      "Epoch [1953/2000]\n",
      "Train Loss: 27315283.0470\n",
      "Val Loss: 33944530.1731, MAE: 4924.9976, NMAE: 75.0856, R^2: 0.0714\n",
      "Epoch [1954/2000]\n",
      "Train Loss: 27237876.7246\n",
      "Val Loss: 34256481.4329, MAE: 4968.6392, NMAE: 75.7510, R^2: 0.0629\n",
      "Epoch [1955/2000]\n",
      "Train Loss: 26713795.4207\n",
      "Val Loss: 34417257.8830, MAE: 4916.2778, NMAE: 74.9527, R^2: 0.0585\n",
      "Epoch [1956/2000]\n",
      "Train Loss: 26005937.2289\n",
      "Val Loss: 34250386.3331, MAE: 4869.9717, NMAE: 74.2467, R^2: 0.0630\n",
      "Epoch [1957/2000]\n",
      "Train Loss: 25839385.2284\n",
      "Val Loss: 34364509.1684, MAE: 4934.3813, NMAE: 75.2287, R^2: 0.0599\n",
      "Epoch [1958/2000]\n",
      "Train Loss: 25989229.0608\n",
      "Val Loss: 35006972.7351, MAE: 4939.2388, NMAE: 75.3027, R^2: 0.0423\n",
      "Epoch [1959/2000]\n",
      "Train Loss: 26253869.0983\n",
      "Val Loss: 34202746.9904, MAE: 4929.9468, NMAE: 75.1611, R^2: 0.0643\n",
      "Epoch [1960/2000]\n",
      "Train Loss: 27513604.9974\n",
      "Val Loss: 34065953.1557, MAE: 4915.9780, NMAE: 74.9481, R^2: 0.0681\n",
      "Epoch [1961/2000]\n",
      "Train Loss: 26583649.3603\n",
      "Val Loss: 34291240.6058, MAE: 4925.7456, NMAE: 75.0970, R^2: 0.0619\n",
      "Epoch [1962/2000]\n",
      "Train Loss: 27640207.7250\n",
      "Val Loss: 34358131.7828, MAE: 4923.1431, NMAE: 75.0574, R^2: 0.0601\n",
      "Epoch [1963/2000]\n",
      "Train Loss: 26103859.3349\n",
      "Val Loss: 34323310.0803, MAE: 4924.0405, NMAE: 75.0710, R^2: 0.0610\n",
      "Epoch [1964/2000]\n",
      "Train Loss: 26528369.8422\n",
      "Val Loss: 33837444.8994, MAE: 4903.8223, NMAE: 74.7628, R^2: 0.0743\n",
      "Epoch [1965/2000]\n",
      "Train Loss: 26178699.3642\n",
      "Val Loss: 32709034.2934, MAE: 4762.6973, NMAE: 72.6112, R^2: 0.1052\n",
      "Epoch [1966/2000]\n",
      "Train Loss: 25624725.8483\n",
      "Val Loss: 33817591.0307, MAE: 4889.7690, NMAE: 74.5485, R^2: 0.0749\n",
      "Epoch [1967/2000]\n",
      "Train Loss: 25584042.0978\n",
      "Val Loss: 33897497.0607, MAE: 4819.2319, NMAE: 73.4731, R^2: 0.0727\n",
      "Epoch [1968/2000]\n",
      "Train Loss: 25466849.2401\n",
      "Val Loss: 33585079.4119, MAE: 4830.8613, NMAE: 73.6504, R^2: 0.0812\n",
      "Epoch [1969/2000]\n",
      "Train Loss: 27173413.1388\n",
      "Val Loss: 34033951.0542, MAE: 4884.0625, NMAE: 74.4615, R^2: 0.0690\n",
      "Epoch [1970/2000]\n",
      "Train Loss: 29606785.3733\n",
      "Val Loss: 33788929.0851, MAE: 4832.0728, NMAE: 73.6689, R^2: 0.0757\n",
      "Epoch [1971/2000]\n",
      "Train Loss: 29396883.0362\n",
      "Val Loss: 32664108.3126, MAE: 4753.0762, NMAE: 72.4645, R^2: 0.1064\n",
      "Epoch [1972/2000]\n",
      "Train Loss: 28860063.9241\n",
      "Val Loss: 33556224.8469, MAE: 4837.3169, NMAE: 73.7489, R^2: 0.0820\n",
      "Epoch [1973/2000]\n",
      "Train Loss: 28909839.1534\n",
      "Val Loss: 33227326.4005, MAE: 4796.0527, NMAE: 73.1198, R^2: 0.0910\n",
      "Epoch [1974/2000]\n",
      "Train Loss: 28160143.2690\n",
      "Val Loss: 32758358.4396, MAE: 4749.9390, NMAE: 72.4167, R^2: 0.1038\n",
      "Epoch [1975/2000]\n",
      "Train Loss: 27177017.1095\n",
      "Val Loss: 33428708.5650, MAE: 4879.3315, NMAE: 74.3894, R^2: 0.0855\n",
      "Epoch [1976/2000]\n",
      "Train Loss: 28012420.9948\n",
      "Val Loss: 33786066.1675, MAE: 4824.2910, NMAE: 73.5503, R^2: 0.0757\n",
      "Epoch [1977/2000]\n",
      "Train Loss: 27920199.1655\n",
      "Val Loss: 34026014.6097, MAE: 4886.5884, NMAE: 74.5000, R^2: 0.0692\n",
      "Epoch [1978/2000]\n",
      "Train Loss: 27442952.9733\n",
      "Val Loss: 33389451.7807, MAE: 4855.4165, NMAE: 74.0248, R^2: 0.0866\n",
      "Epoch [1979/2000]\n",
      "Train Loss: 28081832.1741\n",
      "Val Loss: 32922422.7811, MAE: 4781.1675, NMAE: 72.8928, R^2: 0.0994\n",
      "Epoch [1980/2000]\n",
      "Train Loss: 28198074.1750\n",
      "Val Loss: 33291932.0060, MAE: 4907.1621, NMAE: 74.8137, R^2: 0.0892\n",
      "Epoch [1981/2000]\n",
      "Train Loss: 27698691.9966\n",
      "Val Loss: 33795102.9806, MAE: 4931.0239, NMAE: 75.1775, R^2: 0.0755\n",
      "Epoch [1982/2000]\n",
      "Train Loss: 27934763.0776\n",
      "Val Loss: 32102511.3474, MAE: 4732.3887, NMAE: 72.1491, R^2: 0.1218\n",
      "Epoch [1983/2000]\n",
      "Train Loss: 27266336.6052\n",
      "Val Loss: 34279528.9100, MAE: 4881.3418, NMAE: 74.4201, R^2: 0.0622\n",
      "Epoch [1984/2000]\n",
      "Train Loss: 27961698.5612\n",
      "Val Loss: 33378341.0738, MAE: 4872.3984, NMAE: 74.2837, R^2: 0.0869\n",
      "Epoch [1985/2000]\n",
      "Train Loss: 28329064.9060\n",
      "Val Loss: 34304998.0047, MAE: 4978.7578, NMAE: 75.9052, R^2: 0.0615\n",
      "Epoch [1986/2000]\n",
      "Train Loss: 27461930.8897\n",
      "Val Loss: 32731402.4845, MAE: 4801.7764, NMAE: 73.2070, R^2: 0.1046\n",
      "Epoch [1987/2000]\n",
      "Train Loss: 27492350.4017\n",
      "Val Loss: 34299687.6915, MAE: 4912.3481, NMAE: 74.8928, R^2: 0.0617\n",
      "Epoch [1988/2000]\n",
      "Train Loss: 27941768.5534\n",
      "Val Loss: 33329117.5554, MAE: 4800.7158, NMAE: 73.1909, R^2: 0.0882\n",
      "Epoch [1989/2000]\n",
      "Train Loss: 28800894.3621\n",
      "Val Loss: 33301129.5939, MAE: 4773.2788, NMAE: 72.7726, R^2: 0.0890\n",
      "Epoch [1990/2000]\n",
      "Train Loss: 28504668.8888\n",
      "Val Loss: 31799627.8849, MAE: 4662.0566, NMAE: 71.0769, R^2: 0.1301\n",
      "Epoch [1991/2000]\n",
      "Train Loss: 27837661.6767\n",
      "Val Loss: 32273933.9585, MAE: 4754.8438, NMAE: 72.4915, R^2: 0.1171\n",
      "Epoch [1992/2000]\n",
      "Train Loss: 28323544.3009\n",
      "Val Loss: 33193387.1071, MAE: 4849.1445, NMAE: 73.9292, R^2: 0.0919\n",
      "Epoch [1993/2000]\n",
      "Train Loss: 28079186.5698\n",
      "Val Loss: 32877354.5380, MAE: 4846.8799, NMAE: 73.8947, R^2: 0.1006\n",
      "Epoch [1994/2000]\n",
      "Train Loss: 28118857.7112\n",
      "Val Loss: 32459819.4542, MAE: 4777.1597, NMAE: 72.8317, R^2: 0.1120\n",
      "Epoch [1995/2000]\n",
      "Train Loss: 27542824.1095\n",
      "Val Loss: 33169955.1826, MAE: 4858.6274, NMAE: 74.0738, R^2: 0.0926\n",
      "Epoch [1996/2000]\n",
      "Train Loss: 27211395.8207\n",
      "Val Loss: 32136446.1546, MAE: 4671.5850, NMAE: 71.2221, R^2: 0.1209\n",
      "Epoch [1997/2000]\n",
      "Train Loss: 31285905.3595\n",
      "Val Loss: 33463261.5842, MAE: 4754.6084, NMAE: 72.4879, R^2: 0.0846\n",
      "Epoch [1998/2000]\n",
      "Train Loss: 28947784.9043\n",
      "Val Loss: 33079133.6995, MAE: 4815.5610, NMAE: 73.4172, R^2: 0.0951\n",
      "Epoch [1999/2000]\n",
      "Train Loss: 27736961.1086\n",
      "Val Loss: 32680337.8294, MAE: 4783.8813, NMAE: 72.9342, R^2: 0.1060\n",
      "Epoch [2000/2000]\n",
      "Train Loss: 27008555.4017\n",
      "Val Loss: 32082316.3890, MAE: 4744.0020, NMAE: 72.3262, R^2: 0.1223\n",
      "Final Model saved with best validation loss: 18183440813.1250\n",
      "MAE: 4744.0020, NMAE: 72.3262, R^2: 0.1223\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gru_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m lstm_model \u001b[38;5;241m=\u001b[39m GRU(input_dim\u001b[38;5;241m=\u001b[39mx_train_m_selected\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n\u001b[1;32m     20\u001b[0m save_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(ipynb_path, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnotebooks/test_basicRecurrent/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_GRU_m/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m train_model(save_dir, \u001b[43mgru_model\u001b[49m, x_train_m_selected, y_train, x_test_m_selected, y_test,\u001b[38;5;241m2000\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# ====================\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# z-정규화 데이터\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# ====================\u001b[39;00m\n\u001b[1;32m     26\u001b[0m x_train_z_selected \u001b[38;5;241m=\u001b[39m x_train_z[x_dict[key]]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gru_model' is not defined"
     ]
    }
   ],
   "source": [
    "for key in x_dict.keys():\n",
    "    # ====================\n",
    "    # Min-Max 정규화 데이터\n",
    "    # ====================\n",
    "    x_train_m_selected = x_train_m[x_dict[key]]\n",
    "    x_test_m_selected = x_test_m[x_dict[key]]\n",
    "\n",
    "    # RNN 모델 학습\n",
    "    rnn_model = RNN(input_dim=x_train_m_selected.shape[1], hidden_dim=128)\n",
    "    save_dir = os.path.join(ipynb_path, f'notebooks/test_basicRecurrent/{key}_RNN_m/')\n",
    "    train_model(save_dir, rnn_model, x_train_m_selected, y_train, x_test_m_selected, y_test,2000)\n",
    "\n",
    "    # LSTM 모델 학습\n",
    "    lstm_model = LSTM(input_dim=x_train_m_selected.shape[1], hidden_dim=128)\n",
    "    save_dir = os.path.join(ipynb_path, f'notebooks/test_basicRecurrent/{key}_LSTM_m/')\n",
    "    train_model(save_dir, lstm_model, x_train_m_selected, y_train, x_test_m_selected, y_test,2000)\n",
    "\n",
    "    # GRU 모델 학습\n",
    "    lstm_model = GRU(input_dim=x_train_m_selected.shape[1], hidden_dim=128)\n",
    "    save_dir = os.path.join(ipynb_path, f'notebooks/test_basicRecurrent/{key}_GRU_m/')\n",
    "    train_model(save_dir, gru_model, x_train_m_selected, y_train, x_test_m_selected, y_test,2000)\n",
    "\n",
    "    # ====================\n",
    "    # z-정규화 데이터\n",
    "    # ====================\n",
    "    x_train_z_selected = x_train_z[x_dict[key]]\n",
    "    x_test_z_selected = x_test_z[x_dict[key]]\n",
    "\n",
    "    # RNN 모델 학습\n",
    "    rnn_model = RNN(input_dim=x_train_z_selected.shape[1], hidden_dim=128)\n",
    "    save_dir = os.path.join(ipynb_path, f'notebooks/test_basicRecurrent/{key}_RNN_z/')\n",
    "    train_model(save_dir, rnn_model, x_train_z_selected, y_train, x_test_z_selected, y_test,2000)\n",
    "\n",
    "    # LSTM 모델 학습\n",
    "    lstm_model = LSTM(input_dim=x_train_z_selected.shape[1], hidden_dim=128)\n",
    "    save_dir = os.path.join(ipynb_path, f'notebooks/test_basicRecurrent/{key}_LSTM_z/')\n",
    "    train_model(save_dir, lstm_model, x_train_z_selected, y_train, x_test_z_selected, y_test,2000)\n",
    "\n",
    "    # GRU 모델 학습\n",
    "    gru_model = GRU(input_dim=x_train_z_selected.shape[1], hidden_dim=128)\n",
    "    save_dir = os.path.join(ipynb_path, f'notebooks/test_basicRecurrent/{key}_GRU_z/')\n",
    "    train_model(save_dir, gru_model, x_train_z_selected, y_train, x_test_z_selected, y_test,2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
