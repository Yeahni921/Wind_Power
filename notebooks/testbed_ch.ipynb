{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# 아래는 우분투일때\n",
    "# ipynb_path = os.getcwd()\n",
    "# src_path = os.path.join(ipynb_path, '../src/')\n",
    "# input_path = os.path.join(\"../input/\")\n",
    "\n",
    "ipynb_path = 'C:/Users/User/Documents/Wind_Power/notebooks'\n",
    "src_path = 'C:/Users/User/Documents/Wind_Power/src'\n",
    "input_path = \"C:/Users/User/Documents/Wind_Power/input/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: windpowerlib in c:\\users\\user\\anaconda3\\lib\\site-packages (0.2.1)\n",
      "Requirement already satisfied: pandas>=0.20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from windpowerlib) (2.2.2)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from windpowerlib) (2.32.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas>=0.20.0->windpowerlib) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas>=0.20.0->windpowerlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas>=0.20.0->windpowerlib) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas>=0.20.0->windpowerlib) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->windpowerlib) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->windpowerlib) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->windpowerlib) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->windpowerlib) (2024.7.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=0.20.0->windpowerlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install windpowerlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import scipy.stats as spst\n",
    "\n",
    "sys.path.append(src_path)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from windpowerlib.wind_speed import logarithmic_profile\n",
    "from utils import uv_to_wsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\User'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power:  (155528, 29)\n",
      "train_y:  (52608, 4)\n",
      "LDAPS:  (235818, 15)\n"
     ]
    }
   ],
   "source": [
    "power_2020 = pd.read_parquet(input_path + \"dynamic_report_ewp02_2020_10min.parquet\").rename({'Date/Time': 'dt', 'WTG.Name': 'turbine_id'}, axis=1)[:-3]\n",
    "power_2021 = pd.read_parquet(input_path + \"dynamic_report_ewp02_2021_10min.parquet\").rename({'Date/Time': 'dt', 'WTG.Name': 'turbine_id'}, axis=1)[:-3]\n",
    "power_2022 = pd.read_parquet(input_path + \"dynamic_report_ewp02_2022_10min.parquet\").rename({'Date/Time': 'dt', 'WTG.Name': 'turbine_id'}, axis=1)[:-3]\n",
    "power = pd.concat([power_2020, power_2021, power_2022], ignore_index=True)\n",
    "\n",
    "gj_y = pd.read_parquet(input_path + \"train_y.parquet\").rename({'end_datetime': 'dt'}, axis=1)\n",
    "ldaps = pd.read_parquet(input_path + \"train_ldaps_gyeongju.parquet\")\n",
    "\n",
    "print(\"Power: \", power.shape)\n",
    "print(\"train_y: \", gj_y.shape)\n",
    "print(\"LDAPS: \", ldaps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power:  (155528, 29) 2020-01-01 00:00:00+09:00 2022-12-31 23:50:00+09:00\n",
      "train_y:  (26279, 4) 2020-01-01 01:00:00+09:00 2022-12-30 23:00:00+09:00\n",
      "LDAPS:  (235602, 15) 2020-01-02 00:00:00+09:00 2022-12-30 23:00:00+09:00\n"
     ]
    }
   ],
   "source": [
    "datas = [power, gj_y, ldaps]\n",
    "for d in datas:\n",
    "    try:\n",
    "        d['dt'] = (pd.to_datetime(d['dt'])\n",
    "                    .dt\n",
    "                    .tz_convert(\"Asia/Seoul\"))\n",
    "    except TypeError:\n",
    "        d['dt'] = (pd.to_datetime(d['dt'])\n",
    "                    .dt\n",
    "                    .tz_localize(\"Asia/Seoul\"))\n",
    "\n",
    "gj_y = (gj_y.loc[(gj_y['plant_name'] == \"경주풍력\")\n",
    "                 & (gj_y['dt']).between('2020-01-01', '2022-12-31', inclusive='left')])\n",
    "\n",
    "ldaps = ldaps.loc[ldaps['dt'].between('2020-01-01', '2022-12-31', inclusive='left')]\n",
    "\n",
    "print(\"Power: \", power.shape, power['dt'].min(), power['dt'].max())\n",
    "print(\"train_y: \", gj_y.shape, gj_y['dt'].min(), gj_y['dt'].max())\n",
    "print(\"LDAPS: \", ldaps.shape, ldaps['dt'].min(), ldaps['dt'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23468\\85188720.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ldaps[\"wind_speed\"], ldaps[\"wind_direction\"] = uv_to_wsd(\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23468\\85188720.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ldaps[\"wind_speed\"], ldaps[\"wind_direction\"] = uv_to_wsd(\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23468\\85188720.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ldaps[\"wind_speed_100m\"] = logarithmic_profile(ldaps[\"wind_speed\"], 10, 100, 0.3)\n"
     ]
    }
   ],
   "source": [
    "# add wind speed in 100m feature\n",
    "ldaps[\"wind_speed\"], ldaps[\"wind_direction\"] = uv_to_wsd(\n",
    "    ldaps[\"wind_u_10m\"], ldaps[\"wind_v_10m\"]\n",
    ")\n",
    "\n",
    "ldaps[\"wind_speed_100m\"] = logarithmic_profile(ldaps[\"wind_speed\"], 10, 100, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['dt', 'elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m',\n",
      "       'frictional_vmin_50m', 'pressure', 'relative_humid', 'specific_humid',\n",
      "       'temp_air', 'storm_u_5m', 'storm_v_5m', 'wind_u_10m', 'wind_v_10m',\n",
      "       'turbine_id', 'wind_speed', 'wind_direction', 'wind_speed_100m'],\n",
      "      dtype='object')\n",
      "Index(['dt', 'turbine_id', 'WTG.Serial', 'AvailabilityForcedOutageTime[Min.]',\n",
      "       'AvailabilityFullPerformanceTime[Min.]',\n",
      "       'AvailabilityRequestedShutdownTime[Min.]',\n",
      "       'AvailabilityScheduledMaintenanceTime[Min.]',\n",
      "       'AvailabilityTechnicalStandbyTime[Min.]',\n",
      "       'EnergyProductionActiveEnergyProduction[KWh]',\n",
      "       'GeneratorAverageWindingTemp.[℃]', 'GridActivePower[kW]',\n",
      "       'GridReactivePower[kVAr]', 'HydraulicSystemPressure[bar]',\n",
      "       'NacelleAirDensity[kg/㎥]', 'NacelleNacellePosition[deg]',\n",
      "       'NacelleOutdoorTemp[℃]', 'NacelleWindDirection[deg]',\n",
      "       'NacelleWindSpeed[m/s]', 'RotorBlade1Pos.[deg]', 'RotorBlade2Pos.[deg]',\n",
      "       'RotorBlade3Pos.[deg]', 'RotorMotor1Pos.[deg]', 'RotorMotor2Pos.[deg]',\n",
      "       'RotorMotor3Pos.[deg]', 'RotorPitch1Angle[deg]',\n",
      "       'RotorPitch2Angle[deg]', 'RotorPitch3Angle[deg]',\n",
      "       'RotorRotorSpeed[rpm]', 'YawYawcablewindup[deg]'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(ldaps.columns)\n",
    "print(power.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23468\\2284999207.py:1: FutureWarning: DataFrame.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  power.interpolate(method='linear', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "power.interpolate(method='linear', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17927568.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power['EnergyProductionActiveEnergyProduction[KWh]'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23468\\1740558130.py:3: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  power_h = power.resample('H', on='dt').sum()\n"
     ]
    }
   ],
   "source": [
    "power_h = power[['dt', 'EnergyProductionActiveEnergyProduction[KWh]']]\n",
    "\n",
    "power_h = power.resample('H', on='dt').sum() # tlr\n",
    "\n",
    "# print(df_hourly.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17927568.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power_h['EnergyProductionActiveEnergyProduction[KWh]'].sum() # 시간당 발전량의 발전소 단위 평균과 얼추 비슷한 단위가 나옴. \n",
    "# 그러므로 sum을 label로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtg1_df = pd.merge(ldaps, power_h, on = ['dt'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>elevation</th>\n",
       "      <th>land_cover</th>\n",
       "      <th>surf_rough</th>\n",
       "      <th>frictional_vmax_50m</th>\n",
       "      <th>frictional_vmin_50m</th>\n",
       "      <th>pressure</th>\n",
       "      <th>relative_humid</th>\n",
       "      <th>specific_humid</th>\n",
       "      <th>temp_air</th>\n",
       "      <th>...</th>\n",
       "      <th>RotorBlade3Pos.[deg]</th>\n",
       "      <th>RotorMotor1Pos.[deg]</th>\n",
       "      <th>RotorMotor2Pos.[deg]</th>\n",
       "      <th>RotorMotor3Pos.[deg]</th>\n",
       "      <th>RotorPitch1Angle[deg]</th>\n",
       "      <th>RotorPitch2Angle[deg]</th>\n",
       "      <th>RotorPitch3Angle[deg]</th>\n",
       "      <th>RotorRotorSpeed[rpm]</th>\n",
       "      <th>YawYawcablewindup[deg]</th>\n",
       "      <th>Day_Night</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02 00:00:00+09:00</td>\n",
       "      <td>387.640625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.286911</td>\n",
       "      <td>10.428498</td>\n",
       "      <td>10.059580</td>\n",
       "      <td>97974.593750</td>\n",
       "      <td>91.796478</td>\n",
       "      <td>0.002686</td>\n",
       "      <td>269.467560</td>\n",
       "      <td>...</td>\n",
       "      <td>88.277039</td>\n",
       "      <td>87.729630</td>\n",
       "      <td>87.727097</td>\n",
       "      <td>87.727165</td>\n",
       "      <td>87.728065</td>\n",
       "      <td>87.730698</td>\n",
       "      <td>87.728134</td>\n",
       "      <td>80.915436</td>\n",
       "      <td>2299.693115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02 01:00:00+09:00</td>\n",
       "      <td>387.640625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.286911</td>\n",
       "      <td>10.472921</td>\n",
       "      <td>10.044404</td>\n",
       "      <td>97970.132812</td>\n",
       "      <td>91.729774</td>\n",
       "      <td>0.002686</td>\n",
       "      <td>269.430847</td>\n",
       "      <td>...</td>\n",
       "      <td>75.720596</td>\n",
       "      <td>75.119034</td>\n",
       "      <td>75.120232</td>\n",
       "      <td>75.119667</td>\n",
       "      <td>75.118935</td>\n",
       "      <td>75.121033</td>\n",
       "      <td>75.119667</td>\n",
       "      <td>80.925980</td>\n",
       "      <td>2304.814941</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-02 02:00:00+09:00</td>\n",
       "      <td>387.640625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.286911</td>\n",
       "      <td>10.682985</td>\n",
       "      <td>10.478634</td>\n",
       "      <td>97951.546875</td>\n",
       "      <td>92.788666</td>\n",
       "      <td>0.002686</td>\n",
       "      <td>269.374390</td>\n",
       "      <td>...</td>\n",
       "      <td>75.713768</td>\n",
       "      <td>75.044365</td>\n",
       "      <td>75.045097</td>\n",
       "      <td>75.045631</td>\n",
       "      <td>75.044403</td>\n",
       "      <td>75.045067</td>\n",
       "      <td>75.045631</td>\n",
       "      <td>80.982483</td>\n",
       "      <td>2304.814941</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-02 03:00:00+09:00</td>\n",
       "      <td>387.640625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.286911</td>\n",
       "      <td>10.676681</td>\n",
       "      <td>10.090029</td>\n",
       "      <td>97908.968750</td>\n",
       "      <td>92.494576</td>\n",
       "      <td>0.002686</td>\n",
       "      <td>269.352112</td>\n",
       "      <td>...</td>\n",
       "      <td>91.202034</td>\n",
       "      <td>90.510536</td>\n",
       "      <td>90.510330</td>\n",
       "      <td>90.509796</td>\n",
       "      <td>90.511368</td>\n",
       "      <td>90.511604</td>\n",
       "      <td>90.510834</td>\n",
       "      <td>80.949768</td>\n",
       "      <td>2304.814941</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-02 04:00:00+09:00</td>\n",
       "      <td>387.640625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.286911</td>\n",
       "      <td>10.079557</td>\n",
       "      <td>9.672620</td>\n",
       "      <td>97858.398438</td>\n",
       "      <td>88.986443</td>\n",
       "      <td>0.002686</td>\n",
       "      <td>269.413269</td>\n",
       "      <td>...</td>\n",
       "      <td>48.426533</td>\n",
       "      <td>47.839668</td>\n",
       "      <td>47.839432</td>\n",
       "      <td>47.840401</td>\n",
       "      <td>47.839668</td>\n",
       "      <td>47.839401</td>\n",
       "      <td>47.840401</td>\n",
       "      <td>80.988869</td>\n",
       "      <td>2288.006348</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         dt   elevation  land_cover  surf_rough  \\\n",
       "0 2020-01-02 00:00:00+09:00  387.640625         1.0    0.286911   \n",
       "1 2020-01-02 01:00:00+09:00  387.640625         1.0    0.286911   \n",
       "2 2020-01-02 02:00:00+09:00  387.640625         1.0    0.286911   \n",
       "3 2020-01-02 03:00:00+09:00  387.640625         1.0    0.286911   \n",
       "4 2020-01-02 04:00:00+09:00  387.640625         1.0    0.286911   \n",
       "\n",
       "   frictional_vmax_50m  frictional_vmin_50m      pressure  relative_humid  \\\n",
       "0            10.428498            10.059580  97974.593750       91.796478   \n",
       "1            10.472921            10.044404  97970.132812       91.729774   \n",
       "2            10.682985            10.478634  97951.546875       92.788666   \n",
       "3            10.676681            10.090029  97908.968750       92.494576   \n",
       "4            10.079557             9.672620  97858.398438       88.986443   \n",
       "\n",
       "   specific_humid    temp_air  ...  RotorBlade3Pos.[deg]  \\\n",
       "0        0.002686  269.467560  ...             88.277039   \n",
       "1        0.002686  269.430847  ...             75.720596   \n",
       "2        0.002686  269.374390  ...             75.713768   \n",
       "3        0.002686  269.352112  ...             91.202034   \n",
       "4        0.002686  269.413269  ...             48.426533   \n",
       "\n",
       "   RotorMotor1Pos.[deg]  RotorMotor2Pos.[deg]  RotorMotor3Pos.[deg]  \\\n",
       "0             87.729630             87.727097             87.727165   \n",
       "1             75.119034             75.120232             75.119667   \n",
       "2             75.044365             75.045097             75.045631   \n",
       "3             90.510536             90.510330             90.509796   \n",
       "4             47.839668             47.839432             47.840401   \n",
       "\n",
       "  RotorPitch1Angle[deg]  RotorPitch2Angle[deg]  RotorPitch3Angle[deg]  \\\n",
       "0             87.728065              87.730698              87.728134   \n",
       "1             75.118935              75.121033              75.119667   \n",
       "2             75.044403              75.045067              75.045631   \n",
       "3             90.511368              90.511604              90.510834   \n",
       "4             47.839668              47.839401              47.840401   \n",
       "\n",
       "   RotorRotorSpeed[rpm] YawYawcablewindup[deg] Day_Night  \n",
       "0             80.915436            2299.693115         1  \n",
       "1             80.925980            2304.814941         1  \n",
       "2             80.982483            2304.814941         1  \n",
       "3             80.949768            2304.814941         1  \n",
       "4             80.988869            2288.006348         1  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from astral import LocationInfo\n",
    "from astral.sun import sun\n",
    "import pytz\n",
    "\n",
    "location = LocationInfo(\"Seoul\", \"South Korea\", \"Asia/Seoul\", 35.72409, 129.3746)\n",
    "\n",
    "# 밤/낮 feature 추가\n",
    "\n",
    "def is_day_or_night(dt):\n",
    "    if dt.tzinfo is not None:\n",
    "        dt = dt.tz_convert('Asia/Seoul')\n",
    "    else:\n",
    "        dt = dt.tz_localize('Asia/Seoul')\n",
    "    \n",
    "    s = sun(location.observer, date=dt)\n",
    "    sunrise = s['sunrise']\n",
    "    sunset = s['sunset']\n",
    "    \n",
    "    if sunrise < dt < sunset:\n",
    "        return 0  # Day\n",
    "    else:\n",
    "        return 1  # Night\n",
    "\n",
    "wtg1_df['Day_Night'] = wtg1_df['dt'].apply(is_day_or_night)\n",
    "wtg1_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# wtg1_df의 열 이름에서 특수 문자를 '_'로 교체\n",
    "wtg1_df.columns = wtg1_df.columns.str.replace(r'[<>\\[\\]]', '_', regex=True)\n",
    "wtg1_df.columns = wtg1_df.columns.str.replace(r'[^\\w]', '_', regex=True)\n",
    "wtg1_df.columns = wtg1_df.columns.str.replace(r'__+', '_', regex=True)  # '__'를 '_'로 변경\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dt', 'elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m',\n",
       "       'frictional_vmin_50m', 'pressure', 'relative_humid', 'specific_humid',\n",
       "       'temp_air', 'storm_u_5m', 'storm_v_5m', 'wind_u_10m', 'wind_v_10m',\n",
       "       'turbine_id_x', 'wind_speed', 'wind_direction', 'wind_speed_100m',\n",
       "       'turbine_id_y', 'WTG_Serial', 'AvailabilityForcedOutageTime_Min_',\n",
       "       'AvailabilityFullPerformanceTime_Min_',\n",
       "       'AvailabilityRequestedShutdownTime_Min_',\n",
       "       'AvailabilityScheduledMaintenanceTime_Min_',\n",
       "       'AvailabilityTechnicalStandbyTime_Min_',\n",
       "       'EnergyProductionActiveEnergyProduction_KWh_',\n",
       "       'GeneratorAverageWindingTemp_', 'GridActivePower_kW_',\n",
       "       'GridReactivePower_kVAr_', 'HydraulicSystemPressure_bar_',\n",
       "       'NacelleAirDensity_kg_', 'NacelleNacellePosition_deg_',\n",
       "       'NacelleOutdoorTemp_', 'NacelleWindDirection_deg_',\n",
       "       'NacelleWindSpeed_m_s_', 'RotorBlade1Pos_deg_', 'RotorBlade2Pos_deg_',\n",
       "       'RotorBlade3Pos_deg_', 'RotorMotor1Pos_deg_', 'RotorMotor2Pos_deg_',\n",
       "       'RotorMotor3Pos_deg_', 'RotorPitch1Angle_deg_', 'RotorPitch2Angle_deg_',\n",
       "       'RotorPitch3Angle_deg_', 'RotorRotorSpeed_rpm_',\n",
       "       'YawYawcablewindup_deg_', 'Day_Night'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wtg1_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'EnergyProductionActiveEnergyProduction_KWh_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = wtg1_df.select_dtypes(include=['float', 'int']).columns.drop(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = wtg1_df.loc[wtg1_df['dt'].between('2020-01-01', '2020-12-31', inclusive='left'), numeric_columns]\n",
    "x_test = wtg1_df.loc[wtg1_df['dt'].between('2021-01-01', '2022-12-31', inclusive='left'), numeric_columns]\n",
    "\n",
    "y_train = wtg1_df.loc[wtg1_df['dt'].between('2020-01-01', '2020-12-31', inclusive='left'), target].shift(-144)\n",
    "y_test = wtg1_df.loc[wtg1_df['dt'].between('2021-01-01', '2022-12-31', inclusive='left'), target].shift(-144)\n",
    "\n",
    "x_train = x_train.iloc[:-144]\n",
    "y_train = y_train.iloc[:-144]\n",
    "\n",
    "x_test = x_test.iloc[:-144]\n",
    "y_test = y_test.iloc[:-144]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "def get_trasforms_datas():\n",
    "    z_scaler = StandardScaler()\n",
    "    minmax_scaler = MinMaxScaler()\n",
    "    \n",
    "    x_train = wtg1_df.loc[wtg1_df['dt'].between('2020-01-01', '2020-12-31', inclusive='left'), numeric_columns]\n",
    "    x_test = wtg1_df.loc[wtg1_df['dt'].between('2021-01-01', '2022-12-31', inclusive='left'), numeric_columns]\n",
    "\n",
    "    y_train = wtg1_df.loc[wtg1_df['dt'].between('2020-01-01', '2020-12-31', inclusive='left'), target].shift(-144)\n",
    "    y_test = wtg1_df.loc[wtg1_df['dt'].between('2021-01-01', '2022-12-31', inclusive='left'), target].shift(-144)\n",
    "\n",
    "    x_train = x_train.iloc[:-144]\n",
    "    y_train = y_train.iloc[:-144]\n",
    "\n",
    "    x_test = x_test.iloc[:-144]\n",
    "    y_test = y_test.iloc[:-144]\n",
    "\n",
    "    # Min-Max Scaling\n",
    "    x_train_m = minmax_scaler.fit_transform(x_train)\n",
    "    x_train_m = pd.DataFrame(x_train_m, columns=x_train.columns)\n",
    "    x_test_m = minmax_scaler.transform(x_test)\n",
    "    x_test_m = pd.DataFrame(x_test_m, columns=x_train.columns)\n",
    "\n",
    "    # Standard Scaling\n",
    "    x_train_z = z_scaler.fit_transform(x_train)\n",
    "    x_train_z = pd.DataFrame(x_train_z, columns=x_train.columns)\n",
    "    x_test_z = z_scaler.transform(x_test)\n",
    "    x_test_z = pd.DataFrame(x_test_z, columns=x_train.columns)\n",
    "\n",
    "    return x_train, x_test, x_train_m, x_test_m, x_train_z, x_test_z, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, x_train_m, x_test_m, x_train_z, x_test_z, y_train, y_test = get_trasforms_datas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# 이제 특징 생성에 클러스터링 결과는 보지 않을 예정.\n",
    "def addKmeansFeature(train_data, test_data):\n",
    "    pd.options.mode.chained_assignment = None\n",
    "\n",
    "    for n_clusters in range(2, 7):  # 2부터 6까지 클러스터 생성\n",
    "        kmeans = KMeans(n_clusters=n_clusters, n_init=10)\n",
    "\n",
    "        train_data[f'cluster_{n_clusters}'] = kmeans.fit_predict(train_data[['wind_speed', 'wind_direction']])\n",
    "        \n",
    "        test_data[f'cluster_{n_clusters}'] = kmeans.predict(test_data[['wind_speed', 'wind_direction']])\n",
    "\n",
    "    return train_data, test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def addPCAFeature(train_data, test_data):\n",
    "    # PCA 적용할 특징 열 선택 (u, v 성분)\n",
    "    wind_features = ['storm_u_5m', 'storm_v_5m', 'wind_u_10m', 'wind_v_10m', \n",
    "                     'wind_speed', 'wind_direction']\n",
    "    \n",
    "    # 훈련 데이터에서 PCA 학습\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_train = pca.fit_transform(train_data[wind_features])\n",
    "    \n",
    "    # 훈련 데이터에 주성분 추가\n",
    "    train_data['PC1'] = pca_train[:, 0]\n",
    "    train_data['PC2'] = pca_train[:, 1]\n",
    "    \n",
    "    # 테스트 데이터에 PCA 적용\n",
    "    pca_test = pca.transform(test_data[wind_features])\n",
    "    test_data['PC1'] = pca_test[:, 0]\n",
    "    test_data['PC2'] = pca_test[:, 1]\n",
    "\n",
    "    # PCA 설명력 확인\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "    print(f\"PC1 설명력: {explained_variance[0]}\")\n",
    "    print(f\"PC2 설명력: {explained_variance[1]}\")\n",
    "\n",
    "    return train_data, test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_extra.cluster import KMedoids\n",
    "\n",
    "def addKMedoidsFeature(train_data, test_data):\n",
    "    pd.options.mode.chained_assignment = None\n",
    "\n",
    "    for n_clusters in range(2, 7):  # 2부터 6까지 클러스터 생성\n",
    "        kmedoids = KMedoids(n_clusters=n_clusters, random_state=42)\n",
    "\n",
    "        # 훈련 데이터에 K-Medoids 클러스터링 적용\n",
    "        train_data[f'medoid_cluster_{n_clusters}'] = kmedoids.fit_predict(train_data[['wind_speed', 'wind_direction']])\n",
    "\n",
    "        # 테스트 데이터에 학습된 K-Medoids 모델 적용\n",
    "        test_data[f'medoid_cluster_{n_clusters}'] = kmedoids.predict(test_data[['wind_speed', 'wind_direction']])\n",
    "\n",
    "    return train_data, test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.drop(columns=['cluster'], inplace=True, errors='ignore')\n",
    "x_test.drop(columns=['cluster'], inplace=True, errors='ignore')\n",
    "x_train_m.drop(columns=['cluster'], inplace=True, errors='ignore')\n",
    "x_test_m.drop(columns=['cluster'], inplace=True, errors='ignore')\n",
    "x_train_z.drop(columns=['cluster'], inplace=True, errors='ignore')\n",
    "x_test_z.drop(columns=['cluster'], inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = addKmeansFeature(x_train, x_test)\n",
    "x_train_m, x_test_m = addKmeansFeature(x_train_m, x_test_m)\n",
    "x_train_z, x_test_z = addKmeansFeature(x_train_z, x_test_z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PC1 설명력: 0.9982893179797387\n",
      "PC2 설명력: 0.000787891560487553\n",
      "PC1 설명력: 0.769956023089617\n",
      "PC2 설명력: 0.1072706241482032\n",
      "PC1 설명력: 0.331150624315771\n",
      "PC2 설명력: 0.3263920177870679\n"
     ]
    }
   ],
   "source": [
    "# 각 데이터프레임에 addPCAFeature 적용\n",
    "x_train, x_test = addPCAFeature(x_train, x_test)\n",
    "x_train_m, x_test_m = addPCAFeature(x_train_m, x_test_m)\n",
    "x_train_z, x_test_z = addPCAFeature(x_train_z, x_test_z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 4.59 GiB for an array with shape (24816, 24816) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 각 데이터프레임에 addKMedoidsFeature 적용\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m x_train, x_test \u001b[38;5;241m=\u001b[39m addKMedoidsFeature(x_train, x_test)\n\u001b[0;32m      3\u001b[0m x_train_m, x_test_m \u001b[38;5;241m=\u001b[39m addKMedoidsFeature(x_train_m, x_test_m)\n\u001b[0;32m      4\u001b[0m x_train_z, x_test_z \u001b[38;5;241m=\u001b[39m addKMedoidsFeature(x_train_z, x_test_z)\n",
      "Cell \u001b[1;32mIn[76], line 10\u001b[0m, in \u001b[0;36maddKMedoidsFeature\u001b[1;34m(train_data, test_data)\u001b[0m\n\u001b[0;32m      7\u001b[0m kmedoids \u001b[38;5;241m=\u001b[39m KMedoids(n_clusters\u001b[38;5;241m=\u001b[39mn_clusters, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# 훈련 데이터에 K-Medoids 클러스터링 적용\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m train_data[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedoid_cluster_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_clusters\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m kmedoids\u001b[38;5;241m.\u001b[39mfit_predict(train_data[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwind_speed\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwind_direction\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# 테스트 데이터에 학습된 K-Medoids 모델 적용\u001b[39;00m\n\u001b[0;32m     13\u001b[0m test_data[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedoid_cluster_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_clusters\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m kmedoids\u001b[38;5;241m.\u001b[39mpredict(test_data[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwind_speed\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwind_direction\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:900\u001b[0m, in \u001b[0;36mClusterMixin.fit_predict\u001b[1;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;124;03mPerform clustering on `X` and returns cluster labels.\u001b[39;00m\n\u001b[0;32m    879\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    896\u001b[0m \u001b[38;5;124;03m    Cluster labels.\u001b[39;00m\n\u001b[0;32m    897\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    899\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m--> 900\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn_extra\\cluster\\_k_medoids.py:239\u001b[0m, in \u001b[0;36mKMedoids.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_clusters \u001b[38;5;241m>\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    234\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of medoids (\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m) must be less \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthan the number of samples \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    236\u001b[0m         \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_clusters, X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    237\u001b[0m     )\n\u001b[1;32m--> 239\u001b[0m D \u001b[38;5;241m=\u001b[39m pairwise_distances(X, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric)\n\u001b[0;32m    241\u001b[0m medoid_idxs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_medoids(\n\u001b[0;32m    242\u001b[0m     D, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_clusters, random_state_, X\n\u001b[0;32m    243\u001b[0m )\n\u001b[0;32m    244\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2331\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   2328\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m distance\u001b[38;5;241m.\u001b[39msquareform(distance\u001b[38;5;241m.\u001b[39mpdist(X, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[0;32m   2329\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(distance\u001b[38;5;241m.\u001b[39mcdist, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m-> 2331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _parallel_pairwise(X, Y, func, n_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:1871\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1868\u001b[0m X, Y, dtype \u001b[38;5;241m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 1871\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(X, Y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m   1873\u001b[0m \u001b[38;5;66;03m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[0;32m   1874\u001b[0m fd \u001b[38;5;241m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:347\u001b[0m, in \u001b[0;36meuclidean_distances\u001b[1;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m Y_norm_squared\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;241m1\u001b[39m, Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m    342\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    343\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncompatible dimensions for Y of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mY\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    344\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY_norm_squared of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moriginal_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    345\u001b[0m         )\n\u001b[1;32m--> 347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _euclidean_distances(X, Y, X_norm_squared, Y_norm_squared, squared)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:379\u001b[0m, in \u001b[0;36m_euclidean_distances\u001b[1;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[0m\n\u001b[0;32m    374\u001b[0m         YY \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32 \u001b[38;5;129;01mor\u001b[39;00m Y\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32:\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;66;03m# To minimize precision issues with float32, we compute the distance\u001b[39;00m\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;66;03m# matrix on chunks of X and Y upcast to float64\u001b[39;00m\n\u001b[1;32m--> 379\u001b[0m     distances \u001b[38;5;241m=\u001b[39m _euclidean_distances_upcast(X, XX, Y, YY)\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;66;03m# if dtype is already float64, no need to chunk and upcast\u001b[39;00m\n\u001b[0;32m    382\u001b[0m     distances \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m safe_sparse_dot(X, Y\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:591\u001b[0m, in \u001b[0;36m_euclidean_distances_upcast\u001b[1;34m(X, XX, Y, YY, batch_size)\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    589\u001b[0m     YY_chunk \u001b[38;5;241m=\u001b[39m YY[:, y_slice]\n\u001b[1;32m--> 591\u001b[0m d \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m safe_sparse_dot(X_chunk, Y_chunk\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    592\u001b[0m d \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m XX_chunk\n\u001b[0;32m    593\u001b[0m d \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m YY_chunk\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:208\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    206\u001b[0m         ret \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(a, b)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 208\u001b[0m     ret \u001b[38;5;241m=\u001b[39m a \u001b[38;5;241m@\u001b[39m b\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    211\u001b[0m     sparse\u001b[38;5;241m.\u001b[39missparse(a)\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(b)\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    215\u001b[0m ):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 4.59 GiB for an array with shape (24816, 24816) and data type float64"
     ]
    }
   ],
   "source": [
    "# 각 데이터프레임에 addKMedoidsFeature 적용\n",
    "x_train, x_test = addKMedoidsFeature(x_train, x_test)\n",
    "x_train_m, x_test_m = addKMedoidsFeature(x_train_m, x_test_m)\n",
    "x_train_z, x_test_z = addKMedoidsFeature(x_train_z, x_test_z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m',\n",
       "       'frictional_vmin_50m', 'pressure', 'relative_humid', 'specific_humid',\n",
       "       'temp_air', 'storm_u_5m', 'storm_v_5m', 'wind_u_10m', 'wind_v_10m',\n",
       "       'wind_speed', 'wind_direction', 'wind_speed_100m',\n",
       "       'AvailabilityForcedOutageTime_Min_',\n",
       "       'AvailabilityFullPerformanceTime_Min_',\n",
       "       'AvailabilityRequestedShutdownTime_Min_',\n",
       "       'AvailabilityScheduledMaintenanceTime_Min_',\n",
       "       'AvailabilityTechnicalStandbyTime_Min_', 'GeneratorAverageWindingTemp_',\n",
       "       'GridActivePower_kW_', 'GridReactivePower_kVAr_',\n",
       "       'HydraulicSystemPressure_bar_', 'NacelleAirDensity_kg_',\n",
       "       'NacelleNacellePosition_deg_', 'NacelleOutdoorTemp_',\n",
       "       'NacelleWindDirection_deg_', 'NacelleWindSpeed_m_s_',\n",
       "       'RotorBlade1Pos_deg_', 'RotorBlade2Pos_deg_', 'RotorBlade3Pos_deg_',\n",
       "       'RotorMotor1Pos_deg_', 'RotorMotor2Pos_deg_', 'RotorMotor3Pos_deg_',\n",
       "       'RotorPitch1Angle_deg_', 'RotorPitch2Angle_deg_',\n",
       "       'RotorPitch3Angle_deg_', 'RotorRotorSpeed_rpm_',\n",
       "       'YawYawcablewindup_deg_', 'Day_Night', 'cluster_2', 'cluster_3',\n",
       "       'cluster_4', 'cluster_5', 'cluster_6', 'PC1', 'PC2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dict = {\n",
    "    # 원본 데이터만 사용\n",
    "    'original': ['elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m', 'frictional_vmin_50m', \n",
    "                 'pressure', 'relative_humid', 'specific_humid', 'temp_air', 'storm_u_5m', 'storm_v_5m', \n",
    "                 'wind_u_10m', 'wind_v_10m', 'wind_speed', 'wind_direction', 'wind_speed_100m'],\n",
    "\n",
    "    # PCA 추가\n",
    "    'pca_only': ['elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m', 'frictional_vmin_50m', \n",
    "                 'pressure', 'relative_humid', 'specific_humid', 'temp_air', 'storm_u_5m', 'storm_v_5m', \n",
    "                 'wind_u_10m', 'wind_v_10m', 'wind_speed', 'wind_direction', 'wind_speed_100m', 'PC1', 'PC2'],\n",
    "\n",
    "    # 클러스터(2~6) 추가\n",
    "    'cluster_only': ['elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m', 'frictional_vmin_50m', \n",
    "                     'pressure', 'relative_humid', 'specific_humid', 'temp_air', 'storm_u_5m', 'storm_v_5m', \n",
    "                     'wind_u_10m', 'wind_v_10m', 'wind_speed', 'wind_direction', 'wind_speed_100m', \n",
    "                     'cluster_2', 'cluster_3', 'cluster_4', 'cluster_5', 'cluster_6'],\n",
    "\n",
    "    # PCA + 클러스터(2~6) 추가\n",
    "    'pca_and_cluster': ['elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m', 'frictional_vmin_50m', \n",
    "                        'pressure', 'relative_humid', 'specific_humid', 'temp_air', 'storm_u_5m', 'storm_v_5m', \n",
    "                        'wind_u_10m', 'wind_v_10m', 'wind_speed', 'wind_direction', 'wind_speed_100m', \n",
    "                        'PC1', 'PC2', 'cluster_2', 'cluster_3', 'cluster_4', 'cluster_5', 'cluster_6'],\n",
    "\n",
    "    # 클러스터 개수에 따른 경우\n",
    "    'cluster_2_only': ['elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m', 'frictional_vmin_50m', \n",
    "                       'pressure', 'relative_humid', 'specific_humid', 'temp_air', 'storm_u_5m', 'storm_v_5m', \n",
    "                       'wind_u_10m', 'wind_v_10m', 'wind_speed', 'wind_direction', 'wind_speed_100m', 'cluster_2'],\n",
    "    \n",
    "    'cluster_3_only': ['elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m', 'frictional_vmin_50m', \n",
    "                       'pressure', 'relative_humid', 'specific_humid', 'temp_air', 'storm_u_5m', 'storm_v_5m', \n",
    "                       'wind_u_10m', 'wind_v_10m', 'wind_speed', 'wind_direction', 'wind_speed_100m', 'cluster_3'],\n",
    "    \n",
    "    'cluster_4_only': ['elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m', 'frictional_vmin_50m', \n",
    "                       'pressure', 'relative_humid', 'specific_humid', 'temp_air', 'storm_u_5m', 'storm_v_5m', \n",
    "                       'wind_u_10m', 'wind_v_10m', 'wind_speed', 'wind_direction', 'wind_speed_100m', 'cluster_4'],\n",
    "    \n",
    "    'cluster_5_only': ['elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m', 'frictional_vmin_50m', \n",
    "                       'pressure', 'relative_humid', 'specific_humid', 'temp_air', 'storm_u_5m', 'storm_v_5m', \n",
    "                       'wind_u_10m', 'wind_v_10m', 'wind_speed', 'wind_direction', 'wind_speed_100m', 'cluster_5'],\n",
    "    \n",
    "    'cluster_6_only': ['elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m', 'frictional_vmin_50m', \n",
    "                       'pressure', 'relative_humid', 'specific_humid', 'temp_air', 'storm_u_5m', 'storm_v_5m', \n",
    "                       'wind_u_10m', 'wind_v_10m', 'wind_speed', 'wind_direction', 'wind_speed_100m', 'cluster_6']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 아래는 학습관렵 함수 및 Plot 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor,XGBRFRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼 파라미터 그리드\n",
    "param_grids = {\n",
    "    'GradientBoostingRegressor': {'n_estimators': [1, 100], 'learning_rate': [0.01, 0.1]},\n",
    "    'SVR': {'C': [0.1, 1], 'kernel': ['linear']},\n",
    "    'RandomForestRegressor': {'n_estimators': [1, 200], 'max_depth': [10, 20, None]},\n",
    "    'LinearRegression': {},  # LinearRegression은 기본 파라미터로 사용\n",
    "    'ExtraTreesRegressor': {'n_estimators': [11, 200], 'max_depth': [10, 20, None]},\n",
    "    'AdaBoostRegressor': {'n_estimators': [1, 100], 'learning_rate': [0.01, 0.1]},\n",
    "    'DecisionTreeRegressor': {'max_depth': [10, 20, None]},\n",
    "    'XGBRegressor': {'n_estimators': [1, 100], 'learning_rate': [0.01, 0.1]},\n",
    "    'XGBRFRegressor': {'n_estimators': [1, 100], 'learning_rate': [0.01, 0.1]},\n",
    "    'LGBMRegressor' : {'n_estimators': [1, 100], 'learning_rate': [0.01, 0.1]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(model, x_col,x_shape, model_name, save_dir):\n",
    "    save_dir = os.path.join(ipynb_path, save_dir)\n",
    "    \n",
    "    try:\n",
    "        importances = model.feature_importances_\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.title(f\"Feature Importance : {model_name}\")\n",
    "        plt.bar(range(x_shape[1]), importances[indices], align='center')\n",
    "        plt.xticks(range(x_shape[1]), x_col[indices], rotation=90)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(save_dir, f\"{model_name}_feature_importance.png\"))\n",
    "        plt.close()\n",
    "    except AttributeError:\n",
    "        if hasattr(model, 'coef_'):\n",
    "            importances = np.abs(model.coef_)\n",
    "            indices = np.argsort(importances)[::-1]\n",
    "\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.title(f\"Coefficient : {model_name}\")\n",
    "            plt.bar(range(x_shape[1]), importances[indices], align='center')\n",
    "            plt.xticks(range(x_shape[1]), x_col[indices], rotation=90)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(save_dir, f\"{model_name}_coefficient.png\"))\n",
    "            plt.close()\n",
    "        else:\n",
    "            print(f\"{model_name} has no feature importances or coefficients.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predict_actual(pred, actual ,model_name, save_dir):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(f\"Feature Importance : {model_name}\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.plot(list(pred), label='pred')\n",
    "    plt.plot(list(actual), label='Actual')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, f\"{model_name}_predict.png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import joblib\n",
    "\n",
    "def train(save_dir, x_train, y_train, x_test, y_test):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    log_file = open(os.path.join(save_dir, \"model_training_log.txt\"), \"w\")\n",
    "\n",
    "    models = [\n",
    "        GradientBoostingRegressor(),\n",
    "        # SVR(),\n",
    "        RandomForestRegressor(),\n",
    "        LinearRegression(),\n",
    "        ExtraTreesRegressor(),\n",
    "        AdaBoostRegressor(),\n",
    "        DecisionTreeRegressor(),\n",
    "        XGBRegressor(),\n",
    "        XGBRFRegressor(),\n",
    "        LGBMRegressor(verbose=-1),\n",
    "    ]\n",
    "\n",
    "    results = {\n",
    "        'Model_Name': [],\n",
    "        'R2_score': [],\n",
    "        'RMSE': [],\n",
    "        'NMAE': [],\n",
    "        'Best_Params': [],\n",
    "        'Predict' : []\n",
    "    }\n",
    "\n",
    "    for model in models:\n",
    "        model_name_current = model.__class__.__name__\n",
    "\n",
    "        param_grid = param_grids.get(model_name_current, {})\n",
    "\n",
    "        search = search = RandomizedSearchCV(model, param_distributions=param_grid, cv=3, n_jobs=-1, n_iter=5)\n",
    "        log_file.write(f\"Searching best hyperparameters for {model_name_current}\\n\")\n",
    "        search.fit(x_train, y_train)\n",
    "        best_model = search.best_estimator_\n",
    "        best_params = search.best_params_\n",
    "\n",
    "        log_file.write(f\"Training {model_name_current}\\n\")\n",
    "\n",
    "        y_pred = best_model.predict(x_test)\n",
    "\n",
    "        r2 = r2_score(y_test, y_pred) * 100\n",
    "        rmse_value = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        nmae_value = mae / y_test.mean()\n",
    "\n",
    "        results['Model_Name'].append(model_name_current)\n",
    "        results['R2_score'].append(r2)\n",
    "        results['RMSE'].append(rmse_value)\n",
    "        results['NMAE'].append(nmae_value)\n",
    "        results['Best_Params'].append(best_params)\n",
    "        results['Predict'].append(y_pred)\n",
    "\n",
    "        joblib.dump(search, os.path.join(save_dir, f'{model_name_current}.pkl'))\n",
    "        \n",
    "        plot_predict_actual(y_pred, y_test, model_name_current, save_dir)\n",
    "\n",
    "        log_file.write(f\"R2 Score: {r2:.2f}\\n\")\n",
    "        log_file.write(f\"RMSE: {rmse_value:.2f}\\n\")\n",
    "        log_file.write(f\"NMAE: {nmae_value:.4f}\\n\")\n",
    "        log_file.write(f\"Best Hyperparameters: {best_params}\\n\\n\")\n",
    "\n",
    "        \n",
    "        # def plot_feature_importance(model, x_col,x_shape, model_name, save_dir):\n",
    "\n",
    "        plot_feature_importance(best_model, x_train.columns, x_train.shape, model_name_current,save_dir)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    results_df.to_csv(os.path.join(save_dir, \"model_scores.csv\"), index=False)\n",
    "\n",
    "    log_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:318: UserWarning: The total space of parameters 4 is smaller than n_iter=5. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:318: UserWarning: The total space of parameters 1 is smaller than n_iter=5. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:318: UserWarning: The total space of parameters 4 is smaller than n_iter=5. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:318: UserWarning: The total space of parameters 3 is smaller than n_iter=5. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:318: UserWarning: The total space of parameters 4 is smaller than n_iter=5. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:318: UserWarning: The total space of parameters 4 is smaller than n_iter=5. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:318: UserWarning: The total space of parameters 4 is smaller than n_iter=5. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:318: UserWarning: The total space of parameters 4 is smaller than n_iter=5. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:318: UserWarning: The total space of parameters 1 is smaller than n_iter=5. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:318: UserWarning: The total space of parameters 4 is smaller than n_iter=5. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:318: UserWarning: The total space of parameters 3 is smaller than n_iter=5. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:318: UserWarning: The total space of parameters 4 is smaller than n_iter=5. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:318: UserWarning: The total space of parameters 4 is smaller than n_iter=5. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:318: UserWarning: The total space of parameters 4 is smaller than n_iter=5. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:318: UserWarning: The total space of parameters 4 is smaller than n_iter=5. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 29\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# ====================\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# z-정규화\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# ====================\u001b[39;00m\n\u001b[0;32m     27\u001b[0m save_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(ipynb_path, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest10_09-11/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_General_z_testBaseline/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 29\u001b[0m train(save_dir, x_train_z_selected, y_train, x_test_z_selected, y_test)\n",
      "Cell \u001b[1;32mIn[85], line 38\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(save_dir, x_train, y_train, x_test, y_test)\u001b[0m\n\u001b[0;32m     36\u001b[0m search \u001b[38;5;241m=\u001b[39m search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(model, param_distributions\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     37\u001b[0m log_file\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSearching best hyperparameters for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name_current\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 38\u001b[0m search\u001b[38;5;241m.\u001b[39mfit(x_train, y_train)\n\u001b[0;32m     39\u001b[0m best_model \u001b[38;5;241m=\u001b[39m search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m     40\u001b[0m best_params \u001b[38;5;241m=\u001b[39m search\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1914\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1913\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1914\u001b[0m     evaluate_candidates(\n\u001b[0;32m   1915\u001b[0m         ParameterSampler(\n\u001b[0;32m   1916\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_distributions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state\n\u001b[0;32m   1917\u001b[0m         )\n\u001b[0;32m   1918\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[1;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    917\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    918\u001b[0m         clone(base_estimator),\n\u001b[0;32m    919\u001b[0m         X,\n\u001b[0;32m    920\u001b[0m         y,\n\u001b[0;32m    921\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    922\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    923\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    924\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    925\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    926\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    927\u001b[0m     )\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    929\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[0;32m    930\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[0;32m    931\u001b[0m     )\n\u001b[0;32m    932\u001b[0m )\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for key in x_dict.keys():\n",
    "    # 필요한 컬럼만 선택해서 데이터셋 생성\n",
    "    x_train_selected = x_train[x_dict[key]]\n",
    "    x_test_selected = x_test[x_dict[key]]\n",
    "    x_train_m_selected = x_train_m[x_dict[key]]\n",
    "    x_test_m_selected = x_test_m[x_dict[key]]\n",
    "    x_train_z_selected = x_train_z[x_dict[key]]\n",
    "    x_test_z_selected = x_test_z[x_dict[key]]\n",
    "\n",
    "    # ====================\n",
    "    # 정규화 없는 데이터\n",
    "    # ====================\n",
    "    save_dir = os.path.join(ipynb_path, f'test10/{key}_General_testBaseline/')\n",
    "    \n",
    "    train(save_dir, x_train_selected, y_train, x_test_selected, y_test)\n",
    "\n",
    "    # ====================\n",
    "    # Min-Max 정규화\n",
    "    # ====================\n",
    "    save_dir = os.path.join(ipynb_path, f'test10/{key}_General_m_testBaseline/')\n",
    "    \n",
    "    train(save_dir, x_train_m_selected, y_train, x_test_m_selected, y_test)\n",
    "\n",
    "    # ====================\n",
    "    # z-정규화\n",
    "    # ====================\n",
    "    save_dir = os.path.join(ipynb_path, f'test10/{key}_General_z_testBaseline/')\n",
    "    \n",
    "    train(save_dir, x_train_z_selected, y_train, x_test_z_selected, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
